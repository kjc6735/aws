{"version":3,"file":"static/js/main.13ffde9a.js","mappings":";oDAYa,IAAIA,EAAGC,EAAQ,KAASC,EAAGD,EAAQ,KAAa,SAASE,EAAEC,GAAG,IAAI,IAAIC,EAAE,yDAAyDD,EAAEE,EAAE,EAAEA,EAAEC,UAAUC,OAAOF,IAAID,GAAG,WAAWI,mBAAmBF,UAAUD,IAAI,MAAM,yBAAyBF,EAAE,WAAWC,EAAE,iHAAiH,IAAIK,EAAG,IAAIC,IAAIC,EAAG,GAAG,SAASC,EAAGT,EAAEC,GAAGS,EAAGV,EAAEC,GAAGS,EAAGV,EAAE,UAAUC,GACtb,SAASS,EAAGV,EAAEC,GAAW,IAARO,EAAGR,GAAGC,EAAMD,EAAE,EAAEA,EAAEC,EAAEG,OAAOJ,IAAIM,EAAGK,IAAIV,EAAED,IACzD,IAAIY,IAAK,qBAAqBC,QAAQ,qBAAqBA,OAAOC,UAAU,qBAAqBD,OAAOC,SAASC,eAAeC,EAAGC,OAAOC,UAAUC,eAAeC,EAAG,8VAA8VC,EACpgB,GAAGC,EAAG,GACkN,SAASC,EAAEvB,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,GAAGC,KAAKC,gBAAgB,IAAI5B,GAAG,IAAIA,GAAG,IAAIA,EAAE2B,KAAKE,cAAcN,EAAEI,KAAKG,mBAAmBN,EAAEG,KAAKI,gBAAgB9B,EAAE0B,KAAKK,aAAajC,EAAE4B,KAAKM,KAAKjC,EAAE2B,KAAKO,YAAYT,EAAEE,KAAKQ,kBAAkBT,EAAE,IAAIU,EAAE,GACnb,uIAAuIC,MAAM,KAAKC,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAE,MAAK,GAAG,MAAM,CAAC,CAAC,gBAAgB,kBAAkB,CAAC,YAAY,SAAS,CAAC,UAAU,OAAO,CAAC,YAAY,eAAeuC,SAAQ,SAASvC,GAAG,IAAIC,EAAED,EAAE,GAAGqC,EAAEpC,GAAG,IAAIsB,EAAEtB,EAAE,GAAE,EAAGD,EAAE,GAAG,MAAK,GAAG,MAAM,CAAC,kBAAkB,YAAY,aAAa,SAASuC,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAEwC,cAAc,MAAK,GAAG,MACve,CAAC,cAAc,4BAA4B,YAAY,iBAAiBD,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAE,MAAK,GAAG,MAAM,8OAA8OsC,MAAM,KAAKC,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAEwC,cAAc,MAAK,GAAG,MACrb,CAAC,UAAU,WAAW,QAAQ,YAAYD,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAE,MAAK,GAAG,MAAM,CAAC,UAAU,YAAYuC,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAE,MAAK,GAAG,MAAM,CAAC,OAAO,OAAO,OAAO,QAAQuC,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAE,MAAK,GAAG,MAAM,CAAC,UAAU,SAASuC,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAEwC,cAAc,MAAK,GAAG,MAAM,IAAIC,EAAG,gBAAgB,SAASC,EAAG1C,GAAG,OAAOA,EAAE,GAAG2C,cAI3Y,SAASC,EAAG5C,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAEY,EAAElB,eAAelB,GAAGoC,EAAEpC,GAAG,MAAQ,OAAOwB,EAAE,IAAIA,EAAES,KAAKV,KAAK,EAAEvB,EAAEG,SAAS,MAAMH,EAAE,IAAI,MAAMA,EAAE,IAAI,MAAMA,EAAE,IAAI,MAAMA,EAAE,MAP9I,SAAYD,EAAEC,EAAEC,EAAEsB,GAAG,GAAG,OAAOvB,GAAG,qBAAqBA,GADqE,SAAYD,EAAEC,EAAEC,EAAEsB,GAAG,GAAG,OAAOtB,GAAG,IAAIA,EAAEgC,KAAK,OAAM,EAAG,cAAcjC,GAAG,IAAK,WAAW,IAAK,SAAS,OAAM,EAAG,IAAK,UAAU,OAAGuB,IAAc,OAAOtB,GAASA,EAAE2B,gBAAmD,WAAnC7B,EAAEA,EAAEwC,cAAcK,MAAM,EAAE,KAAsB,UAAU7C,GAAE,QAAQ,OAAM,GAC5T8C,CAAG9C,EAAEC,EAAEC,EAAEsB,GAAG,OAAM,EAAG,GAAGA,EAAE,OAAM,EAAG,GAAG,OAAOtB,EAAE,OAAOA,EAAEgC,MAAM,KAAK,EAAE,OAAOjC,EAAE,KAAK,EAAE,OAAM,IAAKA,EAAE,KAAK,EAAE,OAAO8C,MAAM9C,GAAG,KAAK,EAAE,OAAO8C,MAAM9C,IAAI,EAAEA,EAAE,OAAM,EAOpE+C,CAAG/C,EAAEC,EAAEuB,EAAED,KAAKtB,EAAE,MAAMsB,GAAG,OAAOC,EARxK,SAAYzB,GAAG,QAAGgB,EAAGiC,KAAK3B,EAAGtB,KAAegB,EAAGiC,KAAK5B,EAAGrB,KAAeoB,EAAG8B,KAAKlD,GAAUsB,EAAGtB,IAAG,GAAGqB,EAAGrB,IAAG,GAAS,IAQ0DmD,CAAGlD,KAAK,OAAOC,EAAEF,EAAEoD,gBAAgBnD,GAAGD,EAAEqD,aAAapD,EAAE,GAAGC,IAAIuB,EAAEO,gBAAgBhC,EAAEyB,EAAEQ,cAAc,OAAO/B,EAAE,IAAIuB,EAAES,MAAQ,GAAGhC,GAAGD,EAAEwB,EAAEK,cAAcN,EAAEC,EAAEM,mBAAmB,OAAO7B,EAAEF,EAAEoD,gBAAgBnD,IAAaC,EAAE,KAAXuB,EAAEA,EAAES,OAAc,IAAIT,IAAG,IAAKvB,EAAE,GAAG,GAAGA,EAAEsB,EAAExB,EAAEsD,eAAe9B,EAAEvB,EAAEC,GAAGF,EAAEqD,aAAapD,EAAEC,MAH7c,0jCAA0jCoC,MAAM,KAAKC,SAAQ,SAASvC,GAAG,IAAIC,EAAED,EAAEuD,QAAQd,EACzmCC,GAAIL,EAAEpC,GAAG,IAAIsB,EAAEtB,EAAE,GAAE,EAAGD,EAAE,MAAK,GAAG,MAAM,2EAA2EsC,MAAM,KAAKC,SAAQ,SAASvC,GAAG,IAAIC,EAAED,EAAEuD,QAAQd,EAAGC,GAAIL,EAAEpC,GAAG,IAAIsB,EAAEtB,EAAE,GAAE,EAAGD,EAAE,gCAA+B,GAAG,MAAM,CAAC,WAAW,WAAW,aAAauC,SAAQ,SAASvC,GAAG,IAAIC,EAAED,EAAEuD,QAAQd,EAAGC,GAAIL,EAAEpC,GAAG,IAAIsB,EAAEtB,EAAE,GAAE,EAAGD,EAAE,wCAAuC,GAAG,MAAM,CAAC,WAAW,eAAeuC,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAEwC,cAAc,MAAK,GAAG,MAC/cH,EAAEmB,UAAU,IAAIjC,EAAE,YAAY,GAAE,EAAG,aAAa,gCAA+B,GAAG,GAAI,CAAC,MAAM,OAAO,SAAS,cAAcgB,SAAQ,SAASvC,GAAGqC,EAAErC,GAAG,IAAIuB,EAAEvB,EAAE,GAAE,EAAGA,EAAEwC,cAAc,MAAK,GAAG,MAEzL,IAAIiB,EAAG7D,EAAG8D,mDAAmDC,EAAGC,OAAOC,IAAI,iBAAiBC,EAAGF,OAAOC,IAAI,gBAAgBE,EAAGH,OAAOC,IAAI,kBAAkBG,EAAGJ,OAAOC,IAAI,qBAAqBI,EAAGL,OAAOC,IAAI,kBAAkBK,EAAGN,OAAOC,IAAI,kBAAkBM,EAAGP,OAAOC,IAAI,iBAAiBO,EAAGR,OAAOC,IAAI,qBAAqBQ,EAAGT,OAAOC,IAAI,kBAAkBS,EAAGV,OAAOC,IAAI,uBAAuBU,EAAGX,OAAOC,IAAI,cAAcW,EAAGZ,OAAOC,IAAI,cAAcD,OAAOC,IAAI,eAAeD,OAAOC,IAAI,0BACje,IAAIY,EAAGb,OAAOC,IAAI,mBAAmBD,OAAOC,IAAI,uBAAuBD,OAAOC,IAAI,eAAeD,OAAOC,IAAI,wBAAwB,IAAIa,EAAGd,OAAOe,SAAS,SAASC,EAAG5E,GAAG,OAAG,OAAOA,GAAG,kBAAkBA,EAAS,KAAwC,oBAAnCA,EAAE0E,GAAI1E,EAAE0E,IAAK1E,EAAE,eAA0CA,EAAE,KAAK,IAAoB6E,EAAhBC,EAAE7D,OAAO8D,OAAU,SAASC,EAAGhF,GAAG,QAAG,IAAS6E,EAAG,IAAI,MAAMI,QAAS,MAAM/E,GAAG,IAAID,EAAEC,EAAEgF,MAAMC,OAAOC,MAAM,gBAAgBP,EAAG5E,GAAGA,EAAE,IAAI,GAAG,MAAM,KAAK4E,EAAG7E,EAAE,IAAIqF,GAAG,EACzb,SAASC,EAAGtF,EAAEC,GAAG,IAAID,GAAGqF,EAAG,MAAM,GAAGA,GAAG,EAAG,IAAInF,EAAE+E,MAAMM,kBAAkBN,MAAMM,uBAAkB,EAAO,IAAI,GAAGtF,EAAE,GAAGA,EAAE,WAAW,MAAMgF,SAAUhE,OAAOuE,eAAevF,EAAEiB,UAAU,QAAQ,CAACuE,IAAI,WAAW,MAAMR,WAAY,kBAAkBS,SAASA,QAAQC,UAAU,CAAC,IAAID,QAAQC,UAAU1F,EAAE,IAAI,MAAM2F,GAAG,IAAIpE,EAAEoE,EAAEF,QAAQC,UAAU3F,EAAE,GAAGC,OAAO,CAAC,IAAIA,EAAEgD,OAAO,MAAM2C,GAAGpE,EAAEoE,EAAE5F,EAAEiD,KAAKhD,EAAEiB,eAAe,CAAC,IAAI,MAAM+D,QAAS,MAAMW,GAAGpE,EAAEoE,EAAE5F,KAAK,MAAM4F,GAAG,GAAGA,GAAGpE,GAAG,kBAAkBoE,EAAEV,MAAM,CAAC,IAAI,IAAIzD,EAAEmE,EAAEV,MAAM5C,MAAM,MACnfZ,EAAEF,EAAE0D,MAAM5C,MAAM,MAAMX,EAAEF,EAAErB,OAAO,EAAEyF,EAAEnE,EAAEtB,OAAO,EAAE,GAAGuB,GAAG,GAAGkE,GAAGpE,EAAEE,KAAKD,EAAEmE,IAAIA,IAAI,KAAK,GAAGlE,GAAG,GAAGkE,EAAElE,IAAIkE,IAAI,GAAGpE,EAAEE,KAAKD,EAAEmE,GAAG,CAAC,GAAG,IAAIlE,GAAG,IAAIkE,EAAG,GAAG,GAAGlE,IAAQ,IAAJkE,GAASpE,EAAEE,KAAKD,EAAEmE,GAAG,CAAC,IAAIC,EAAE,KAAKrE,EAAEE,GAAG4B,QAAQ,WAAW,QAA6F,OAArFvD,EAAE+F,aAAaD,EAAEE,SAAS,iBAAiBF,EAAEA,EAAEvC,QAAQ,cAAcvD,EAAE+F,cAAqBD,SAAQ,GAAGnE,GAAG,GAAGkE,GAAG,QAD1N,QAC0OR,GAAG,EAAGJ,MAAMM,kBAAkBrF,EAAE,OAAOF,EAAEA,EAAEA,EAAE+F,aAAa/F,EAAEiG,KAAK,IAAIjB,EAAGhF,GAAG,GAC5Z,SAASkG,EAAGlG,GAAG,OAAOA,EAAEmG,KAAK,KAAK,EAAE,OAAOnB,EAAGhF,EAAEkC,MAAM,KAAK,GAAG,OAAO8C,EAAG,QAAQ,KAAK,GAAG,OAAOA,EAAG,YAAY,KAAK,GAAG,OAAOA,EAAG,gBAAgB,KAAK,EAAE,KAAK,EAAE,KAAK,GAAG,OAAOhF,EAAEsF,EAAGtF,EAAEkC,MAAK,GAAM,KAAK,GAAG,OAAOlC,EAAEsF,EAAGtF,EAAEkC,KAAKkE,QAAO,GAAM,KAAK,EAAE,OAAOpG,EAAEsF,EAAGtF,EAAEkC,MAAK,GAAM,QAAQ,MAAM,IACrR,SAASmE,EAAGrG,GAAG,GAAG,MAAMA,EAAE,OAAO,KAAK,GAAG,oBAAoBA,EAAE,OAAOA,EAAE+F,aAAa/F,EAAEiG,MAAM,KAAK,GAAG,kBAAkBjG,EAAE,OAAOA,EAAE,OAAOA,GAAG,KAAK+D,EAAG,MAAM,WAAW,KAAKD,EAAG,MAAM,SAAS,KAAKG,EAAG,MAAM,WAAW,KAAKD,EAAG,MAAM,aAAa,KAAKK,EAAG,MAAM,WAAW,KAAKC,EAAG,MAAM,eAAe,GAAG,kBAAkBtE,EAAE,OAAOA,EAAEsG,UAAU,KAAKnC,EAAG,OAAOnE,EAAE+F,aAAa,WAAW,YAAY,KAAK7B,EAAG,OAAOlE,EAAEuG,SAASR,aAAa,WAAW,YAAY,KAAK3B,EAAG,IAAInE,EAAED,EAAEoG,OAC7Z,OADoapG,EAAEA,EAAE+F,eACnd/F,EAAE,MADieA,EAAEC,EAAE8F,aAClf9F,EAAEgG,MAAM,IAAY,cAAcjG,EAAE,IAAI,cAAqBA,EAAE,KAAKuE,EAAG,OAA6B,QAAtBtE,EAAED,EAAE+F,aAAa,MAAc9F,EAAEoG,EAAGrG,EAAEkC,OAAO,OAAO,KAAKsC,EAAGvE,EAAED,EAAEwG,SAASxG,EAAEA,EAAEyG,MAAM,IAAI,OAAOJ,EAAGrG,EAAEC,IAAI,MAAMC,KAAK,OAAO,KACvM,SAASwG,EAAG1G,GAAG,IAAIC,EAAED,EAAEkC,KAAK,OAAOlC,EAAEmG,KAAK,KAAK,GAAG,MAAM,QAAQ,KAAK,EAAE,OAAOlG,EAAE8F,aAAa,WAAW,YAAY,KAAK,GAAG,OAAO9F,EAAEsG,SAASR,aAAa,WAAW,YAAY,KAAK,GAAG,MAAM,qBAAqB,KAAK,GAAG,OAAkB/F,GAAXA,EAAEC,EAAEmG,QAAWL,aAAa/F,EAAEiG,MAAM,GAAGhG,EAAE8F,cAAc,KAAK/F,EAAE,cAAcA,EAAE,IAAI,cAAc,KAAK,EAAE,MAAM,WAAW,KAAK,EAAE,OAAOC,EAAE,KAAK,EAAE,MAAM,SAAS,KAAK,EAAE,MAAM,OAAO,KAAK,EAAE,MAAM,OAAO,KAAK,GAAG,OAAOoG,EAAGpG,GAAG,KAAK,EAAE,OAAOA,IAAI+D,EAAG,aAAa,OAAO,KAAK,GAAG,MAAM,YACtf,KAAK,GAAG,MAAM,WAAW,KAAK,GAAG,MAAM,QAAQ,KAAK,GAAG,MAAM,WAAW,KAAK,GAAG,MAAM,eAAe,KAAK,GAAG,MAAM,gBAAgB,KAAK,EAAE,KAAK,EAAE,KAAK,GAAG,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG,GAAG,oBAAoB/D,EAAE,OAAOA,EAAE8F,aAAa9F,EAAEgG,MAAM,KAAK,GAAG,kBAAkBhG,EAAE,OAAOA,EAAE,OAAO,KAAK,SAAS0G,EAAG3G,GAAG,cAAcA,GAAG,IAAK,UAAU,IAAK,SAAS,IAAK,SAAS,IAAK,YAAqB,IAAK,SAAS,OAAOA,EAAE,QAAQ,MAAM,IACla,SAAS4G,EAAG5G,GAAG,IAAIC,EAAED,EAAEkC,KAAK,OAAOlC,EAAEA,EAAE6G,WAAW,UAAU7G,EAAEwC,gBAAgB,aAAavC,GAAG,UAAUA,GAEpF,SAAS6G,EAAG9G,GAAGA,EAAE+G,gBAAgB/G,EAAE+G,cADvD,SAAY/G,GAAG,IAAIC,EAAE2G,EAAG5G,GAAG,UAAU,QAAQE,EAAEe,OAAO+F,yBAAyBhH,EAAEiH,YAAY/F,UAAUjB,GAAGuB,EAAE,GAAGxB,EAAEC,GAAG,IAAID,EAAEmB,eAAelB,IAAI,qBAAqBC,GAAG,oBAAoBA,EAAEgH,KAAK,oBAAoBhH,EAAEuF,IAAI,CAAC,IAAIhE,EAAEvB,EAAEgH,IAAIxF,EAAExB,EAAEuF,IAAiL,OAA7KxE,OAAOuE,eAAexF,EAAEC,EAAE,CAACkH,cAAa,EAAGD,IAAI,WAAW,OAAOzF,EAAEwB,KAAKrB,OAAO6D,IAAI,SAASzF,GAAGwB,EAAE,GAAGxB,EAAE0B,EAAEuB,KAAKrB,KAAK5B,MAAMiB,OAAOuE,eAAexF,EAAEC,EAAE,CAACmH,WAAWlH,EAAEkH,aAAmB,CAACC,SAAS,WAAW,OAAO7F,GAAG8F,SAAS,SAAStH,GAAGwB,EAAE,GAAGxB,GAAGuH,aAAa,WAAWvH,EAAE+G,cACxf,YAAY/G,EAAEC,MAAuDuH,CAAGxH,IAAI,SAASyH,EAAGzH,GAAG,IAAIA,EAAE,OAAM,EAAG,IAAIC,EAAED,EAAE+G,cAAc,IAAI9G,EAAE,OAAM,EAAG,IAAIC,EAAED,EAAEoH,WAAe7F,EAAE,GAAqD,OAAlDxB,IAAIwB,EAAEoF,EAAG5G,GAAGA,EAAE0H,QAAQ,OAAO,QAAQ1H,EAAE2H,QAAO3H,EAAEwB,KAAatB,IAAGD,EAAEqH,SAAStH,IAAG,GAAO,SAAS4H,EAAG5H,GAAwD,GAAG,qBAAxDA,EAAEA,IAAI,qBAAqBc,SAASA,cAAS,IAAkC,OAAO,KAAK,IAAI,OAAOd,EAAE6H,eAAe7H,EAAE8H,KAAK,MAAM7H,GAAG,OAAOD,EAAE8H,MAC/Z,SAASC,EAAG/H,EAAEC,GAAG,IAAIC,EAAED,EAAEyH,QAAQ,OAAO5C,EAAE,GAAG7E,EAAE,CAAC+H,oBAAe,EAAOC,kBAAa,EAAON,WAAM,EAAOD,QAAQ,MAAMxH,EAAEA,EAAEF,EAAEkI,cAAcC,iBAAiB,SAASC,EAAGpI,EAAEC,GAAG,IAAIC,EAAE,MAAMD,EAAEgI,aAAa,GAAGhI,EAAEgI,aAAazG,EAAE,MAAMvB,EAAEyH,QAAQzH,EAAEyH,QAAQzH,EAAE+H,eAAe9H,EAAEyG,EAAG,MAAM1G,EAAE0H,MAAM1H,EAAE0H,MAAMzH,GAAGF,EAAEkI,cAAc,CAACC,eAAe3G,EAAE6G,aAAanI,EAAEoI,WAAW,aAAarI,EAAEiC,MAAM,UAAUjC,EAAEiC,KAAK,MAAMjC,EAAEyH,QAAQ,MAAMzH,EAAE0H,OAAO,SAASY,EAAGvI,EAAEC,GAAe,OAAZA,EAAEA,EAAEyH,UAAiB9E,EAAG5C,EAAE,UAAUC,GAAE,GAC3d,SAASuI,EAAGxI,EAAEC,GAAGsI,EAAGvI,EAAEC,GAAG,IAAIC,EAAEyG,EAAG1G,EAAE0H,OAAOnG,EAAEvB,EAAEiC,KAAK,GAAG,MAAMhC,EAAK,WAAWsB,GAAM,IAAItB,GAAG,KAAKF,EAAE2H,OAAO3H,EAAE2H,OAAOzH,KAAEF,EAAE2H,MAAM,GAAGzH,GAAOF,EAAE2H,QAAQ,GAAGzH,IAAIF,EAAE2H,MAAM,GAAGzH,QAAQ,GAAG,WAAWsB,GAAG,UAAUA,EAA8B,YAA3BxB,EAAEoD,gBAAgB,SAAgBnD,EAAEkB,eAAe,SAASsH,GAAGzI,EAAEC,EAAEiC,KAAKhC,GAAGD,EAAEkB,eAAe,iBAAiBsH,GAAGzI,EAAEC,EAAEiC,KAAKyE,EAAG1G,EAAEgI,eAAe,MAAMhI,EAAEyH,SAAS,MAAMzH,EAAE+H,iBAAiBhI,EAAEgI,iBAAiB/H,EAAE+H,gBACnZ,SAASU,EAAG1I,EAAEC,EAAEC,GAAG,GAAGD,EAAEkB,eAAe,UAAUlB,EAAEkB,eAAe,gBAAgB,CAAC,IAAIK,EAAEvB,EAAEiC,KAAK,KAAK,WAAWV,GAAG,UAAUA,QAAG,IAASvB,EAAE0H,OAAO,OAAO1H,EAAE0H,OAAO,OAAO1H,EAAE,GAAGD,EAAEkI,cAAcG,aAAanI,GAAGD,IAAID,EAAE2H,QAAQ3H,EAAE2H,MAAM1H,GAAGD,EAAEiI,aAAahI,EAAW,MAATC,EAAEF,EAAEiG,QAAcjG,EAAEiG,KAAK,IAAIjG,EAAEgI,iBAAiBhI,EAAEkI,cAAcC,eAAe,KAAKjI,IAAIF,EAAEiG,KAAK/F,GACvV,SAASuI,GAAGzI,EAAEC,EAAEC,GAAM,WAAWD,GAAG2H,EAAG5H,EAAE2I,iBAAiB3I,IAAE,MAAME,EAAEF,EAAEiI,aAAa,GAAGjI,EAAEkI,cAAcG,aAAarI,EAAEiI,eAAe,GAAG/H,IAAIF,EAAEiI,aAAa,GAAG/H,IAAG,IAAI0I,GAAGC,MAAMC,QAC7K,SAASC,GAAG/I,EAAEC,EAAEC,EAAEsB,GAAe,GAAZxB,EAAEA,EAAEgJ,QAAW/I,EAAE,CAACA,EAAE,GAAG,IAAI,IAAIwB,EAAE,EAAEA,EAAEvB,EAAEE,OAAOqB,IAAIxB,EAAE,IAAIC,EAAEuB,KAAI,EAAG,IAAIvB,EAAE,EAAEA,EAAEF,EAAEI,OAAOF,IAAIuB,EAAExB,EAAEkB,eAAe,IAAInB,EAAEE,GAAGyH,OAAO3H,EAAEE,GAAG+I,WAAWxH,IAAIzB,EAAEE,GAAG+I,SAASxH,GAAGA,GAAGD,IAAIxB,EAAEE,GAAGgJ,iBAAgB,OAAQ,CAAmB,IAAlBhJ,EAAE,GAAGyG,EAAGzG,GAAGD,EAAE,KAASwB,EAAE,EAAEA,EAAEzB,EAAEI,OAAOqB,IAAI,CAAC,GAAGzB,EAAEyB,GAAGkG,QAAQzH,EAAiD,OAA9CF,EAAEyB,GAAGwH,UAAS,OAAGzH,IAAIxB,EAAEyB,GAAGyH,iBAAgB,IAAW,OAAOjJ,GAAGD,EAAEyB,GAAG0H,WAAWlJ,EAAED,EAAEyB,IAAI,OAAOxB,IAAIA,EAAEgJ,UAAS,IACpY,SAASG,GAAGpJ,EAAEC,GAAG,GAAG,MAAMA,EAAEoJ,wBAAwB,MAAMpE,MAAMlF,EAAE,KAAK,OAAO+E,EAAE,GAAG7E,EAAE,CAAC0H,WAAM,EAAOM,kBAAa,EAAOqB,SAAS,GAAGtJ,EAAEkI,cAAcG,eAAe,SAASkB,GAAGvJ,EAAEC,GAAG,IAAIC,EAAED,EAAE0H,MAAM,GAAG,MAAMzH,EAAE,CAA+B,GAA9BA,EAAED,EAAEqJ,SAASrJ,EAAEA,EAAEgI,aAAgB,MAAM/H,EAAE,CAAC,GAAG,MAAMD,EAAE,MAAMgF,MAAMlF,EAAE,KAAK,GAAG6I,GAAG1I,GAAG,CAAC,GAAG,EAAEA,EAAEE,OAAO,MAAM6E,MAAMlF,EAAE,KAAKG,EAAEA,EAAE,GAAGD,EAAEC,EAAE,MAAMD,IAAIA,EAAE,IAAIC,EAAED,EAAED,EAAEkI,cAAc,CAACG,aAAa1B,EAAGzG,IAChY,SAASsJ,GAAGxJ,EAAEC,GAAG,IAAIC,EAAEyG,EAAG1G,EAAE0H,OAAOnG,EAAEmF,EAAG1G,EAAEgI,cAAc,MAAM/H,KAAIA,EAAE,GAAGA,KAAMF,EAAE2H,QAAQ3H,EAAE2H,MAAMzH,GAAG,MAAMD,EAAEgI,cAAcjI,EAAEiI,eAAe/H,IAAIF,EAAEiI,aAAa/H,IAAI,MAAMsB,IAAIxB,EAAEiI,aAAa,GAAGzG,GAAG,SAASiI,GAAGzJ,GAAG,IAAIC,EAAED,EAAE0J,YAAYzJ,IAAID,EAAEkI,cAAcG,cAAc,KAAKpI,GAAG,OAAOA,IAAID,EAAE2H,MAAM1H,GAAG,SAAS0J,GAAG3J,GAAG,OAAOA,GAAG,IAAK,MAAM,MAAM,6BAA6B,IAAK,OAAO,MAAM,qCAAqC,QAAQ,MAAM,gCAC9a,SAAS4J,GAAG5J,EAAEC,GAAG,OAAO,MAAMD,GAAG,iCAAiCA,EAAE2J,GAAG1J,GAAG,+BAA+BD,GAAG,kBAAkBC,EAAE,+BAA+BD,EAC/J,IAAI6J,GAAe7J,GAAZ8J,IAAY9J,GAAsJ,SAASA,EAAEC,GAAG,GAAG,+BAA+BD,EAAE+J,cAAc,cAAc/J,EAAEA,EAAEgK,UAAU/J,MAAM,CAA2F,KAA1F4J,GAAGA,IAAI/I,SAASC,cAAc,QAAUiJ,UAAU,QAAQ/J,EAAEgK,UAAUC,WAAW,SAAajK,EAAE4J,GAAGM,WAAWnK,EAAEmK,YAAYnK,EAAEoK,YAAYpK,EAAEmK,YAAY,KAAKlK,EAAEkK,YAAYnK,EAAEqK,YAAYpK,EAAEkK,cAA3a,qBAAqBG,OAAOA,MAAMC,wBAAwB,SAAStK,EAAEC,EAAEsB,EAAEC,GAAG6I,MAAMC,yBAAwB,WAAW,OAAOvK,GAAEC,EAAEC,OAAUF,IACtK,SAASwK,GAAGxK,EAAEC,GAAG,GAAGA,EAAE,CAAC,IAAIC,EAAEF,EAAEmK,WAAW,GAAGjK,GAAGA,IAAIF,EAAEyK,WAAW,IAAIvK,EAAEwK,SAAwB,YAAdxK,EAAEyK,UAAU1K,GAAUD,EAAE0J,YAAYzJ,EACrH,IAAI2K,GAAG,CAACC,yBAAwB,EAAGC,aAAY,EAAGC,mBAAkB,EAAGC,kBAAiB,EAAGC,kBAAiB,EAAGC,SAAQ,EAAGC,cAAa,EAAGC,iBAAgB,EAAGC,aAAY,EAAGC,SAAQ,EAAGC,MAAK,EAAGC,UAAS,EAAGC,cAAa,EAAGC,YAAW,EAAGC,cAAa,EAAGC,WAAU,EAAGC,UAAS,EAAGC,SAAQ,EAAGC,YAAW,EAAGC,aAAY,EAAGC,cAAa,EAAGC,YAAW,EAAGC,eAAc,EAAGC,gBAAe,EAAGC,iBAAgB,EAAGC,YAAW,EAAGC,WAAU,EAAGC,YAAW,EAAGC,SAAQ,EAAGC,OAAM,EAAGC,SAAQ,EAAGC,SAAQ,EAAGC,QAAO,EAAGC,QAAO,EAClfC,MAAK,EAAGC,aAAY,EAAGC,cAAa,EAAGC,aAAY,EAAGC,iBAAgB,EAAGC,kBAAiB,EAAGC,kBAAiB,EAAGC,eAAc,EAAGC,aAAY,GAAIC,GAAG,CAAC,SAAS,KAAK,MAAM,KAA6H,SAASC,GAAGzN,EAAEC,EAAEC,GAAG,OAAO,MAAMD,GAAG,mBAAmBA,GAAG,KAAKA,EAAE,GAAGC,GAAG,kBAAkBD,GAAG,IAAIA,GAAG2K,GAAGzJ,eAAenB,IAAI4K,GAAG5K,IAAI,GAAGC,GAAGkF,OAAOlF,EAAE,KACrb,SAASyN,GAAG1N,EAAEC,GAAa,IAAI,IAAIC,KAAlBF,EAAEA,EAAE2N,MAAmB1N,EAAE,GAAGA,EAAEkB,eAAejB,GAAG,CAAC,IAAIsB,EAAE,IAAItB,EAAE0N,QAAQ,MAAMnM,EAAEgM,GAAGvN,EAAED,EAAEC,GAAGsB,GAAG,UAAUtB,IAAIA,EAAE,YAAYsB,EAAExB,EAAE6N,YAAY3N,EAAEuB,GAAGzB,EAAEE,GAAGuB,GADcR,OAAO6M,KAAKlD,IAAIrI,SAAQ,SAASvC,GAAGwN,GAAGjL,SAAQ,SAAStC,GAAGA,EAAEA,EAAED,EAAE+N,OAAO,GAAGpL,cAAc3C,EAAEgO,UAAU,GAAGpD,GAAG3K,GAAG2K,GAAG5K,SAC5H,IAAIiO,GAAGnJ,EAAE,CAACoJ,UAAS,GAAI,CAACC,MAAK,EAAGC,MAAK,EAAGC,IAAG,EAAGC,KAAI,EAAGC,OAAM,EAAGC,IAAG,EAAGC,KAAI,EAAGC,OAAM,EAAGC,QAAO,EAAGC,MAAK,EAAGC,MAAK,EAAGC,OAAM,EAAGC,QAAO,EAAGC,OAAM,EAAGC,KAAI,IAClT,SAASC,GAAGlP,EAAEC,GAAG,GAAGA,EAAE,CAAC,GAAGgO,GAAGjO,KAAK,MAAMC,EAAEqJ,UAAU,MAAMrJ,EAAEoJ,yBAAyB,MAAMpE,MAAMlF,EAAE,IAAIC,IAAI,GAAG,MAAMC,EAAEoJ,wBAAwB,CAAC,GAAG,MAAMpJ,EAAEqJ,SAAS,MAAMrE,MAAMlF,EAAE,KAAK,GAAG,kBAAkBE,EAAEoJ,2BAA2B,WAAWpJ,EAAEoJ,yBAAyB,MAAMpE,MAAMlF,EAAE,KAAM,GAAG,MAAME,EAAE0N,OAAO,kBAAkB1N,EAAE0N,MAAM,MAAM1I,MAAMlF,EAAE,MAC5V,SAASoP,GAAGnP,EAAEC,GAAG,IAAI,IAAID,EAAE4N,QAAQ,KAAK,MAAM,kBAAkB3N,EAAEmP,GAAG,OAAOpP,GAAG,IAAK,iBAAiB,IAAK,gBAAgB,IAAK,YAAY,IAAK,gBAAgB,IAAK,gBAAgB,IAAK,mBAAmB,IAAK,iBAAiB,IAAK,gBAAgB,OAAM,EAAG,QAAQ,OAAM,GAAI,IAAIqP,GAAG,KAAK,SAASC,GAAGtP,GAA6F,OAA1FA,EAAEA,EAAEuP,QAAQvP,EAAEwP,YAAY3O,QAAS4O,0BAA0BzP,EAAEA,EAAEyP,yBAAgC,IAAIzP,EAAE0K,SAAS1K,EAAE0P,WAAW1P,EAAE,IAAI2P,GAAG,KAAKC,GAAG,KAAKC,GAAG,KACpc,SAASC,GAAG9P,GAAG,GAAGA,EAAE+P,GAAG/P,GAAG,CAAC,GAAG,oBAAoB2P,GAAG,MAAM1K,MAAMlF,EAAE,MAAM,IAAIE,EAAED,EAAEgQ,UAAU/P,IAAIA,EAAEgQ,GAAGhQ,GAAG0P,GAAG3P,EAAEgQ,UAAUhQ,EAAEkC,KAAKjC,KAAK,SAASiQ,GAAGlQ,GAAG4P,GAAGC,GAAGA,GAAGM,KAAKnQ,GAAG6P,GAAG,CAAC7P,GAAG4P,GAAG5P,EAAE,SAASoQ,KAAK,GAAGR,GAAG,CAAC,IAAI5P,EAAE4P,GAAG3P,EAAE4P,GAAoB,GAAjBA,GAAGD,GAAG,KAAKE,GAAG9P,GAAMC,EAAE,IAAID,EAAE,EAAEA,EAAEC,EAAEG,OAAOJ,IAAI8P,GAAG7P,EAAED,KAAK,SAASqQ,GAAGrQ,EAAEC,GAAG,OAAOD,EAAEC,GAAG,SAASqQ,MAAM,IAAIC,IAAG,EAAG,SAASC,GAAGxQ,EAAEC,EAAEC,GAAG,GAAGqQ,GAAG,OAAOvQ,EAAEC,EAAEC,GAAGqQ,IAAG,EAAG,IAAI,OAAOF,GAAGrQ,EAAEC,EAAEC,GAAlB,QAAgCqQ,IAAG,GAAG,OAAOX,IAAI,OAAOC,MAAGS,KAAKF,OAC3a,SAASK,GAAGzQ,EAAEC,GAAG,IAAIC,EAAEF,EAAEgQ,UAAU,GAAG,OAAO9P,EAAE,OAAO,KAAK,IAAIsB,EAAEyO,GAAG/P,GAAG,GAAG,OAAOsB,EAAE,OAAO,KAAKtB,EAAEsB,EAAEvB,GAAGD,EAAE,OAAOC,GAAG,IAAK,UAAU,IAAK,iBAAiB,IAAK,gBAAgB,IAAK,uBAAuB,IAAK,cAAc,IAAK,qBAAqB,IAAK,cAAc,IAAK,qBAAqB,IAAK,YAAY,IAAK,mBAAmB,IAAK,gBAAgBuB,GAAGA,EAAE2H,YAAqB3H,IAAI,YAAbxB,EAAEA,EAAEkC,OAAuB,UAAUlC,GAAG,WAAWA,GAAG,aAAaA,IAAIA,GAAGwB,EAAE,MAAMxB,EAAE,QAAQA,GAAE,EAAG,GAAGA,EAAE,OAAO,KAAK,GAAGE,GAAG,oBACleA,EAAE,MAAM+E,MAAMlF,EAAE,IAAIE,SAASC,IAAI,OAAOA,EAAE,IAAIwQ,IAAG,EAAG,GAAG9P,EAAG,IAAI,IAAI+P,GAAG,GAAG1P,OAAOuE,eAAemL,GAAG,UAAU,CAACzJ,IAAI,WAAWwJ,IAAG,KAAM7P,OAAO+P,iBAAiB,OAAOD,GAAGA,IAAI9P,OAAOgQ,oBAAoB,OAAOF,GAAGA,IAAI,MAAM3Q,IAAG0Q,IAAG,EAAG,SAASI,GAAG9Q,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,EAAEkE,EAAEC,GAAG,IAAIF,EAAEiD,MAAM3H,UAAU2B,MAAMI,KAAK9C,UAAU,GAAG,IAAIF,EAAE8Q,MAAM7Q,EAAE0F,GAAG,MAAMoL,GAAGpP,KAAKqP,QAAQD,IAAI,IAAIE,IAAG,EAAGC,GAAG,KAAKC,IAAG,EAAGC,GAAG,KAAKC,GAAG,CAACL,QAAQ,SAASjR,GAAGkR,IAAG,EAAGC,GAAGnR,IAAI,SAASuR,GAAGvR,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,EAAEkE,EAAEC,GAAGoL,IAAG,EAAGC,GAAG,KAAKL,GAAGC,MAAMO,GAAGnR,WACvV,SAASqR,GAAGxR,GAAG,IAAIC,EAAED,EAAEE,EAAEF,EAAE,GAAGA,EAAEyR,UAAU,KAAKxR,EAAEyR,QAAQzR,EAAEA,EAAEyR,WAAW,CAAC1R,EAAEC,EAAE,GAAO,KAAa,MAAjBA,EAAED,GAAS2R,SAAczR,EAAED,EAAEyR,QAAQ1R,EAAEC,EAAEyR,aAAa1R,GAAG,OAAO,IAAIC,EAAEkG,IAAIjG,EAAE,KAAK,SAAS0R,GAAG5R,GAAG,GAAG,KAAKA,EAAEmG,IAAI,CAAC,IAAIlG,EAAED,EAAE6R,cAAsE,GAAxD,OAAO5R,IAAkB,QAAdD,EAAEA,EAAEyR,aAAqBxR,EAAED,EAAE6R,gBAAmB,OAAO5R,EAAE,OAAOA,EAAE6R,WAAW,OAAO,KAAK,SAASC,GAAG/R,GAAG,GAAGwR,GAAGxR,KAAKA,EAAE,MAAMiF,MAAMlF,EAAE,MAEpS,SAASiS,GAAGhS,GAAW,OAAO,QAAfA,EADtN,SAAYA,GAAG,IAAIC,EAAED,EAAEyR,UAAU,IAAIxR,EAAE,CAAS,GAAG,QAAXA,EAAEuR,GAAGxR,IAAe,MAAMiF,MAAMlF,EAAE,MAAM,OAAOE,IAAID,EAAE,KAAKA,EAAE,IAAI,IAAIE,EAAEF,EAAEwB,EAAEvB,IAAI,CAAC,IAAIwB,EAAEvB,EAAEwR,OAAO,GAAG,OAAOjQ,EAAE,MAAM,IAAIC,EAAED,EAAEgQ,UAAU,GAAG,OAAO/P,EAAE,CAAY,GAAG,QAAdF,EAAEC,EAAEiQ,QAAmB,CAACxR,EAAEsB,EAAE,SAAS,MAAM,GAAGC,EAAEwQ,QAAQvQ,EAAEuQ,MAAM,CAAC,IAAIvQ,EAAED,EAAEwQ,MAAMvQ,GAAG,CAAC,GAAGA,IAAIxB,EAAE,OAAO6R,GAAGtQ,GAAGzB,EAAE,GAAG0B,IAAIF,EAAE,OAAOuQ,GAAGtQ,GAAGxB,EAAEyB,EAAEA,EAAEwQ,QAAQ,MAAMjN,MAAMlF,EAAE,MAAO,GAAGG,EAAEwR,SAASlQ,EAAEkQ,OAAOxR,EAAEuB,EAAED,EAAEE,MAAM,CAAC,IAAI,IAAIC,GAAE,EAAGkE,EAAEpE,EAAEwQ,MAAMpM,GAAG,CAAC,GAAGA,IAAI3F,EAAE,CAACyB,GAAE,EAAGzB,EAAEuB,EAAED,EAAEE,EAAE,MAAM,GAAGmE,IAAIrE,EAAE,CAACG,GAAE,EAAGH,EAAEC,EAAEvB,EAAEwB,EAAE,MAAMmE,EAAEA,EAAEqM,QAAQ,IAAIvQ,EAAE,CAAC,IAAIkE,EAAEnE,EAAEuQ,MAAMpM,GAAG,CAAC,GAAGA,IAC5f3F,EAAE,CAACyB,GAAE,EAAGzB,EAAEwB,EAAEF,EAAEC,EAAE,MAAM,GAAGoE,IAAIrE,EAAE,CAACG,GAAE,EAAGH,EAAEE,EAAExB,EAAEuB,EAAE,MAAMoE,EAAEA,EAAEqM,QAAQ,IAAIvQ,EAAE,MAAMsD,MAAMlF,EAAE,OAAQ,GAAGG,EAAEuR,YAAYjQ,EAAE,MAAMyD,MAAMlF,EAAE,MAAO,GAAG,IAAIG,EAAEiG,IAAI,MAAMlB,MAAMlF,EAAE,MAAM,OAAOG,EAAE8P,UAAUmC,UAAUjS,EAAEF,EAAEC,EAAmBmS,CAAGpS,IAAmBqS,GAAGrS,GAAG,KAAK,SAASqS,GAAGrS,GAAG,GAAG,IAAIA,EAAEmG,KAAK,IAAInG,EAAEmG,IAAI,OAAOnG,EAAE,IAAIA,EAAEA,EAAEiS,MAAM,OAAOjS,GAAG,CAAC,IAAIC,EAAEoS,GAAGrS,GAAG,GAAG,OAAOC,EAAE,OAAOA,EAAED,EAAEA,EAAEkS,QAAQ,OAAO,KACtX,IAAII,GAAGxS,EAAGyS,0BAA0BC,GAAG1S,EAAG2S,wBAAwBC,GAAG5S,EAAG6S,qBAAqBC,GAAG9S,EAAG+S,sBAAsBC,GAAEhT,EAAGiT,aAAaC,GAAGlT,EAAGmT,iCAAiCC,GAAGpT,EAAGqT,2BAA2BC,GAAGtT,EAAGuT,8BAA8BC,GAAGxT,EAAGyT,wBAAwBC,GAAG1T,EAAG2T,qBAAqBC,GAAG5T,EAAG6T,sBAAsBC,GAAG,KAAKC,GAAG,KACvV,IAAIC,GAAGC,KAAKC,MAAMD,KAAKC,MAAiC,SAAYhU,GAAU,OAAO,KAAdA,KAAK,GAAe,GAAG,IAAIiU,GAAGjU,GAAGkU,GAAG,GAAG,GAA9ED,GAAGF,KAAKI,IAAID,GAAGH,KAAKK,IAA4D,IAAIC,GAAG,GAAGC,GAAG,QAC7H,SAASC,GAAGvU,GAAG,OAAOA,GAAGA,GAAG,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EAAE,KAAK,GAAG,OAAO,GAAG,KAAK,GAAG,OAAO,GAAG,KAAK,GAAG,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,OAAO,KAAK,OAAO,KAAK,OAAO,KAAK,QAAQ,KAAK,QAAQ,OAAS,QAAFA,EAAU,KAAK,QAAQ,KAAK,QAAQ,KAAK,SAAS,KAAK,SAAS,KAAK,SAAS,OAAS,UAAFA,EAAY,KAAK,UAAU,OAAO,UAAU,KAAK,UAAU,OAAO,UAAU,KAAK,UAAU,OAAO,UAAU,KAAK,WAAW,OAAO,WACzgB,QAAQ,OAAOA,GAAG,SAASwU,GAAGxU,EAAEC,GAAG,IAAIC,EAAEF,EAAEyU,aAAa,GAAG,IAAIvU,EAAE,OAAO,EAAE,IAAIsB,EAAE,EAAEC,EAAEzB,EAAE0U,eAAehT,EAAE1B,EAAE2U,YAAYhT,EAAI,UAAFzB,EAAY,GAAG,IAAIyB,EAAE,CAAC,IAAIkE,EAAElE,GAAGF,EAAE,IAAIoE,EAAErE,EAAE+S,GAAG1O,GAAS,KAALnE,GAAGC,KAAUH,EAAE+S,GAAG7S,SAAiB,KAAPC,EAAEzB,GAAGuB,GAAQD,EAAE+S,GAAG5S,GAAG,IAAID,IAAIF,EAAE+S,GAAG7S,IAAI,GAAG,IAAIF,EAAE,OAAO,EAAE,GAAG,IAAIvB,GAAGA,IAAIuB,GAAG,KAAKvB,EAAEwB,MAAKA,EAAED,GAAGA,KAAEE,EAAEzB,GAAGA,IAAQ,KAAKwB,GAAG,KAAO,QAAFC,IAAY,OAAOzB,EAA0C,GAAxC,KAAO,EAAFuB,KAAOA,GAAK,GAAFtB,GAA4B,KAAtBD,EAAED,EAAE4U,gBAAwB,IAAI5U,EAAEA,EAAE6U,cAAc5U,GAAGuB,EAAE,EAAEvB,GAAcwB,EAAE,IAAbvB,EAAE,GAAG4T,GAAG7T,IAAUuB,GAAGxB,EAAEE,GAAGD,IAAIwB,EAAE,OAAOD,EACtc,SAASsT,GAAG9U,EAAEC,GAAG,OAAOD,GAAG,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,OAAOC,EAAE,IAAI,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG,KAAK,GAAG,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,OAAO,KAAK,OAAO,KAAK,OAAO,KAAK,QAAQ,KAAK,QAAQ,OAAOA,EAAE,IAAuJ,QAAQ,OAAO,GACnN,SAAS8U,GAAG/U,GAAgC,OAAO,KAApCA,GAAkB,WAAhBA,EAAEyU,cAAsCzU,EAAI,WAAFA,EAAa,WAAW,EAAE,SAASgV,KAAK,IAAIhV,EAAEqU,GAAoC,OAA1B,KAAQ,SAAfA,KAAK,MAAqBA,GAAG,IAAWrU,EAAE,SAASiV,GAAGjV,GAAG,IAAI,IAAIC,EAAE,GAAGC,EAAE,EAAE,GAAGA,EAAEA,IAAID,EAAEkQ,KAAKnQ,GAAG,OAAOC,EAC1a,SAASiV,GAAGlV,EAAEC,EAAEC,GAAGF,EAAEyU,cAAcxU,EAAE,YAAYA,IAAID,EAAE0U,eAAe,EAAE1U,EAAE2U,YAAY,IAAG3U,EAAEA,EAAEmV,YAAWlV,EAAE,GAAG6T,GAAG7T,IAAQC,EACxH,SAASkV,GAAGpV,EAAEC,GAAG,IAAIC,EAAEF,EAAE4U,gBAAgB3U,EAAE,IAAID,EAAEA,EAAE6U,cAAc3U,GAAG,CAAC,IAAIsB,EAAE,GAAGsS,GAAG5T,GAAGuB,EAAE,GAAGD,EAAEC,EAAExB,EAAED,EAAEwB,GAAGvB,IAAID,EAAEwB,IAAIvB,GAAGC,IAAIuB,GAAG,IAAI4T,GAAE,EAAE,SAASC,GAAGtV,GAAS,OAAO,GAAbA,IAAIA,GAAa,EAAEA,EAAE,KAAO,UAAFA,GAAa,GAAG,UAAU,EAAE,EAAE,IAAIuV,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,IAAG,EAAGC,GAAG,GAAGC,GAAG,KAAKC,GAAG,KAAKC,GAAG,KAAKC,GAAG,IAAIC,IAAIC,GAAG,IAAID,IAAIE,GAAG,GAAGC,GAAG,6PAA6P/T,MAAM,KAChiB,SAASgU,GAAGtW,EAAEC,GAAG,OAAOD,GAAG,IAAK,UAAU,IAAK,WAAW8V,GAAG,KAAK,MAAM,IAAK,YAAY,IAAK,YAAYC,GAAG,KAAK,MAAM,IAAK,YAAY,IAAK,WAAWC,GAAG,KAAK,MAAM,IAAK,cAAc,IAAK,aAAaC,GAAGM,OAAOtW,EAAEuW,WAAW,MAAM,IAAK,oBAAoB,IAAK,qBAAqBL,GAAGI,OAAOtW,EAAEuW,YACxS,SAASC,GAAGzW,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,GAAG,OAAG,OAAO1B,GAAGA,EAAE0W,cAAchV,GAAS1B,EAAE,CAAC2W,UAAU1W,EAAE2W,aAAa1W,EAAE2W,iBAAiBrV,EAAEkV,YAAYhV,EAAEoV,iBAAiB,CAACrV,IAAI,OAAOxB,IAAY,QAARA,EAAE8P,GAAG9P,KAAauV,GAAGvV,IAAID,IAAEA,EAAE6W,kBAAkBrV,EAAEvB,EAAED,EAAE8W,iBAAiB,OAAOrV,IAAI,IAAIxB,EAAE2N,QAAQnM,IAAIxB,EAAEkQ,KAAK1O,GAAUzB,GAEnR,SAAS+W,GAAG/W,GAAG,IAAIC,EAAE+W,GAAGhX,EAAEuP,QAAQ,GAAG,OAAOtP,EAAE,CAAC,IAAIC,EAAEsR,GAAGvR,GAAG,GAAG,OAAOC,EAAE,GAAW,MAARD,EAAEC,EAAEiG,MAAY,GAAW,QAARlG,EAAE2R,GAAG1R,IAA4D,OAA/CF,EAAE2W,UAAU1W,OAAE0V,GAAG3V,EAAEiX,UAAS,WAAWxB,GAAGvV,WAAkB,GAAG,IAAID,GAAGC,EAAE8P,UAAUmC,QAAQN,cAAcqF,aAAmE,YAArDlX,EAAE2W,UAAU,IAAIzW,EAAEiG,IAAIjG,EAAE8P,UAAUmH,cAAc,MAAanX,EAAE2W,UAAU,KAC9S,SAASS,GAAGpX,GAAG,GAAG,OAAOA,EAAE2W,UAAU,OAAM,EAAG,IAAI,IAAI1W,EAAED,EAAE8W,iBAAiB,EAAE7W,EAAEG,QAAQ,CAAC,IAAIF,EAAEmX,GAAGrX,EAAE4W,aAAa5W,EAAE6W,iBAAiB5W,EAAE,GAAGD,EAAE0W,aAAa,GAAG,OAAOxW,EAAiG,OAAe,QAARD,EAAE8P,GAAG7P,KAAasV,GAAGvV,GAAGD,EAAE2W,UAAUzW,GAAE,EAA3H,IAAIsB,EAAE,IAAtBtB,EAAEF,EAAE0W,aAAwBzP,YAAY/G,EAAEgC,KAAKhC,GAAGmP,GAAG7N,EAAEtB,EAAEqP,OAAO+H,cAAc9V,GAAG6N,GAAG,KAA0DpP,EAAEsX,QAAQ,OAAM,EAAG,SAASC,GAAGxX,EAAEC,EAAEC,GAAGkX,GAAGpX,IAAIE,EAAEqW,OAAOtW,GAAG,SAASwX,KAAK7B,IAAG,EAAG,OAAOE,IAAIsB,GAAGtB,MAAMA,GAAG,MAAM,OAAOC,IAAIqB,GAAGrB,MAAMA,GAAG,MAAM,OAAOC,IAAIoB,GAAGpB,MAAMA,GAAG,MAAMC,GAAG1T,QAAQiV,IAAIrB,GAAG5T,QAAQiV,IAChf,SAASE,GAAG1X,EAAEC,GAAGD,EAAE2W,YAAY1W,IAAID,EAAE2W,UAAU,KAAKf,KAAKA,IAAG,EAAG9V,EAAGyS,0BAA0BzS,EAAGyT,wBAAwBkE,MACvH,SAASE,GAAG3X,GAAG,SAASC,EAAEA,GAAG,OAAOyX,GAAGzX,EAAED,GAAG,GAAG,EAAE6V,GAAGzV,OAAO,CAACsX,GAAG7B,GAAG,GAAG7V,GAAG,IAAI,IAAIE,EAAE,EAAEA,EAAE2V,GAAGzV,OAAOF,IAAI,CAAC,IAAIsB,EAAEqU,GAAG3V,GAAGsB,EAAEmV,YAAY3W,IAAIwB,EAAEmV,UAAU,OAA+F,IAAxF,OAAOb,IAAI4B,GAAG5B,GAAG9V,GAAG,OAAO+V,IAAI2B,GAAG3B,GAAG/V,GAAG,OAAOgW,IAAI0B,GAAG1B,GAAGhW,GAAGiW,GAAG1T,QAAQtC,GAAGkW,GAAG5T,QAAQtC,GAAOC,EAAE,EAAEA,EAAEkW,GAAGhW,OAAOF,KAAIsB,EAAE4U,GAAGlW,IAAKyW,YAAY3W,IAAIwB,EAAEmV,UAAU,MAAM,KAAK,EAAEP,GAAGhW,QAAiB,QAARF,EAAEkW,GAAG,IAAYO,WAAYI,GAAG7W,GAAG,OAAOA,EAAEyW,WAAWP,GAAGmB,QAAQ,IAAIK,GAAGnU,EAAGoU,wBAAwBC,IAAG,EAC5a,SAASC,GAAG/X,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAE4T,GAAE3T,EAAEkW,GAAGI,WAAWJ,GAAGI,WAAW,KAAK,IAAI3C,GAAE,EAAE4C,GAAGjY,EAAEC,EAAEC,EAAEsB,GAAjB,QAA4B6T,GAAE5T,EAAEmW,GAAGI,WAAWtW,GAAG,SAASwW,GAAGlY,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAE4T,GAAE3T,EAAEkW,GAAGI,WAAWJ,GAAGI,WAAW,KAAK,IAAI3C,GAAE,EAAE4C,GAAGjY,EAAEC,EAAEC,EAAEsB,GAAjB,QAA4B6T,GAAE5T,EAAEmW,GAAGI,WAAWtW,GAC/N,SAASuW,GAAGjY,EAAEC,EAAEC,EAAEsB,GAAG,GAAGsW,GAAG,CAAC,IAAIrW,EAAE4V,GAAGrX,EAAEC,EAAEC,EAAEsB,GAAG,GAAG,OAAOC,EAAE0W,GAAGnY,EAAEC,EAAEuB,EAAE4W,GAAGlY,GAAGoW,GAAGtW,EAAEwB,QAAQ,GANtF,SAAYxB,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,OAAOxB,GAAG,IAAK,UAAU,OAAO6V,GAAGW,GAAGX,GAAG9V,EAAEC,EAAEC,EAAEsB,EAAEC,IAAG,EAAG,IAAK,YAAY,OAAOsU,GAAGU,GAAGV,GAAG/V,EAAEC,EAAEC,EAAEsB,EAAEC,IAAG,EAAG,IAAK,YAAY,OAAOuU,GAAGS,GAAGT,GAAGhW,EAAEC,EAAEC,EAAEsB,EAAEC,IAAG,EAAG,IAAK,cAAc,IAAIC,EAAED,EAAE+U,UAAkD,OAAxCP,GAAGxQ,IAAI/D,EAAE+U,GAAGR,GAAG/O,IAAIxF,IAAI,KAAK1B,EAAEC,EAAEC,EAAEsB,EAAEC,KAAU,EAAG,IAAK,oBAAoB,OAAOC,EAAED,EAAE+U,UAAUL,GAAG1Q,IAAI/D,EAAE+U,GAAGN,GAAGjP,IAAIxF,IAAI,KAAK1B,EAAEC,EAAEC,EAAEsB,EAAEC,KAAI,EAAG,OAAM,EAMxQ4W,CAAG5W,EAAEzB,EAAEC,EAAEC,EAAEsB,GAAGA,EAAE8W,uBAAuB,GAAGhC,GAAGtW,EAAEwB,GAAK,EAAFvB,IAAM,EAAEoW,GAAGzI,QAAQ5N,GAAG,CAAC,KAAK,OAAOyB,GAAG,CAAC,IAAIC,EAAEqO,GAAGtO,GAA0D,GAAvD,OAAOC,GAAG6T,GAAG7T,GAAiB,QAAdA,EAAE2V,GAAGrX,EAAEC,EAAEC,EAAEsB,KAAa2W,GAAGnY,EAAEC,EAAEuB,EAAE4W,GAAGlY,GAAMwB,IAAID,EAAE,MAAMA,EAAEC,EAAE,OAAOD,GAAGD,EAAE8W,uBAAuBH,GAAGnY,EAAEC,EAAEuB,EAAE,KAAKtB,IAAI,IAAIkY,GAAG,KACpU,SAASf,GAAGrX,EAAEC,EAAEC,EAAEsB,GAA2B,GAAxB4W,GAAG,KAAwB,QAAXpY,EAAEgX,GAAVhX,EAAEsP,GAAG9N,KAAuB,GAAW,QAARvB,EAAEuR,GAAGxR,IAAYA,EAAE,UAAU,GAAW,MAARE,EAAED,EAAEkG,KAAW,CAAS,GAAG,QAAXnG,EAAE4R,GAAG3R,IAAe,OAAOD,EAAEA,EAAE,UAAU,GAAG,IAAIE,EAAE,CAAC,GAAGD,EAAE+P,UAAUmC,QAAQN,cAAcqF,aAAa,OAAO,IAAIjX,EAAEkG,IAAIlG,EAAE+P,UAAUmH,cAAc,KAAKnX,EAAE,UAAUC,IAAID,IAAIA,EAAE,MAAW,OAALoY,GAAGpY,EAAS,KACzS,SAASuY,GAAGvY,GAAG,OAAOA,GAAG,IAAK,SAAS,IAAK,QAAQ,IAAK,QAAQ,IAAK,cAAc,IAAK,OAAO,IAAK,MAAM,IAAK,WAAW,IAAK,WAAW,IAAK,UAAU,IAAK,YAAY,IAAK,OAAO,IAAK,UAAU,IAAK,WAAW,IAAK,QAAQ,IAAK,UAAU,IAAK,UAAU,IAAK,WAAW,IAAK,QAAQ,IAAK,YAAY,IAAK,UAAU,IAAK,QAAQ,IAAK,QAAQ,IAAK,OAAO,IAAK,gBAAgB,IAAK,cAAc,IAAK,YAAY,IAAK,aAAa,IAAK,QAAQ,IAAK,SAAS,IAAK,SAAS,IAAK,SAAS,IAAK,cAAc,IAAK,WAAW,IAAK,aAAa,IAAK,eAAe,IAAK,SAAS,IAAK,kBAAkB,IAAK,YAAY,IAAK,mBAAmB,IAAK,iBAAiB,IAAK,oBAAoB,IAAK,aAAa,IAAK,YAAY,IAAK,cAAc,IAAK,OAAO,IAAK,mBAAmB,IAAK,QAAQ,IAAK,aAAa,IAAK,WAAW,IAAK,SAAS,IAAK,cAAc,OAAO,EAAE,IAAK,OAAO,IAAK,YAAY,IAAK,WAAW,IAAK,YAAY,IAAK,WAAW,IAAK,YAAY,IAAK,WAAW,IAAK,YAAY,IAAK,cAAc,IAAK,aAAa,IAAK,cAAc,IAAK,SAAS,IAAK,SAAS,IAAK,YAAY,IAAK,QAAQ,IAAK,aAAa,IAAK,aAAa,IAAK,eAAe,IAAK,eAAe,OAAO,EACpqC,IAAK,UAAU,OAAOgT,MAAM,KAAKE,GAAG,OAAO,EAAE,KAAKE,GAAG,OAAO,EAAE,KAAKE,GAAG,KAAKE,GAAG,OAAO,GAAG,KAAKE,GAAG,OAAO,UAAU,QAAQ,OAAO,GAAG,QAAQ,OAAO,IAAI,IAAI8E,GAAG,KAAKC,GAAG,KAAKC,GAAG,KAAK,SAASC,KAAK,GAAGD,GAAG,OAAOA,GAAG,IAAI1Y,EAAkBwB,EAAhBvB,EAAEwY,GAAGvY,EAAED,EAAEG,OAASqB,EAAE,UAAU+W,GAAGA,GAAG7Q,MAAM6Q,GAAG9O,YAAYhI,EAAED,EAAErB,OAAO,IAAIJ,EAAE,EAAEA,EAAEE,GAAGD,EAAED,KAAKyB,EAAEzB,GAAGA,KAAK,IAAI2B,EAAEzB,EAAEF,EAAE,IAAIwB,EAAE,EAAEA,GAAGG,GAAG1B,EAAEC,EAAEsB,KAAKC,EAAEC,EAAEF,GAAGA,KAAK,OAAOkX,GAAGjX,EAAEoB,MAAM7C,EAAE,EAAEwB,EAAE,EAAEA,OAAE,GACjY,SAASoX,GAAG5Y,GAAG,IAAIC,EAAED,EAAE6Y,QAA+E,MAAvE,aAAa7Y,EAAgB,KAAbA,EAAEA,EAAE8Y,WAAgB,KAAK7Y,IAAID,EAAE,IAAKA,EAAEC,EAAE,KAAKD,IAAIA,EAAE,IAAW,IAAIA,GAAG,KAAKA,EAAEA,EAAE,EAAE,SAAS+Y,KAAK,OAAM,EAAG,SAASC,KAAK,OAAM,EAC1K,SAASC,GAAGjZ,GAAG,SAASC,EAAEA,EAAEuB,EAAEC,EAAEC,EAAEC,GAA6G,IAAI,IAAIzB,KAAlH0B,KAAKsX,WAAWjZ,EAAE2B,KAAKuX,YAAY1X,EAAEG,KAAKM,KAAKV,EAAEI,KAAK8U,YAAYhV,EAAEE,KAAK2N,OAAO5N,EAAEC,KAAKwX,cAAc,KAAkBpZ,EAAEA,EAAEmB,eAAejB,KAAKD,EAAED,EAAEE,GAAG0B,KAAK1B,GAAGD,EAAEA,EAAEyB,GAAGA,EAAExB,IAAgI,OAA5H0B,KAAKyX,oBAAoB,MAAM3X,EAAE4X,iBAAiB5X,EAAE4X,kBAAiB,IAAK5X,EAAE6X,aAAaR,GAAGC,GAAGpX,KAAK4X,qBAAqBR,GAAUpX,KAC1E,OAD+EkD,EAAE7E,EAAEiB,UAAU,CAACuY,eAAe,WAAW7X,KAAK0X,kBAAiB,EAAG,IAAItZ,EAAE4B,KAAK8U,YAAY1W,IAAIA,EAAEyZ,eAAezZ,EAAEyZ,iBAAiB,mBAAmBzZ,EAAEuZ,cAC7evZ,EAAEuZ,aAAY,GAAI3X,KAAKyX,mBAAmBN,KAAKT,gBAAgB,WAAW,IAAItY,EAAE4B,KAAK8U,YAAY1W,IAAIA,EAAEsY,gBAAgBtY,EAAEsY,kBAAkB,mBAAmBtY,EAAE0Z,eAAe1Z,EAAE0Z,cAAa,GAAI9X,KAAK4X,qBAAqBT,KAAKY,QAAQ,aAAaC,aAAab,KAAY9Y,EAChR,IAAoL4Z,GAAGC,GAAGC,GAAtLC,GAAG,CAACC,WAAW,EAAEC,QAAQ,EAAEC,WAAW,EAAEC,UAAU,SAASpa,GAAG,OAAOA,EAAEoa,WAAWC,KAAKC,OAAOhB,iBAAiB,EAAEiB,UAAU,GAAGC,GAAGvB,GAAGe,IAAIS,GAAG3V,EAAE,GAAGkV,GAAG,CAACU,KAAK,EAAEC,OAAO,IAAIC,GAAG3B,GAAGwB,IAAaI,GAAG/V,EAAE,GAAG2V,GAAG,CAACK,QAAQ,EAAEC,QAAQ,EAAEC,QAAQ,EAAEC,QAAQ,EAAEC,MAAM,EAAEC,MAAM,EAAEC,QAAQ,EAAEC,SAAS,EAAEC,OAAO,EAAEC,QAAQ,EAAEC,iBAAiBC,GAAGC,OAAO,EAAEC,QAAQ,EAAEC,cAAc,SAAS5b,GAAG,YAAO,IAASA,EAAE4b,cAAc5b,EAAE6b,cAAc7b,EAAEwP,WAAWxP,EAAE8b,UAAU9b,EAAE6b,YAAY7b,EAAE4b,eAAeG,UAAU,SAAS/b,GAAG,MAAG,cAC3eA,EAASA,EAAE+b,WAAU/b,IAAI+Z,KAAKA,IAAI,cAAc/Z,EAAEkC,MAAM2X,GAAG7Z,EAAE8a,QAAQf,GAAGe,QAAQhB,GAAG9Z,EAAE+a,QAAQhB,GAAGgB,SAASjB,GAAGD,GAAG,EAAEE,GAAG/Z,GAAU6Z,KAAImC,UAAU,SAAShc,GAAG,MAAM,cAAcA,EAAEA,EAAEgc,UAAUlC,MAAMmC,GAAGhD,GAAG4B,IAAiCqB,GAAGjD,GAA7BnU,EAAE,GAAG+V,GAAG,CAACsB,aAAa,KAA4CC,GAAGnD,GAA9BnU,EAAE,GAAG2V,GAAG,CAACmB,cAAc,KAA0ES,GAAGpD,GAA5DnU,EAAE,GAAGkV,GAAG,CAACsC,cAAc,EAAEC,YAAY,EAAEC,cAAc,KAAcC,GAAG3X,EAAE,GAAGkV,GAAG,CAAC0C,cAAc,SAAS1c,GAAG,MAAM,kBAAkBA,EAAEA,EAAE0c,cAAc7b,OAAO6b,iBAAiBC,GAAG1D,GAAGwD,IAAyBG,GAAG3D,GAArBnU,EAAE,GAAGkV,GAAG,CAAC6C,KAAK,KAAcC,GAAG,CAACC,IAAI,SACxfC,SAAS,IAAIC,KAAK,YAAYC,GAAG,UAAUC,MAAM,aAAaC,KAAK,YAAYC,IAAI,SAASC,IAAI,KAAKC,KAAK,cAAcC,KAAK,cAAcC,OAAO,aAAaC,gBAAgB,gBAAgBC,GAAG,CAAC,EAAE,YAAY,EAAE,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,GAAG,UAAU,GAAG,MAAM,GAAG,QAAQ,GAAG,WAAW,GAAG,SAAS,GAAG,IAAI,GAAG,SAAS,GAAG,WAAW,GAAG,MAAM,GAAG,OAAO,GAAG,YAAY,GAAG,UAAU,GAAG,aAAa,GAAG,YAAY,GAAG,SAAS,GAAG,SAAS,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KACtf,IAAI,KAAK,IAAI,KAAK,IAAI,MAAM,IAAI,MAAM,IAAI,MAAM,IAAI,UAAU,IAAI,aAAa,IAAI,QAAQC,GAAG,CAACC,IAAI,SAASC,QAAQ,UAAUC,KAAK,UAAUC,MAAM,YAAY,SAASC,GAAGje,GAAG,IAAIC,EAAE2B,KAAK8U,YAAY,OAAOzW,EAAEub,iBAAiBvb,EAAEub,iBAAiBxb,MAAIA,EAAE4d,GAAG5d,OAAMC,EAAED,GAAM,SAASyb,KAAK,OAAOwC,GAC9R,IAAIC,GAAGpZ,EAAE,GAAG2V,GAAG,CAAC0D,IAAI,SAASne,GAAG,GAAGA,EAAEme,IAAI,CAAC,IAAIle,EAAE6c,GAAG9c,EAAEme,MAAMne,EAAEme,IAAI,GAAG,iBAAiBle,EAAE,OAAOA,EAAE,MAAM,aAAaD,EAAEkC,KAAc,MAARlC,EAAE4Y,GAAG5Y,IAAU,QAAQoe,OAAOC,aAAare,GAAI,YAAYA,EAAEkC,MAAM,UAAUlC,EAAEkC,KAAKyb,GAAG3d,EAAE6Y,UAAU,eAAe,IAAIyF,KAAK,EAAEC,SAAS,EAAEnD,QAAQ,EAAEC,SAAS,EAAEC,OAAO,EAAEC,QAAQ,EAAEiD,OAAO,EAAEC,OAAO,EAAEjD,iBAAiBC,GAAG3C,SAAS,SAAS9Y,GAAG,MAAM,aAAaA,EAAEkC,KAAK0W,GAAG5Y,GAAG,GAAG6Y,QAAQ,SAAS7Y,GAAG,MAAM,YAAYA,EAAEkC,MAAM,UAAUlC,EAAEkC,KAAKlC,EAAE6Y,QAAQ,GAAG6F,MAAM,SAAS1e,GAAG,MAAM,aAC7eA,EAAEkC,KAAK0W,GAAG5Y,GAAG,YAAYA,EAAEkC,MAAM,UAAUlC,EAAEkC,KAAKlC,EAAE6Y,QAAQ,KAAK8F,GAAG1F,GAAGiF,IAAiIU,GAAG3F,GAA7HnU,EAAE,GAAG+V,GAAG,CAACrE,UAAU,EAAEqI,MAAM,EAAEC,OAAO,EAAEC,SAAS,EAAEC,mBAAmB,EAAEC,MAAM,EAAEC,MAAM,EAAEC,MAAM,EAAEC,YAAY,EAAEC,UAAU,KAAmIC,GAAGrG,GAArHnU,EAAE,GAAG2V,GAAG,CAAC8E,QAAQ,EAAEC,cAAc,EAAEC,eAAe,EAAEnE,OAAO,EAAEC,QAAQ,EAAEH,QAAQ,EAAEC,SAAS,EAAEG,iBAAiBC,MAA0EiE,GAAGzG,GAA3DnU,EAAE,GAAGkV,GAAG,CAAC/X,aAAa,EAAEsa,YAAY,EAAEC,cAAc,KAAcmD,GAAG7a,EAAE,GAAG+V,GAAG,CAAC+E,OAAO,SAAS5f,GAAG,MAAM,WAAWA,EAAEA,EAAE4f,OAAO,gBAAgB5f,GAAGA,EAAE6f,YAAY,GAClfC,OAAO,SAAS9f,GAAG,MAAM,WAAWA,EAAEA,EAAE8f,OAAO,gBAAgB9f,GAAGA,EAAE+f,YAAY,eAAe/f,GAAGA,EAAEggB,WAAW,GAAGC,OAAO,EAAEC,UAAU,IAAIC,GAAGlH,GAAG0G,IAAIS,GAAG,CAAC,EAAE,GAAG,GAAG,IAAIC,GAAGzf,GAAI,qBAAqBC,OAAOyf,GAAG,KAAK1f,GAAI,iBAAiBE,WAAWwf,GAAGxf,SAASyf,cAAc,IAAIC,GAAG5f,GAAI,cAAcC,SAASyf,GAAGG,GAAG7f,KAAMyf,IAAIC,IAAI,EAAEA,IAAI,IAAIA,IAAII,GAAGtC,OAAOC,aAAa,IAAIsC,IAAG,EAC1W,SAASC,GAAG5gB,EAAEC,GAAG,OAAOD,GAAG,IAAK,QAAQ,OAAO,IAAIogB,GAAGxS,QAAQ3N,EAAE4Y,SAAS,IAAK,UAAU,OAAO,MAAM5Y,EAAE4Y,QAAQ,IAAK,WAAW,IAAK,YAAY,IAAK,WAAW,OAAM,EAAG,QAAQ,OAAM,GAAI,SAASgI,GAAG7gB,GAAc,MAAM,kBAAjBA,EAAEA,EAAE2a,SAAkC,SAAS3a,EAAEA,EAAE6c,KAAK,KAAK,IAAIiE,IAAG,EAE9Q,IAAIC,GAAG,CAACC,OAAM,EAAGC,MAAK,EAAGC,UAAS,EAAG,kBAAiB,EAAGC,OAAM,EAAGC,OAAM,EAAGC,QAAO,EAAGC,UAAS,EAAGC,OAAM,EAAGC,QAAO,EAAGC,KAAI,EAAGC,MAAK,EAAGC,MAAK,EAAGC,KAAI,EAAGC,MAAK,GAAI,SAASC,GAAG9hB,GAAG,IAAIC,EAAED,GAAGA,EAAE6G,UAAU7G,EAAE6G,SAASrE,cAAc,MAAM,UAAUvC,IAAI8gB,GAAG/gB,EAAEkC,MAAM,aAAajC,EAAQ,SAAS8hB,GAAG/hB,EAAEC,EAAEC,EAAEsB,GAAG0O,GAAG1O,GAAsB,GAAnBvB,EAAE+hB,GAAG/hB,EAAE,aAAgBG,SAASF,EAAE,IAAIsa,GAAG,WAAW,SAAS,KAAKta,EAAEsB,GAAGxB,EAAEmQ,KAAK,CAAC8R,MAAM/hB,EAAEgiB,UAAUjiB,KAAK,IAAIkiB,GAAG,KAAKC,GAAG,KAAK,SAASC,GAAGriB,GAAGsiB,GAAGtiB,EAAE,GAAG,SAASuiB,GAAGviB,GAAe,GAAGyH,EAAT+a,GAAGxiB,IAAY,OAAOA,EACne,SAASyiB,GAAGziB,EAAEC,GAAG,GAAG,WAAWD,EAAE,OAAOC,EAAE,IAAIyiB,IAAG,EAAG,GAAG9hB,EAAG,CAAC,IAAI+hB,GAAG,GAAG/hB,EAAG,CAAC,IAAIgiB,GAAG,YAAY9hB,SAAS,IAAI8hB,GAAG,CAAC,IAAIC,GAAG/hB,SAASC,cAAc,OAAO8hB,GAAGxf,aAAa,UAAU,WAAWuf,GAAG,oBAAoBC,GAAGC,QAAQH,GAAGC,QAAQD,IAAG,EAAGD,GAAGC,MAAM7hB,SAASyf,cAAc,EAAEzf,SAASyf,cAAc,SAASwC,KAAKZ,KAAKA,GAAGa,YAAY,mBAAmBC,IAAIb,GAAGD,GAAG,MAAM,SAASc,GAAGjjB,GAAG,GAAG,UAAUA,EAAEiC,cAAcsgB,GAAGH,IAAI,CAAC,IAAIniB,EAAE,GAAG8hB,GAAG9hB,EAAEmiB,GAAGpiB,EAAEsP,GAAGtP,IAAIwQ,GAAG6R,GAAGpiB,IAC5b,SAASijB,GAAGljB,EAAEC,EAAEC,GAAG,YAAYF,GAAG+iB,KAAUX,GAAGliB,GAARiiB,GAAGliB,GAAUkjB,YAAY,mBAAmBF,KAAK,aAAajjB,GAAG+iB,KAAK,SAASK,GAAGpjB,GAAG,GAAG,oBAAoBA,GAAG,UAAUA,GAAG,YAAYA,EAAE,OAAOuiB,GAAGH,IAAI,SAASiB,GAAGrjB,EAAEC,GAAG,GAAG,UAAUD,EAAE,OAAOuiB,GAAGtiB,GAAG,SAASqjB,GAAGtjB,EAAEC,GAAG,GAAG,UAAUD,GAAG,WAAWA,EAAE,OAAOuiB,GAAGtiB,GAAmE,IAAIsjB,GAAG,oBAAoBtiB,OAAOmO,GAAGnO,OAAOmO,GAA5G,SAAYpP,EAAEC,GAAG,OAAOD,IAAIC,IAAI,IAAID,GAAG,EAAEA,IAAI,EAAEC,IAAID,IAAIA,GAAGC,IAAIA,GACrW,SAASujB,GAAGxjB,EAAEC,GAAG,GAAGsjB,GAAGvjB,EAAEC,GAAG,OAAM,EAAG,GAAG,kBAAkBD,GAAG,OAAOA,GAAG,kBAAkBC,GAAG,OAAOA,EAAE,OAAM,EAAG,IAAIC,EAAEe,OAAO6M,KAAK9N,GAAGwB,EAAEP,OAAO6M,KAAK7N,GAAG,GAAGC,EAAEE,SAASoB,EAAEpB,OAAO,OAAM,EAAG,IAAIoB,EAAE,EAAEA,EAAEtB,EAAEE,OAAOoB,IAAI,CAAC,IAAIC,EAAEvB,EAAEsB,GAAG,IAAIR,EAAGiC,KAAKhD,EAAEwB,KAAK8hB,GAAGvjB,EAAEyB,GAAGxB,EAAEwB,IAAI,OAAM,EAAG,OAAM,EAAG,SAASgiB,GAAGzjB,GAAG,KAAKA,GAAGA,EAAEmK,YAAYnK,EAAEA,EAAEmK,WAAW,OAAOnK,EACrU,SAAS0jB,GAAG1jB,EAAEC,GAAG,IAAwBuB,EAApBtB,EAAEujB,GAAGzjB,GAAO,IAAJA,EAAE,EAAYE,GAAG,CAAC,GAAG,IAAIA,EAAEwK,SAAS,CAA0B,GAAzBlJ,EAAExB,EAAEE,EAAEwJ,YAAYtJ,OAAUJ,GAAGC,GAAGuB,GAAGvB,EAAE,MAAM,CAAC0jB,KAAKzjB,EAAE0jB,OAAO3jB,EAAED,GAAGA,EAAEwB,EAAExB,EAAE,CAAC,KAAKE,GAAG,CAAC,GAAGA,EAAE2jB,YAAY,CAAC3jB,EAAEA,EAAE2jB,YAAY,MAAM7jB,EAAEE,EAAEA,EAAEwP,WAAWxP,OAAE,EAAOA,EAAEujB,GAAGvjB,IAAI,SAAS4jB,GAAG9jB,EAAEC,GAAG,SAAOD,IAAGC,KAAED,IAAIC,KAAKD,GAAG,IAAIA,EAAE0K,YAAYzK,GAAG,IAAIA,EAAEyK,SAASoZ,GAAG9jB,EAAEC,EAAEyP,YAAY,aAAa1P,EAAEA,EAAE+jB,SAAS9jB,KAAGD,EAAEgkB,4BAAwD,GAA7BhkB,EAAEgkB,wBAAwB/jB,MAClZ,SAASgkB,KAAK,IAAI,IAAIjkB,EAAEa,OAAOZ,EAAE2H,IAAK3H,aAAaD,EAAEkkB,mBAAmB,CAAC,IAAI,IAAIhkB,EAAE,kBAAkBD,EAAEkkB,cAAc5F,SAAS6F,KAAK,MAAM5iB,GAAGtB,GAAE,EAAG,IAAGA,EAAyB,MAAMD,EAAE2H,GAA/B5H,EAAEC,EAAEkkB,eAAgCrjB,UAAU,OAAOb,EAAE,SAASokB,GAAGrkB,GAAG,IAAIC,EAAED,GAAGA,EAAE6G,UAAU7G,EAAE6G,SAASrE,cAAc,OAAOvC,IAAI,UAAUA,IAAI,SAASD,EAAEkC,MAAM,WAAWlC,EAAEkC,MAAM,QAAQlC,EAAEkC,MAAM,QAAQlC,EAAEkC,MAAM,aAAalC,EAAEkC,OAAO,aAAajC,GAAG,SAASD,EAAEskB,iBACxZ,SAASC,GAAGvkB,GAAG,IAAIC,EAAEgkB,KAAK/jB,EAAEF,EAAEwkB,YAAYhjB,EAAExB,EAAEykB,eAAe,GAAGxkB,IAAIC,GAAGA,GAAGA,EAAEyI,eAAemb,GAAG5jB,EAAEyI,cAAc+b,gBAAgBxkB,GAAG,CAAC,GAAG,OAAOsB,GAAG6iB,GAAGnkB,GAAG,GAAGD,EAAEuB,EAAEmjB,WAAc,KAAR3kB,EAAEwB,EAAEojB,OAAiB5kB,EAAEC,GAAG,mBAAmBC,EAAEA,EAAE2kB,eAAe5kB,EAAEC,EAAE4kB,aAAa/Q,KAAKgR,IAAI/kB,EAAEE,EAAEyH,MAAMvH,aAAa,IAAGJ,GAAGC,EAAEC,EAAEyI,eAAe7H,WAAWb,EAAE+kB,aAAankB,QAASokB,aAAa,CAACjlB,EAAEA,EAAEilB,eAAe,IAAIxjB,EAAEvB,EAAEwJ,YAAYtJ,OAAOsB,EAAEqS,KAAKgR,IAAIvjB,EAAEmjB,MAAMljB,GAAGD,OAAE,IAASA,EAAEojB,IAAIljB,EAAEqS,KAAKgR,IAAIvjB,EAAEojB,IAAInjB,IAAIzB,EAAEklB,QAAQxjB,EAAEF,IAAIC,EAAED,EAAEA,EAAEE,EAAEA,EAAED,GAAGA,EAAEiiB,GAAGxjB,EAAEwB,GAAG,IAAIC,EAAE+hB,GAAGxjB,EACvfsB,GAAGC,GAAGE,IAAI,IAAI3B,EAAEmlB,YAAYnlB,EAAEolB,aAAa3jB,EAAEkiB,MAAM3jB,EAAEqlB,eAAe5jB,EAAEmiB,QAAQ5jB,EAAEslB,YAAY3jB,EAAEgiB,MAAM3jB,EAAEulB,cAAc5jB,EAAEiiB,WAAU3jB,EAAEA,EAAEulB,eAAgBC,SAAShkB,EAAEkiB,KAAKliB,EAAEmiB,QAAQ5jB,EAAE0lB,kBAAkBhkB,EAAEF,GAAGxB,EAAE2lB,SAAS1lB,GAAGD,EAAEklB,OAAOvjB,EAAEgiB,KAAKhiB,EAAEiiB,UAAU3jB,EAAE2lB,OAAOjkB,EAAEgiB,KAAKhiB,EAAEiiB,QAAQ5jB,EAAE2lB,SAAS1lB,KAAU,IAALA,EAAE,GAAOD,EAAEE,EAAEF,EAAEA,EAAE0P,YAAY,IAAI1P,EAAE0K,UAAUzK,EAAEkQ,KAAK,CAAC0V,QAAQ7lB,EAAE8lB,KAAK9lB,EAAE+lB,WAAWC,IAAIhmB,EAAEimB,YAAmD,IAAvC,oBAAoB/lB,EAAEgmB,OAAOhmB,EAAEgmB,QAAYhmB,EAAE,EAAEA,EAAED,EAAEG,OAAOF,KAAIF,EAAEC,EAAEC,IAAK2lB,QAAQE,WAAW/lB,EAAE8lB,KAAK9lB,EAAE6lB,QAAQI,UAAUjmB,EAAEgmB,KACrf,IAAIG,GAAGvlB,GAAI,iBAAiBE,UAAU,IAAIA,SAASyf,aAAa6F,GAAG,KAAKC,GAAG,KAAKC,GAAG,KAAKC,IAAG,EAC3F,SAASC,GAAGxmB,EAAEC,EAAEC,GAAG,IAAIsB,EAAEtB,EAAEW,SAASX,EAAEA,EAAEY,SAAS,IAAIZ,EAAEwK,SAASxK,EAAEA,EAAEyI,cAAc4d,IAAI,MAAMH,IAAIA,KAAKxe,EAAGpG,KAAU,mBAALA,EAAE4kB,KAAyB/B,GAAG7iB,GAAGA,EAAE,CAACmjB,MAAMnjB,EAAEqjB,eAAeD,IAAIpjB,EAAEsjB,cAAuFtjB,EAAE,CAAC4jB,YAA3E5jB,GAAGA,EAAEmH,eAAenH,EAAEmH,cAAcqc,aAAankB,QAAQokB,gBAA+BG,WAAWC,aAAa7jB,EAAE6jB,aAAaC,UAAU9jB,EAAE8jB,UAAUC,YAAY/jB,EAAE+jB,aAAce,IAAI9C,GAAG8C,GAAG9kB,KAAK8kB,GAAG9kB,EAAsB,GAApBA,EAAEwgB,GAAGqE,GAAG,aAAgBjmB,SAASH,EAAE,IAAIua,GAAG,WAAW,SAAS,KAAKva,EAAEC,GAAGF,EAAEmQ,KAAK,CAAC8R,MAAMhiB,EAAEiiB,UAAU1gB,IAAIvB,EAAEsP,OAAO6W,MACjf,SAASK,GAAGzmB,EAAEC,GAAG,IAAIC,EAAE,GAAkF,OAA/EA,EAAEF,EAAEwC,eAAevC,EAAEuC,cAActC,EAAE,SAASF,GAAG,SAASC,EAAEC,EAAE,MAAMF,GAAG,MAAMC,EAASC,EAAE,IAAIwmB,GAAG,CAACC,aAAaF,GAAG,YAAY,gBAAgBG,mBAAmBH,GAAG,YAAY,sBAAsBI,eAAeJ,GAAG,YAAY,kBAAkBK,cAAcL,GAAG,aAAa,kBAAkBM,GAAG,GAAGC,GAAG,GACnF,SAASC,GAAGjnB,GAAG,GAAG+mB,GAAG/mB,GAAG,OAAO+mB,GAAG/mB,GAAG,IAAI0mB,GAAG1mB,GAAG,OAAOA,EAAE,IAAYE,EAARD,EAAEymB,GAAG1mB,GAAK,IAAIE,KAAKD,EAAE,GAAGA,EAAEkB,eAAejB,IAAIA,KAAK8mB,GAAG,OAAOD,GAAG/mB,GAAGC,EAAEC,GAAG,OAAOF,EAA9XY,IAAKomB,GAAGlmB,SAASC,cAAc,OAAO4M,MAAM,mBAAmB9M,gBAAgB6lB,GAAGC,aAAaO,iBAAiBR,GAAGE,mBAAmBM,iBAAiBR,GAAGG,eAAeK,WAAW,oBAAoBrmB,eAAe6lB,GAAGI,cAAc9O,YAAwJ,IAAImP,GAAGF,GAAG,gBAAgBG,GAAGH,GAAG,sBAAsBI,GAAGJ,GAAG,kBAAkBK,GAAGL,GAAG,iBAAiBM,GAAG,IAAIrR,IAAIsR,GAAG,smBAAsmBllB,MAAM,KAC/lC,SAASmlB,GAAGznB,EAAEC,GAAGsnB,GAAG9hB,IAAIzF,EAAEC,GAAGQ,EAAGR,EAAE,CAACD,IAAI,IAAI,IAAI0nB,GAAG,EAAEA,GAAGF,GAAGpnB,OAAOsnB,KAAK,CAAC,IAAIC,GAAGH,GAAGE,IAA2DD,GAApDE,GAAGnlB,cAAuD,MAAtCmlB,GAAG,GAAGhlB,cAAcglB,GAAG9kB,MAAM,KAAkB4kB,GAAGN,GAAG,kBAAkBM,GAAGL,GAAG,wBAAwBK,GAAGJ,GAAG,oBAAoBI,GAAG,WAAW,iBAAiBA,GAAG,UAAU,WAAWA,GAAG,WAAW,UAAUA,GAAGH,GAAG,mBAAmB5mB,EAAG,eAAe,CAAC,WAAW,cAAcA,EAAG,eAAe,CAAC,WAAW,cAAcA,EAAG,iBAAiB,CAAC,aAAa,gBAC7cA,EAAG,iBAAiB,CAAC,aAAa,gBAAgBD,EAAG,WAAW,oEAAoE6B,MAAM,MAAM7B,EAAG,WAAW,uFAAuF6B,MAAM,MAAM7B,EAAG,gBAAgB,CAAC,iBAAiB,WAAW,YAAY,UAAUA,EAAG,mBAAmB,2DAA2D6B,MAAM,MAAM7B,EAAG,qBAAqB,6DAA6D6B,MAAM,MAC/f7B,EAAG,sBAAsB,8DAA8D6B,MAAM,MAAM,IAAIslB,GAAG,6NAA6NtlB,MAAM,KAAKulB,GAAG,IAAItnB,IAAI,0CAA0C+B,MAAM,KAAKwlB,OAAOF,KACzZ,SAASG,GAAG/nB,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAEkC,MAAM,gBAAgBlC,EAAEoZ,cAAclZ,EAlDjE,SAAYF,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,EAAEkE,EAAEC,GAA4B,GAAzByL,GAAGR,MAAMnP,KAAKzB,WAAc+Q,GAAG,CAAC,IAAGA,GAAgC,MAAMjM,MAAMlF,EAAE,MAA1C,IAAI6F,EAAEuL,GAAGD,IAAG,EAAGC,GAAG,KAA8BC,KAAKA,IAAG,EAAGC,GAAGzL,IAkDjEoiB,CAAGxmB,EAAEvB,OAAE,EAAOD,GAAGA,EAAEoZ,cAAc,KACpG,SAASkJ,GAAGtiB,EAAEC,GAAGA,EAAE,KAAO,EAAFA,GAAK,IAAI,IAAIC,EAAE,EAAEA,EAAEF,EAAEI,OAAOF,IAAI,CAAC,IAAIsB,EAAExB,EAAEE,GAAGuB,EAAED,EAAEygB,MAAMzgB,EAAEA,EAAE0gB,UAAUliB,EAAE,CAAC,IAAI0B,OAAE,EAAO,GAAGzB,EAAE,IAAI,IAAI0B,EAAEH,EAAEpB,OAAO,EAAE,GAAGuB,EAAEA,IAAI,CAAC,IAAIkE,EAAErE,EAAEG,GAAGmE,EAAED,EAAEoiB,SAASriB,EAAEC,EAAEuT,cAA2B,GAAbvT,EAAEA,EAAEqiB,SAAYpiB,IAAIpE,GAAGD,EAAE+X,uBAAuB,MAAMxZ,EAAE+nB,GAAGtmB,EAAEoE,EAAED,GAAGlE,EAAEoE,OAAO,IAAInE,EAAE,EAAEA,EAAEH,EAAEpB,OAAOuB,IAAI,CAAoD,GAA5CmE,GAAPD,EAAErE,EAAEG,IAAOsmB,SAASriB,EAAEC,EAAEuT,cAAcvT,EAAEA,EAAEqiB,SAAYpiB,IAAIpE,GAAGD,EAAE+X,uBAAuB,MAAMxZ,EAAE+nB,GAAGtmB,EAAEoE,EAAED,GAAGlE,EAAEoE,IAAI,GAAGsL,GAAG,MAAMpR,EAAEqR,GAAGD,IAAG,EAAGC,GAAG,KAAKrR,EAC1a,SAASmoB,GAAEnoB,EAAEC,GAAG,IAAIC,EAAED,EAAEmoB,SAAI,IAASloB,IAAIA,EAAED,EAAEmoB,IAAI,IAAI7nB,KAAK,IAAIiB,EAAExB,EAAE,WAAWE,EAAEmoB,IAAI7mB,KAAK8mB,GAAGroB,EAAED,EAAE,GAAE,GAAIE,EAAES,IAAIa,IAAI,SAAS+mB,GAAGvoB,EAAEC,EAAEC,GAAG,IAAIsB,EAAE,EAAEvB,IAAIuB,GAAG,GAAG8mB,GAAGpoB,EAAEF,EAAEwB,EAAEvB,GAAG,IAAIuoB,GAAG,kBAAkBzU,KAAK0U,SAASve,SAAS,IAAIrH,MAAM,GAAG,SAAS6lB,GAAG1oB,GAAG,IAAIA,EAAEwoB,IAAI,CAACxoB,EAAEwoB,KAAI,EAAGloB,EAAGiC,SAAQ,SAAStC,GAAG,oBAAoBA,IAAI4nB,GAAGQ,IAAIpoB,IAAIsoB,GAAGtoB,GAAE,EAAGD,GAAGuoB,GAAGtoB,GAAE,EAAGD,OAAM,IAAIC,EAAE,IAAID,EAAE0K,SAAS1K,EAAEA,EAAE2I,cAAc,OAAO1I,GAAGA,EAAEuoB,MAAMvoB,EAAEuoB,KAAI,EAAGD,GAAG,mBAAkB,EAAGtoB,KAC7a,SAASqoB,GAAGtoB,EAAEC,EAAEC,EAAEsB,GAAG,OAAO+W,GAAGtY,IAAI,KAAK,EAAE,IAAIwB,EAAEsW,GAAG,MAAM,KAAK,EAAEtW,EAAEyW,GAAG,MAAM,QAAQzW,EAAEwW,GAAG/X,EAAEuB,EAAEknB,KAAK,KAAK1oB,EAAEC,EAAEF,GAAGyB,OAAE,GAAQiP,IAAI,eAAezQ,GAAG,cAAcA,GAAG,UAAUA,IAAIwB,GAAE,GAAID,OAAE,IAASC,EAAEzB,EAAE4Q,iBAAiB3Q,EAAEC,EAAE,CAAC0oB,SAAQ,EAAGC,QAAQpnB,IAAIzB,EAAE4Q,iBAAiB3Q,EAAEC,GAAE,QAAI,IAASuB,EAAEzB,EAAE4Q,iBAAiB3Q,EAAEC,EAAE,CAAC2oB,QAAQpnB,IAAIzB,EAAE4Q,iBAAiB3Q,EAAEC,GAAE,GAC/U,SAASiY,GAAGnY,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,IAAIC,EAAEF,EAAE,GAAG,KAAO,EAAFvB,IAAM,KAAO,EAAFA,IAAM,OAAOuB,EAAExB,EAAE,OAAO,CAAC,GAAG,OAAOwB,EAAE,OAAO,IAAIG,EAAEH,EAAE2E,IAAI,GAAG,IAAIxE,GAAG,IAAIA,EAAE,CAAC,IAAIkE,EAAErE,EAAEwO,UAAUmH,cAAc,GAAGtR,IAAIpE,GAAG,IAAIoE,EAAE6E,UAAU7E,EAAE6J,aAAajO,EAAE,MAAM,GAAG,IAAIE,EAAE,IAAIA,EAAEH,EAAEkQ,OAAO,OAAO/P,GAAG,CAAC,IAAImE,EAAEnE,EAAEwE,IAAI,IAAG,IAAIL,GAAG,IAAIA,MAAKA,EAAEnE,EAAEqO,UAAUmH,iBAAkB1V,GAAG,IAAIqE,EAAE4E,UAAU5E,EAAE4J,aAAajO,GAAE,OAAOE,EAAEA,EAAE+P,OAAO,KAAK,OAAO7L,GAAG,CAAS,GAAG,QAAXlE,EAAEqV,GAAGnR,IAAe,OAAe,GAAG,KAAXC,EAAEnE,EAAEwE,MAAc,IAAIL,EAAE,CAACtE,EAAEE,EAAEC,EAAE,SAAS3B,EAAE6F,EAAEA,EAAE6J,YAAYlO,EAAEA,EAAEkQ,OAAOlB,IAAG,WAAW,IAAIhP,EAAEE,EAAED,EAAE6N,GAAGpP,GAAGyB,EAAE,GACpf3B,EAAE,CAAC,IAAI6F,EAAE0hB,GAAGrgB,IAAIlH,GAAG,QAAG,IAAS6F,EAAE,CAAC,IAAIC,EAAE0U,GAAGsO,EAAE9oB,EAAE,OAAOA,GAAG,IAAK,WAAW,GAAG,IAAI4Y,GAAG1Y,GAAG,MAAMF,EAAE,IAAK,UAAU,IAAK,QAAQ8F,EAAE6Y,GAAG,MAAM,IAAK,UAAUmK,EAAE,QAAQhjB,EAAEsW,GAAG,MAAM,IAAK,WAAW0M,EAAE,OAAOhjB,EAAEsW,GAAG,MAAM,IAAK,aAAa,IAAK,YAAYtW,EAAEsW,GAAG,MAAM,IAAK,QAAQ,GAAG,IAAIlc,EAAEwb,OAAO,MAAM1b,EAAE,IAAK,WAAW,IAAK,WAAW,IAAK,YAAY,IAAK,YAAY,IAAK,UAAU,IAAK,WAAW,IAAK,YAAY,IAAK,cAAc8F,EAAEmW,GAAG,MAAM,IAAK,OAAO,IAAK,UAAU,IAAK,YAAY,IAAK,WAAW,IAAK,YAAY,IAAK,WAAW,IAAK,YAAY,IAAK,OAAOnW,EAC1iBoW,GAAG,MAAM,IAAK,cAAc,IAAK,WAAW,IAAK,YAAY,IAAK,aAAapW,EAAEwZ,GAAG,MAAM,KAAK6H,GAAG,KAAKC,GAAG,KAAKC,GAAGvhB,EAAEuW,GAAG,MAAM,KAAKiL,GAAGxhB,EAAE4Z,GAAG,MAAM,IAAK,SAAS5Z,EAAE8U,GAAG,MAAM,IAAK,QAAQ9U,EAAEqa,GAAG,MAAM,IAAK,OAAO,IAAK,MAAM,IAAK,QAAQra,EAAE6W,GAAG,MAAM,IAAK,oBAAoB,IAAK,qBAAqB,IAAK,gBAAgB,IAAK,cAAc,IAAK,cAAc,IAAK,aAAa,IAAK,cAAc,IAAK,YAAY7W,EAAE8Y,GAAG,IAAImK,EAAE,KAAO,EAAF9oB,GAAK+oB,GAAGD,GAAG,WAAW/oB,EAAEipB,EAAEF,EAAE,OAAOljB,EAAEA,EAAE,UAAU,KAAKA,EAAEkjB,EAAE,GAAG,IAAI,IAAQG,EAAJC,EAAE3nB,EAAI,OAC/e2nB,GAAG,CAAK,IAAIC,GAARF,EAAEC,GAAUnZ,UAAsF,GAA5E,IAAIkZ,EAAE/iB,KAAK,OAAOijB,IAAIF,EAAEE,EAAE,OAAOH,IAAc,OAAVG,EAAE3Y,GAAG0Y,EAAEF,KAAYF,EAAE5Y,KAAKkZ,GAAGF,EAAEC,EAAEF,MAASF,EAAE,MAAMG,EAAEA,EAAEzX,OAAO,EAAEqX,EAAE3oB,SAASyF,EAAE,IAAIC,EAAED,EAAEijB,EAAE,KAAK5oB,EAAEuB,GAAGE,EAAEwO,KAAK,CAAC8R,MAAMpc,EAAEqc,UAAU6G,MAAM,GAAG,KAAO,EAAF9oB,GAAK,CAA4E,GAAnC6F,EAAE,aAAa9F,GAAG,eAAeA,KAAtE6F,EAAE,cAAc7F,GAAG,gBAAgBA,IAA2CE,IAAImP,MAAKyZ,EAAE5oB,EAAE0b,eAAe1b,EAAE2b,eAAe7E,GAAG8R,KAAIA,EAAEQ,OAAgBxjB,GAAGD,KAAGA,EAAEpE,EAAEZ,SAASY,EAAEA,GAAGoE,EAAEpE,EAAEkH,eAAe9C,EAAEmf,aAAanf,EAAE0jB,aAAa1oB,OAAUiF,GAAqCA,EAAEtE,EAAiB,QAAfsnB,GAAnCA,EAAE5oB,EAAE0b,eAAe1b,EAAE4b,WAAkB9E,GAAG8R,GAAG,QAC9dA,KAARE,EAAExX,GAAGsX,KAAU,IAAIA,EAAE3iB,KAAK,IAAI2iB,EAAE3iB,OAAK2iB,EAAE,QAAUhjB,EAAE,KAAKgjB,EAAEtnB,GAAKsE,IAAIgjB,GAAE,CAAgU,GAA/TC,EAAE9M,GAAGmN,EAAE,eAAeH,EAAE,eAAeE,EAAE,QAAW,eAAenpB,GAAG,gBAAgBA,IAAE+oB,EAAEnK,GAAGwK,EAAE,iBAAiBH,EAAE,iBAAiBE,EAAE,WAAUH,EAAE,MAAMljB,EAAED,EAAE2c,GAAG1c,GAAGojB,EAAE,MAAMJ,EAAEjjB,EAAE2c,GAAGsG,IAAGjjB,EAAE,IAAIkjB,EAAEK,EAAED,EAAE,QAAQrjB,EAAE5F,EAAEuB,IAAK8N,OAAOyZ,EAAEnjB,EAAE+V,cAAcsN,EAAEE,EAAE,KAAKpS,GAAGvV,KAAKD,KAAIunB,EAAE,IAAIA,EAAEE,EAAEE,EAAE,QAAQL,EAAE5oB,EAAEuB,IAAK8N,OAAO2Z,EAAEH,EAAEnN,cAAcoN,EAAEI,EAAEL,GAAGC,EAAEI,EAAKtjB,GAAGgjB,EAAE7oB,EAAE,CAAa,IAARgpB,EAAEH,EAAEK,EAAE,EAAMD,EAAhBH,EAAEjjB,EAAkBojB,EAAEA,EAAEM,GAAGN,GAAGC,IAAQ,IAAJD,EAAE,EAAME,EAAEH,EAAEG,EAAEA,EAAEI,GAAGJ,GAAGF,IAAI,KAAK,EAAEC,EAAED,GAAGH,EAAES,GAAGT,GAAGI,IAAI,KAAK,EAAED,EAAEC,GAAGF,EACpfO,GAAGP,GAAGC,IAAI,KAAKC,KAAK,CAAC,GAAGJ,IAAIE,GAAG,OAAOA,GAAGF,IAAIE,EAAExX,UAAU,MAAMxR,EAAE8oB,EAAES,GAAGT,GAAGE,EAAEO,GAAGP,GAAGF,EAAE,UAAUA,EAAE,KAAK,OAAOjjB,GAAG2jB,GAAG9nB,EAAEkE,EAAEC,EAAEijB,GAAE,GAAI,OAAOD,GAAG,OAAOE,GAAGS,GAAG9nB,EAAEqnB,EAAEF,EAAEC,GAAE,GAAiE,GAAG,YAA1CjjB,GAAjBD,EAAErE,EAAEghB,GAAGhhB,GAAGX,QAAWgG,UAAUhB,EAAEgB,SAASrE,gBAA+B,UAAUsD,GAAG,SAASD,EAAE3D,KAAK,IAAIwnB,EAAGjH,QAAQ,GAAGX,GAAGjc,GAAG,GAAG6c,GAAGgH,EAAGpG,OAAO,CAACoG,EAAGtG,GAAG,IAAIuG,EAAGzG,QAAQpd,EAAED,EAAEgB,WAAW,UAAUf,EAAEtD,gBAAgB,aAAaqD,EAAE3D,MAAM,UAAU2D,EAAE3D,QAAQwnB,EAAGrG,IACrV,OAD4VqG,IAAKA,EAAGA,EAAG1pB,EAAEwB,IAAKugB,GAAGpgB,EAAE+nB,EAAGxpB,EAAEuB,IAAWkoB,GAAIA,EAAG3pB,EAAE6F,EAAErE,GAAG,aAAaxB,IAAI2pB,EAAG9jB,EAAEqC,gBAClfyhB,EAAGrhB,YAAY,WAAWzC,EAAE3D,MAAMuG,GAAG5C,EAAE,SAASA,EAAE8B,QAAOgiB,EAAGnoB,EAAEghB,GAAGhhB,GAAGX,OAAcb,GAAG,IAAK,WAAa8hB,GAAG6H,IAAK,SAASA,EAAGrF,mBAAgB8B,GAAGuD,EAAGtD,GAAG7kB,EAAE8kB,GAAG,MAAK,MAAM,IAAK,WAAWA,GAAGD,GAAGD,GAAG,KAAK,MAAM,IAAK,YAAYG,IAAG,EAAG,MAAM,IAAK,cAAc,IAAK,UAAU,IAAK,UAAUA,IAAG,EAAGC,GAAG7kB,EAAEzB,EAAEuB,GAAG,MAAM,IAAK,kBAAkB,GAAG0kB,GAAG,MAAM,IAAK,UAAU,IAAK,QAAQK,GAAG7kB,EAAEzB,EAAEuB,GAAG,IAAImoB,EAAG,GAAGvJ,GAAGpgB,EAAE,CAAC,OAAOD,GAAG,IAAK,mBAAmB,IAAI6pB,EAAG,qBAAqB,MAAM5pB,EAAE,IAAK,iBAAiB4pB,EAAG,mBACpe,MAAM5pB,EAAE,IAAK,oBAAoB4pB,EAAG,sBAAsB,MAAM5pB,EAAE4pB,OAAG,OAAY/I,GAAGF,GAAG5gB,EAAEE,KAAK2pB,EAAG,oBAAoB,YAAY7pB,GAAG,MAAME,EAAE2Y,UAAUgR,EAAG,sBAAsBA,IAAKpJ,IAAI,OAAOvgB,EAAEue,SAASqC,IAAI,uBAAuB+I,EAAG,qBAAqBA,GAAI/I,KAAK8I,EAAGjR,OAAYF,GAAG,UAARD,GAAG/W,GAAkB+W,GAAG7Q,MAAM6Q,GAAG9O,YAAYoX,IAAG,IAAiB,GAAZ6I,EAAG3H,GAAGxgB,EAAEqoB,IAASzpB,SAASypB,EAAG,IAAIjN,GAAGiN,EAAG7pB,EAAE,KAAKE,EAAEuB,GAAGE,EAAEwO,KAAK,CAAC8R,MAAM4H,EAAG3H,UAAUyH,IAAKC,EAAGC,EAAGhN,KAAK+M,EAAa,QAATA,EAAG/I,GAAG3gB,MAAe2pB,EAAGhN,KAAK+M,MAAUA,EAAGpJ,GA5BhM,SAAYxgB,EAAEC,GAAG,OAAOD,GAAG,IAAK,iBAAiB,OAAO6gB,GAAG5gB,GAAG,IAAK,WAAW,OAAG,KAAKA,EAAEye,MAAa,MAAKiC,IAAG,EAAUD,IAAG,IAAK,YAAY,OAAO1gB,EAAEC,EAAE4c,QAAS6D,IAAIC,GAAG,KAAK3gB,EAAE,QAAQ,OAAO,MA4BO8pB,CAAG9pB,EAAEE,GA3Bzd,SAAYF,EAAEC,GAAG,GAAG6gB,GAAG,MAAM,mBAAmB9gB,IAAIqgB,IAAIO,GAAG5gB,EAAEC,IAAID,EAAE2Y,KAAKD,GAAGD,GAAGD,GAAG,KAAKsI,IAAG,EAAG9gB,GAAG,KAAK,OAAOA,GAAG,IAAK,QAAgQ,QAAQ,OAAO,KAA3P,IAAK,WAAW,KAAKC,EAAEmb,SAASnb,EAAEqb,QAAQrb,EAAEsb,UAAUtb,EAAEmb,SAASnb,EAAEqb,OAAO,CAAC,GAAGrb,EAAE8pB,MAAM,EAAE9pB,EAAE8pB,KAAK3pB,OAAO,OAAOH,EAAE8pB,KAAK,GAAG9pB,EAAEye,MAAM,OAAON,OAAOC,aAAape,EAAEye,OAAO,OAAO,KAAK,IAAK,iBAAiB,OAAO+B,IAAI,OAAOxgB,EAAEwe,OAAO,KAAKxe,EAAE4c,MA2B8GmN,CAAGhqB,EAAEE,MACje,GADoesB,EAAEwgB,GAAGxgB,EAAE,kBACvepB,SAASqB,EAAE,IAAImb,GAAG,gBAAgB,cAAc,KAAK1c,EAAEuB,GAAGE,EAAEwO,KAAK,CAAC8R,MAAMxgB,EAAEygB,UAAU1gB,IAAIC,EAAEob,KAAK+M,IAAItH,GAAG3gB,EAAE1B,MAAK,SAASopB,GAAGrpB,EAAEC,EAAEC,GAAG,MAAM,CAAC+nB,SAASjoB,EAAEkoB,SAASjoB,EAAEmZ,cAAclZ,GAAG,SAAS8hB,GAAGhiB,EAAEC,GAAG,IAAI,IAAIC,EAAED,EAAE,UAAUuB,EAAE,GAAG,OAAOxB,GAAG,CAAC,IAAIyB,EAAEzB,EAAE0B,EAAED,EAAEuO,UAAU,IAAIvO,EAAE0E,KAAK,OAAOzE,IAAID,EAAEC,EAAY,OAAVA,EAAE+O,GAAGzQ,EAAEE,KAAYsB,EAAEyoB,QAAQZ,GAAGrpB,EAAE0B,EAAED,IAAc,OAAVC,EAAE+O,GAAGzQ,EAAEC,KAAYuB,EAAE2O,KAAKkZ,GAAGrpB,EAAE0B,EAAED,KAAKzB,EAAEA,EAAE0R,OAAO,OAAOlQ,EAAE,SAASgoB,GAAGxpB,GAAG,GAAG,OAAOA,EAAE,OAAO,KAAK,GAAGA,EAAEA,EAAE0R,aAAa1R,GAAG,IAAIA,EAAEmG,KAAK,OAAOnG,GAAI,KAC/c,SAASypB,GAAGzpB,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,IAAI,IAAIC,EAAEzB,EAAEiZ,WAAWvX,EAAE,GAAG,OAAOzB,GAAGA,IAAIsB,GAAG,CAAC,IAAIqE,EAAE3F,EAAE4F,EAAED,EAAE4L,UAAU7L,EAAEC,EAAEmK,UAAU,GAAG,OAAOlK,GAAGA,IAAItE,EAAE,MAAM,IAAIqE,EAAEM,KAAK,OAAOP,IAAIC,EAAED,EAAEnE,EAAa,OAAVqE,EAAE2K,GAAGvQ,EAAEwB,KAAYC,EAAEsoB,QAAQZ,GAAGnpB,EAAE4F,EAAED,IAAKpE,GAAc,OAAVqE,EAAE2K,GAAGvQ,EAAEwB,KAAYC,EAAEwO,KAAKkZ,GAAGnpB,EAAE4F,EAAED,KAAM3F,EAAEA,EAAEwR,OAAO,IAAI/P,EAAEvB,QAAQJ,EAAEmQ,KAAK,CAAC8R,MAAMhiB,EAAEiiB,UAAUvgB,IAAI,IAAIuoB,GAAG,SAASC,GAAG,iBAAiB,SAASC,GAAGpqB,GAAG,OAAO,kBAAkBA,EAAEA,EAAE,GAAGA,GAAGuD,QAAQ2mB,GAAG,MAAM3mB,QAAQ4mB,GAAG,IAAI,SAASE,GAAGrqB,EAAEC,EAAEC,GAAW,GAARD,EAAEmqB,GAAGnqB,GAAMmqB,GAAGpqB,KAAKC,GAAGC,EAAE,MAAM+E,MAAMlF,EAAE,MAAO,SAASuqB,MACze,IAAIC,GAAG,KAAKC,GAAG,KAAK,SAASC,GAAGzqB,EAAEC,GAAG,MAAM,aAAaD,GAAG,aAAaA,GAAG,kBAAkBC,EAAEqJ,UAAU,kBAAkBrJ,EAAEqJ,UAAU,kBAAkBrJ,EAAEoJ,yBAAyB,OAAOpJ,EAAEoJ,yBAAyB,MAAMpJ,EAAEoJ,wBAAwBqhB,OACtP,IAAIC,GAAG,oBAAoBC,WAAWA,gBAAW,EAAOC,GAAG,oBAAoBC,aAAaA,kBAAa,EAAOC,GAAG,oBAAoBC,QAAQA,aAAQ,EAAOC,GAAG,oBAAoBC,eAAeA,eAAe,qBAAqBH,GAAG,SAAS/qB,GAAG,OAAO+qB,GAAGI,QAAQ,MAAMC,KAAKprB,GAAGqrB,MAAMC,KAAKX,GAAG,SAASW,GAAGtrB,GAAG4qB,YAAW,WAAW,MAAM5qB,KAChV,SAASurB,GAAGvrB,EAAEC,GAAG,IAAIC,EAAED,EAAEuB,EAAE,EAAE,EAAE,CAAC,IAAIC,EAAEvB,EAAE2jB,YAA6B,GAAjB7jB,EAAEoK,YAAYlK,GAAMuB,GAAG,IAAIA,EAAEiJ,SAAS,GAAY,QAATxK,EAAEuB,EAAEob,MAAc,CAAC,GAAG,IAAIrb,EAA0B,OAAvBxB,EAAEoK,YAAY3I,QAAGkW,GAAG1X,GAAUuB,QAAQ,MAAMtB,GAAG,OAAOA,GAAG,OAAOA,GAAGsB,IAAItB,EAAEuB,QAAQvB,GAAGyX,GAAG1X,GAAG,SAASurB,GAAGxrB,GAAG,KAAK,MAAMA,EAAEA,EAAEA,EAAE6jB,YAAY,CAAC,IAAI5jB,EAAED,EAAE0K,SAAS,GAAG,IAAIzK,GAAG,IAAIA,EAAE,MAAM,GAAG,IAAIA,EAAE,CAAU,GAAG,OAAZA,EAAED,EAAE6c,OAAiB,OAAO5c,GAAG,OAAOA,EAAE,MAAM,GAAG,OAAOA,EAAE,OAAO,MAAM,OAAOD,EAChY,SAASyrB,GAAGzrB,GAAGA,EAAEA,EAAE0rB,gBAAgB,IAAI,IAAIzrB,EAAE,EAAED,GAAG,CAAC,GAAG,IAAIA,EAAE0K,SAAS,CAAC,IAAIxK,EAAEF,EAAE6c,KAAK,GAAG,MAAM3c,GAAG,OAAOA,GAAG,OAAOA,EAAE,CAAC,GAAG,IAAID,EAAE,OAAOD,EAAEC,QAAQ,OAAOC,GAAGD,IAAID,EAAEA,EAAE0rB,gBAAgB,OAAO,KAAK,IAAIC,GAAG5X,KAAK0U,SAASve,SAAS,IAAIrH,MAAM,GAAG+oB,GAAG,gBAAgBD,GAAGE,GAAG,gBAAgBF,GAAGrC,GAAG,oBAAoBqC,GAAGvD,GAAG,iBAAiBuD,GAAGG,GAAG,oBAAoBH,GAAGI,GAAG,kBAAkBJ,GAClX,SAAS3U,GAAGhX,GAAG,IAAIC,EAAED,EAAE4rB,IAAI,GAAG3rB,EAAE,OAAOA,EAAE,IAAI,IAAIC,EAAEF,EAAE0P,WAAWxP,GAAG,CAAC,GAAGD,EAAEC,EAAEopB,KAAKppB,EAAE0rB,IAAI,CAAe,GAAd1rB,EAAED,EAAEwR,UAAa,OAAOxR,EAAEgS,OAAO,OAAO/R,GAAG,OAAOA,EAAE+R,MAAM,IAAIjS,EAAEyrB,GAAGzrB,GAAG,OAAOA,GAAG,CAAC,GAAGE,EAAEF,EAAE4rB,IAAI,OAAO1rB,EAAEF,EAAEyrB,GAAGzrB,GAAG,OAAOC,EAAMC,GAAJF,EAAEE,GAAMwP,WAAW,OAAO,KAAK,SAASK,GAAG/P,GAAkB,QAAfA,EAAEA,EAAE4rB,KAAK5rB,EAAEspB,MAAc,IAAItpB,EAAEmG,KAAK,IAAInG,EAAEmG,KAAK,KAAKnG,EAAEmG,KAAK,IAAInG,EAAEmG,IAAI,KAAKnG,EAAE,SAASwiB,GAAGxiB,GAAG,GAAG,IAAIA,EAAEmG,KAAK,IAAInG,EAAEmG,IAAI,OAAOnG,EAAEgQ,UAAU,MAAM/K,MAAMlF,EAAE,KAAM,SAASkQ,GAAGjQ,GAAG,OAAOA,EAAE6rB,KAAK,KAAK,IAAIG,GAAG,GAAGC,IAAI,EAAE,SAASC,GAAGlsB,GAAG,MAAM,CAACmS,QAAQnS,GACre,SAASmsB,GAAEnsB,GAAG,EAAEisB,KAAKjsB,EAAEmS,QAAQ6Z,GAAGC,IAAID,GAAGC,IAAI,KAAKA,MAAM,SAASG,GAAEpsB,EAAEC,GAAGgsB,KAAKD,GAAGC,IAAIjsB,EAAEmS,QAAQnS,EAAEmS,QAAQlS,EAAE,IAAIosB,GAAG,GAAGC,GAAEJ,GAAGG,IAAIE,GAAGL,IAAG,GAAIM,GAAGH,GAAG,SAASI,GAAGzsB,EAAEC,GAAG,IAAIC,EAAEF,EAAEkC,KAAKwqB,aAAa,IAAIxsB,EAAE,OAAOmsB,GAAG,IAAI7qB,EAAExB,EAAEgQ,UAAU,GAAGxO,GAAGA,EAAEmrB,8CAA8C1sB,EAAE,OAAOuB,EAAEorB,0CAA0C,IAASlrB,EAALD,EAAE,GAAK,IAAIC,KAAKxB,EAAEuB,EAAEC,GAAGzB,EAAEyB,GAAoH,OAAjHF,KAAIxB,EAAEA,EAAEgQ,WAAY2c,4CAA4C1sB,EAAED,EAAE4sB,0CAA0CnrB,GAAUA,EAC7d,SAASorB,GAAG7sB,GAAyB,OAAO,QAA7BA,EAAEA,EAAE8sB,yBAAmC,IAAS9sB,EAAE,SAAS+sB,KAAKZ,GAAEI,IAAIJ,GAAEG,IAAG,SAASU,GAAGhtB,EAAEC,EAAEC,GAAG,GAAGosB,GAAEna,UAAUka,GAAG,MAAMpnB,MAAMlF,EAAE,MAAMqsB,GAAEE,GAAErsB,GAAGmsB,GAAEG,GAAGrsB,GAAG,SAAS+sB,GAAGjtB,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAEgQ,UAAgC,GAAtB/P,EAAEA,EAAE6sB,kBAAqB,oBAAoBtrB,EAAE0rB,gBAAgB,OAAOhtB,EAAwB,IAAI,IAAIuB,KAA9BD,EAAEA,EAAE0rB,kBAAiC,KAAKzrB,KAAKxB,GAAG,MAAMgF,MAAMlF,EAAE,IAAI2G,EAAG1G,IAAI,UAAUyB,IAAI,OAAOqD,EAAE,GAAG5E,EAAEsB,GACtX,SAAS2rB,GAAGntB,GAA2G,OAAxGA,GAAGA,EAAEA,EAAEgQ,YAAYhQ,EAAEotB,2CAA2Cf,GAAGG,GAAGF,GAAEna,QAAQia,GAAEE,GAAEtsB,GAAGosB,GAAEG,GAAGA,GAAGpa,UAAe,EAAG,SAASkb,GAAGrtB,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAEgQ,UAAU,IAAIxO,EAAE,MAAMyD,MAAMlF,EAAE,MAAMG,GAAGF,EAAEitB,GAAGjtB,EAAEC,EAAEusB,IAAIhrB,EAAE4rB,0CAA0CptB,EAAEmsB,GAAEI,IAAIJ,GAAEG,IAAGF,GAAEE,GAAEtsB,IAAImsB,GAAEI,IAAIH,GAAEG,GAAGrsB,GAAG,IAAIotB,GAAG,KAAKC,IAAG,EAAGC,IAAG,EAAG,SAASC,GAAGztB,GAAG,OAAOstB,GAAGA,GAAG,CAACttB,GAAGstB,GAAGnd,KAAKnQ,GAC9V,SAAS0tB,KAAK,IAAIF,IAAI,OAAOF,GAAG,CAACE,IAAG,EAAG,IAAIxtB,EAAE,EAAEC,EAAEoV,GAAE,IAAI,IAAInV,EAAEotB,GAAG,IAAIjY,GAAE,EAAErV,EAAEE,EAAEE,OAAOJ,IAAI,CAAC,IAAIwB,EAAEtB,EAAEF,GAAG,GAAGwB,EAAEA,GAAE,SAAU,OAAOA,GAAG8rB,GAAG,KAAKC,IAAG,EAAG,MAAM9rB,GAAG,MAAM,OAAO6rB,KAAKA,GAAGA,GAAGzqB,MAAM7C,EAAE,IAAIsS,GAAGY,GAAGwa,IAAIjsB,EAAhJ,QAA2J4T,GAAEpV,EAAEutB,IAAG,GAAI,OAAO,KAAK,IAAIG,GAAG,GAAGC,GAAG,EAAEC,GAAG,KAAKC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,KAAKC,GAAG,EAAEC,GAAG,GAAG,SAASC,GAAGpuB,EAAEC,GAAG0tB,GAAGC,MAAME,GAAGH,GAAGC,MAAMC,GAAGA,GAAG7tB,EAAE8tB,GAAG7tB,EAChV,SAASouB,GAAGruB,EAAEC,EAAEC,GAAG6tB,GAAGC,MAAME,GAAGH,GAAGC,MAAMG,GAAGJ,GAAGC,MAAMC,GAAGA,GAAGjuB,EAAE,IAAIwB,EAAE0sB,GAAGluB,EAAEmuB,GAAG,IAAI1sB,EAAE,GAAGqS,GAAGtS,GAAG,EAAEA,KAAK,GAAGC,GAAGvB,GAAG,EAAE,IAAIwB,EAAE,GAAGoS,GAAG7T,GAAGwB,EAAE,GAAG,GAAGC,EAAE,CAAC,IAAIC,EAAEF,EAAEA,EAAE,EAAEC,GAAGF,GAAG,GAAGG,GAAG,GAAGuI,SAAS,IAAI1I,IAAIG,EAAEF,GAAGE,EAAEusB,GAAG,GAAG,GAAGpa,GAAG7T,GAAGwB,EAAEvB,GAAGuB,EAAED,EAAE2sB,GAAGzsB,EAAE1B,OAAOkuB,GAAG,GAAGxsB,EAAExB,GAAGuB,EAAED,EAAE2sB,GAAGnuB,EAAE,SAASsuB,GAAGtuB,GAAG,OAAOA,EAAE0R,SAAS0c,GAAGpuB,EAAE,GAAGquB,GAAGruB,EAAE,EAAE,IAAI,SAASuuB,GAAGvuB,GAAG,KAAKA,IAAI6tB,IAAIA,GAAGF,KAAKC,IAAID,GAAGC,IAAI,KAAKE,GAAGH,KAAKC,IAAID,GAAGC,IAAI,KAAK,KAAK5tB,IAAIiuB,IAAIA,GAAGF,KAAKC,IAAID,GAAGC,IAAI,KAAKG,GAAGJ,KAAKC,IAAID,GAAGC,IAAI,KAAKE,GAAGH,KAAKC,IAAID,GAAGC,IAAI,KAAK,IAAIQ,GAAG,KAAKC,GAAG,KAAKC,IAAE,EAAGC,GAAG,KACje,SAASC,GAAG5uB,EAAEC,GAAG,IAAIC,EAAE2uB,GAAG,EAAE,KAAK,KAAK,GAAG3uB,EAAE4uB,YAAY,UAAU5uB,EAAE8P,UAAU/P,EAAEC,EAAEwR,OAAO1R,EAAgB,QAAdC,EAAED,EAAE+uB,YAAoB/uB,EAAE+uB,UAAU,CAAC7uB,GAAGF,EAAE2R,OAAO,IAAI1R,EAAEkQ,KAAKjQ,GACtJ,SAAS8uB,GAAGhvB,EAAEC,GAAG,OAAOD,EAAEmG,KAAK,KAAK,EAAE,IAAIjG,EAAEF,EAAEkC,KAAyE,OAAO,QAA3EjC,EAAE,IAAIA,EAAEyK,UAAUxK,EAAEsC,gBAAgBvC,EAAE4G,SAASrE,cAAc,KAAKvC,KAAmBD,EAAEgQ,UAAU/P,EAAEuuB,GAAGxuB,EAAEyuB,GAAGjD,GAAGvrB,EAAEkK,aAAY,GAAO,KAAK,EAAE,OAAoD,QAA7ClK,EAAE,KAAKD,EAAEivB,cAAc,IAAIhvB,EAAEyK,SAAS,KAAKzK,KAAYD,EAAEgQ,UAAU/P,EAAEuuB,GAAGxuB,EAAEyuB,GAAG,MAAK,GAAO,KAAK,GAAG,OAA+B,QAAxBxuB,EAAE,IAAIA,EAAEyK,SAAS,KAAKzK,KAAYC,EAAE,OAAO+tB,GAAG,CAAC7V,GAAG8V,GAAGgB,SAASf,IAAI,KAAKnuB,EAAE6R,cAAc,CAACC,WAAW7R,EAAEkvB,YAAYjvB,EAAEkvB,UAAU,aAAYlvB,EAAE2uB,GAAG,GAAG,KAAK,KAAK,IAAK7e,UAAU/P,EAAEC,EAAEwR,OAAO1R,EAAEA,EAAEiS,MAAM/R,EAAEsuB,GAAGxuB,EAAEyuB,GAClf,MAAK,GAAO,QAAQ,OAAM,GAAI,SAASY,GAAGrvB,GAAG,OAAO,KAAY,EAAPA,EAAEsvB,OAAS,KAAa,IAARtvB,EAAE2R,OAAW,SAAS4d,GAAGvvB,GAAG,GAAG0uB,GAAE,CAAC,IAAIzuB,EAAEwuB,GAAG,GAAGxuB,EAAE,CAAC,IAAIC,EAAED,EAAE,IAAI+uB,GAAGhvB,EAAEC,GAAG,CAAC,GAAGovB,GAAGrvB,GAAG,MAAMiF,MAAMlF,EAAE,MAAME,EAAEurB,GAAGtrB,EAAE2jB,aAAa,IAAIriB,EAAEgtB,GAAGvuB,GAAG+uB,GAAGhvB,EAAEC,GAAG2uB,GAAGptB,EAAEtB,IAAIF,EAAE2R,OAAe,KAAT3R,EAAE2R,MAAY,EAAE+c,IAAE,EAAGF,GAAGxuB,QAAQ,CAAC,GAAGqvB,GAAGrvB,GAAG,MAAMiF,MAAMlF,EAAE,MAAMC,EAAE2R,OAAe,KAAT3R,EAAE2R,MAAY,EAAE+c,IAAE,EAAGF,GAAGxuB,IAAI,SAASwvB,GAAGxvB,GAAG,IAAIA,EAAEA,EAAE0R,OAAO,OAAO1R,GAAG,IAAIA,EAAEmG,KAAK,IAAInG,EAAEmG,KAAK,KAAKnG,EAAEmG,KAAKnG,EAAEA,EAAE0R,OAAO8c,GAAGxuB,EAC/Z,SAASyvB,GAAGzvB,GAAG,GAAGA,IAAIwuB,GAAG,OAAM,EAAG,IAAIE,GAAE,OAAOc,GAAGxvB,GAAG0uB,IAAE,GAAG,EAAG,IAAIzuB,EAAkG,IAA/FA,EAAE,IAAID,EAAEmG,QAAQlG,EAAE,IAAID,EAAEmG,OAAgBlG,EAAE,UAAXA,EAAED,EAAEkC,OAAmB,SAASjC,IAAIwqB,GAAGzqB,EAAEkC,KAAKlC,EAAE0vB,gBAAmBzvB,IAAIA,EAAEwuB,IAAI,CAAC,GAAGY,GAAGrvB,GAAG,MAAM2vB,KAAK1qB,MAAMlF,EAAE,MAAM,KAAKE,GAAG2uB,GAAG5uB,EAAEC,GAAGA,EAAEurB,GAAGvrB,EAAE4jB,aAAmB,GAAN2L,GAAGxvB,GAAM,KAAKA,EAAEmG,IAAI,CAAgD,KAA7BnG,EAAE,QAApBA,EAAEA,EAAE6R,eAAyB7R,EAAE8R,WAAW,MAAW,MAAM7M,MAAMlF,EAAE,MAAMC,EAAE,CAAiB,IAAhBA,EAAEA,EAAE6jB,YAAgB5jB,EAAE,EAAED,GAAG,CAAC,GAAG,IAAIA,EAAE0K,SAAS,CAAC,IAAIxK,EAAEF,EAAE6c,KAAK,GAAG,OAAO3c,EAAE,CAAC,GAAG,IAAID,EAAE,CAACwuB,GAAGjD,GAAGxrB,EAAE6jB,aAAa,MAAM7jB,EAAEC,QAAQ,MAAMC,GAAG,OAAOA,GAAG,OAAOA,GAAGD,IAAID,EAAEA,EAAE6jB,YAAY4K,GACjgB,WAAWA,GAAGD,GAAGhD,GAAGxrB,EAAEgQ,UAAU6T,aAAa,KAAK,OAAM,EAAG,SAAS8L,KAAK,IAAI,IAAI3vB,EAAEyuB,GAAGzuB,GAAGA,EAAEwrB,GAAGxrB,EAAE6jB,aAAa,SAAS+L,KAAKnB,GAAGD,GAAG,KAAKE,IAAE,EAAG,SAASmB,GAAG7vB,GAAG,OAAO2uB,GAAGA,GAAG,CAAC3uB,GAAG2uB,GAAGxe,KAAKnQ,GAAG,IAAI8vB,GAAGrsB,EAAGoU,wBAAwB,SAASkY,GAAG/vB,EAAEC,GAAG,GAAGD,GAAGA,EAAEgwB,aAAa,CAA4B,IAAI,IAAI9vB,KAAnCD,EAAE6E,EAAE,GAAG7E,GAAGD,EAAEA,EAAEgwB,kBAA4B,IAAS/vB,EAAEC,KAAKD,EAAEC,GAAGF,EAAEE,IAAI,OAAOD,EAAE,OAAOA,EAAE,IAAIgwB,GAAG/D,GAAG,MAAMgE,GAAG,KAAKC,GAAG,KAAKC,GAAG,KAAK,SAASC,KAAKD,GAAGD,GAAGD,GAAG,KAAK,SAASI,GAAGtwB,GAAG,IAAIC,EAAEgwB,GAAG9d,QAAQga,GAAE8D,IAAIjwB,EAAEuwB,cAActwB,EAChd,SAASuwB,GAAGxwB,EAAEC,EAAEC,GAAG,KAAK,OAAOF,GAAG,CAAC,IAAIwB,EAAExB,EAAEyR,UAA+H,IAApHzR,EAAEywB,WAAWxwB,KAAKA,GAAGD,EAAEywB,YAAYxwB,EAAE,OAAOuB,IAAIA,EAAEivB,YAAYxwB,IAAI,OAAOuB,IAAIA,EAAEivB,WAAWxwB,KAAKA,IAAIuB,EAAEivB,YAAYxwB,GAAMD,IAAIE,EAAE,MAAMF,EAAEA,EAAE0R,QAAQ,SAASgf,GAAG1wB,EAAEC,GAAGiwB,GAAGlwB,EAAEowB,GAAGD,GAAG,KAAsB,QAAjBnwB,EAAEA,EAAE2wB,eAAuB,OAAO3wB,EAAE4wB,eAAe,KAAK5wB,EAAE6wB,MAAM5wB,KAAK6wB,IAAG,GAAI9wB,EAAE4wB,aAAa,MACjU,SAASG,GAAG/wB,GAAG,IAAIC,EAAED,EAAEuwB,cAAc,GAAGH,KAAKpwB,EAAE,GAAGA,EAAE,CAACgxB,QAAQhxB,EAAEixB,cAAchxB,EAAEixB,KAAK,MAAM,OAAOf,GAAG,CAAC,GAAG,OAAOD,GAAG,MAAMjrB,MAAMlF,EAAE,MAAMowB,GAAGnwB,EAAEkwB,GAAGS,aAAa,CAACE,MAAM,EAAED,aAAa5wB,QAAQmwB,GAAGA,GAAGe,KAAKlxB,EAAE,OAAOC,EAAE,IAAIkxB,GAAG,KAAK,SAASC,GAAGpxB,GAAG,OAAOmxB,GAAGA,GAAG,CAACnxB,GAAGmxB,GAAGhhB,KAAKnQ,GAAG,SAASqxB,GAAGrxB,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAExB,EAAEqxB,YAA+E,OAAnE,OAAO7vB,GAAGvB,EAAEgxB,KAAKhxB,EAAEkxB,GAAGnxB,KAAKC,EAAEgxB,KAAKzvB,EAAEyvB,KAAKzvB,EAAEyvB,KAAKhxB,GAAGD,EAAEqxB,YAAYpxB,EAASqxB,GAAGvxB,EAAEwB,GAC9X,SAAS+vB,GAAGvxB,EAAEC,GAAGD,EAAE6wB,OAAO5wB,EAAE,IAAIC,EAAEF,EAAEyR,UAAqC,IAA3B,OAAOvR,IAAIA,EAAE2wB,OAAO5wB,GAAGC,EAAEF,EAAMA,EAAEA,EAAE0R,OAAO,OAAO1R,GAAGA,EAAEywB,YAAYxwB,EAAgB,QAAdC,EAAEF,EAAEyR,aAAqBvR,EAAEuwB,YAAYxwB,GAAGC,EAAEF,EAAEA,EAAEA,EAAE0R,OAAO,OAAO,IAAIxR,EAAEiG,IAAIjG,EAAE8P,UAAU,KAAK,IAAIwhB,IAAG,EAAG,SAASC,GAAGzxB,GAAGA,EAAE0xB,YAAY,CAACC,UAAU3xB,EAAE6R,cAAc+f,gBAAgB,KAAKC,eAAe,KAAKC,OAAO,CAACC,QAAQ,KAAKT,YAAY,KAAKT,MAAM,GAAGmB,QAAQ,MAC/W,SAASC,GAAGjyB,EAAEC,GAAGD,EAAEA,EAAE0xB,YAAYzxB,EAAEyxB,cAAc1xB,IAAIC,EAAEyxB,YAAY,CAACC,UAAU3xB,EAAE2xB,UAAUC,gBAAgB5xB,EAAE4xB,gBAAgBC,eAAe7xB,EAAE6xB,eAAeC,OAAO9xB,EAAE8xB,OAAOE,QAAQhyB,EAAEgyB,UAAU,SAASE,GAAGlyB,EAAEC,GAAG,MAAM,CAACkyB,UAAUnyB,EAAEoyB,KAAKnyB,EAAEkG,IAAI,EAAEksB,QAAQ,KAAKC,SAAS,KAAKpB,KAAK,MACjR,SAASqB,GAAGvyB,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAE0xB,YAAY,GAAG,OAAOlwB,EAAE,OAAO,KAAgB,GAAXA,EAAEA,EAAEswB,OAAU,KAAO,EAAFU,IAAK,CAAC,IAAI/wB,EAAED,EAAEuwB,QAA+D,OAAvD,OAAOtwB,EAAExB,EAAEixB,KAAKjxB,GAAGA,EAAEixB,KAAKzvB,EAAEyvB,KAAKzvB,EAAEyvB,KAAKjxB,GAAGuB,EAAEuwB,QAAQ9xB,EAASsxB,GAAGvxB,EAAEE,GAAsF,OAAnE,QAAhBuB,EAAED,EAAE8vB,cAAsBrxB,EAAEixB,KAAKjxB,EAAEmxB,GAAG5vB,KAAKvB,EAAEixB,KAAKzvB,EAAEyvB,KAAKzvB,EAAEyvB,KAAKjxB,GAAGuB,EAAE8vB,YAAYrxB,EAASsxB,GAAGvxB,EAAEE,GAAG,SAASuyB,GAAGzyB,EAAEC,EAAEC,GAAmB,GAAG,QAAnBD,EAAEA,EAAEyxB,eAA0BzxB,EAAEA,EAAE6xB,OAAO,KAAO,QAAF5xB,IAAY,CAAC,IAAIsB,EAAEvB,EAAE4wB,MAAwB3wB,GAAlBsB,GAAGxB,EAAEyU,aAAkBxU,EAAE4wB,MAAM3wB,EAAEkV,GAAGpV,EAAEE,IAClZ,SAASwyB,GAAG1yB,EAAEC,GAAG,IAAIC,EAAEF,EAAE0xB,YAAYlwB,EAAExB,EAAEyR,UAAU,GAAG,OAAOjQ,GAAoBtB,KAAhBsB,EAAEA,EAAEkwB,aAAmB,CAAC,IAAIjwB,EAAE,KAAKC,EAAE,KAAyB,GAAG,QAAvBxB,EAAEA,EAAE0xB,iBAA4B,CAAC,EAAE,CAAC,IAAIjwB,EAAE,CAACwwB,UAAUjyB,EAAEiyB,UAAUC,KAAKlyB,EAAEkyB,KAAKjsB,IAAIjG,EAAEiG,IAAIksB,QAAQnyB,EAAEmyB,QAAQC,SAASpyB,EAAEoyB,SAASpB,KAAK,MAAM,OAAOxvB,EAAED,EAAEC,EAAEC,EAAED,EAAEA,EAAEwvB,KAAKvvB,EAAEzB,EAAEA,EAAEgxB,WAAW,OAAOhxB,GAAG,OAAOwB,EAAED,EAAEC,EAAEzB,EAAEyB,EAAEA,EAAEwvB,KAAKjxB,OAAOwB,EAAEC,EAAEzB,EAAiH,OAA/GC,EAAE,CAACyxB,UAAUnwB,EAAEmwB,UAAUC,gBAAgBnwB,EAAEowB,eAAenwB,EAAEowB,OAAOtwB,EAAEswB,OAAOE,QAAQxwB,EAAEwwB,cAAShyB,EAAE0xB,YAAYxxB,GAA4B,QAAnBF,EAAEE,EAAE2xB,gBAAwB3xB,EAAE0xB,gBAAgB3xB,EAAED,EAAEkxB,KACnfjxB,EAAEC,EAAE2xB,eAAe5xB,EACnB,SAAS0yB,GAAG3yB,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAEzB,EAAE0xB,YAAYF,IAAG,EAAG,IAAI9vB,EAAED,EAAEmwB,gBAAgBjwB,EAAEF,EAAEowB,eAAehsB,EAAEpE,EAAEqwB,OAAOC,QAAQ,GAAG,OAAOlsB,EAAE,CAACpE,EAAEqwB,OAAOC,QAAQ,KAAK,IAAIjsB,EAAED,EAAED,EAAEE,EAAEorB,KAAKprB,EAAEorB,KAAK,KAAK,OAAOvvB,EAAED,EAAEkE,EAAEjE,EAAEuvB,KAAKtrB,EAAEjE,EAAEmE,EAAE,IAAIkL,EAAEhR,EAAEyR,UAAU,OAAOT,KAAoBnL,GAAhBmL,EAAEA,EAAE0gB,aAAgBG,kBAAmBlwB,IAAI,OAAOkE,EAAEmL,EAAE4gB,gBAAgBhsB,EAAEC,EAAEqrB,KAAKtrB,EAAEoL,EAAE6gB,eAAe/rB,IAAI,GAAG,OAAOpE,EAAE,CAAC,IAAIkxB,EAAEnxB,EAAEkwB,UAA6B,IAAnBhwB,EAAE,EAAEqP,EAAEpL,EAAEE,EAAE,KAAKD,EAAEnE,IAAI,CAAC,IAAImxB,EAAEhtB,EAAEusB,KAAKU,EAAEjtB,EAAEssB,UAAU,IAAI3wB,EAAEqxB,KAAKA,EAAE,CAAC,OAAO7hB,IAAIA,EAAEA,EAAEkgB,KAAK,CAACiB,UAAUW,EAAEV,KAAK,EAAEjsB,IAAIN,EAAEM,IAAIksB,QAAQxsB,EAAEwsB,QAAQC,SAASzsB,EAAEysB,SACvfpB,KAAK,OAAOlxB,EAAE,CAAC,IAAI8oB,EAAE9oB,EAAE+oB,EAAEljB,EAAU,OAARgtB,EAAE5yB,EAAE6yB,EAAE5yB,EAAS6oB,EAAE5iB,KAAK,KAAK,EAAc,GAAG,oBAAf2iB,EAAEC,EAAEsJ,SAAiC,CAACO,EAAE9J,EAAE7lB,KAAK6vB,EAAEF,EAAEC,GAAG,MAAM7yB,EAAE4yB,EAAE9J,EAAE,MAAM9oB,EAAE,KAAK,EAAE8oB,EAAEnX,OAAe,MAATmX,EAAEnX,MAAa,IAAI,KAAK,EAAsD,GAAG,QAA3CkhB,EAAE,oBAAd/J,EAAEC,EAAEsJ,SAAgCvJ,EAAE7lB,KAAK6vB,EAAEF,EAAEC,GAAG/J,SAAe,IAAS+J,EAAE,MAAM7yB,EAAE4yB,EAAE9tB,EAAE,GAAG8tB,EAAEC,GAAG,MAAM7yB,EAAE,KAAK,EAAEwxB,IAAG,GAAI,OAAO3rB,EAAEysB,UAAU,IAAIzsB,EAAEusB,OAAOpyB,EAAE2R,OAAO,GAAe,QAAZkhB,EAAEpxB,EAAEuwB,SAAiBvwB,EAAEuwB,QAAQ,CAACnsB,GAAGgtB,EAAE1iB,KAAKtK,SAASitB,EAAE,CAACX,UAAUW,EAAEV,KAAKS,EAAE1sB,IAAIN,EAAEM,IAAIksB,QAAQxsB,EAAEwsB,QAAQC,SAASzsB,EAAEysB,SAASpB,KAAK,MAAM,OAAOlgB,GAAGpL,EAAEoL,EAAE8hB,EAAEhtB,EAAE8sB,GAAG5hB,EAAEA,EAAEkgB,KAAK4B,EAAEnxB,GAAGkxB,EAC3e,GAAG,QAAZhtB,EAAEA,EAAEqrB,MAAiB,IAAsB,QAAnBrrB,EAAEpE,EAAEqwB,OAAOC,SAAiB,MAAelsB,GAAJgtB,EAAEhtB,GAAMqrB,KAAK2B,EAAE3B,KAAK,KAAKzvB,EAAEowB,eAAegB,EAAEpxB,EAAEqwB,OAAOC,QAAQ,MAA0G,GAA5F,OAAO/gB,IAAIlL,EAAE8sB,GAAGnxB,EAAEkwB,UAAU7rB,EAAErE,EAAEmwB,gBAAgBhsB,EAAEnE,EAAEowB,eAAe7gB,EAA4B,QAA1B/Q,EAAEwB,EAAEqwB,OAAOR,aAAwB,CAAC7vB,EAAExB,EAAE,GAAG0B,GAAGF,EAAE2wB,KAAK3wB,EAAEA,EAAEyvB,WAAWzvB,IAAIxB,QAAQ,OAAOyB,IAAID,EAAEqwB,OAAOjB,MAAM,GAAGkC,IAAIpxB,EAAE3B,EAAE6wB,MAAMlvB,EAAE3B,EAAE6R,cAAc+gB,GAC5V,SAASI,GAAGhzB,EAAEC,EAAEC,GAA8B,GAA3BF,EAAEC,EAAE+xB,QAAQ/xB,EAAE+xB,QAAQ,KAAQ,OAAOhyB,EAAE,IAAIC,EAAE,EAAEA,EAAED,EAAEI,OAAOH,IAAI,CAAC,IAAIuB,EAAExB,EAAEC,GAAGwB,EAAED,EAAE8wB,SAAS,GAAG,OAAO7wB,EAAE,CAAqB,GAApBD,EAAE8wB,SAAS,KAAK9wB,EAAEtB,EAAK,oBAAoBuB,EAAE,MAAMwD,MAAMlF,EAAE,IAAI0B,IAAIA,EAAEwB,KAAKzB,KAAK,IAAIyxB,IAAI,IAAIrzB,EAAGszB,WAAWC,KAAK,SAASC,GAAGpzB,EAAEC,EAAEC,EAAEsB,GAA8BtB,EAAE,QAAXA,EAAEA,EAAEsB,EAAtBvB,EAAED,EAAE6R,sBAAmC,IAAS3R,EAAED,EAAE6E,EAAE,GAAG7E,EAAEC,GAAGF,EAAE6R,cAAc3R,EAAE,IAAIF,EAAE6wB,QAAQ7wB,EAAE0xB,YAAYC,UAAUzxB,GAChX,IAAImzB,GAAG,CAACC,UAAU,SAAStzB,GAAG,SAAOA,EAAEA,EAAEuzB,kBAAiB/hB,GAAGxR,KAAKA,GAAMwzB,gBAAgB,SAASxzB,EAAEC,EAAEC,GAAGF,EAAEA,EAAEuzB,gBAAgB,IAAI/xB,EAAEiyB,KAAIhyB,EAAEiyB,GAAG1zB,GAAG0B,EAAEwwB,GAAG1wB,EAAEC,GAAGC,EAAE2wB,QAAQpyB,OAAE,IAASC,GAAG,OAAOA,IAAIwB,EAAE4wB,SAASpyB,GAAe,QAAZD,EAAEsyB,GAAGvyB,EAAE0B,EAAED,MAAckyB,GAAG1zB,EAAED,EAAEyB,EAAED,GAAGixB,GAAGxyB,EAAED,EAAEyB,KAAKmyB,oBAAoB,SAAS5zB,EAAEC,EAAEC,GAAGF,EAAEA,EAAEuzB,gBAAgB,IAAI/xB,EAAEiyB,KAAIhyB,EAAEiyB,GAAG1zB,GAAG0B,EAAEwwB,GAAG1wB,EAAEC,GAAGC,EAAEyE,IAAI,EAAEzE,EAAE2wB,QAAQpyB,OAAE,IAASC,GAAG,OAAOA,IAAIwB,EAAE4wB,SAASpyB,GAAe,QAAZD,EAAEsyB,GAAGvyB,EAAE0B,EAAED,MAAckyB,GAAG1zB,EAAED,EAAEyB,EAAED,GAAGixB,GAAGxyB,EAAED,EAAEyB,KAAKoyB,mBAAmB,SAAS7zB,EAAEC,GAAGD,EAAEA,EAAEuzB,gBAAgB,IAAIrzB,EAAEuzB,KAAIjyB,EACnfkyB,GAAG1zB,GAAGyB,EAAEywB,GAAGhyB,EAAEsB,GAAGC,EAAE0E,IAAI,OAAE,IAASlG,GAAG,OAAOA,IAAIwB,EAAE6wB,SAASryB,GAAe,QAAZA,EAAEsyB,GAAGvyB,EAAEyB,EAAED,MAAcmyB,GAAG1zB,EAAED,EAAEwB,EAAEtB,GAAGuyB,GAAGxyB,EAAED,EAAEwB,MAAM,SAASsyB,GAAG9zB,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,GAAiB,MAAM,oBAApB3B,EAAEA,EAAEgQ,WAAsC+jB,sBAAsB/zB,EAAE+zB,sBAAsBvyB,EAAEE,EAAEC,IAAG1B,EAAEiB,YAAWjB,EAAEiB,UAAU8yB,wBAAsBxQ,GAAGtjB,EAAEsB,KAAKgiB,GAAG/hB,EAAEC,IACrS,SAASuyB,GAAGj0B,EAAEC,EAAEC,GAAG,IAAIsB,GAAE,EAAGC,EAAE4qB,GAAO3qB,EAAEzB,EAAEi0B,YAA2W,MAA/V,kBAAkBxyB,GAAG,OAAOA,EAAEA,EAAEqvB,GAAGrvB,IAAID,EAAEorB,GAAG5sB,GAAGusB,GAAGF,GAAEna,QAAyBzQ,GAAGF,EAAE,QAAtBA,EAAEvB,EAAEysB,oBAA4B,IAASlrB,GAAGirB,GAAGzsB,EAAEyB,GAAG4qB,IAAIpsB,EAAE,IAAIA,EAAEC,EAAEwB,GAAG1B,EAAE6R,cAAc,OAAO5R,EAAEk0B,YAAO,IAASl0B,EAAEk0B,MAAMl0B,EAAEk0B,MAAM,KAAKl0B,EAAEm0B,QAAQf,GAAGrzB,EAAEgQ,UAAU/P,EAAEA,EAAEszB,gBAAgBvzB,EAAEwB,KAAIxB,EAAEA,EAAEgQ,WAAY2c,4CAA4ClrB,EAAEzB,EAAE4sB,0CAA0ClrB,GAAUzB,EAC3Z,SAASo0B,GAAGr0B,EAAEC,EAAEC,EAAEsB,GAAGxB,EAAEC,EAAEk0B,MAAM,oBAAoBl0B,EAAEq0B,2BAA2Br0B,EAAEq0B,0BAA0Bp0B,EAAEsB,GAAG,oBAAoBvB,EAAEs0B,kCAAkCt0B,EAAEs0B,iCAAiCr0B,EAAEsB,GAAGvB,EAAEk0B,QAAQn0B,GAAGqzB,GAAGO,oBAAoB3zB,EAAEA,EAAEk0B,MAAM,MAC/P,SAASK,GAAGx0B,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAEzB,EAAEgQ,UAAUvO,EAAEgzB,MAAMv0B,EAAEuB,EAAE0yB,MAAMn0B,EAAE6R,cAAcpQ,EAAE0xB,KAAKF,GAAGxB,GAAGzxB,GAAG,IAAI0B,EAAEzB,EAAEi0B,YAAY,kBAAkBxyB,GAAG,OAAOA,EAAED,EAAEuvB,QAAQD,GAAGrvB,IAAIA,EAAEmrB,GAAG5sB,GAAGusB,GAAGF,GAAEna,QAAQ1Q,EAAEuvB,QAAQvE,GAAGzsB,EAAE0B,IAAID,EAAE0yB,MAAMn0B,EAAE6R,cAA2C,oBAA7BnQ,EAAEzB,EAAEy0B,4BAAiDtB,GAAGpzB,EAAEC,EAAEyB,EAAExB,GAAGuB,EAAE0yB,MAAMn0B,EAAE6R,eAAe,oBAAoB5R,EAAEy0B,0BAA0B,oBAAoBjzB,EAAEkzB,yBAAyB,oBAAoBlzB,EAAEmzB,2BAA2B,oBAAoBnzB,EAAEozB,qBAAqB50B,EAAEwB,EAAE0yB,MACrf,oBAAoB1yB,EAAEozB,oBAAoBpzB,EAAEozB,qBAAqB,oBAAoBpzB,EAAEmzB,2BAA2BnzB,EAAEmzB,4BAA4B30B,IAAIwB,EAAE0yB,OAAOd,GAAGO,oBAAoBnyB,EAAEA,EAAE0yB,MAAM,MAAMxB,GAAG3yB,EAAEE,EAAEuB,EAAED,GAAGC,EAAE0yB,MAAMn0B,EAAE6R,eAAe,oBAAoBpQ,EAAEqzB,oBAAoB90B,EAAE2R,OAAO,SAC5R,SAASojB,GAAG/0B,EAAEC,EAAEC,GAAW,GAAG,QAAXF,EAAEE,EAAE80B,MAAiB,oBAAoBh1B,GAAG,kBAAkBA,EAAE,CAAC,GAAGE,EAAE+0B,OAAO,CAAY,GAAX/0B,EAAEA,EAAE+0B,OAAY,CAAC,GAAG,IAAI/0B,EAAEiG,IAAI,MAAMlB,MAAMlF,EAAE,MAAM,IAAIyB,EAAEtB,EAAE8P,UAAU,IAAIxO,EAAE,MAAMyD,MAAMlF,EAAE,IAAIC,IAAI,IAAIyB,EAAED,EAAEE,EAAE,GAAG1B,EAAE,OAAG,OAAOC,GAAG,OAAOA,EAAE+0B,KAAK,oBAAoB/0B,EAAE+0B,KAAK/0B,EAAE+0B,IAAIE,aAAaxzB,EAASzB,EAAE+0B,KAAI/0B,EAAE,SAASD,GAAG,IAAIC,EAAEwB,EAAE0xB,KAAKlzB,IAAIgzB,KAAKhzB,EAAEwB,EAAE0xB,KAAK,IAAI,OAAOnzB,SAASC,EAAEyB,GAAGzB,EAAEyB,GAAG1B,GAAGC,EAAEi1B,WAAWxzB,EAASzB,GAAE,GAAG,kBAAkBD,EAAE,MAAMiF,MAAMlF,EAAE,MAAM,IAAIG,EAAE+0B,OAAO,MAAMhwB,MAAMlF,EAAE,IAAIC,IAAK,OAAOA,EACpe,SAASm1B,GAAGn1B,EAAEC,GAAuC,MAApCD,EAAEiB,OAAOC,UAAUgJ,SAASjH,KAAKhD,GAASgF,MAAMlF,EAAE,GAAG,oBAAoBC,EAAE,qBAAqBiB,OAAO6M,KAAK7N,GAAGm1B,KAAK,MAAM,IAAIp1B,IAAK,SAASq1B,GAAGr1B,GAAiB,OAAOC,EAAfD,EAAEyG,OAAezG,EAAEwG,UAC5L,SAAS8uB,GAAGt1B,GAAG,SAASC,EAAEA,EAAEC,GAAG,GAAGF,EAAE,CAAC,IAAIwB,EAAEvB,EAAE8uB,UAAU,OAAOvtB,GAAGvB,EAAE8uB,UAAU,CAAC7uB,GAAGD,EAAE0R,OAAO,IAAInQ,EAAE2O,KAAKjQ,IAAI,SAASA,EAAEA,EAAEsB,GAAG,IAAIxB,EAAE,OAAO,KAAK,KAAK,OAAOwB,GAAGvB,EAAEC,EAAEsB,GAAGA,EAAEA,EAAE0Q,QAAQ,OAAO,KAAK,SAAS1Q,EAAExB,EAAEC,GAAG,IAAID,EAAE,IAAIkW,IAAI,OAAOjW,GAAG,OAAOA,EAAEke,IAAIne,EAAEyF,IAAIxF,EAAEke,IAAIle,GAAGD,EAAEyF,IAAIxF,EAAEs1B,MAAMt1B,GAAGA,EAAEA,EAAEiS,QAAQ,OAAOlS,EAAE,SAASyB,EAAEzB,EAAEC,GAAsC,OAAnCD,EAAEw1B,GAAGx1B,EAAEC,IAAKs1B,MAAM,EAAEv1B,EAAEkS,QAAQ,KAAYlS,EAAE,SAAS0B,EAAEzB,EAAEC,EAAEsB,GAAa,OAAVvB,EAAEs1B,MAAM/zB,EAAMxB,EAA6C,QAAjBwB,EAAEvB,EAAEwR,YAA6BjQ,EAAEA,EAAE+zB,OAAQr1B,GAAGD,EAAE0R,OAAO,EAAEzR,GAAGsB,GAAEvB,EAAE0R,OAAO,EAASzR,IAArGD,EAAE0R,OAAO,QAAQzR,GAAsF,SAASyB,EAAE1B,GACzd,OAD4dD,GAC7f,OAAOC,EAAEwR,YAAYxR,EAAE0R,OAAO,GAAU1R,EAAE,SAAS4F,EAAE7F,EAAEC,EAAEC,EAAEsB,GAAG,OAAG,OAAOvB,GAAG,IAAIA,EAAEkG,MAAWlG,EAAEw1B,GAAGv1B,EAAEF,EAAEsvB,KAAK9tB,IAAKkQ,OAAO1R,EAAEC,KAAEA,EAAEwB,EAAExB,EAAEC,IAAKwR,OAAO1R,EAASC,GAAE,SAAS6F,EAAE9F,EAAEC,EAAEC,EAAEsB,GAAG,IAAIE,EAAExB,EAAEgC,KAAK,OAAGR,IAAIqC,EAAUiN,EAAEhR,EAAEC,EAAEC,EAAEu0B,MAAMnrB,SAAS9H,EAAEtB,EAAEie,KAAQ,OAAOle,IAAIA,EAAE6uB,cAAcptB,GAAG,kBAAkBA,GAAG,OAAOA,GAAGA,EAAE4E,WAAW9B,GAAI6wB,GAAG3zB,KAAKzB,EAAEiC,QAAaV,EAAEC,EAAExB,EAAEC,EAAEu0B,QAASO,IAAID,GAAG/0B,EAAEC,EAAEC,GAAGsB,EAAEkQ,OAAO1R,EAAEwB,KAAEA,EAAEk0B,GAAGx1B,EAAEgC,KAAKhC,EAAEie,IAAIje,EAAEu0B,MAAM,KAAKz0B,EAAEsvB,KAAK9tB,IAAKwzB,IAAID,GAAG/0B,EAAEC,EAAEC,GAAGsB,EAAEkQ,OAAO1R,EAASwB,GAAE,SAASoE,EAAE5F,EAAEC,EAAEC,EAAEsB,GAAG,OAAG,OAAOvB,GAAG,IAAIA,EAAEkG,KACjflG,EAAE+P,UAAUmH,gBAAgBjX,EAAEiX,eAAelX,EAAE+P,UAAU2lB,iBAAiBz1B,EAAEy1B,iBAAsB11B,EAAE21B,GAAG11B,EAAEF,EAAEsvB,KAAK9tB,IAAKkQ,OAAO1R,EAAEC,KAAEA,EAAEwB,EAAExB,EAAEC,EAAEoJ,UAAU,KAAMoI,OAAO1R,EAASC,GAAE,SAAS+Q,EAAEhR,EAAEC,EAAEC,EAAEsB,EAAEE,GAAG,OAAG,OAAOzB,GAAG,IAAIA,EAAEkG,MAAWlG,EAAE41B,GAAG31B,EAAEF,EAAEsvB,KAAK9tB,EAAEE,IAAKgQ,OAAO1R,EAAEC,KAAEA,EAAEwB,EAAExB,EAAEC,IAAKwR,OAAO1R,EAASC,GAAE,SAAS2yB,EAAE5yB,EAAEC,EAAEC,GAAG,GAAG,kBAAkBD,GAAG,KAAKA,GAAG,kBAAkBA,EAAE,OAAOA,EAAEw1B,GAAG,GAAGx1B,EAAED,EAAEsvB,KAAKpvB,IAAKwR,OAAO1R,EAAEC,EAAE,GAAG,kBAAkBA,GAAG,OAAOA,EAAE,CAAC,OAAOA,EAAEqG,UAAU,KAAK3C,EAAG,OAAOzD,EAAEw1B,GAAGz1B,EAAEiC,KAAKjC,EAAEke,IAAIle,EAAEw0B,MAAM,KAAKz0B,EAAEsvB,KAAKpvB,IACjf80B,IAAID,GAAG/0B,EAAE,KAAKC,GAAGC,EAAEwR,OAAO1R,EAAEE,EAAE,KAAK4D,EAAG,OAAO7D,EAAE21B,GAAG31B,EAAED,EAAEsvB,KAAKpvB,IAAKwR,OAAO1R,EAAEC,EAAE,KAAKuE,EAAiB,OAAOouB,EAAE5yB,GAAEwB,EAAnBvB,EAAEwG,OAAmBxG,EAAEuG,UAAUtG,GAAG,GAAG0I,GAAG3I,IAAI2E,EAAG3E,GAAG,OAAOA,EAAE41B,GAAG51B,EAAED,EAAEsvB,KAAKpvB,EAAE,OAAQwR,OAAO1R,EAAEC,EAAEk1B,GAAGn1B,EAAEC,GAAG,OAAO,KAAK,SAAS4yB,EAAE7yB,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAE,OAAOxB,EAAEA,EAAEke,IAAI,KAAK,GAAG,kBAAkBje,GAAG,KAAKA,GAAG,kBAAkBA,EAAE,OAAO,OAAOuB,EAAE,KAAKoE,EAAE7F,EAAEC,EAAE,GAAGC,EAAEsB,GAAG,GAAG,kBAAkBtB,GAAG,OAAOA,EAAE,CAAC,OAAOA,EAAEoG,UAAU,KAAK3C,EAAG,OAAOzD,EAAEie,MAAM1c,EAAEqE,EAAE9F,EAAEC,EAAEC,EAAEsB,GAAG,KAAK,KAAKsC,EAAG,OAAO5D,EAAEie,MAAM1c,EAAEmE,EAAE5F,EAAEC,EAAEC,EAAEsB,GAAG,KAAK,KAAKgD,EAAG,OAAiBquB,EAAE7yB,EACpfC,GADwewB,EAAEvB,EAAEuG,OACxevG,EAAEsG,UAAUhF,GAAG,GAAGoH,GAAG1I,IAAI0E,EAAG1E,GAAG,OAAO,OAAOuB,EAAE,KAAKuP,EAAEhR,EAAEC,EAAEC,EAAEsB,EAAE,MAAM2zB,GAAGn1B,EAAEE,GAAG,OAAO,KAAK,SAAS4yB,EAAE9yB,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,GAAG,kBAAkBD,GAAG,KAAKA,GAAG,kBAAkBA,EAAE,OAAwBqE,EAAE5F,EAAnBD,EAAEA,EAAEkH,IAAIhH,IAAI,KAAW,GAAGsB,EAAEC,GAAG,GAAG,kBAAkBD,GAAG,OAAOA,EAAE,CAAC,OAAOA,EAAE8E,UAAU,KAAK3C,EAAG,OAA2CmC,EAAE7F,EAAtCD,EAAEA,EAAEkH,IAAI,OAAO1F,EAAE2c,IAAIje,EAAEsB,EAAE2c,MAAM,KAAW3c,EAAEC,GAAG,KAAKqC,EAAG,OAA2C8B,EAAE3F,EAAtCD,EAAEA,EAAEkH,IAAI,OAAO1F,EAAE2c,IAAIje,EAAEsB,EAAE2c,MAAM,KAAW3c,EAAEC,GAAG,KAAK+C,EAAiB,OAAOsuB,EAAE9yB,EAAEC,EAAEC,GAAEwB,EAAvBF,EAAEiF,OAAuBjF,EAAEgF,UAAU/E,GAAG,GAAGmH,GAAGpH,IAAIoD,EAAGpD,GAAG,OAAwBwP,EAAE/Q,EAAnBD,EAAEA,EAAEkH,IAAIhH,IAAI,KAAWsB,EAAEC,EAAE,MAAM0zB,GAAGl1B,EAAEuB,GAAG,OAAO,KAC1f,SAASsnB,EAAErnB,EAAEE,EAAEkE,EAAEC,GAAG,IAAI,IAAIF,EAAE,KAAKoL,EAAE,KAAKkY,EAAEvnB,EAAEwnB,EAAExnB,EAAE,EAAEsnB,EAAE,KAAK,OAAOC,GAAGC,EAAEtjB,EAAEzF,OAAO+oB,IAAI,CAACD,EAAEqM,MAAMpM,GAAGF,EAAEC,EAAEA,EAAE,MAAMD,EAAEC,EAAEhX,QAAQ,IAAI4W,EAAE+J,EAAEpxB,EAAEynB,EAAErjB,EAAEsjB,GAAGrjB,GAAG,GAAG,OAAOgjB,EAAE,CAAC,OAAOI,IAAIA,EAAED,GAAG,MAAMjpB,GAAGkpB,GAAG,OAAOJ,EAAErX,WAAWxR,EAAEwB,EAAEynB,GAAGvnB,EAAED,EAAEonB,EAAEnnB,EAAEwnB,GAAG,OAAOnY,EAAEpL,EAAEkjB,EAAE9X,EAAEkB,QAAQ4W,EAAE9X,EAAE8X,EAAEI,EAAED,EAAE,GAAGE,IAAItjB,EAAEzF,OAAO,OAAOF,EAAEuB,EAAEynB,GAAGwF,IAAGN,GAAG3sB,EAAE0nB,GAAGvjB,EAAE,GAAG,OAAOsjB,EAAE,CAAC,KAAKC,EAAEtjB,EAAEzF,OAAO+oB,IAAkB,QAAdD,EAAE0J,EAAEnxB,EAAEoE,EAAEsjB,GAAGrjB,MAAcnE,EAAED,EAAEwnB,EAAEvnB,EAAEwnB,GAAG,OAAOnY,EAAEpL,EAAEsjB,EAAElY,EAAEkB,QAAQgX,EAAElY,EAAEkY,GAAc,OAAXwF,IAAGN,GAAG3sB,EAAE0nB,GAAUvjB,EAAE,IAAIsjB,EAAE1nB,EAAEC,EAAEynB,GAAGC,EAAEtjB,EAAEzF,OAAO+oB,IAAsB,QAAlBF,EAAE6J,EAAE5J,EAAEznB,EAAE0nB,EAAEtjB,EAAEsjB,GAAGrjB,MAAc9F,GAAG,OAAOipB,EAAExX,WAAWyX,EAAE3S,OAAO,OACvf0S,EAAE9K,IAAIgL,EAAEF,EAAE9K,KAAKxc,EAAED,EAAEunB,EAAEtnB,EAAEwnB,GAAG,OAAOnY,EAAEpL,EAAEqjB,EAAEjY,EAAEkB,QAAQ+W,EAAEjY,EAAEiY,GAAuD,OAApDjpB,GAAGkpB,EAAE3mB,SAAQ,SAASvC,GAAG,OAAOC,EAAEwB,EAAEzB,MAAK0uB,IAAGN,GAAG3sB,EAAE0nB,GAAUvjB,EAAE,SAASmjB,EAAEtnB,EAAEE,EAAEkE,EAAEC,GAAG,IAAIF,EAAEhB,EAAGiB,GAAG,GAAG,oBAAoBD,EAAE,MAAMX,MAAMlF,EAAE,MAAkB,GAAG,OAAf8F,EAAED,EAAE3C,KAAK4C,IAAc,MAAMZ,MAAMlF,EAAE,MAAM,IAAI,IAAImpB,EAAEtjB,EAAE,KAAKoL,EAAErP,EAAEwnB,EAAExnB,EAAE,EAAEsnB,EAAE,KAAKH,EAAEjjB,EAAEqrB,OAAO,OAAOlgB,IAAI8X,EAAEgN,KAAK3M,IAAIL,EAAEjjB,EAAEqrB,OAAO,CAAClgB,EAAEukB,MAAMpM,GAAGF,EAAEjY,EAAEA,EAAE,MAAMiY,EAAEjY,EAAEkB,QAAQ,IAAI6W,EAAE8J,EAAEpxB,EAAEuP,EAAE8X,EAAEnhB,MAAM7B,GAAG,GAAG,OAAOijB,EAAE,CAAC,OAAO/X,IAAIA,EAAEiY,GAAG,MAAMjpB,GAAGgR,GAAG,OAAO+X,EAAEtX,WAAWxR,EAAEwB,EAAEuP,GAAGrP,EAAED,EAAEqnB,EAAEpnB,EAAEwnB,GAAG,OAAOD,EAAEtjB,EAAEmjB,EAAEG,EAAEhX,QAAQ6W,EAAEG,EAAEH,EAAE/X,EAAEiY,EAAE,GAAGH,EAAEgN,KAAK,OAAO51B,EAAEuB,EACzfuP,GAAG0d,IAAGN,GAAG3sB,EAAE0nB,GAAGvjB,EAAE,GAAG,OAAOoL,EAAE,CAAC,MAAM8X,EAAEgN,KAAK3M,IAAIL,EAAEjjB,EAAEqrB,OAAwB,QAAjBpI,EAAE8J,EAAEnxB,EAAEqnB,EAAEnhB,MAAM7B,MAAcnE,EAAED,EAAEonB,EAAEnnB,EAAEwnB,GAAG,OAAOD,EAAEtjB,EAAEkjB,EAAEI,EAAEhX,QAAQ4W,EAAEI,EAAEJ,GAAc,OAAX4F,IAAGN,GAAG3sB,EAAE0nB,GAAUvjB,EAAE,IAAIoL,EAAExP,EAAEC,EAAEuP,IAAI8X,EAAEgN,KAAK3M,IAAIL,EAAEjjB,EAAEqrB,OAA4B,QAArBpI,EAAEgK,EAAE9hB,EAAEvP,EAAE0nB,EAAEL,EAAEnhB,MAAM7B,MAAc9F,GAAG,OAAO8oB,EAAErX,WAAWT,EAAEuF,OAAO,OAAOuS,EAAE3K,IAAIgL,EAAEL,EAAE3K,KAAKxc,EAAED,EAAEonB,EAAEnnB,EAAEwnB,GAAG,OAAOD,EAAEtjB,EAAEkjB,EAAEI,EAAEhX,QAAQ4W,EAAEI,EAAEJ,GAAuD,OAApD9oB,GAAGgR,EAAEzO,SAAQ,SAASvC,GAAG,OAAOC,EAAEwB,EAAEzB,MAAK0uB,IAAGN,GAAG3sB,EAAE0nB,GAAUvjB,EAG1T,OAH4T,SAASojB,EAAEhpB,EAAEwB,EAAEE,EAAEmE,GAAkF,GAA/E,kBAAkBnE,GAAG,OAAOA,GAAGA,EAAEQ,OAAO6B,GAAI,OAAOrC,EAAEyc,MAAMzc,EAAEA,EAAE+yB,MAAMnrB,UAAa,kBAAkB5H,GAAG,OAAOA,EAAE,CAAC,OAAOA,EAAE4E,UAAU,KAAK3C,EAAG3D,EAAE,CAAC,IAAI,IAAI8F,EAC7hBpE,EAAEyc,IAAIvY,EAAEpE,EAAE,OAAOoE,GAAG,CAAC,GAAGA,EAAEuY,MAAMrY,EAAE,CAAU,IAATA,EAAEpE,EAAEQ,QAAY6B,GAAI,GAAG,IAAI6B,EAAEO,IAAI,CAACjG,EAAEF,EAAE4F,EAAEsM,UAAS1Q,EAAEC,EAAEmE,EAAElE,EAAE+yB,MAAMnrB,WAAYoI,OAAO1R,EAAEA,EAAEwB,EAAE,MAAMxB,QAAQ,GAAG4F,EAAEkpB,cAAchpB,GAAG,kBAAkBA,GAAG,OAAOA,GAAGA,EAAEQ,WAAW9B,GAAI6wB,GAAGvvB,KAAKF,EAAE1D,KAAK,CAAChC,EAAEF,EAAE4F,EAAEsM,UAAS1Q,EAAEC,EAAEmE,EAAElE,EAAE+yB,QAASO,IAAID,GAAG/0B,EAAE4F,EAAElE,GAAGF,EAAEkQ,OAAO1R,EAAEA,EAAEwB,EAAE,MAAMxB,EAAEE,EAAEF,EAAE4F,GAAG,MAAW3F,EAAED,EAAE4F,GAAGA,EAAEA,EAAEsM,QAAQxQ,EAAEQ,OAAO6B,IAAIvC,EAAEq0B,GAAGn0B,EAAE+yB,MAAMnrB,SAAStJ,EAAEsvB,KAAKzpB,EAAEnE,EAAEyc,MAAOzM,OAAO1R,EAAEA,EAAEwB,KAAIqE,EAAE6vB,GAAGh0B,EAAEQ,KAAKR,EAAEyc,IAAIzc,EAAE+yB,MAAM,KAAKz0B,EAAEsvB,KAAKzpB,IAAKmvB,IAAID,GAAG/0B,EAAEwB,EAAEE,GAAGmE,EAAE6L,OAAO1R,EAAEA,EAAE6F,GAAG,OAAOlE,EAAE3B,GAAG,KAAK8D,EAAG9D,EAAE,CAAC,IAAI4F,EAAElE,EAAEyc,IAAI,OACzf3c,GAAG,CAAC,GAAGA,EAAE2c,MAAMvY,EAAX,CAAa,GAAG,IAAIpE,EAAE2E,KAAK3E,EAAEwO,UAAUmH,gBAAgBzV,EAAEyV,eAAe3V,EAAEwO,UAAU2lB,iBAAiBj0B,EAAEi0B,eAAe,CAACz1B,EAAEF,EAAEwB,EAAE0Q,UAAS1Q,EAAEC,EAAED,EAAEE,EAAE4H,UAAU,KAAMoI,OAAO1R,EAAEA,EAAEwB,EAAE,MAAMxB,EAAOE,EAAEF,EAAEwB,GAAG,MAAWvB,EAAED,EAAEwB,GAAGA,EAAEA,EAAE0Q,SAAQ1Q,EAAEo0B,GAAGl0B,EAAE1B,EAAEsvB,KAAKzpB,IAAK6L,OAAO1R,EAAEA,EAAEwB,EAAE,OAAOG,EAAE3B,GAAG,KAAKwE,EAAG,OAAiBwkB,EAAEhpB,EAAEwB,GAAdoE,EAAElE,EAAE+E,OAAc/E,EAAE8E,UAAUX,GAAG,GAAG+C,GAAGlH,GAAG,OAAOonB,EAAE9oB,EAAEwB,EAAEE,EAAEmE,GAAG,GAAGjB,EAAGlD,GAAG,OAAOqnB,EAAE/oB,EAAEwB,EAAEE,EAAEmE,GAAGsvB,GAAGn1B,EAAE0B,GAAG,MAAM,kBAAkBA,GAAG,KAAKA,GAAG,kBAAkBA,GAAGA,EAAE,GAAGA,EAAE,OAAOF,GAAG,IAAIA,EAAE2E,KAAKjG,EAAEF,EAAEwB,EAAE0Q,UAAS1Q,EAAEC,EAAED,EAAEE,IAAKgQ,OAAO1R,EAAEA,EAAEwB,IACnftB,EAAEF,EAAEwB,IAAGA,EAAEi0B,GAAG/zB,EAAE1B,EAAEsvB,KAAKzpB,IAAK6L,OAAO1R,EAAEA,EAAEwB,GAAGG,EAAE3B,IAAIE,EAAEF,EAAEwB,IAAY,IAAIu0B,GAAGT,IAAG,GAAIU,GAAGV,IAAG,GAAIW,GAAG,GAAGC,GAAGhK,GAAG+J,IAAIE,GAAGjK,GAAG+J,IAAIG,GAAGlK,GAAG+J,IAAI,SAASI,GAAGr2B,GAAG,GAAGA,IAAIi2B,GAAG,MAAMhxB,MAAMlF,EAAE,MAAM,OAAOC,EAAE,SAASs2B,GAAGt2B,EAAEC,GAAyC,OAAtCmsB,GAAEgK,GAAGn2B,GAAGmsB,GAAE+J,GAAGn2B,GAAGosB,GAAE8J,GAAGD,IAAIj2B,EAAEC,EAAEyK,UAAmB,KAAK,EAAE,KAAK,GAAGzK,GAAGA,EAAEA,EAAEykB,iBAAiBzkB,EAAE8J,aAAaH,GAAG,KAAK,IAAI,MAAM,QAAkE3J,EAAE2J,GAArC3J,GAAvBD,EAAE,IAAIA,EAAEC,EAAEyP,WAAWzP,GAAM8J,cAAc,KAAK/J,EAAEA,EAAEu2B,SAAkBpK,GAAE+J,IAAI9J,GAAE8J,GAAGj2B,GAAG,SAASu2B,KAAKrK,GAAE+J,IAAI/J,GAAEgK,IAAIhK,GAAEiK,IAChb,SAASK,GAAGz2B,GAAGq2B,GAAGD,GAAGjkB,SAAS,IAAIlS,EAAEo2B,GAAGH,GAAG/jB,SAAajS,EAAE0J,GAAG3J,EAAED,EAAEkC,MAAMjC,IAAIC,IAAIksB,GAAE+J,GAAGn2B,GAAGosB,GAAE8J,GAAGh2B,IAAI,SAASw2B,GAAG12B,GAAGm2B,GAAGhkB,UAAUnS,IAAImsB,GAAE+J,IAAI/J,GAAEgK,KAAK,IAAIQ,GAAEzK,GAAG,GACrJ,SAAS0K,GAAG52B,GAAG,IAAI,IAAIC,EAAED,EAAE,OAAOC,GAAG,CAAC,GAAG,KAAKA,EAAEkG,IAAI,CAAC,IAAIjG,EAAED,EAAE4R,cAAc,GAAG,OAAO3R,IAAmB,QAAfA,EAAEA,EAAE4R,aAAqB,OAAO5R,EAAE2c,MAAM,OAAO3c,EAAE2c,MAAM,OAAO5c,OAAO,GAAG,KAAKA,EAAEkG,UAAK,IAASlG,EAAEyvB,cAAcmH,aAAa,GAAG,KAAa,IAAR52B,EAAE0R,OAAW,OAAO1R,OAAO,GAAG,OAAOA,EAAEgS,MAAM,CAAChS,EAAEgS,MAAMP,OAAOzR,EAAEA,EAAEA,EAAEgS,MAAM,SAAS,GAAGhS,IAAID,EAAE,MAAM,KAAK,OAAOC,EAAEiS,SAAS,CAAC,GAAG,OAAOjS,EAAEyR,QAAQzR,EAAEyR,SAAS1R,EAAE,OAAO,KAAKC,EAAEA,EAAEyR,OAAOzR,EAAEiS,QAAQR,OAAOzR,EAAEyR,OAAOzR,EAAEA,EAAEiS,QAAQ,OAAO,KAAK,IAAI4kB,GAAG,GACrc,SAASC,KAAK,IAAI,IAAI/2B,EAAE,EAAEA,EAAE82B,GAAG12B,OAAOJ,IAAI82B,GAAG92B,GAAGg3B,8BAA8B,KAAKF,GAAG12B,OAAO,EAAE,IAAI62B,GAAGxzB,EAAGyzB,uBAAuBC,GAAG1zB,EAAGoU,wBAAwBuf,GAAG,EAAEC,GAAE,KAAKC,GAAE,KAAKC,GAAE,KAAKC,IAAG,EAAGC,IAAG,EAAGC,GAAG,EAAEC,GAAG,EAAE,SAASC,KAAI,MAAM3yB,MAAMlF,EAAE,MAAO,SAAS83B,GAAG73B,EAAEC,GAAG,GAAG,OAAOA,EAAE,OAAM,EAAG,IAAI,IAAIC,EAAE,EAAEA,EAAED,EAAEG,QAAQF,EAAEF,EAAEI,OAAOF,IAAI,IAAIqjB,GAAGvjB,EAAEE,GAAGD,EAAEC,IAAI,OAAM,EAAG,OAAM,EAC9V,SAAS43B,GAAG93B,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,GAAyH,GAAtH01B,GAAG11B,EAAE21B,GAAEp3B,EAAEA,EAAE4R,cAAc,KAAK5R,EAAEyxB,YAAY,KAAKzxB,EAAE4wB,MAAM,EAAEoG,GAAG9kB,QAAQ,OAAOnS,GAAG,OAAOA,EAAE6R,cAAckmB,GAAGC,GAAGh4B,EAAEE,EAAEsB,EAAEC,GAAMg2B,GAAG,CAAC/1B,EAAE,EAAE,EAAE,CAAY,GAAX+1B,IAAG,EAAGC,GAAG,EAAK,IAAIh2B,EAAE,MAAMuD,MAAMlF,EAAE,MAAM2B,GAAG,EAAE61B,GAAED,GAAE,KAAKr3B,EAAEyxB,YAAY,KAAKuF,GAAG9kB,QAAQ8lB,GAAGj4B,EAAEE,EAAEsB,EAAEC,SAASg2B,IAAkE,GAA9DR,GAAG9kB,QAAQ+lB,GAAGj4B,EAAE,OAAOq3B,IAAG,OAAOA,GAAEpG,KAAKkG,GAAG,EAAEG,GAAED,GAAED,GAAE,KAAKG,IAAG,EAAMv3B,EAAE,MAAMgF,MAAMlF,EAAE,MAAM,OAAOC,EAAE,SAASm4B,KAAK,IAAIn4B,EAAE,IAAI03B,GAAQ,OAALA,GAAG,EAAS13B,EAC9Y,SAASo4B,KAAK,IAAIp4B,EAAE,CAAC6R,cAAc,KAAK8f,UAAU,KAAK0G,UAAU,KAAKC,MAAM,KAAKpH,KAAK,MAA8C,OAAxC,OAAOqG,GAAEF,GAAExlB,cAAc0lB,GAAEv3B,EAAEu3B,GAAEA,GAAErG,KAAKlxB,EAASu3B,GAAE,SAASgB,KAAK,GAAG,OAAOjB,GAAE,CAAC,IAAIt3B,EAAEq3B,GAAE5lB,UAAUzR,EAAE,OAAOA,EAAEA,EAAE6R,cAAc,UAAU7R,EAAEs3B,GAAEpG,KAAK,IAAIjxB,EAAE,OAAOs3B,GAAEF,GAAExlB,cAAc0lB,GAAErG,KAAK,GAAG,OAAOjxB,EAAEs3B,GAAEt3B,EAAEq3B,GAAEt3B,MAAM,CAAC,GAAG,OAAOA,EAAE,MAAMiF,MAAMlF,EAAE,MAAUC,EAAE,CAAC6R,eAAPylB,GAAEt3B,GAAqB6R,cAAc8f,UAAU2F,GAAE3F,UAAU0G,UAAUf,GAAEe,UAAUC,MAAMhB,GAAEgB,MAAMpH,KAAK,MAAM,OAAOqG,GAAEF,GAAExlB,cAAc0lB,GAAEv3B,EAAEu3B,GAAEA,GAAErG,KAAKlxB,EAAE,OAAOu3B,GAChe,SAASiB,GAAGx4B,EAAEC,GAAG,MAAM,oBAAoBA,EAAEA,EAAED,GAAGC,EAClD,SAASw4B,GAAGz4B,GAAG,IAAIC,EAAEs4B,KAAKr4B,EAAED,EAAEq4B,MAAM,GAAG,OAAOp4B,EAAE,MAAM+E,MAAMlF,EAAE,MAAMG,EAAEw4B,oBAAoB14B,EAAE,IAAIwB,EAAE81B,GAAE71B,EAAED,EAAE62B,UAAU32B,EAAExB,EAAE6xB,QAAQ,GAAG,OAAOrwB,EAAE,CAAC,GAAG,OAAOD,EAAE,CAAC,IAAIE,EAAEF,EAAEyvB,KAAKzvB,EAAEyvB,KAAKxvB,EAAEwvB,KAAKxvB,EAAEwvB,KAAKvvB,EAAEH,EAAE62B,UAAU52B,EAAEC,EAAExB,EAAE6xB,QAAQ,KAAK,GAAG,OAAOtwB,EAAE,CAACC,EAAED,EAAEyvB,KAAK1vB,EAAEA,EAAEmwB,UAAU,IAAI9rB,EAAElE,EAAE,KAAKmE,EAAE,KAAKF,EAAElE,EAAE,EAAE,CAAC,IAAIsP,EAAEpL,EAAEwsB,KAAK,IAAIgF,GAAGpmB,KAAKA,EAAE,OAAOlL,IAAIA,EAAEA,EAAEorB,KAAK,CAACkB,KAAK,EAAEuG,OAAO/yB,EAAE+yB,OAAOC,cAAchzB,EAAEgzB,cAAcC,WAAWjzB,EAAEizB,WAAW3H,KAAK,OAAO1vB,EAAEoE,EAAEgzB,cAAchzB,EAAEizB,WAAW74B,EAAEwB,EAAEoE,EAAE+yB,YAAY,CAAC,IAAI/F,EAAE,CAACR,KAAKphB,EAAE2nB,OAAO/yB,EAAE+yB,OAAOC,cAAchzB,EAAEgzB,cACngBC,WAAWjzB,EAAEizB,WAAW3H,KAAK,MAAM,OAAOprB,GAAGD,EAAEC,EAAE8sB,EAAEjxB,EAAEH,GAAGsE,EAAEA,EAAEorB,KAAK0B,EAAEyE,GAAExG,OAAO7f,EAAE+hB,IAAI/hB,EAAEpL,EAAEA,EAAEsrB,WAAW,OAAOtrB,GAAGA,IAAIlE,GAAG,OAAOoE,EAAEnE,EAAEH,EAAEsE,EAAEorB,KAAKrrB,EAAE0d,GAAG/hB,EAAEvB,EAAE4R,iBAAiBif,IAAG,GAAI7wB,EAAE4R,cAAcrQ,EAAEvB,EAAE0xB,UAAUhwB,EAAE1B,EAAEo4B,UAAUvyB,EAAE5F,EAAE44B,kBAAkBt3B,EAAkB,GAAG,QAAnBxB,EAAEE,EAAEoxB,aAAwB,CAAC7vB,EAAEzB,EAAE,GAAG0B,EAAED,EAAE2wB,KAAKiF,GAAExG,OAAOnvB,EAAEqxB,IAAIrxB,EAAED,EAAEA,EAAEyvB,WAAWzvB,IAAIzB,QAAQ,OAAOyB,IAAIvB,EAAE2wB,MAAM,GAAG,MAAM,CAAC5wB,EAAE4R,cAAc3R,EAAE64B,UACrX,SAASC,GAAGh5B,GAAG,IAAIC,EAAEs4B,KAAKr4B,EAAED,EAAEq4B,MAAM,GAAG,OAAOp4B,EAAE,MAAM+E,MAAMlF,EAAE,MAAMG,EAAEw4B,oBAAoB14B,EAAE,IAAIwB,EAAEtB,EAAE64B,SAASt3B,EAAEvB,EAAE6xB,QAAQrwB,EAAEzB,EAAE4R,cAAc,GAAG,OAAOpQ,EAAE,CAACvB,EAAE6xB,QAAQ,KAAK,IAAIpwB,EAAEF,EAAEA,EAAEyvB,KAAK,GAAGxvB,EAAE1B,EAAE0B,EAAEC,EAAEg3B,QAAQh3B,EAAEA,EAAEuvB,WAAWvvB,IAAIF,GAAG8hB,GAAG7hB,EAAEzB,EAAE4R,iBAAiBif,IAAG,GAAI7wB,EAAE4R,cAAcnQ,EAAE,OAAOzB,EAAEo4B,YAAYp4B,EAAE0xB,UAAUjwB,GAAGxB,EAAE44B,kBAAkBp3B,EAAE,MAAM,CAACA,EAAEF,GAAG,SAASy3B,MAC/V,SAASC,GAAGl5B,EAAEC,GAAG,IAAIC,EAAEm3B,GAAE71B,EAAE+2B,KAAK92B,EAAExB,IAAIyB,GAAG6hB,GAAG/hB,EAAEqQ,cAAcpQ,GAAsE,GAAnEC,IAAIF,EAAEqQ,cAAcpQ,EAAEqvB,IAAG,GAAItvB,EAAEA,EAAE82B,MAAMa,GAAGC,GAAGzQ,KAAK,KAAKzoB,EAAEsB,EAAExB,GAAG,CAACA,IAAOwB,EAAE63B,cAAcp5B,GAAGyB,GAAG,OAAO61B,IAAuB,EAApBA,GAAE1lB,cAAc1L,IAAM,CAAuD,GAAtDjG,EAAEyR,OAAO,KAAK2nB,GAAG,EAAEC,GAAG5Q,KAAK,KAAKzoB,EAAEsB,EAAEC,EAAExB,QAAG,EAAO,MAAS,OAAOu5B,GAAE,MAAMv0B,MAAMlF,EAAE,MAAM,KAAQ,GAAHq3B,KAAQqC,GAAGv5B,EAAED,EAAEwB,GAAG,OAAOA,EAAE,SAASg4B,GAAGz5B,EAAEC,EAAEC,GAAGF,EAAE2R,OAAO,MAAM3R,EAAE,CAACq5B,YAAYp5B,EAAE0H,MAAMzH,GAAmB,QAAhBD,EAAEo3B,GAAE3F,cAAsBzxB,EAAE,CAACy5B,WAAW,KAAKC,OAAO,MAAMtC,GAAE3F,YAAYzxB,EAAEA,EAAE05B,OAAO,CAAC35B,IAAgB,QAAXE,EAAED,EAAE05B,QAAgB15B,EAAE05B,OAAO,CAAC35B,GAAGE,EAAEiQ,KAAKnQ,GAC/e,SAASu5B,GAAGv5B,EAAEC,EAAEC,EAAEsB,GAAGvB,EAAE0H,MAAMzH,EAAED,EAAEo5B,YAAY73B,EAAEo4B,GAAG35B,IAAI45B,GAAG75B,GAAG,SAASo5B,GAAGp5B,EAAEC,EAAEC,GAAG,OAAOA,GAAE,WAAW05B,GAAG35B,IAAI45B,GAAG75B,MAAK,SAAS45B,GAAG55B,GAAG,IAAIC,EAAED,EAAEq5B,YAAYr5B,EAAEA,EAAE2H,MAAM,IAAI,IAAIzH,EAAED,IAAI,OAAOsjB,GAAGvjB,EAAEE,GAAG,MAAMsB,GAAG,OAAM,GAAI,SAASq4B,GAAG75B,GAAG,IAAIC,EAAEsxB,GAAGvxB,EAAE,GAAG,OAAOC,GAAG0zB,GAAG1zB,EAAED,EAAE,GAAG,GAChQ,SAAS85B,GAAG95B,GAAG,IAAIC,EAAEm4B,KAA8M,MAAzM,oBAAoBp4B,IAAIA,EAAEA,KAAKC,EAAE4R,cAAc5R,EAAE0xB,UAAU3xB,EAAEA,EAAE,CAAC+xB,QAAQ,KAAKT,YAAY,KAAKT,MAAM,EAAEkI,SAAS,KAAKL,oBAAoBF,GAAGM,kBAAkB94B,GAAGC,EAAEq4B,MAAMt4B,EAAEA,EAAEA,EAAE+4B,SAASgB,GAAGpR,KAAK,KAAK0O,GAAEr3B,GAAS,CAACC,EAAE4R,cAAc7R,GAC1P,SAASs5B,GAAGt5B,EAAEC,EAAEC,EAAEsB,GAA8O,OAA3OxB,EAAE,CAACmG,IAAInG,EAAEg6B,OAAO/5B,EAAEg6B,QAAQ/5B,EAAEg6B,KAAK14B,EAAE0vB,KAAK,MAAsB,QAAhBjxB,EAAEo3B,GAAE3F,cAAsBzxB,EAAE,CAACy5B,WAAW,KAAKC,OAAO,MAAMtC,GAAE3F,YAAYzxB,EAAEA,EAAEy5B,WAAW15B,EAAEkxB,KAAKlxB,GAAmB,QAAfE,EAAED,EAAEy5B,YAAoBz5B,EAAEy5B,WAAW15B,EAAEkxB,KAAKlxB,GAAGwB,EAAEtB,EAAEgxB,KAAKhxB,EAAEgxB,KAAKlxB,EAAEA,EAAEkxB,KAAK1vB,EAAEvB,EAAEy5B,WAAW15B,GAAWA,EAAE,SAASm6B,KAAK,OAAO5B,KAAK1mB,cAAc,SAASuoB,GAAGp6B,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAE22B,KAAKf,GAAE1lB,OAAO3R,EAAEyB,EAAEoQ,cAAcynB,GAAG,EAAEr5B,EAAEC,OAAE,OAAO,IAASsB,EAAE,KAAKA,GAC5Y,SAAS64B,GAAGr6B,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAE82B,KAAK/2B,OAAE,IAASA,EAAE,KAAKA,EAAE,IAAIE,OAAE,EAAO,GAAG,OAAO41B,GAAE,CAAC,IAAI31B,EAAE21B,GAAEzlB,cAA0B,GAAZnQ,EAAEC,EAAEs4B,QAAW,OAAOz4B,GAAGq2B,GAAGr2B,EAAEG,EAAEu4B,MAAmC,YAA5Bz4B,EAAEoQ,cAAcynB,GAAGr5B,EAAEC,EAAEwB,EAAEF,IAAW61B,GAAE1lB,OAAO3R,EAAEyB,EAAEoQ,cAAcynB,GAAG,EAAEr5B,EAAEC,EAAEwB,EAAEF,GAAG,SAAS84B,GAAGt6B,EAAEC,GAAG,OAAOm6B,GAAG,QAAQ,EAAEp6B,EAAEC,GAAG,SAASk5B,GAAGn5B,EAAEC,GAAG,OAAOo6B,GAAG,KAAK,EAAEr6B,EAAEC,GAAG,SAASs6B,GAAGv6B,EAAEC,GAAG,OAAOo6B,GAAG,EAAE,EAAEr6B,EAAEC,GAAG,SAASu6B,GAAGx6B,EAAEC,GAAG,OAAOo6B,GAAG,EAAE,EAAEr6B,EAAEC,GAC9W,SAASw6B,GAAGz6B,EAAEC,GAAG,MAAG,oBAAoBA,GAASD,EAAEA,IAAIC,EAAED,GAAG,WAAWC,EAAE,QAAU,OAAOA,QAAG,IAASA,GAASD,EAAEA,IAAIC,EAAEkS,QAAQnS,EAAE,WAAWC,EAAEkS,QAAQ,YAAtE,EAA4E,SAASuoB,GAAG16B,EAAEC,EAAEC,GAA6C,OAA1CA,EAAE,OAAOA,QAAG,IAASA,EAAEA,EAAE4nB,OAAO,CAAC9nB,IAAI,KAAYq6B,GAAG,EAAE,EAAEI,GAAG9R,KAAK,KAAK1oB,EAAED,GAAGE,GAAG,SAASy6B,MAAM,SAASC,GAAG56B,EAAEC,GAAG,IAAIC,EAAEq4B,KAAKt4B,OAAE,IAASA,EAAE,KAAKA,EAAE,IAAIuB,EAAEtB,EAAE2R,cAAc,OAAG,OAAOrQ,GAAG,OAAOvB,GAAG43B,GAAG53B,EAAEuB,EAAE,IAAWA,EAAE,IAAGtB,EAAE2R,cAAc,CAAC7R,EAAEC,GAAUD,GAC5Z,SAAS66B,GAAG76B,EAAEC,GAAG,IAAIC,EAAEq4B,KAAKt4B,OAAE,IAASA,EAAE,KAAKA,EAAE,IAAIuB,EAAEtB,EAAE2R,cAAc,OAAG,OAAOrQ,GAAG,OAAOvB,GAAG43B,GAAG53B,EAAEuB,EAAE,IAAWA,EAAE,IAAGxB,EAAEA,IAAIE,EAAE2R,cAAc,CAAC7R,EAAEC,GAAUD,GAAE,SAAS86B,GAAG96B,EAAEC,EAAEC,GAAG,OAAG,KAAQ,GAAHk3B,KAAcp3B,EAAE2xB,YAAY3xB,EAAE2xB,WAAU,EAAGb,IAAG,GAAI9wB,EAAE6R,cAAc3R,IAAEqjB,GAAGrjB,EAAED,KAAKC,EAAE8U,KAAKqiB,GAAExG,OAAO3wB,EAAE6yB,IAAI7yB,EAAEF,EAAE2xB,WAAU,GAAW1xB,GAAE,SAAS86B,GAAG/6B,EAAEC,GAAG,IAAIC,EAAEmV,GAAEA,GAAE,IAAInV,GAAG,EAAEA,EAAEA,EAAE,EAAEF,GAAE,GAAI,IAAIwB,EAAE21B,GAAGnf,WAAWmf,GAAGnf,WAAW,GAAG,IAAIhY,GAAE,GAAIC,IAAV,QAAsBoV,GAAEnV,EAAEi3B,GAAGnf,WAAWxW,GAAG,SAASw5B,KAAK,OAAOzC,KAAK1mB,cAC7c,SAASopB,GAAGj7B,EAAEC,EAAEC,GAAG,IAAIsB,EAAEkyB,GAAG1zB,GAAkE,GAA/DE,EAAE,CAACkyB,KAAK5wB,EAAEm3B,OAAOz4B,EAAE04B,eAAc,EAAGC,WAAW,KAAK3H,KAAK,MAASgK,GAAGl7B,GAAGm7B,GAAGl7B,EAAEC,QAAQ,GAAiB,QAAdA,EAAEmxB,GAAGrxB,EAAEC,EAAEC,EAAEsB,IAAY,CAAWmyB,GAAGzzB,EAAEF,EAAEwB,EAAXiyB,MAAgB2H,GAAGl7B,EAAED,EAAEuB,IAC5K,SAASu4B,GAAG/5B,EAAEC,EAAEC,GAAG,IAAIsB,EAAEkyB,GAAG1zB,GAAGyB,EAAE,CAAC2wB,KAAK5wB,EAAEm3B,OAAOz4B,EAAE04B,eAAc,EAAGC,WAAW,KAAK3H,KAAK,MAAM,GAAGgK,GAAGl7B,GAAGm7B,GAAGl7B,EAAEwB,OAAO,CAAC,IAAIC,EAAE1B,EAAEyR,UAAU,GAAG,IAAIzR,EAAE6wB,QAAQ,OAAOnvB,GAAG,IAAIA,EAAEmvB,QAAiC,QAAxBnvB,EAAEzB,EAAEy4B,qBAA8B,IAAI,IAAI/2B,EAAE1B,EAAE64B,kBAAkBjzB,EAAEnE,EAAEC,EAAEzB,GAAqC,GAAlCuB,EAAEm3B,eAAc,EAAGn3B,EAAEo3B,WAAWhzB,EAAK0d,GAAG1d,EAAElE,GAAG,CAAC,IAAImE,EAAE7F,EAAEqxB,YAA+E,OAAnE,OAAOxrB,GAAGrE,EAAEyvB,KAAKzvB,EAAE2vB,GAAGnxB,KAAKwB,EAAEyvB,KAAKprB,EAAEorB,KAAKprB,EAAEorB,KAAKzvB,QAAGxB,EAAEqxB,YAAY7vB,IAAU,MAAMmE,IAA2B,QAAd1F,EAAEmxB,GAAGrxB,EAAEC,EAAEwB,EAAED,MAAoBmyB,GAAGzzB,EAAEF,EAAEwB,EAAbC,EAAEgyB,MAAgB2H,GAAGl7B,EAAED,EAAEuB,KAC3c,SAAS05B,GAAGl7B,GAAG,IAAIC,EAAED,EAAEyR,UAAU,OAAOzR,IAAIq3B,IAAG,OAAOp3B,GAAGA,IAAIo3B,GAAE,SAAS8D,GAAGn7B,EAAEC,GAAGw3B,GAAGD,IAAG,EAAG,IAAIt3B,EAAEF,EAAE+xB,QAAQ,OAAO7xB,EAAED,EAAEixB,KAAKjxB,GAAGA,EAAEixB,KAAKhxB,EAAEgxB,KAAKhxB,EAAEgxB,KAAKjxB,GAAGD,EAAE+xB,QAAQ9xB,EAAE,SAASm7B,GAAGp7B,EAAEC,EAAEC,GAAG,GAAG,KAAO,QAAFA,GAAW,CAAC,IAAIsB,EAAEvB,EAAE4wB,MAAwB3wB,GAAlBsB,GAAGxB,EAAEyU,aAAkBxU,EAAE4wB,MAAM3wB,EAAEkV,GAAGpV,EAAEE,IAC3P,IAAIg4B,GAAG,CAACmD,YAAYtK,GAAGuK,YAAY1D,GAAE2D,WAAW3D,GAAE4D,UAAU5D,GAAE6D,oBAAoB7D,GAAE8D,mBAAmB9D,GAAE+D,gBAAgB/D,GAAEgE,QAAQhE,GAAEiE,WAAWjE,GAAEkE,OAAOlE,GAAEmE,SAASnE,GAAEoE,cAAcpE,GAAEqE,iBAAiBrE,GAAEsE,cAActE,GAAEuE,iBAAiBvE,GAAEwE,qBAAqBxE,GAAEyE,MAAMzE,GAAE0E,0BAAyB,GAAIvE,GAAG,CAACsD,YAAYtK,GAAGuK,YAAY,SAASt7B,EAAEC,GAA4C,OAAzCm4B,KAAKvmB,cAAc,CAAC7R,OAAE,IAASC,EAAE,KAAKA,GAAUD,GAAGu7B,WAAWxK,GAAGyK,UAAUlB,GAAGmB,oBAAoB,SAASz7B,EAAEC,EAAEC,GAA6C,OAA1CA,EAAE,OAAOA,QAAG,IAASA,EAAEA,EAAE4nB,OAAO,CAAC9nB,IAAI,KAAYo6B,GAAG,QAC3f,EAAEK,GAAG9R,KAAK,KAAK1oB,EAAED,GAAGE,IAAIy7B,gBAAgB,SAAS37B,EAAEC,GAAG,OAAOm6B,GAAG,QAAQ,EAAEp6B,EAAEC,IAAIy7B,mBAAmB,SAAS17B,EAAEC,GAAG,OAAOm6B,GAAG,EAAE,EAAEp6B,EAAEC,IAAI27B,QAAQ,SAAS57B,EAAEC,GAAG,IAAIC,EAAEk4B,KAAqD,OAAhDn4B,OAAE,IAASA,EAAE,KAAKA,EAAED,EAAEA,IAAIE,EAAE2R,cAAc,CAAC7R,EAAEC,GAAUD,GAAG67B,WAAW,SAAS77B,EAAEC,EAAEC,GAAG,IAAIsB,EAAE42B,KAAkM,OAA7Ln4B,OAAE,IAASC,EAAEA,EAAED,GAAGA,EAAEuB,EAAEqQ,cAAcrQ,EAAEmwB,UAAU1xB,EAAED,EAAE,CAAC+xB,QAAQ,KAAKT,YAAY,KAAKT,MAAM,EAAEkI,SAAS,KAAKL,oBAAoB14B,EAAE84B,kBAAkB74B,GAAGuB,EAAE82B,MAAMt4B,EAAEA,EAAEA,EAAE+4B,SAASkC,GAAGtS,KAAK,KAAK0O,GAAEr3B,GAAS,CAACwB,EAAEqQ,cAAc7R,IAAI87B,OAAO,SAAS97B,GAC3d,OAAdA,EAAE,CAACmS,QAAQnS,GAAhBo4B,KAA4BvmB,cAAc7R,GAAG+7B,SAASjC,GAAGkC,cAAcrB,GAAGsB,iBAAiB,SAASj8B,GAAG,OAAOo4B,KAAKvmB,cAAc7R,GAAGk8B,cAAc,WAAW,IAAIl8B,EAAE85B,IAAG,GAAI75B,EAAED,EAAE,GAA6C,OAA1CA,EAAE+6B,GAAGpS,KAAK,KAAK3oB,EAAE,IAAIo4B,KAAKvmB,cAAc7R,EAAQ,CAACC,EAAED,IAAIm8B,iBAAiB,aAAaC,qBAAqB,SAASp8B,EAAEC,EAAEC,GAAG,IAAIsB,EAAE61B,GAAE51B,EAAE22B,KAAK,GAAG1J,GAAE,CAAC,QAAG,IAASxuB,EAAE,MAAM+E,MAAMlF,EAAE,MAAMG,EAAEA,QAAQ,CAAO,GAANA,EAAED,IAAO,OAAOu5B,GAAE,MAAMv0B,MAAMlF,EAAE,MAAM,KAAQ,GAAHq3B,KAAQqC,GAAGj4B,EAAEvB,EAAEC,GAAGuB,EAAEoQ,cAAc3R,EAAE,IAAIwB,EAAE,CAACiG,MAAMzH,EAAEm5B,YAAYp5B,GACvZ,OAD0ZwB,EAAE62B,MAAM52B,EAAE44B,GAAGlB,GAAGzQ,KAAK,KAAKnnB,EACpfE,EAAE1B,GAAG,CAACA,IAAIwB,EAAEmQ,OAAO,KAAK2nB,GAAG,EAAEC,GAAG5Q,KAAK,KAAKnnB,EAAEE,EAAExB,EAAED,QAAG,EAAO,MAAaC,GAAGm8B,MAAM,WAAW,IAAIr8B,EAAEo4B,KAAKn4B,EAAEu5B,GAAE+C,iBAAiB,GAAG7N,GAAE,CAAC,IAAIxuB,EAAEiuB,GAAkDluB,EAAE,IAAIA,EAAE,KAA9CC,GAAHguB,KAAU,GAAG,GAAGpa,GAAhBoa,IAAsB,IAAIhkB,SAAS,IAAIhK,GAAuB,GAAPA,EAAEw3B,QAAWz3B,GAAG,IAAIC,EAAEgK,SAAS,KAAKjK,GAAG,SAAgBA,EAAE,IAAIA,EAAE,KAAfC,EAAEy3B,MAAmBztB,SAAS,IAAI,IAAI,OAAOlK,EAAE6R,cAAc5R,GAAGq8B,0BAAyB,GAAItE,GAAG,CAACqD,YAAYtK,GAAGuK,YAAYV,GAAGW,WAAWxK,GAAGyK,UAAUrC,GAAGsC,oBAAoBf,GAAGgB,mBAAmBnB,GAAGoB,gBAAgBnB,GAAGoB,QAAQf,GAAGgB,WAAWpD,GAAGqD,OAAO3B,GAAG4B,SAAS,WAAW,OAAOtD,GAAGD,KAClhBwD,cAAcrB,GAAGsB,iBAAiB,SAASj8B,GAAc,OAAO86B,GAAZvC,KAAiBjB,GAAEzlB,cAAc7R,IAAIk8B,cAAc,WAAgD,MAAM,CAArCzD,GAAGD,IAAI,GAAKD,KAAK1mB,gBAA2BsqB,iBAAiBlD,GAAGmD,qBAAqBlD,GAAGmD,MAAMrB,GAAGsB,0BAAyB,GAAIrE,GAAG,CAACoD,YAAYtK,GAAGuK,YAAYV,GAAGW,WAAWxK,GAAGyK,UAAUrC,GAAGsC,oBAAoBf,GAAGgB,mBAAmBnB,GAAGoB,gBAAgBnB,GAAGoB,QAAQf,GAAGgB,WAAW7C,GAAG8C,OAAO3B,GAAG4B,SAAS,WAAW,OAAO/C,GAAGR,KAAKwD,cAAcrB,GAAGsB,iBAAiB,SAASj8B,GAAG,IAAIC,EAAEs4B,KAAK,OAAO,OACzfjB,GAAEr3B,EAAE4R,cAAc7R,EAAE86B,GAAG76B,EAAEq3B,GAAEzlB,cAAc7R,IAAIk8B,cAAc,WAAgD,MAAM,CAArClD,GAAGR,IAAI,GAAKD,KAAK1mB,gBAA2BsqB,iBAAiBlD,GAAGmD,qBAAqBlD,GAAGmD,MAAMrB,GAAGsB,0BAAyB,GAAI,SAASE,GAAGx8B,EAAEC,GAAG,IAAI,IAAIC,EAAE,GAAGsB,EAAEvB,EAAE,GAAGC,GAAGgG,EAAG1E,GAAGA,EAAEA,EAAEkQ,aAAalQ,GAAG,IAAIC,EAAEvB,EAAE,MAAMwB,GAAGD,EAAE,6BAA6BC,EAAE+6B,QAAQ,KAAK/6B,EAAEwD,MAAM,MAAM,CAACyC,MAAM3H,EAAE+O,OAAO9O,EAAEiF,MAAMzD,EAAEi7B,OAAO,MAAM,SAASC,GAAG38B,EAAEC,EAAEC,GAAG,MAAM,CAACyH,MAAM3H,EAAE+O,OAAO,KAAK7J,MAAM,MAAMhF,EAAEA,EAAE,KAAKw8B,OAAO,MAAMz8B,EAAEA,EAAE,MACpd,SAAS28B,GAAG58B,EAAEC,GAAG,IAAI48B,QAAQC,MAAM78B,EAAE0H,OAAO,MAAMzH,GAAG0qB,YAAW,WAAW,MAAM1qB,MAAM,IAAI68B,GAAG,oBAAoBC,QAAQA,QAAQ9mB,IAAI,SAAS+mB,GAAGj9B,EAAEC,EAAEC,IAAGA,EAAEgyB,IAAI,EAAEhyB,IAAKiG,IAAI,EAAEjG,EAAEmyB,QAAQ,CAACxM,QAAQ,MAAM,IAAIrkB,EAAEvB,EAAE0H,MAAsD,OAAhDzH,EAAEoyB,SAAS,WAAW4K,KAAKA,IAAG,EAAGC,GAAG37B,GAAGo7B,GAAG58B,EAAEC,IAAWC,EAC1Q,SAASk9B,GAAGp9B,EAAEC,EAAEC,IAAGA,EAAEgyB,IAAI,EAAEhyB,IAAKiG,IAAI,EAAE,IAAI3E,EAAExB,EAAEkC,KAAKm7B,yBAAyB,GAAG,oBAAoB77B,EAAE,CAAC,IAAIC,EAAExB,EAAE0H,MAAMzH,EAAEmyB,QAAQ,WAAW,OAAO7wB,EAAEC,IAAIvB,EAAEoyB,SAAS,WAAWsK,GAAG58B,EAAEC,IAAI,IAAIyB,EAAE1B,EAAEgQ,UAA8O,OAApO,OAAOtO,GAAG,oBAAoBA,EAAE47B,oBAAoBp9B,EAAEoyB,SAAS,WAAWsK,GAAG58B,EAAEC,GAAG,oBAAoBuB,IAAI,OAAO+7B,GAAGA,GAAG,IAAIh9B,IAAI,CAACqB,OAAO27B,GAAG58B,IAAIiB,OAAO,IAAI1B,EAAED,EAAEiF,MAAMtD,KAAK07B,kBAAkBr9B,EAAE0H,MAAM,CAAC61B,eAAe,OAAOt9B,EAAEA,EAAE,OAAcA,EAClb,SAASu9B,GAAGz9B,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAE09B,UAAU,GAAG,OAAOl8B,EAAE,CAACA,EAAExB,EAAE09B,UAAU,IAAIX,GAAG,IAAIt7B,EAAE,IAAIlB,IAAIiB,EAAEiE,IAAIxF,EAAEwB,aAAmB,KAAXA,EAAED,EAAE0F,IAAIjH,MAAgBwB,EAAE,IAAIlB,IAAIiB,EAAEiE,IAAIxF,EAAEwB,IAAIA,EAAE4mB,IAAInoB,KAAKuB,EAAEd,IAAIT,GAAGF,EAAE29B,GAAGhV,KAAK,KAAK3oB,EAAEC,EAAEC,GAAGD,EAAEmrB,KAAKprB,EAAEA,IAAI,SAAS49B,GAAG59B,GAAG,EAAE,CAAC,IAAIC,EAA4E,IAAvEA,EAAE,KAAKD,EAAEmG,OAAsBlG,EAAE,QAApBA,EAAED,EAAE6R,gBAAyB,OAAO5R,EAAE6R,YAAuB7R,EAAE,OAAOD,EAAEA,EAAEA,EAAE0R,aAAa,OAAO1R,GAAG,OAAO,KAC5V,SAAS69B,GAAG79B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,OAAG,KAAY,EAAPzB,EAAEsvB,OAAetvB,IAAIC,EAAED,EAAE2R,OAAO,OAAO3R,EAAE2R,OAAO,IAAIzR,EAAEyR,OAAO,OAAOzR,EAAEyR,QAAQ,MAAM,IAAIzR,EAAEiG,MAAM,OAAOjG,EAAEuR,UAAUvR,EAAEiG,IAAI,KAAIlG,EAAEiyB,IAAI,EAAE,IAAK/rB,IAAI,EAAEosB,GAAGryB,EAAED,EAAE,KAAKC,EAAE2wB,OAAO,GAAG7wB,IAAEA,EAAE2R,OAAO,MAAM3R,EAAE6wB,MAAMpvB,EAASzB,GAAE,IAAI89B,GAAGr6B,EAAGs6B,kBAAkBjN,IAAG,EAAG,SAASkN,GAAGh+B,EAAEC,EAAEC,EAAEsB,GAAGvB,EAAEgS,MAAM,OAAOjS,EAAEg2B,GAAG/1B,EAAE,KAAKC,EAAEsB,GAAGu0B,GAAG91B,EAAED,EAAEiS,MAAM/R,EAAEsB,GACjV,SAASy8B,GAAGj+B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAGvB,EAAEA,EAAEkG,OAAO,IAAI1E,EAAEzB,EAAE+0B,IAAqC,OAAjCtE,GAAGzwB,EAAEwB,GAAGD,EAAEs2B,GAAG93B,EAAEC,EAAEC,EAAEsB,EAAEE,EAAED,GAAGvB,EAAEi4B,KAAQ,OAAOn4B,GAAI8wB,IAA2EpC,IAAGxuB,GAAGouB,GAAGruB,GAAGA,EAAE0R,OAAO,EAAEqsB,GAAGh+B,EAAEC,EAAEuB,EAAEC,GAAUxB,EAAEgS,QAA7GhS,EAAEyxB,YAAY1xB,EAAE0xB,YAAYzxB,EAAE0R,QAAQ,KAAK3R,EAAE6wB,QAAQpvB,EAAEy8B,GAAGl+B,EAAEC,EAAEwB,IACrK,SAAS08B,GAAGn+B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,GAAG,OAAOzB,EAAE,CAAC,IAAI0B,EAAExB,EAAEgC,KAAK,MAAG,oBAAoBR,GAAI08B,GAAG18B,SAAI,IAASA,EAAEsuB,cAAc,OAAO9vB,EAAEm+B,cAAS,IAASn+B,EAAE8vB,eAAoDhwB,EAAE01B,GAAGx1B,EAAEgC,KAAK,KAAKV,EAAEvB,EAAEA,EAAEqvB,KAAK7tB,IAAKuzB,IAAI/0B,EAAE+0B,IAAIh1B,EAAE0R,OAAOzR,EAASA,EAAEgS,MAAMjS,IAArGC,EAAEkG,IAAI,GAAGlG,EAAEiC,KAAKR,EAAE48B,GAAGt+B,EAAEC,EAAEyB,EAAEF,EAAEC,IAAoF,GAAVC,EAAE1B,EAAEiS,MAAS,KAAKjS,EAAE6wB,MAAMpvB,GAAG,CAAC,IAAIE,EAAED,EAAEguB,cAA0C,IAAhBxvB,EAAE,QAAdA,EAAEA,EAAEm+B,SAAmBn+B,EAAEsjB,IAAQ7hB,EAAEH,IAAIxB,EAAEg1B,MAAM/0B,EAAE+0B,IAAI,OAAOkJ,GAAGl+B,EAAEC,EAAEwB,GAA+C,OAA5CxB,EAAE0R,OAAO,GAAE3R,EAAEw1B,GAAG9zB,EAAEF,IAAKwzB,IAAI/0B,EAAE+0B,IAAIh1B,EAAE0R,OAAOzR,EAASA,EAAEgS,MAAMjS,EACzb,SAASs+B,GAAGt+B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,GAAG,OAAOzB,EAAE,CAAC,IAAI0B,EAAE1B,EAAE0vB,cAAc,GAAGlM,GAAG9hB,EAAEF,IAAIxB,EAAEg1B,MAAM/0B,EAAE+0B,IAAI,IAAGlE,IAAG,EAAG7wB,EAAEgvB,aAAaztB,EAAEE,EAAE,KAAK1B,EAAE6wB,MAAMpvB,GAAsC,OAAOxB,EAAE4wB,MAAM7wB,EAAE6wB,MAAMqN,GAAGl+B,EAAEC,EAAEwB,GAAjE,KAAa,OAARzB,EAAE2R,SAAgBmf,IAAG,IAA0C,OAAOyN,GAAGv+B,EAAEC,EAAEC,EAAEsB,EAAEC,GACtN,SAAS+8B,GAAGx+B,EAAEC,EAAEC,GAAG,IAAIsB,EAAEvB,EAAEgvB,aAAaxtB,EAAED,EAAE8H,SAAS5H,EAAE,OAAO1B,EAAEA,EAAE6R,cAAc,KAAK,GAAG,WAAWrQ,EAAE8tB,KAAK,GAAG,KAAY,EAAPrvB,EAAEqvB,MAAQrvB,EAAE4R,cAAc,CAAC4sB,UAAU,EAAEC,UAAU,KAAKC,YAAY,MAAMvS,GAAEwS,GAAGC,IAAIA,IAAI3+B,MAAM,CAAC,GAAG,KAAO,WAAFA,GAAc,OAAOF,EAAE,OAAO0B,EAAEA,EAAE+8B,UAAUv+B,EAAEA,EAAED,EAAE4wB,MAAM5wB,EAAEwwB,WAAW,WAAWxwB,EAAE4R,cAAc,CAAC4sB,UAAUz+B,EAAE0+B,UAAU,KAAKC,YAAY,MAAM1+B,EAAEyxB,YAAY,KAAKtF,GAAEwS,GAAGC,IAAIA,IAAI7+B,EAAE,KAAKC,EAAE4R,cAAc,CAAC4sB,UAAU,EAAEC,UAAU,KAAKC,YAAY,MAAMn9B,EAAE,OAAOE,EAAEA,EAAE+8B,UAAUv+B,EAAEksB,GAAEwS,GAAGC,IAAIA,IAAIr9B,OAAO,OACtfE,GAAGF,EAAEE,EAAE+8B,UAAUv+B,EAAED,EAAE4R,cAAc,MAAMrQ,EAAEtB,EAAEksB,GAAEwS,GAAGC,IAAIA,IAAIr9B,EAAc,OAAZw8B,GAAGh+B,EAAEC,EAAEwB,EAAEvB,GAAUD,EAAEgS,MAAM,SAAS6sB,GAAG9+B,EAAEC,GAAG,IAAIC,EAAED,EAAE+0B,KAAO,OAAOh1B,GAAG,OAAOE,GAAG,OAAOF,GAAGA,EAAEg1B,MAAM90B,KAAED,EAAE0R,OAAO,IAAI1R,EAAE0R,OAAO,SAAQ,SAAS4sB,GAAGv+B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,IAAIC,EAAEmrB,GAAG3sB,GAAGssB,GAAGF,GAAEna,QAAmD,OAA3CzQ,EAAE+qB,GAAGxsB,EAAEyB,GAAGgvB,GAAGzwB,EAAEwB,GAAGvB,EAAE43B,GAAG93B,EAAEC,EAAEC,EAAEsB,EAAEE,EAAED,GAAGD,EAAE22B,KAAQ,OAAOn4B,GAAI8wB,IAA2EpC,IAAGltB,GAAG8sB,GAAGruB,GAAGA,EAAE0R,OAAO,EAAEqsB,GAAGh+B,EAAEC,EAAEC,EAAEuB,GAAUxB,EAAEgS,QAA7GhS,EAAEyxB,YAAY1xB,EAAE0xB,YAAYzxB,EAAE0R,QAAQ,KAAK3R,EAAE6wB,QAAQpvB,EAAEy8B,GAAGl+B,EAAEC,EAAEwB,IAC9W,SAASs9B,GAAG/+B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,GAAGorB,GAAG3sB,GAAG,CAAC,IAAIwB,GAAE,EAAGyrB,GAAGltB,QAAQyB,GAAE,EAAW,GAARgvB,GAAGzwB,EAAEwB,GAAM,OAAOxB,EAAE+P,UAAUgvB,GAAGh/B,EAAEC,GAAGg0B,GAAGh0B,EAAEC,EAAEsB,GAAGgzB,GAAGv0B,EAAEC,EAAEsB,EAAEC,GAAGD,GAAE,OAAQ,GAAG,OAAOxB,EAAE,CAAC,IAAI2B,EAAE1B,EAAE+P,UAAUnK,EAAE5F,EAAEyvB,cAAc/tB,EAAE8yB,MAAM5uB,EAAE,IAAIC,EAAEnE,EAAEqvB,QAAQprB,EAAE1F,EAAEg0B,YAAY,kBAAkBtuB,GAAG,OAAOA,EAAEA,EAAEmrB,GAAGnrB,GAAyBA,EAAE6mB,GAAGxsB,EAA1B2F,EAAEinB,GAAG3sB,GAAGssB,GAAGF,GAAEna,SAAmB,IAAInB,EAAE9Q,EAAEw0B,yBAAyB9B,EAAE,oBAAoB5hB,GAAG,oBAAoBrP,EAAEgzB,wBAAwB/B,GAAG,oBAAoBjxB,EAAE4yB,kCAAkC,oBAAoB5yB,EAAE2yB,4BAC1dzuB,IAAIrE,GAAGsE,IAAIF,IAAIyuB,GAAGp0B,EAAE0B,EAAEH,EAAEoE,GAAG4rB,IAAG,EAAG,IAAIqB,EAAE5yB,EAAE4R,cAAclQ,EAAEwyB,MAAMtB,EAAEF,GAAG1yB,EAAEuB,EAAEG,EAAEF,GAAGqE,EAAE7F,EAAE4R,cAAchM,IAAIrE,GAAGqxB,IAAI/sB,GAAGymB,GAAGpa,SAASqf,IAAI,oBAAoBxgB,IAAIoiB,GAAGnzB,EAAEC,EAAE8Q,EAAExP,GAAGsE,EAAE7F,EAAE4R,gBAAgBhM,EAAE2rB,IAAIsC,GAAG7zB,EAAEC,EAAE2F,EAAErE,EAAEqxB,EAAE/sB,EAAEF,KAAKgtB,GAAG,oBAAoBjxB,EAAEizB,2BAA2B,oBAAoBjzB,EAAEkzB,qBAAqB,oBAAoBlzB,EAAEkzB,oBAAoBlzB,EAAEkzB,qBAAqB,oBAAoBlzB,EAAEizB,2BAA2BjzB,EAAEizB,6BAA6B,oBAAoBjzB,EAAEmzB,oBAAoB70B,EAAE0R,OAAO,WAClf,oBAAoBhQ,EAAEmzB,oBAAoB70B,EAAE0R,OAAO,SAAS1R,EAAEyvB,cAAcluB,EAAEvB,EAAE4R,cAAc/L,GAAGnE,EAAE8yB,MAAMjzB,EAAEG,EAAEwyB,MAAMruB,EAAEnE,EAAEqvB,QAAQprB,EAAEpE,EAAEqE,IAAI,oBAAoBlE,EAAEmzB,oBAAoB70B,EAAE0R,OAAO,SAASnQ,GAAE,OAAQ,CAACG,EAAE1B,EAAE+P,UAAUiiB,GAAGjyB,EAAEC,GAAG4F,EAAE5F,EAAEyvB,cAAc9pB,EAAE3F,EAAEiC,OAAOjC,EAAE6uB,YAAYjpB,EAAEkqB,GAAG9vB,EAAEiC,KAAK2D,GAAGlE,EAAE8yB,MAAM7uB,EAAEgtB,EAAE3yB,EAAEgvB,aAAa4D,EAAElxB,EAAEqvB,QAAwB,kBAAhBlrB,EAAE5F,EAAEg0B,cAAiC,OAAOpuB,EAAEA,EAAEirB,GAAGjrB,GAAyBA,EAAE2mB,GAAGxsB,EAA1B6F,EAAE+mB,GAAG3sB,GAAGssB,GAAGF,GAAEna,SAAmB,IAAI2gB,EAAE5yB,EAAEw0B,0BAA0B1jB,EAAE,oBAAoB8hB,GAAG,oBAAoBnxB,EAAEgzB,0BAC9e,oBAAoBhzB,EAAE4yB,kCAAkC,oBAAoB5yB,EAAE2yB,4BAA4BzuB,IAAI+sB,GAAGC,IAAI/sB,IAAIuuB,GAAGp0B,EAAE0B,EAAEH,EAAEsE,GAAG0rB,IAAG,EAAGqB,EAAE5yB,EAAE4R,cAAclQ,EAAEwyB,MAAMtB,EAAEF,GAAG1yB,EAAEuB,EAAEG,EAAEF,GAAG,IAAIqnB,EAAE7oB,EAAE4R,cAAchM,IAAI+sB,GAAGC,IAAI/J,GAAGyD,GAAGpa,SAASqf,IAAI,oBAAoBsB,IAAIM,GAAGnzB,EAAEC,EAAE4yB,EAAEtxB,GAAGsnB,EAAE7oB,EAAE4R,gBAAgBjM,EAAE4rB,IAAIsC,GAAG7zB,EAAEC,EAAE0F,EAAEpE,EAAEqxB,EAAE/J,EAAEhjB,KAAI,IAAKkL,GAAG,oBAAoBrP,EAAEs9B,4BAA4B,oBAAoBt9B,EAAEu9B,sBAAsB,oBAAoBv9B,EAAEu9B,qBAAqBv9B,EAAEu9B,oBAAoB19B,EAAEsnB,EAAEhjB,GAAG,oBAAoBnE,EAAEs9B,4BAC5ft9B,EAAEs9B,2BAA2Bz9B,EAAEsnB,EAAEhjB,IAAI,oBAAoBnE,EAAEw9B,qBAAqBl/B,EAAE0R,OAAO,GAAG,oBAAoBhQ,EAAEgzB,0BAA0B10B,EAAE0R,OAAO,QAAQ,oBAAoBhQ,EAAEw9B,oBAAoBt5B,IAAI7F,EAAE0vB,eAAemD,IAAI7yB,EAAE6R,gBAAgB5R,EAAE0R,OAAO,GAAG,oBAAoBhQ,EAAEgzB,yBAAyB9uB,IAAI7F,EAAE0vB,eAAemD,IAAI7yB,EAAE6R,gBAAgB5R,EAAE0R,OAAO,MAAM1R,EAAEyvB,cAAcluB,EAAEvB,EAAE4R,cAAciX,GAAGnnB,EAAE8yB,MAAMjzB,EAAEG,EAAEwyB,MAAMrL,EAAEnnB,EAAEqvB,QAAQlrB,EAAEtE,EAAEoE,IAAI,oBAAoBjE,EAAEw9B,oBAAoBt5B,IAAI7F,EAAE0vB,eAAemD,IACjf7yB,EAAE6R,gBAAgB5R,EAAE0R,OAAO,GAAG,oBAAoBhQ,EAAEgzB,yBAAyB9uB,IAAI7F,EAAE0vB,eAAemD,IAAI7yB,EAAE6R,gBAAgB5R,EAAE0R,OAAO,MAAMnQ,GAAE,GAAI,OAAO49B,GAAGp/B,EAAEC,EAAEC,EAAEsB,EAAEE,EAAED,GACjK,SAAS29B,GAAGp/B,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,GAAGo9B,GAAG9+B,EAAEC,GAAG,IAAI0B,EAAE,KAAa,IAAR1B,EAAE0R,OAAW,IAAInQ,IAAIG,EAAE,OAAOF,GAAG4rB,GAAGptB,EAAEC,GAAE,GAAIg+B,GAAGl+B,EAAEC,EAAEyB,GAAGF,EAAEvB,EAAE+P,UAAU8tB,GAAG3rB,QAAQlS,EAAE,IAAI4F,EAAElE,GAAG,oBAAoBzB,EAAEm9B,yBAAyB,KAAK77B,EAAE4E,SAAwI,OAA/HnG,EAAE0R,OAAO,EAAE,OAAO3R,GAAG2B,GAAG1B,EAAEgS,MAAM8jB,GAAG91B,EAAED,EAAEiS,MAAM,KAAKvQ,GAAGzB,EAAEgS,MAAM8jB,GAAG91B,EAAE,KAAK4F,EAAEnE,IAAIs8B,GAAGh+B,EAAEC,EAAE4F,EAAEnE,GAAGzB,EAAE4R,cAAcrQ,EAAE2yB,MAAM1yB,GAAG4rB,GAAGptB,EAAEC,GAAE,GAAWD,EAAEgS,MAAM,SAASotB,GAAGr/B,GAAG,IAAIC,EAAED,EAAEgQ,UAAU/P,EAAEq/B,eAAetS,GAAGhtB,EAAEC,EAAEq/B,eAAer/B,EAAEq/B,iBAAiBr/B,EAAE+wB,SAAS/wB,EAAE+wB,SAAShE,GAAGhtB,EAAEC,EAAE+wB,SAAQ,GAAIsF,GAAGt2B,EAAEC,EAAEkX,eAC9d,SAASooB,GAAGv/B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAuC,OAApCmuB,KAAKC,GAAGpuB,GAAGxB,EAAE0R,OAAO,IAAIqsB,GAAGh+B,EAAEC,EAAEC,EAAEsB,GAAUvB,EAAEgS,MAAM,IAaqLutB,GAAMC,GAAGC,GAb1LC,GAAG,CAAC7tB,WAAW,KAAKqd,YAAY,KAAKC,UAAU,GAAG,SAASwQ,GAAG5/B,GAAG,MAAM,CAACy+B,UAAUz+B,EAAE0+B,UAAU,KAAKC,YAAY,MAC7L,SAASkB,GAAG7/B,EAAEC,EAAEC,GAAG,IAA0D2F,EAAtDrE,EAAEvB,EAAEgvB,aAAaxtB,EAAEk1B,GAAExkB,QAAQzQ,GAAE,EAAGC,EAAE,KAAa,IAAR1B,EAAE0R,OAAqJ,IAAvI9L,EAAElE,KAAKkE,GAAE,OAAO7F,GAAG,OAAOA,EAAE6R,gBAAiB,KAAO,EAAFpQ,IAASoE,GAAEnE,GAAE,EAAGzB,EAAE0R,QAAQ,KAAY,OAAO3R,GAAG,OAAOA,EAAE6R,gBAAcpQ,GAAG,GAAE2qB,GAAEuK,GAAI,EAAFl1B,GAAQ,OAAOzB,EAA2B,OAAxBuvB,GAAGtvB,GAAwB,QAArBD,EAAEC,EAAE4R,gBAA2C,QAAf7R,EAAEA,EAAE8R,aAA4B,KAAY,EAAP7R,EAAEqvB,MAAQrvB,EAAE4wB,MAAM,EAAE,OAAO7wB,EAAE6c,KAAK5c,EAAE4wB,MAAM,EAAE5wB,EAAE4wB,MAAM,WAAW,OAAKlvB,EAAEH,EAAE8H,SAAStJ,EAAEwB,EAAEs+B,SAAgBp+B,GAAGF,EAAEvB,EAAEqvB,KAAK5tB,EAAEzB,EAAEgS,MAAMtQ,EAAE,CAAC2tB,KAAK,SAAShmB,SAAS3H,GAAG,KAAO,EAAFH,IAAM,OAAOE,GAAGA,EAAE+uB,WAAW,EAAE/uB,EAAEutB,aAC7ettB,GAAGD,EAAEq+B,GAAGp+B,EAAEH,EAAE,EAAE,MAAMxB,EAAE61B,GAAG71B,EAAEwB,EAAEtB,EAAE,MAAMwB,EAAEgQ,OAAOzR,EAAED,EAAE0R,OAAOzR,EAAEyB,EAAEwQ,QAAQlS,EAAEC,EAAEgS,MAAMvQ,EAAEzB,EAAEgS,MAAMJ,cAAc+tB,GAAG1/B,GAAGD,EAAE4R,cAAc8tB,GAAG3/B,GAAGggC,GAAG//B,EAAE0B,IAAqB,GAAG,QAArBF,EAAEzB,EAAE6R,gBAA2C,QAAfhM,EAAEpE,EAAEqQ,YAAqB,OAGpM,SAAY9R,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,GAAG,GAAGzB,EAAG,OAAW,IAARD,EAAE0R,OAAiB1R,EAAE0R,QAAQ,IAAwBsuB,GAAGjgC,EAAEC,EAAE0B,EAA3BH,EAAEm7B,GAAG13B,MAAMlF,EAAE,SAAsB,OAAOE,EAAE4R,eAAqB5R,EAAEgS,MAAMjS,EAAEiS,MAAMhS,EAAE0R,OAAO,IAAI,OAAKjQ,EAAEF,EAAEs+B,SAASr+B,EAAExB,EAAEqvB,KAAK9tB,EAAEu+B,GAAG,CAACzQ,KAAK,UAAUhmB,SAAS9H,EAAE8H,UAAU7H,EAAE,EAAE,OAAMC,EAAEm0B,GAAGn0B,EAAED,EAAEE,EAAE,OAAQgQ,OAAO,EAAEnQ,EAAEkQ,OAAOzR,EAAEyB,EAAEgQ,OAAOzR,EAAEuB,EAAE0Q,QAAQxQ,EAAEzB,EAAEgS,MAAMzQ,EAAE,KAAY,EAAPvB,EAAEqvB,OAASyG,GAAG91B,EAAED,EAAEiS,MAAM,KAAKtQ,GAAG1B,EAAEgS,MAAMJ,cAAc+tB,GAAGj+B,GAAG1B,EAAE4R,cAAc8tB,GAAUj+B,GAAE,GAAG,KAAY,EAAPzB,EAAEqvB,MAAQ,OAAO2Q,GAAGjgC,EAAEC,EAAE0B,EAAE,MAAM,GAAG,OAAOF,EAAEob,KAAK,CAChd,GADidrb,EAAEC,EAAEoiB,aAAapiB,EAAEoiB,YAAYqc,QAC3e,IAAIr6B,EAAErE,EAAE2+B,KAA0C,OAArC3+B,EAAEqE,EAA0Co6B,GAAGjgC,EAAEC,EAAE0B,EAA/BH,EAAEm7B,GAAlBj7B,EAAEuD,MAAMlF,EAAE,MAAayB,OAAE,IAAkD,GAAvBqE,EAAE,KAAKlE,EAAE3B,EAAEywB,YAAeK,IAAIjrB,EAAE,CAAK,GAAG,QAAPrE,EAAEg4B,IAAc,CAAC,OAAO73B,GAAGA,GAAG,KAAK,EAAEF,EAAE,EAAE,MAAM,KAAK,GAAGA,EAAE,EAAE,MAAM,KAAK,GAAG,KAAK,IAAI,KAAK,IAAI,KAAK,IAAI,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,OAAO,KAAK,OAAO,KAAK,OAAO,KAAK,QAAQ,KAAK,QAAQ,KAAK,QAAQ,KAAK,QAAQ,KAAK,SAAS,KAAK,SAAS,KAAK,SAASA,EAAE,GAAG,MAAM,KAAK,UAAUA,EAAE,UAAU,MAAM,QAAQA,EAAE,EAChd,KADkdA,EAAE,KAAKA,GAAGD,EAAEkT,eAAe/S,IAAI,EAAEF,IAC5eA,IAAIC,EAAE0tB,YAAY1tB,EAAE0tB,UAAU3tB,EAAE8vB,GAAGvxB,EAAEyB,GAAGkyB,GAAGnyB,EAAExB,EAAEyB,GAAG,IAA6B,OAAzB2+B,KAAgCH,GAAGjgC,EAAEC,EAAE0B,EAAlCH,EAAEm7B,GAAG13B,MAAMlF,EAAE,QAA0B,MAAG,OAAO0B,EAAEob,MAAY5c,EAAE0R,OAAO,IAAI1R,EAAEgS,MAAMjS,EAAEiS,MAAMhS,EAAEogC,GAAG1X,KAAK,KAAK3oB,GAAGyB,EAAE6+B,YAAYrgC,EAAE,OAAKD,EAAE0B,EAAEytB,YAAYV,GAAGjD,GAAG/pB,EAAEoiB,aAAa2K,GAAGvuB,EAAEyuB,IAAE,EAAGC,GAAG,KAAK,OAAO3uB,IAAI+tB,GAAGC,MAAME,GAAGH,GAAGC,MAAMG,GAAGJ,GAAGC,MAAMC,GAAGC,GAAGluB,EAAEoY,GAAG+V,GAAGnuB,EAAEkvB,SAASjB,GAAGhuB,IAAGA,EAAE+/B,GAAG//B,EAAEuB,EAAE8H,WAAYqI,OAAO,KAAY1R,GALpKsgC,CAAGvgC,EAAEC,EAAE0B,EAAEH,EAAEqE,EAAEpE,EAAEvB,GAAG,GAAGwB,EAAE,CAACA,EAAEF,EAAEs+B,SAASn+B,EAAE1B,EAAEqvB,KAAezpB,GAAVpE,EAAEzB,EAAEiS,OAAUC,QAAQ,IAAIpM,EAAE,CAACwpB,KAAK,SAAShmB,SAAS9H,EAAE8H,UAChF,OAD0F,KAAO,EAAF3H,IAAM1B,EAAEgS,QAAQxQ,IAAGD,EAAEvB,EAAEgS,OAAQwe,WAAW,EAAEjvB,EAAEytB,aAAanpB,EAAE7F,EAAE8uB,UAAU,OAAOvtB,EAAEg0B,GAAG/zB,EAAEqE,IAAK06B,aAA4B,SAAf/+B,EAAE++B,aAAuB,OAAO36B,EAAEnE,EAAE8zB,GAAG3vB,EAAEnE,IAAIA,EAAEm0B,GAAGn0B,EAAEC,EAAEzB,EAAE,OAAQyR,OAAO,EAAGjQ,EAAEgQ,OACnfzR,EAAEuB,EAAEkQ,OAAOzR,EAAEuB,EAAE0Q,QAAQxQ,EAAEzB,EAAEgS,MAAMzQ,EAAEA,EAAEE,EAAEA,EAAEzB,EAAEgS,MAA8BtQ,EAAE,QAA1BA,EAAE3B,EAAEiS,MAAMJ,eAAyB+tB,GAAG1/B,GAAG,CAACu+B,UAAU98B,EAAE88B,UAAUv+B,EAAEw+B,UAAU,KAAKC,YAAYh9B,EAAEg9B,aAAaj9B,EAAEmQ,cAAclQ,EAAED,EAAE+uB,WAAWzwB,EAAEywB,YAAYvwB,EAAED,EAAE4R,cAAc8tB,GAAUn+B,EAAqO,OAAzNxB,GAAV0B,EAAE1B,EAAEiS,OAAUC,QAAQ1Q,EAAEg0B,GAAG9zB,EAAE,CAAC4tB,KAAK,UAAUhmB,SAAS9H,EAAE8H,WAAW,KAAY,EAAPrJ,EAAEqvB,QAAU9tB,EAAEqvB,MAAM3wB,GAAGsB,EAAEkQ,OAAOzR,EAAEuB,EAAE0Q,QAAQ,KAAK,OAAOlS,IAAkB,QAAdE,EAAED,EAAE8uB,YAAoB9uB,EAAE8uB,UAAU,CAAC/uB,GAAGC,EAAE0R,OAAO,IAAIzR,EAAEiQ,KAAKnQ,IAAIC,EAAEgS,MAAMzQ,EAAEvB,EAAE4R,cAAc,KAAYrQ,EACld,SAASw+B,GAAGhgC,EAAEC,GAA8D,OAA3DA,EAAE8/B,GAAG,CAACzQ,KAAK,UAAUhmB,SAASrJ,GAAGD,EAAEsvB,KAAK,EAAE,OAAQ5d,OAAO1R,EAASA,EAAEiS,MAAMhS,EAAE,SAASggC,GAAGjgC,EAAEC,EAAEC,EAAEsB,GAAwG,OAArG,OAAOA,GAAGquB,GAAGruB,GAAGu0B,GAAG91B,EAAED,EAAEiS,MAAM,KAAK/R,IAAGF,EAAEggC,GAAG//B,EAAEA,EAAEgvB,aAAa3lB,WAAYqI,OAAO,EAAE1R,EAAE4R,cAAc,KAAY7R,EAGmJ,SAASygC,GAAGzgC,EAAEC,EAAEC,GAAGF,EAAE6wB,OAAO5wB,EAAE,IAAIuB,EAAExB,EAAEyR,UAAU,OAAOjQ,IAAIA,EAAEqvB,OAAO5wB,GAAGuwB,GAAGxwB,EAAE0R,OAAOzR,EAAEC,GACtc,SAASwgC,GAAG1gC,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,IAAIC,EAAE1B,EAAE6R,cAAc,OAAOnQ,EAAE1B,EAAE6R,cAAc,CAAC8uB,YAAY1gC,EAAE2gC,UAAU,KAAKC,mBAAmB,EAAEC,KAAKt/B,EAAEu/B,KAAK7gC,EAAE8gC,SAASv/B,IAAIC,EAAEi/B,YAAY1gC,EAAEyB,EAAEk/B,UAAU,KAAKl/B,EAAEm/B,mBAAmB,EAAEn/B,EAAEo/B,KAAKt/B,EAAEE,EAAEq/B,KAAK7gC,EAAEwB,EAAEs/B,SAASv/B,GACzO,SAASw/B,GAAGjhC,EAAEC,EAAEC,GAAG,IAAIsB,EAAEvB,EAAEgvB,aAAaxtB,EAAED,EAAEq1B,YAAYn1B,EAAEF,EAAEu/B,KAAsC,GAAjC/C,GAAGh+B,EAAEC,EAAEuB,EAAE8H,SAASpJ,GAAkB,KAAO,GAAtBsB,EAAEm1B,GAAExkB,UAAqB3Q,EAAI,EAAFA,EAAI,EAAEvB,EAAE0R,OAAO,QAAQ,CAAC,GAAG,OAAO3R,GAAG,KAAa,IAARA,EAAE2R,OAAW3R,EAAE,IAAIA,EAAEC,EAAEgS,MAAM,OAAOjS,GAAG,CAAC,GAAG,KAAKA,EAAEmG,IAAI,OAAOnG,EAAE6R,eAAe4uB,GAAGzgC,EAAEE,EAAED,QAAQ,GAAG,KAAKD,EAAEmG,IAAIs6B,GAAGzgC,EAAEE,EAAED,QAAQ,GAAG,OAAOD,EAAEiS,MAAM,CAACjS,EAAEiS,MAAMP,OAAO1R,EAAEA,EAAEA,EAAEiS,MAAM,SAAS,GAAGjS,IAAIC,EAAE,MAAMD,EAAE,KAAK,OAAOA,EAAEkS,SAAS,CAAC,GAAG,OAAOlS,EAAE0R,QAAQ1R,EAAE0R,SAASzR,EAAE,MAAMD,EAAEA,EAAEA,EAAE0R,OAAO1R,EAAEkS,QAAQR,OAAO1R,EAAE0R,OAAO1R,EAAEA,EAAEkS,QAAQ1Q,GAAG,EAAS,GAAP4qB,GAAEuK,GAAEn1B,GAAM,KAAY,EAAPvB,EAAEqvB,MAAQrvB,EAAE4R,cAC/e,UAAU,OAAOpQ,GAAG,IAAK,WAAqB,IAAVvB,EAAED,EAAEgS,MAAUxQ,EAAE,KAAK,OAAOvB,GAAiB,QAAdF,EAAEE,EAAEuR,YAAoB,OAAOmlB,GAAG52B,KAAKyB,EAAEvB,GAAGA,EAAEA,EAAEgS,QAAY,QAAJhS,EAAEuB,IAAYA,EAAExB,EAAEgS,MAAMhS,EAAEgS,MAAM,OAAOxQ,EAAEvB,EAAEgS,QAAQhS,EAAEgS,QAAQ,MAAMwuB,GAAGzgC,GAAE,EAAGwB,EAAEvB,EAAEwB,GAAG,MAAM,IAAK,YAA6B,IAAjBxB,EAAE,KAAKuB,EAAExB,EAAEgS,MAAUhS,EAAEgS,MAAM,KAAK,OAAOxQ,GAAG,CAAe,GAAG,QAAjBzB,EAAEyB,EAAEgQ,YAAuB,OAAOmlB,GAAG52B,GAAG,CAACC,EAAEgS,MAAMxQ,EAAE,MAAMzB,EAAEyB,EAAEyQ,QAAQzQ,EAAEyQ,QAAQhS,EAAEA,EAAEuB,EAAEA,EAAEzB,EAAE0gC,GAAGzgC,GAAE,EAAGC,EAAE,KAAKwB,GAAG,MAAM,IAAK,WAAWg/B,GAAGzgC,GAAE,EAAG,KAAK,UAAK,GAAQ,MAAM,QAAQA,EAAE4R,cAAc,KAAK,OAAO5R,EAAEgS,MACxd,SAAS+sB,GAAGh/B,EAAEC,GAAG,KAAY,EAAPA,EAAEqvB,OAAS,OAAOtvB,IAAIA,EAAEyR,UAAU,KAAKxR,EAAEwR,UAAU,KAAKxR,EAAE0R,OAAO,GAAG,SAASusB,GAAGl+B,EAAEC,EAAEC,GAAyD,GAAtD,OAAOF,IAAIC,EAAE0wB,aAAa3wB,EAAE2wB,cAAcoC,IAAI9yB,EAAE4wB,MAAS,KAAK3wB,EAAED,EAAEwwB,YAAY,OAAO,KAAK,GAAG,OAAOzwB,GAAGC,EAAEgS,QAAQjS,EAAEiS,MAAM,MAAMhN,MAAMlF,EAAE,MAAM,GAAG,OAAOE,EAAEgS,MAAM,CAA4C,IAAjC/R,EAAEs1B,GAAZx1B,EAAEC,EAAEgS,MAAajS,EAAEivB,cAAchvB,EAAEgS,MAAM/R,EAAMA,EAAEwR,OAAOzR,EAAE,OAAOD,EAAEkS,SAASlS,EAAEA,EAAEkS,SAAQhS,EAAEA,EAAEgS,QAAQsjB,GAAGx1B,EAAEA,EAAEivB,eAAgBvd,OAAOzR,EAAEC,EAAEgS,QAAQ,KAAK,OAAOjS,EAAEgS,MAOza,SAASivB,GAAGlhC,EAAEC,GAAG,IAAIyuB,GAAE,OAAO1uB,EAAEghC,UAAU,IAAK,SAAS/gC,EAAED,EAAE+gC,KAAK,IAAI,IAAI7gC,EAAE,KAAK,OAAOD,GAAG,OAAOA,EAAEwR,YAAYvR,EAAED,GAAGA,EAAEA,EAAEiS,QAAQ,OAAOhS,EAAEF,EAAE+gC,KAAK,KAAK7gC,EAAEgS,QAAQ,KAAK,MAAM,IAAK,YAAYhS,EAAEF,EAAE+gC,KAAK,IAAI,IAAIv/B,EAAE,KAAK,OAAOtB,GAAG,OAAOA,EAAEuR,YAAYjQ,EAAEtB,GAAGA,EAAEA,EAAEgS,QAAQ,OAAO1Q,EAAEvB,GAAG,OAAOD,EAAE+gC,KAAK/gC,EAAE+gC,KAAK,KAAK/gC,EAAE+gC,KAAK7uB,QAAQ,KAAK1Q,EAAE0Q,QAAQ,MACvU,SAASivB,GAAEnhC,GAAG,IAAIC,EAAE,OAAOD,EAAEyR,WAAWzR,EAAEyR,UAAUQ,QAAQjS,EAAEiS,MAAM/R,EAAE,EAAEsB,EAAE,EAAE,GAAGvB,EAAE,IAAI,IAAIwB,EAAEzB,EAAEiS,MAAM,OAAOxQ,GAAGvB,GAAGuB,EAAEovB,MAAMpvB,EAAEgvB,WAAWjvB,GAAkB,SAAfC,EAAE++B,aAAsBh/B,GAAW,SAARC,EAAEkQ,MAAelQ,EAAEiQ,OAAO1R,EAAEyB,EAAEA,EAAEyQ,aAAa,IAAIzQ,EAAEzB,EAAEiS,MAAM,OAAOxQ,GAAGvB,GAAGuB,EAAEovB,MAAMpvB,EAAEgvB,WAAWjvB,GAAGC,EAAE++B,aAAah/B,GAAGC,EAAEkQ,MAAMlQ,EAAEiQ,OAAO1R,EAAEyB,EAAEA,EAAEyQ,QAAyC,OAAjClS,EAAEwgC,cAAch/B,EAAExB,EAAEywB,WAAWvwB,EAASD,EAC5V,SAASmhC,GAAGphC,EAAEC,EAAEC,GAAG,IAAIsB,EAAEvB,EAAEgvB,aAAmB,OAANV,GAAGtuB,GAAUA,EAAEkG,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG,KAAK,EAAE,KAAK,GAAG,KAAK,EAAE,KAAK,EAAE,KAAK,GAAG,KAAK,EAAE,KAAK,GAAG,OAAOg7B,GAAElhC,GAAG,KAAK,KAAK,EAUtD,KAAK,GAAG,OAAO4sB,GAAG5sB,EAAEiC,OAAO6qB,KAAKoU,GAAElhC,GAAG,KAVqD,KAAK,EAA2Q,OAAzQuB,EAAEvB,EAAE+P,UAAUwmB,KAAKrK,GAAEI,IAAIJ,GAAEG,IAAGyK,KAAKv1B,EAAE89B,iBAAiB99B,EAAEwvB,QAAQxvB,EAAE89B,eAAe99B,EAAE89B,eAAe,MAAS,OAAOt/B,GAAG,OAAOA,EAAEiS,QAAMwd,GAAGxvB,GAAGA,EAAE0R,OAAO,EAAE,OAAO3R,GAAGA,EAAE6R,cAAcqF,cAAc,KAAa,IAARjX,EAAE0R,SAAa1R,EAAE0R,OAAO,KAAK,OAAOgd,KAAK0S,GAAG1S,IAAIA,GAAG,QAAewS,GAAElhC,GAAU,KAAK,KAAK,EAAEy2B,GAAGz2B,GAAG,IAAIwB,EAAE40B,GAAGD,GAAGjkB,SAC7e,GAATjS,EAAED,EAAEiC,KAAQ,OAAOlC,GAAG,MAAMC,EAAE+P,UAAUyvB,GAAGz/B,EAAEC,EAAEC,EAAEsB,GAAKxB,EAAEg1B,MAAM/0B,EAAE+0B,MAAM/0B,EAAE0R,OAAO,IAAI1R,EAAE0R,OAAO,aAAa,CAAC,IAAInQ,EAAE,CAAC,GAAG,OAAOvB,EAAE+P,UAAU,MAAM/K,MAAMlF,EAAE,MAAW,OAALohC,GAAElhC,GAAU,KAAsB,GAAjBD,EAAEq2B,GAAGH,GAAG/jB,SAAYsd,GAAGxvB,GAAG,CAACuB,EAAEvB,EAAE+P,UAAU9P,EAAED,EAAEiC,KAAK,IAAIR,EAAEzB,EAAEyvB,cAA+C,OAAjCluB,EAAEoqB,IAAI3rB,EAAEuB,EAAEqqB,IAAInqB,EAAE1B,EAAE,KAAY,EAAPC,EAAEqvB,MAAepvB,GAAG,IAAK,SAASioB,GAAE,SAAS3mB,GAAG2mB,GAAE,QAAQ3mB,GAAG,MAAM,IAAK,SAAS,IAAK,SAAS,IAAK,QAAQ2mB,GAAE,OAAO3mB,GAAG,MAAM,IAAK,QAAQ,IAAK,QAAQ,IAAIC,EAAE,EAAEA,EAAEmmB,GAAGxnB,OAAOqB,IAAI0mB,GAAEP,GAAGnmB,GAAGD,GAAG,MAAM,IAAK,SAAS2mB,GAAE,QAAQ3mB,GAAG,MAAM,IAAK,MAAM,IAAK,QAAQ,IAAK,OAAO2mB,GAAE,QACnhB3mB,GAAG2mB,GAAE,OAAO3mB,GAAG,MAAM,IAAK,UAAU2mB,GAAE,SAAS3mB,GAAG,MAAM,IAAK,QAAQ4G,EAAG5G,EAAEE,GAAGymB,GAAE,UAAU3mB,GAAG,MAAM,IAAK,SAASA,EAAE0G,cAAc,CAACo5B,cAAc5/B,EAAE6/B,UAAUpZ,GAAE,UAAU3mB,GAAG,MAAM,IAAK,WAAW+H,GAAG/H,EAAEE,GAAGymB,GAAE,UAAU3mB,GAAkB,IAAI,IAAIG,KAAvBuN,GAAGhP,EAAEwB,GAAGD,EAAE,KAAkBC,EAAE,GAAGA,EAAEP,eAAeQ,GAAG,CAAC,IAAIkE,EAAEnE,EAAEC,GAAG,aAAaA,EAAE,kBAAkBkE,EAAErE,EAAEkI,cAAc7D,KAAI,IAAKnE,EAAE8/B,0BAA0BnX,GAAG7oB,EAAEkI,YAAY7D,EAAE7F,GAAGyB,EAAE,CAAC,WAAWoE,IAAI,kBAAkBA,GAAGrE,EAAEkI,cAAc,GAAG7D,KAAI,IAAKnE,EAAE8/B,0BAA0BnX,GAAG7oB,EAAEkI,YAC1e7D,EAAE7F,GAAGyB,EAAE,CAAC,WAAW,GAAGoE,IAAIrF,EAAGW,eAAeQ,IAAI,MAAMkE,GAAG,aAAalE,GAAGwmB,GAAE,SAAS3mB,GAAG,OAAOtB,GAAG,IAAK,QAAQ4G,EAAGtF,GAAGkH,EAAGlH,EAAEE,GAAE,GAAI,MAAM,IAAK,WAAWoF,EAAGtF,GAAGiI,GAAGjI,GAAG,MAAM,IAAK,SAAS,IAAK,SAAS,MAAM,QAAQ,oBAAoBE,EAAE+/B,UAAUjgC,EAAEkgC,QAAQpX,IAAI9oB,EAAEC,EAAExB,EAAEyxB,YAAYlwB,EAAE,OAAOA,IAAIvB,EAAE0R,OAAO,OAAO,CAAChQ,EAAE,IAAIF,EAAEiJ,SAASjJ,EAAEA,EAAEkH,cAAc,iCAAiC3I,IAAIA,EAAE2J,GAAGzJ,IAAI,iCAAiCF,EAAE,WAAWE,IAAGF,EAAE2B,EAAEZ,cAAc,QAASiJ,UAAU,qBAAuBhK,EAAEA,EAAEoK,YAAYpK,EAAEmK,aAC/f,kBAAkB3I,EAAE4N,GAAGpP,EAAE2B,EAAEZ,cAAcb,EAAE,CAACkP,GAAG5N,EAAE4N,MAAMpP,EAAE2B,EAAEZ,cAAcb,GAAG,WAAWA,IAAIyB,EAAE3B,EAAEwB,EAAE+/B,SAAS5/B,EAAE4/B,UAAS,EAAG//B,EAAEmgC,OAAOhgC,EAAEggC,KAAKngC,EAAEmgC,QAAQ3hC,EAAE2B,EAAEigC,gBAAgB5hC,EAAEE,GAAGF,EAAE4rB,IAAI3rB,EAAED,EAAE6rB,IAAIrqB,EAAEg+B,GAAGx/B,EAAEC,GAASA,EAAE+P,UAAUhQ,EAAEA,EAAE,CAAW,OAAV2B,EAAEwN,GAAGjP,EAAEsB,GAAUtB,GAAG,IAAK,SAASioB,GAAE,SAASnoB,GAAGmoB,GAAE,QAAQnoB,GAAGyB,EAAED,EAAE,MAAM,IAAK,SAAS,IAAK,SAAS,IAAK,QAAQ2mB,GAAE,OAAOnoB,GAAGyB,EAAED,EAAE,MAAM,IAAK,QAAQ,IAAK,QAAQ,IAAIC,EAAE,EAAEA,EAAEmmB,GAAGxnB,OAAOqB,IAAI0mB,GAAEP,GAAGnmB,GAAGzB,GAAGyB,EAAED,EAAE,MAAM,IAAK,SAAS2mB,GAAE,QAAQnoB,GAAGyB,EAAED,EAAE,MAAM,IAAK,MAAM,IAAK,QAAQ,IAAK,OAAO2mB,GAAE,QAClfnoB,GAAGmoB,GAAE,OAAOnoB,GAAGyB,EAAED,EAAE,MAAM,IAAK,UAAU2mB,GAAE,SAASnoB,GAAGyB,EAAED,EAAE,MAAM,IAAK,QAAQ4G,EAAGpI,EAAEwB,GAAGC,EAAEsG,EAAG/H,EAAEwB,GAAG2mB,GAAE,UAAUnoB,GAAG,MAAM,IAAK,SAAiL,QAAQyB,EAAED,QAAxK,IAAK,SAASxB,EAAEkI,cAAc,CAACo5B,cAAc9/B,EAAE+/B,UAAU9/B,EAAEqD,EAAE,GAAGtD,EAAE,CAACmG,WAAM,IAASwgB,GAAE,UAAUnoB,GAAG,MAAM,IAAK,WAAWuJ,GAAGvJ,EAAEwB,GAAGC,EAAE2H,GAAGpJ,EAAEwB,GAAG2mB,GAAE,UAAUnoB,GAAiC,IAAI0B,KAAhBwN,GAAGhP,EAAEuB,GAAGoE,EAAEpE,EAAa,GAAGoE,EAAE1E,eAAeO,GAAG,CAAC,IAAIoE,EAAED,EAAEnE,GAAG,UAAUA,EAAEgM,GAAG1N,EAAE8F,GAAG,4BAA4BpE,EAAuB,OAApBoE,EAAEA,EAAEA,EAAE4kB,YAAO,IAAgB5gB,GAAG9J,EAAE8F,GAAI,aAAapE,EAAE,kBAAkBoE,GAAG,aAC7e5F,GAAG,KAAK4F,IAAI0E,GAAGxK,EAAE8F,GAAG,kBAAkBA,GAAG0E,GAAGxK,EAAE,GAAG8F,GAAG,mCAAmCpE,GAAG,6BAA6BA,GAAG,cAAcA,IAAIlB,EAAGW,eAAeO,GAAG,MAAMoE,GAAG,aAAapE,GAAGymB,GAAE,SAASnoB,GAAG,MAAM8F,GAAGlD,EAAG5C,EAAE0B,EAAEoE,EAAEnE,IAAI,OAAOzB,GAAG,IAAK,QAAQ4G,EAAG9G,GAAG0I,EAAG1I,EAAEwB,GAAE,GAAI,MAAM,IAAK,WAAWsF,EAAG9G,GAAGyJ,GAAGzJ,GAAG,MAAM,IAAK,SAAS,MAAMwB,EAAEmG,OAAO3H,EAAEqD,aAAa,QAAQ,GAAGsD,EAAGnF,EAAEmG,QAAQ,MAAM,IAAK,SAAS3H,EAAEuhC,WAAW//B,EAAE+/B,SAAmB,OAAV7/B,EAAEF,EAAEmG,OAAcoB,GAAG/I,IAAIwB,EAAE+/B,SAAS7/B,GAAE,GAAI,MAAMF,EAAEyG,cAAcc,GAAG/I,IAAIwB,EAAE+/B,SAAS//B,EAAEyG,cAClf,GAAI,MAAM,QAAQ,oBAAoBxG,EAAEggC,UAAUzhC,EAAE0hC,QAAQpX,IAAI,OAAOpqB,GAAG,IAAK,SAAS,IAAK,QAAQ,IAAK,SAAS,IAAK,WAAWsB,IAAIA,EAAEqgC,UAAU,MAAM7hC,EAAE,IAAK,MAAMwB,GAAE,EAAG,MAAMxB,EAAE,QAAQwB,GAAE,GAAIA,IAAIvB,EAAE0R,OAAO,GAAG,OAAO1R,EAAE+0B,MAAM/0B,EAAE0R,OAAO,IAAI1R,EAAE0R,OAAO,SAAc,OAALwvB,GAAElhC,GAAU,KAAK,KAAK,EAAE,GAAGD,GAAG,MAAMC,EAAE+P,UAAU0vB,GAAG1/B,EAAEC,EAAED,EAAE0vB,cAAcluB,OAAO,CAAC,GAAG,kBAAkBA,GAAG,OAAOvB,EAAE+P,UAAU,MAAM/K,MAAMlF,EAAE,MAAsC,GAAhCG,EAAEm2B,GAAGD,GAAGjkB,SAASkkB,GAAGH,GAAG/jB,SAAYsd,GAAGxvB,GAAG,CAAyC,GAAxCuB,EAAEvB,EAAE+P,UAAU9P,EAAED,EAAEyvB,cAAcluB,EAAEoqB,IAAI3rB,GAAKyB,EAAEF,EAAEmJ,YAAYzK,IAC/e,QADofF,EACvfwuB,IAAY,OAAOxuB,EAAEmG,KAAK,KAAK,EAAEkkB,GAAG7oB,EAAEmJ,UAAUzK,EAAE,KAAY,EAAPF,EAAEsvB,OAAS,MAAM,KAAK,GAAE,IAAKtvB,EAAE0vB,cAAc8R,0BAA0BnX,GAAG7oB,EAAEmJ,UAAUzK,EAAE,KAAY,EAAPF,EAAEsvB,OAAS5tB,IAAIzB,EAAE0R,OAAO,QAAQnQ,GAAG,IAAItB,EAAEwK,SAASxK,EAAEA,EAAEyI,eAAem5B,eAAetgC,IAAKoqB,IAAI3rB,EAAEA,EAAE+P,UAAUxO,EAAO,OAAL2/B,GAAElhC,GAAU,KAAK,KAAK,GAA0B,GAAvBksB,GAAEwK,IAAGn1B,EAAEvB,EAAE4R,cAAiB,OAAO7R,GAAG,OAAOA,EAAE6R,eAAe,OAAO7R,EAAE6R,cAAcC,WAAW,CAAC,GAAG4c,IAAG,OAAOD,IAAI,KAAY,EAAPxuB,EAAEqvB,OAAS,KAAa,IAARrvB,EAAE0R,OAAWge,KAAKC,KAAK3vB,EAAE0R,OAAO,MAAMjQ,GAAE,OAAQ,GAAGA,EAAE+tB,GAAGxvB,GAAG,OAAOuB,GAAG,OAAOA,EAAEsQ,WAAW,CAAC,GAAG,OAC5f9R,EAAE,CAAC,IAAI0B,EAAE,MAAMuD,MAAMlF,EAAE,MAAqD,KAA7B2B,EAAE,QAApBA,EAAEzB,EAAE4R,eAAyBnQ,EAAEoQ,WAAW,MAAW,MAAM7M,MAAMlF,EAAE,MAAM2B,EAAEkqB,IAAI3rB,OAAO2vB,KAAK,KAAa,IAAR3vB,EAAE0R,SAAa1R,EAAE4R,cAAc,MAAM5R,EAAE0R,OAAO,EAAEwvB,GAAElhC,GAAGyB,GAAE,OAAQ,OAAOitB,KAAK0S,GAAG1S,IAAIA,GAAG,MAAMjtB,GAAE,EAAG,IAAIA,EAAE,OAAe,MAARzB,EAAE0R,MAAY1R,EAAE,KAAK,OAAG,KAAa,IAARA,EAAE0R,QAAkB1R,EAAE4wB,MAAM3wB,EAAED,KAAEuB,EAAE,OAAOA,MAAO,OAAOxB,GAAG,OAAOA,EAAE6R,gBAAgBrQ,IAAIvB,EAAEgS,MAAMN,OAAO,KAAK,KAAY,EAAP1R,EAAEqvB,QAAU,OAAOtvB,GAAG,KAAe,EAAV22B,GAAExkB,SAAW,IAAI4vB,KAAIA,GAAE,GAAG3B,OAAO,OAAOngC,EAAEyxB,cAAczxB,EAAE0R,OAAO,GAAGwvB,GAAElhC,GAAU,MAAK,KAAK,EAAE,OAAOu2B,KAC7e,OAAOx2B,GAAG0oB,GAAGzoB,EAAE+P,UAAUmH,eAAegqB,GAAElhC,GAAG,KAAK,KAAK,GAAG,OAAOqwB,GAAGrwB,EAAEiC,KAAKqE,UAAU46B,GAAElhC,GAAG,KAA+C,KAAK,GAA0B,GAAvBksB,GAAEwK,IAAwB,QAArBj1B,EAAEzB,EAAE4R,eAA0B,OAAOsvB,GAAElhC,GAAG,KAAuC,GAAlCuB,EAAE,KAAa,IAARvB,EAAE0R,OAA4B,QAAjBhQ,EAAED,EAAEk/B,WAAsB,GAAGp/B,EAAE0/B,GAAGx/B,GAAE,OAAQ,CAAC,GAAG,IAAIqgC,IAAG,OAAO/hC,GAAG,KAAa,IAARA,EAAE2R,OAAW,IAAI3R,EAAEC,EAAEgS,MAAM,OAAOjS,GAAG,CAAS,GAAG,QAAX2B,EAAEi1B,GAAG52B,IAAe,CAAmG,IAAlGC,EAAE0R,OAAO,IAAIuvB,GAAGx/B,GAAE,GAAoB,QAAhBF,EAAEG,EAAE+vB,eAAuBzxB,EAAEyxB,YAAYlwB,EAAEvB,EAAE0R,OAAO,GAAG1R,EAAEugC,aAAa,EAAEh/B,EAAEtB,EAAMA,EAAED,EAAEgS,MAAM,OAAO/R,GAAOF,EAAEwB,GAANE,EAAExB,GAAQyR,OAAO,SAC/d,QAAdhQ,EAAED,EAAE+P,YAAoB/P,EAAE+uB,WAAW,EAAE/uB,EAAEmvB,MAAM7wB,EAAE0B,EAAEuQ,MAAM,KAAKvQ,EAAE8+B,aAAa,EAAE9+B,EAAEguB,cAAc,KAAKhuB,EAAEmQ,cAAc,KAAKnQ,EAAEgwB,YAAY,KAAKhwB,EAAEivB,aAAa,KAAKjvB,EAAEsO,UAAU,OAAOtO,EAAE+uB,WAAW9uB,EAAE8uB,WAAW/uB,EAAEmvB,MAAMlvB,EAAEkvB,MAAMnvB,EAAEuQ,MAAMtQ,EAAEsQ,MAAMvQ,EAAE8+B,aAAa,EAAE9+B,EAAEqtB,UAAU,KAAKrtB,EAAEguB,cAAc/tB,EAAE+tB,cAAchuB,EAAEmQ,cAAclQ,EAAEkQ,cAAcnQ,EAAEgwB,YAAY/vB,EAAE+vB,YAAYhwB,EAAEQ,KAAKP,EAAEO,KAAKlC,EAAE2B,EAAEgvB,aAAajvB,EAAEivB,aAAa,OAAO3wB,EAAE,KAAK,CAAC6wB,MAAM7wB,EAAE6wB,MAAMD,aAAa5wB,EAAE4wB,eAAe1wB,EAAEA,EAAEgS,QAA2B,OAAnBka,GAAEuK,GAAY,EAAVA,GAAExkB,QAAU,GAAUlS,EAAEgS,MAAMjS,EAClgBA,EAAEkS,QAAQ,OAAOxQ,EAAEq/B,MAAMjuB,KAAIkvB,KAAK/hC,EAAE0R,OAAO,IAAInQ,GAAE,EAAG0/B,GAAGx/B,GAAE,GAAIzB,EAAE4wB,MAAM,aAAa,CAAC,IAAIrvB,EAAE,GAAW,QAARxB,EAAE42B,GAAGj1B,KAAa,GAAG1B,EAAE0R,OAAO,IAAInQ,GAAE,EAAmB,QAAhBtB,EAAEF,EAAE0xB,eAAuBzxB,EAAEyxB,YAAYxxB,EAAED,EAAE0R,OAAO,GAAGuvB,GAAGx/B,GAAE,GAAI,OAAOA,EAAEq/B,MAAM,WAAWr/B,EAAEs/B,WAAWr/B,EAAE8P,YAAYid,GAAE,OAAOyS,GAAElhC,GAAG,UAAU,EAAE6S,KAAIpR,EAAEm/B,mBAAmBmB,IAAI,aAAa9hC,IAAID,EAAE0R,OAAO,IAAInQ,GAAE,EAAG0/B,GAAGx/B,GAAE,GAAIzB,EAAE4wB,MAAM,SAASnvB,EAAEi/B,aAAah/B,EAAEuQ,QAAQjS,EAAEgS,MAAMhS,EAAEgS,MAAMtQ,IAAa,QAATzB,EAAEwB,EAAEo/B,MAAc5gC,EAAEgS,QAAQvQ,EAAE1B,EAAEgS,MAAMtQ,EAAED,EAAEo/B,KAAKn/B,GAAG,OAAG,OAAOD,EAAEq/B,MAAY9gC,EAAEyB,EAAEq/B,KAAKr/B,EAAEk/B,UAC9e3gC,EAAEyB,EAAEq/B,KAAK9gC,EAAEiS,QAAQxQ,EAAEm/B,mBAAmB/tB,KAAI7S,EAAEiS,QAAQ,KAAKhS,EAAEy2B,GAAExkB,QAAQia,GAAEuK,GAAEn1B,EAAI,EAAFtB,EAAI,EAAI,EAAFA,GAAKD,IAAEkhC,GAAElhC,GAAU,MAAK,KAAK,GAAG,KAAK,GAAG,OAAOgiC,KAAKzgC,EAAE,OAAOvB,EAAE4R,cAAc,OAAO7R,GAAG,OAAOA,EAAE6R,gBAAgBrQ,IAAIvB,EAAE0R,OAAO,MAAMnQ,GAAG,KAAY,EAAPvB,EAAEqvB,MAAQ,KAAQ,WAAHuP,MAAiBsC,GAAElhC,GAAkB,EAAfA,EAAEugC,eAAiBvgC,EAAE0R,OAAO,OAAOwvB,GAAElhC,GAAG,KAAK,KAAK,GAAe,KAAK,GAAG,OAAO,KAAK,MAAMgF,MAAMlF,EAAE,IAAIE,EAAEkG,MAC5W,SAAS+7B,GAAGliC,EAAEC,GAAS,OAANsuB,GAAGtuB,GAAUA,EAAEkG,KAAK,KAAK,EAAE,OAAO0mB,GAAG5sB,EAAEiC,OAAO6qB,KAAiB,OAAZ/sB,EAAEC,EAAE0R,QAAe1R,EAAE0R,OAAS,MAAH3R,EAAS,IAAIC,GAAG,KAAK,KAAK,EAAE,OAAOu2B,KAAKrK,GAAEI,IAAIJ,GAAEG,IAAGyK,KAAe,KAAO,OAAjB/2B,EAAEC,EAAE0R,SAAqB,KAAO,IAAF3R,IAAQC,EAAE0R,OAAS,MAAH3R,EAAS,IAAIC,GAAG,KAAK,KAAK,EAAE,OAAOy2B,GAAGz2B,GAAG,KAAK,KAAK,GAA0B,GAAvBksB,GAAEwK,IAAwB,QAArB32B,EAAEC,EAAE4R,gBAA2B,OAAO7R,EAAE8R,WAAW,CAAC,GAAG,OAAO7R,EAAEwR,UAAU,MAAMxM,MAAMlF,EAAE,MAAM6vB,KAAe,OAAS,OAAnB5vB,EAAEC,EAAE0R,QAAsB1R,EAAE0R,OAAS,MAAH3R,EAAS,IAAIC,GAAG,KAAK,KAAK,GAAG,OAAOksB,GAAEwK,IAAG,KAAK,KAAK,EAAE,OAAOH,KAAK,KAAK,KAAK,GAAG,OAAOlG,GAAGrwB,EAAEiC,KAAKqE,UAAU,KAAK,KAAK,GAAG,KAAK,GAAG,OAAO07B,KAC1gB,KAAyB,QAAQ,OAAO,MArBxCzC,GAAG,SAASx/B,EAAEC,GAAG,IAAI,IAAIC,EAAED,EAAEgS,MAAM,OAAO/R,GAAG,CAAC,GAAG,IAAIA,EAAEiG,KAAK,IAAIjG,EAAEiG,IAAInG,EAAEqK,YAAYnK,EAAE8P,gBAAgB,GAAG,IAAI9P,EAAEiG,KAAK,OAAOjG,EAAE+R,MAAM,CAAC/R,EAAE+R,MAAMP,OAAOxR,EAAEA,EAAEA,EAAE+R,MAAM,SAAS,GAAG/R,IAAID,EAAE,MAAM,KAAK,OAAOC,EAAEgS,SAAS,CAAC,GAAG,OAAOhS,EAAEwR,QAAQxR,EAAEwR,SAASzR,EAAE,OAAOC,EAAEA,EAAEwR,OAAOxR,EAAEgS,QAAQR,OAAOxR,EAAEwR,OAAOxR,EAAEA,EAAEgS,UAChSutB,GAAG,SAASz/B,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAEzB,EAAE0vB,cAAc,GAAGjuB,IAAID,EAAE,CAACxB,EAAEC,EAAE+P,UAAUqmB,GAAGH,GAAG/jB,SAAS,IAA4RxQ,EAAxRD,EAAE,KAAK,OAAOxB,GAAG,IAAK,QAAQuB,EAAEsG,EAAG/H,EAAEyB,GAAGD,EAAEuG,EAAG/H,EAAEwB,GAAGE,EAAE,GAAG,MAAM,IAAK,SAASD,EAAEqD,EAAE,GAAGrD,EAAE,CAACkG,WAAM,IAASnG,EAAEsD,EAAE,GAAGtD,EAAE,CAACmG,WAAM,IAASjG,EAAE,GAAG,MAAM,IAAK,WAAWD,EAAE2H,GAAGpJ,EAAEyB,GAAGD,EAAE4H,GAAGpJ,EAAEwB,GAAGE,EAAE,GAAG,MAAM,QAAQ,oBAAoBD,EAAEggC,SAAS,oBAAoBjgC,EAAEigC,UAAUzhC,EAAE0hC,QAAQpX,IAAyB,IAAI1kB,KAAzBsJ,GAAGhP,EAAEsB,GAAStB,EAAE,KAAcuB,EAAE,IAAID,EAAEL,eAAeyE,IAAInE,EAAEN,eAAeyE,IAAI,MAAMnE,EAAEmE,GAAG,GAAG,UAAUA,EAAE,CAAC,IAAIC,EAAEpE,EAAEmE,GAAG,IAAIjE,KAAKkE,EAAEA,EAAE1E,eAAeQ,KACjfzB,IAAIA,EAAE,IAAIA,EAAEyB,GAAG,QAAQ,4BAA4BiE,GAAG,aAAaA,GAAG,mCAAmCA,GAAG,6BAA6BA,GAAG,cAAcA,IAAIpF,EAAGW,eAAeyE,GAAGlE,IAAIA,EAAE,KAAKA,EAAEA,GAAG,IAAIyO,KAAKvK,EAAE,OAAO,IAAIA,KAAKpE,EAAE,CAAC,IAAIsE,EAAEtE,EAAEoE,GAAyB,GAAtBC,EAAE,MAAMpE,EAAEA,EAAEmE,QAAG,EAAUpE,EAAEL,eAAeyE,IAAIE,IAAID,IAAI,MAAMC,GAAG,MAAMD,GAAG,GAAG,UAAUD,EAAE,GAAGC,EAAE,CAAC,IAAIlE,KAAKkE,GAAGA,EAAE1E,eAAeQ,IAAImE,GAAGA,EAAE3E,eAAeQ,KAAKzB,IAAIA,EAAE,IAAIA,EAAEyB,GAAG,IAAI,IAAIA,KAAKmE,EAAEA,EAAE3E,eAAeQ,IAAIkE,EAAElE,KAAKmE,EAAEnE,KAAKzB,IAAIA,EAAE,IAAIA,EAAEyB,GAAGmE,EAAEnE,SAASzB,IAAIwB,IAAIA,EAAE,IAAIA,EAAEyO,KAAKvK,EACpf1F,IAAIA,EAAE4F,MAAM,4BAA4BF,GAAGE,EAAEA,EAAEA,EAAE4kB,YAAO,EAAO7kB,EAAEA,EAAEA,EAAE6kB,YAAO,EAAO,MAAM5kB,GAAGD,IAAIC,IAAIpE,EAAEA,GAAG,IAAIyO,KAAKvK,EAAEE,IAAI,aAAaF,EAAE,kBAAkBE,GAAG,kBAAkBA,IAAIpE,EAAEA,GAAG,IAAIyO,KAAKvK,EAAE,GAAGE,GAAG,mCAAmCF,GAAG,6BAA6BA,IAAIpF,EAAGW,eAAeyE,IAAI,MAAME,GAAG,aAAaF,GAAGuiB,GAAE,SAASnoB,GAAG0B,GAAGmE,IAAIC,IAAIpE,EAAE,MAAMA,EAAEA,GAAG,IAAIyO,KAAKvK,EAAEE,IAAI5F,IAAIwB,EAAEA,GAAG,IAAIyO,KAAK,QAAQjQ,GAAG,IAAI0F,EAAElE,GAAKzB,EAAEyxB,YAAY9rB,KAAE3F,EAAE0R,OAAO,KAAI+tB,GAAG,SAAS1/B,EAAEC,EAAEC,EAAEsB,GAAGtB,IAAIsB,IAAIvB,EAAE0R,OAAO,IAkBhb,IAAIwwB,IAAG,EAAGC,IAAE,EAAGC,GAAG,oBAAoBC,QAAQA,QAAQ/hC,IAAIgiC,GAAE,KAAK,SAASC,GAAGxiC,EAAEC,GAAG,IAAIC,EAAEF,EAAEg1B,IAAI,GAAG,OAAO90B,EAAE,GAAG,oBAAoBA,EAAE,IAAIA,EAAE,MAAM,MAAMsB,GAAGihC,GAAEziC,EAAEC,EAAEuB,QAAQtB,EAAEiS,QAAQ,KAAK,SAASuwB,GAAG1iC,EAAEC,EAAEC,GAAG,IAAIA,IAAI,MAAMsB,GAAGihC,GAAEziC,EAAEC,EAAEuB,IAAI,IAAImhC,IAAG,EAIxR,SAASC,GAAG5iC,EAAEC,EAAEC,GAAG,IAAIsB,EAAEvB,EAAEyxB,YAAyC,GAAG,QAAhClwB,EAAE,OAAOA,EAAEA,EAAEk4B,WAAW,MAAiB,CAAC,IAAIj4B,EAAED,EAAEA,EAAE0vB,KAAK,EAAE,CAAC,IAAIzvB,EAAE0E,IAAInG,KAAKA,EAAE,CAAC,IAAI0B,EAAED,EAAEw4B,QAAQx4B,EAAEw4B,aAAQ,OAAO,IAASv4B,GAAGghC,GAAGziC,EAAEC,EAAEwB,GAAGD,EAAEA,EAAEyvB,WAAWzvB,IAAID,IAAI,SAASqhC,GAAG7iC,EAAEC,GAAgD,GAAG,QAAhCA,EAAE,QAAlBA,EAAEA,EAAEyxB,aAAuBzxB,EAAEy5B,WAAW,MAAiB,CAAC,IAAIx5B,EAAED,EAAEA,EAAEixB,KAAK,EAAE,CAAC,IAAIhxB,EAAEiG,IAAInG,KAAKA,EAAE,CAAC,IAAIwB,EAAEtB,EAAE85B,OAAO95B,EAAE+5B,QAAQz4B,IAAItB,EAAEA,EAAEgxB,WAAWhxB,IAAID,IAAI,SAAS6iC,GAAG9iC,GAAG,IAAIC,EAAED,EAAEg1B,IAAI,GAAG,OAAO/0B,EAAE,CAAC,IAAIC,EAAEF,EAAEgQ,UAAiBhQ,EAAEmG,IAA8BnG,EAAEE,EAAE,oBAAoBD,EAAEA,EAAED,GAAGC,EAAEkS,QAAQnS,GAChf,SAAS+iC,GAAG/iC,GAAG,IAAIC,EAAED,EAAEyR,UAAU,OAAOxR,IAAID,EAAEyR,UAAU,KAAKsxB,GAAG9iC,IAAID,EAAEiS,MAAM,KAAKjS,EAAE+uB,UAAU,KAAK/uB,EAAEkS,QAAQ,KAAK,IAAIlS,EAAEmG,MAAoB,QAAdlG,EAAED,EAAEgQ,oBAA4B/P,EAAE2rB,WAAW3rB,EAAE4rB,WAAW5rB,EAAEmoB,WAAWnoB,EAAE6rB,WAAW7rB,EAAE8rB,MAAM/rB,EAAEgQ,UAAU,KAAKhQ,EAAE0R,OAAO,KAAK1R,EAAE2wB,aAAa,KAAK3wB,EAAE0vB,cAAc,KAAK1vB,EAAE6R,cAAc,KAAK7R,EAAEivB,aAAa,KAAKjvB,EAAEgQ,UAAU,KAAKhQ,EAAE0xB,YAAY,KAAK,SAASsR,GAAGhjC,GAAG,OAAO,IAAIA,EAAEmG,KAAK,IAAInG,EAAEmG,KAAK,IAAInG,EAAEmG,IACha,SAAS88B,GAAGjjC,GAAGA,EAAE,OAAO,CAAC,KAAK,OAAOA,EAAEkS,SAAS,CAAC,GAAG,OAAOlS,EAAE0R,QAAQsxB,GAAGhjC,EAAE0R,QAAQ,OAAO,KAAK1R,EAAEA,EAAE0R,OAAiC,IAA1B1R,EAAEkS,QAAQR,OAAO1R,EAAE0R,OAAW1R,EAAEA,EAAEkS,QAAQ,IAAIlS,EAAEmG,KAAK,IAAInG,EAAEmG,KAAK,KAAKnG,EAAEmG,KAAK,CAAC,GAAW,EAARnG,EAAE2R,MAAQ,SAAS3R,EAAE,GAAG,OAAOA,EAAEiS,OAAO,IAAIjS,EAAEmG,IAAI,SAASnG,EAAOA,EAAEiS,MAAMP,OAAO1R,EAAEA,EAAEA,EAAEiS,MAAM,KAAa,EAARjS,EAAE2R,OAAS,OAAO3R,EAAEgQ,WAC/S,SAASkzB,GAAGljC,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAEmG,IAAI,GAAG,IAAI3E,GAAG,IAAIA,EAAExB,EAAEA,EAAEgQ,UAAU/P,EAAE,IAAIC,EAAEwK,SAASxK,EAAEwP,WAAWyzB,aAAanjC,EAAEC,GAAGC,EAAEijC,aAAanjC,EAAEC,IAAI,IAAIC,EAAEwK,UAAUzK,EAAEC,EAAEwP,YAAayzB,aAAanjC,EAAEE,IAAKD,EAAEC,GAAImK,YAAYrK,GAA4B,QAAxBE,EAAEA,EAAEkjC,2BAA8B,IAASljC,GAAG,OAAOD,EAAEyhC,UAAUzhC,EAAEyhC,QAAQpX,UAAU,GAAG,IAAI9oB,GAAc,QAAVxB,EAAEA,EAAEiS,OAAgB,IAAIixB,GAAGljC,EAAEC,EAAEC,GAAGF,EAAEA,EAAEkS,QAAQ,OAAOlS,GAAGkjC,GAAGljC,EAAEC,EAAEC,GAAGF,EAAEA,EAAEkS,QACnX,SAASmxB,GAAGrjC,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAEmG,IAAI,GAAG,IAAI3E,GAAG,IAAIA,EAAExB,EAAEA,EAAEgQ,UAAU/P,EAAEC,EAAEijC,aAAanjC,EAAEC,GAAGC,EAAEmK,YAAYrK,QAAQ,GAAG,IAAIwB,GAAc,QAAVxB,EAAEA,EAAEiS,OAAgB,IAAIoxB,GAAGrjC,EAAEC,EAAEC,GAAGF,EAAEA,EAAEkS,QAAQ,OAAOlS,GAAGqjC,GAAGrjC,EAAEC,EAAEC,GAAGF,EAAEA,EAAEkS,QAAQ,IAAIoxB,GAAE,KAAKC,IAAG,EAAG,SAASC,GAAGxjC,EAAEC,EAAEC,GAAG,IAAIA,EAAEA,EAAE+R,MAAM,OAAO/R,GAAGujC,GAAGzjC,EAAEC,EAAEC,GAAGA,EAAEA,EAAEgS,QAC5Q,SAASuxB,GAAGzjC,EAAEC,EAAEC,GAAG,GAAG2T,IAAI,oBAAoBA,GAAG6vB,qBAAqB,IAAI7vB,GAAG6vB,qBAAqB9vB,GAAG1T,GAAG,MAAM2F,IAAI,OAAO3F,EAAEiG,KAAK,KAAK,EAAEi8B,IAAGI,GAAGtiC,EAAED,GAAG,KAAK,EAAE,IAAIuB,EAAE8hC,GAAE7hC,EAAE8hC,GAAGD,GAAE,KAAKE,GAAGxjC,EAAEC,EAAEC,GAAOqjC,GAAG9hC,EAAE,QAAT6hC,GAAE9hC,KAAkB+hC,IAAIvjC,EAAEsjC,GAAEpjC,EAAEA,EAAE8P,UAAU,IAAIhQ,EAAE0K,SAAS1K,EAAE0P,WAAWtF,YAAYlK,GAAGF,EAAEoK,YAAYlK,IAAIojC,GAAEl5B,YAAYlK,EAAE8P,YAAY,MAAM,KAAK,GAAG,OAAOszB,KAAIC,IAAIvjC,EAAEsjC,GAAEpjC,EAAEA,EAAE8P,UAAU,IAAIhQ,EAAE0K,SAAS6gB,GAAGvrB,EAAE0P,WAAWxP,GAAG,IAAIF,EAAE0K,UAAU6gB,GAAGvrB,EAAEE,GAAGyX,GAAG3X,IAAIurB,GAAG+X,GAAEpjC,EAAE8P,YAAY,MAAM,KAAK,EAAExO,EAAE8hC,GAAE7hC,EAAE8hC,GAAGD,GAAEpjC,EAAE8P,UAAUmH,cAAcosB,IAAG,EAClfC,GAAGxjC,EAAEC,EAAEC,GAAGojC,GAAE9hC,EAAE+hC,GAAG9hC,EAAE,MAAM,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG,KAAK,GAAG,IAAI2gC,KAAoB,QAAhB5gC,EAAEtB,EAAEwxB,cAAsC,QAAflwB,EAAEA,EAAEk4B,aAAsB,CAACj4B,EAAED,EAAEA,EAAE0vB,KAAK,EAAE,CAAC,IAAIxvB,EAAED,EAAEE,EAAED,EAAEu4B,QAAQv4B,EAAEA,EAAEyE,SAAI,IAASxE,IAAI,KAAO,EAAFD,IAAe,KAAO,EAAFA,KAAfghC,GAAGxiC,EAAED,EAAE0B,GAAyBF,EAAEA,EAAEyvB,WAAWzvB,IAAID,GAAGgiC,GAAGxjC,EAAEC,EAAEC,GAAG,MAAM,KAAK,EAAE,IAAIkiC,KAAII,GAAGtiC,EAAED,GAAiB,oBAAduB,EAAEtB,EAAE8P,WAAgC2zB,sBAAsB,IAAIniC,EAAEizB,MAAMv0B,EAAEwvB,cAAcluB,EAAE2yB,MAAMj0B,EAAE2R,cAAcrQ,EAAEmiC,uBAAuB,MAAM99B,GAAG48B,GAAEviC,EAAED,EAAE4F,GAAG29B,GAAGxjC,EAAEC,EAAEC,GAAG,MAAM,KAAK,GAAGsjC,GAAGxjC,EAAEC,EAAEC,GAAG,MAAM,KAAK,GAAU,EAAPA,EAAEovB,MAAQ8S,IAAG5gC,EAAE4gC,KAAI,OAChfliC,EAAE2R,cAAc2xB,GAAGxjC,EAAEC,EAAEC,GAAGkiC,GAAE5gC,GAAGgiC,GAAGxjC,EAAEC,EAAEC,GAAG,MAAM,QAAQsjC,GAAGxjC,EAAEC,EAAEC,IAAI,SAAS0jC,GAAG5jC,GAAG,IAAIC,EAAED,EAAE0xB,YAAY,GAAG,OAAOzxB,EAAE,CAACD,EAAE0xB,YAAY,KAAK,IAAIxxB,EAAEF,EAAEgQ,UAAU,OAAO9P,IAAIA,EAAEF,EAAEgQ,UAAU,IAAIqyB,IAAIpiC,EAAEsC,SAAQ,SAAStC,GAAG,IAAIuB,EAAEqiC,GAAGlb,KAAK,KAAK3oB,EAAEC,GAAGC,EAAEmoB,IAAIpoB,KAAKC,EAAES,IAAIV,GAAGA,EAAEmrB,KAAK5pB,EAAEA,QACnQ,SAASsiC,GAAG9jC,EAAEC,GAAG,IAAIC,EAAED,EAAE8uB,UAAU,GAAG,OAAO7uB,EAAE,IAAI,IAAIsB,EAAE,EAAEA,EAAEtB,EAAEE,OAAOoB,IAAI,CAAC,IAAIC,EAAEvB,EAAEsB,GAAG,IAAI,IAAIE,EAAE1B,EAAE2B,EAAE1B,EAAE4F,EAAElE,EAAE3B,EAAE,KAAK,OAAO6F,GAAG,CAAC,OAAOA,EAAEM,KAAK,KAAK,EAAEm9B,GAAEz9B,EAAEmK,UAAUuzB,IAAG,EAAG,MAAMvjC,EAAE,KAAK,EAA4C,KAAK,EAAEsjC,GAAEz9B,EAAEmK,UAAUmH,cAAcosB,IAAG,EAAG,MAAMvjC,EAAE6F,EAAEA,EAAE6L,OAAO,GAAG,OAAO4xB,GAAE,MAAMr+B,MAAMlF,EAAE,MAAM0jC,GAAG/hC,EAAEC,EAAEF,GAAG6hC,GAAE,KAAKC,IAAG,EAAG,IAAIz9B,EAAErE,EAAEgQ,UAAU,OAAO3L,IAAIA,EAAE4L,OAAO,MAAMjQ,EAAEiQ,OAAO,KAAK,MAAM9L,GAAG68B,GAAEhhC,EAAExB,EAAE2F,IAAI,GAAkB,MAAf3F,EAAEugC,aAAmB,IAAIvgC,EAAEA,EAAEgS,MAAM,OAAOhS,GAAG8jC,GAAG9jC,EAAED,GAAGC,EAAEA,EAAEiS,QAC1d,SAAS6xB,GAAG/jC,EAAEC,GAAG,IAAIC,EAAEF,EAAEyR,UAAUjQ,EAAExB,EAAE2R,MAAM,OAAO3R,EAAEmG,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG,KAAK,GAAiB,GAAd29B,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAQ,EAAFwB,EAAI,CAAC,IAAIohC,GAAG,EAAE5iC,EAAEA,EAAE0R,QAAQmxB,GAAG,EAAE7iC,GAAG,MAAM+oB,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,GAAG,IAAI6Z,GAAG,EAAE5iC,EAAEA,EAAE0R,QAAQ,MAAMqX,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,IAAI,MAAM,KAAK,EAAE+a,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAK,IAAFwB,GAAO,OAAOtB,GAAGsiC,GAAGtiC,EAAEA,EAAEwR,QAAQ,MAAM,KAAK,EAAgD,GAA9CoyB,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAK,IAAFwB,GAAO,OAAOtB,GAAGsiC,GAAGtiC,EAAEA,EAAEwR,QAAmB,GAAR1R,EAAE2R,MAAS,CAAC,IAAIlQ,EAAEzB,EAAEgQ,UAAU,IAAIxF,GAAG/I,EAAE,IAAI,MAAMsnB,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,IAAI,GAAK,EAAFvnB,GAAoB,OAAdC,EAAEzB,EAAEgQ,WAAmB,CAAC,IAAItO,EAAE1B,EAAE0vB,cAAc/tB,EAAE,OAAOzB,EAAEA,EAAEwvB,cAAchuB,EAAEmE,EAAE7F,EAAEkC,KAAK4D,EAAE9F,EAAE0xB,YACje,GAAnB1xB,EAAE0xB,YAAY,KAAQ,OAAO5rB,EAAE,IAAI,UAAUD,GAAG,UAAUnE,EAAEQ,MAAM,MAAMR,EAAEuE,MAAMsC,EAAG9G,EAAEC,GAAGyN,GAAGtJ,EAAElE,GAAG,IAAIiE,EAAEuJ,GAAGtJ,EAAEnE,GAAG,IAAIC,EAAE,EAAEA,EAAEmE,EAAE1F,OAAOuB,GAAG,EAAE,CAAC,IAAIqP,EAAElL,EAAEnE,GAAGixB,EAAE9sB,EAAEnE,EAAE,GAAG,UAAUqP,EAAEtD,GAAGjM,EAAEmxB,GAAG,4BAA4B5hB,EAAElH,GAAGrI,EAAEmxB,GAAG,aAAa5hB,EAAExG,GAAG/I,EAAEmxB,GAAGhwB,EAAGnB,EAAEuP,EAAE4hB,EAAEhtB,GAAG,OAAOC,GAAG,IAAK,QAAQ2C,EAAG/G,EAAEC,GAAG,MAAM,IAAK,WAAW8H,GAAG/H,EAAEC,GAAG,MAAM,IAAK,SAAS,IAAImxB,EAAEpxB,EAAEyG,cAAco5B,YAAY7/B,EAAEyG,cAAco5B,cAAc5/B,EAAE6/B,SAAS,IAAIzO,EAAEpxB,EAAEiG,MAAM,MAAMmrB,EAAE/pB,GAAGtH,IAAIC,EAAE6/B,SAASzO,GAAE,GAAID,MAAMnxB,EAAE6/B,WAAW,MAAM7/B,EAAEuG,aAAac,GAAGtH,IAAIC,EAAE6/B,SACnf7/B,EAAEuG,cAAa,GAAIc,GAAGtH,IAAIC,EAAE6/B,SAAS7/B,EAAE6/B,SAAS,GAAG,IAAG,IAAK9/B,EAAEoqB,IAAInqB,EAAE,MAAMqnB,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,IAAI,MAAM,KAAK,EAAgB,GAAd+a,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAQ,EAAFwB,EAAI,CAAC,GAAG,OAAOxB,EAAEgQ,UAAU,MAAM/K,MAAMlF,EAAE,MAAM0B,EAAEzB,EAAEgQ,UAAUtO,EAAE1B,EAAE0vB,cAAc,IAAIjuB,EAAEkJ,UAAUjJ,EAAE,MAAMqnB,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,IAAI,MAAM,KAAK,EAAgB,GAAd+a,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAQ,EAAFwB,GAAK,OAAOtB,GAAGA,EAAE2R,cAAcqF,aAAa,IAAIS,GAAG1X,EAAEkX,eAAe,MAAM4R,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,GAAG,MAAM,KAAK,EAG4G,QAAQ+a,GAAG7jC,EACnfD,GAAGgkC,GAAGhkC,SAJ4Y,KAAK,GAAG8jC,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAqB,MAAlByB,EAAEzB,EAAEiS,OAAQN,QAAajQ,EAAE,OAAOD,EAAEoQ,cAAcpQ,EAAEuO,UAAUi0B,SAASviC,GAAGA,GAClf,OAAOD,EAAEgQ,WAAW,OAAOhQ,EAAEgQ,UAAUI,gBAAgBqyB,GAAGpxB,OAAQ,EAAFtR,GAAKoiC,GAAG5jC,GAAG,MAAM,KAAK,GAAsF,GAAnFgR,EAAE,OAAO9Q,GAAG,OAAOA,EAAE2R,cAAqB,EAAP7R,EAAEsvB,MAAQ8S,IAAGx8B,EAAEw8B,KAAIpxB,EAAE8yB,GAAG7jC,EAAED,GAAGoiC,GAAEx8B,GAAGk+B,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAQ,KAAFwB,EAAO,CAA0B,GAAzBoE,EAAE,OAAO5F,EAAE6R,eAAkB7R,EAAEgQ,UAAUi0B,SAASr+B,KAAKoL,GAAG,KAAY,EAAPhR,EAAEsvB,MAAQ,IAAIiT,GAAEviC,EAAEgR,EAAEhR,EAAEiS,MAAM,OAAOjB,GAAG,CAAC,IAAI4hB,EAAE2P,GAAEvxB,EAAE,OAAOuxB,IAAG,CAAe,OAAVzP,GAAJD,EAAE0P,IAAMtwB,MAAa4gB,EAAE1sB,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG,KAAK,GAAGy8B,GAAG,EAAE/P,EAAEA,EAAEnhB,QAAQ,MAAM,KAAK,EAAE8wB,GAAG3P,EAAEA,EAAEnhB,QAAQ,IAAIoX,EAAE+J,EAAE7iB,UAAU,GAAG,oBAAoB8Y,EAAE6a,qBAAqB,CAACniC,EAAEqxB,EAAE3yB,EAAE2yB,EAAEnhB,OAAO,IAAIzR,EAAEuB,EAAEsnB,EAAE2L,MACpfx0B,EAAEyvB,cAAc5G,EAAEqL,MAAMl0B,EAAE4R,cAAciX,EAAE6a,uBAAuB,MAAM5a,GAAG0Z,GAAEjhC,EAAEtB,EAAE6oB,IAAI,MAAM,KAAK,EAAEyZ,GAAG3P,EAAEA,EAAEnhB,QAAQ,MAAM,KAAK,GAAG,GAAG,OAAOmhB,EAAEhhB,cAAc,CAACsyB,GAAGvR,GAAG,UAAU,OAAOE,GAAGA,EAAEphB,OAAOmhB,EAAE0P,GAAEzP,GAAGqR,GAAGvR,GAAG5hB,EAAEA,EAAEkB,QAAQlS,EAAE,IAAIgR,EAAE,KAAK4hB,EAAE5yB,IAAI,CAAC,GAAG,IAAI4yB,EAAEzsB,KAAK,GAAG,OAAO6K,EAAE,CAACA,EAAE4hB,EAAE,IAAInxB,EAAEmxB,EAAE5iB,UAAUpK,EAAa,oBAAVlE,EAAED,EAAEkM,OAA4BE,YAAYnM,EAAEmM,YAAY,UAAU,OAAO,aAAanM,EAAE0iC,QAAQ,QAASv+B,EAAE+sB,EAAE5iB,UAAkCrO,OAAE,KAA1BmE,EAAE8sB,EAAElD,cAAc/hB,QAAoB,OAAO7H,GAAGA,EAAE3E,eAAe,WAAW2E,EAAEs+B,QAAQ,KAAKv+B,EAAE8H,MAAMy2B,QACzf32B,GAAG,UAAU9L,IAAI,MAAMonB,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,UAAU,GAAG,IAAI6J,EAAEzsB,KAAK,GAAG,OAAO6K,EAAE,IAAI4hB,EAAE5iB,UAAUrF,UAAU/E,EAAE,GAAGgtB,EAAElD,cAAc,MAAM3G,GAAG0Z,GAAEziC,EAAEA,EAAE0R,OAAOqX,SAAS,IAAI,KAAK6J,EAAEzsB,KAAK,KAAKysB,EAAEzsB,KAAK,OAAOysB,EAAE/gB,eAAe+gB,IAAI5yB,IAAI,OAAO4yB,EAAE3gB,MAAM,CAAC2gB,EAAE3gB,MAAMP,OAAOkhB,EAAEA,EAAEA,EAAE3gB,MAAM,SAAS,GAAG2gB,IAAI5yB,EAAE,MAAMA,EAAE,KAAK,OAAO4yB,EAAE1gB,SAAS,CAAC,GAAG,OAAO0gB,EAAElhB,QAAQkhB,EAAElhB,SAAS1R,EAAE,MAAMA,EAAEgR,IAAI4hB,IAAI5hB,EAAE,MAAM4hB,EAAEA,EAAElhB,OAAOV,IAAI4hB,IAAI5hB,EAAE,MAAM4hB,EAAE1gB,QAAQR,OAAOkhB,EAAElhB,OAAOkhB,EAAEA,EAAE1gB,SAAS,MAAM,KAAK,GAAG4xB,GAAG7jC,EAAED,GAAGgkC,GAAGhkC,GAAK,EAAFwB,GAAKoiC,GAAG5jC,GAAS,KAAK,KACrd,SAASgkC,GAAGhkC,GAAG,IAAIC,EAAED,EAAE2R,MAAM,GAAK,EAAF1R,EAAI,CAAC,IAAID,EAAE,CAAC,IAAI,IAAIE,EAAEF,EAAE0R,OAAO,OAAOxR,GAAG,CAAC,GAAG8iC,GAAG9iC,GAAG,CAAC,IAAIsB,EAAEtB,EAAE,MAAMF,EAAEE,EAAEA,EAAEwR,OAAO,MAAMzM,MAAMlF,EAAE,MAAO,OAAOyB,EAAE2E,KAAK,KAAK,EAAE,IAAI1E,EAAED,EAAEwO,UAAkB,GAARxO,EAAEmQ,QAAWnH,GAAG/I,EAAE,IAAID,EAAEmQ,QAAQ,IAAgB0xB,GAAGrjC,EAATijC,GAAGjjC,GAAUyB,GAAG,MAAM,KAAK,EAAE,KAAK,EAAE,IAAIE,EAAEH,EAAEwO,UAAUmH,cAAsB+rB,GAAGljC,EAATijC,GAAGjjC,GAAU2B,GAAG,MAAM,QAAQ,MAAMsD,MAAMlF,EAAE,OAAQ,MAAM+F,GAAG28B,GAAEziC,EAAEA,EAAE0R,OAAO5L,GAAG9F,EAAE2R,QAAQ,EAAI,KAAF1R,IAASD,EAAE2R,QAAQ,MAAM,SAAS0yB,GAAGrkC,EAAEC,EAAEC,GAAGqiC,GAAEviC,EAAEskC,GAAGtkC,EAAEC,EAAEC,GACrb,SAASokC,GAAGtkC,EAAEC,EAAEC,GAAG,IAAI,IAAIsB,EAAE,KAAY,EAAPxB,EAAEsvB,MAAQ,OAAOiT,IAAG,CAAC,IAAI9gC,EAAE8gC,GAAE7gC,EAAED,EAAEwQ,MAAM,GAAG,KAAKxQ,EAAE0E,KAAK3E,EAAE,CAAC,IAAIG,EAAE,OAAOF,EAAEoQ,eAAeswB,GAAG,IAAIxgC,EAAE,CAAC,IAAIkE,EAAEpE,EAAEgQ,UAAU3L,EAAE,OAAOD,GAAG,OAAOA,EAAEgM,eAAeuwB,GAAEv8B,EAAEs8B,GAAG,IAAIv8B,EAAEw8B,GAAO,GAALD,GAAGxgC,GAAMygC,GAAEt8B,KAAKF,EAAE,IAAI28B,GAAE9gC,EAAE,OAAO8gC,IAAOz8B,GAAJnE,EAAE4gC,IAAMtwB,MAAM,KAAKtQ,EAAEwE,KAAK,OAAOxE,EAAEkQ,cAAc0yB,GAAG9iC,GAAG,OAAOqE,GAAGA,EAAE4L,OAAO/P,EAAE4gC,GAAEz8B,GAAGy+B,GAAG9iC,GAAG,KAAK,OAAOC,GAAG6gC,GAAE7gC,EAAE4iC,GAAG5iC,EAAEzB,EAAEC,GAAGwB,EAAEA,EAAEwQ,QAAQqwB,GAAE9gC,EAAE0gC,GAAGt8B,EAAEu8B,GAAEx8B,EAAE4+B,GAAGxkC,QAAY,KAAoB,KAAfyB,EAAE++B,eAAoB,OAAO9+B,GAAGA,EAAEgQ,OAAOjQ,EAAE8gC,GAAE7gC,GAAG8iC,GAAGxkC,IAChc,SAASwkC,GAAGxkC,GAAG,KAAK,OAAOuiC,IAAG,CAAC,IAAItiC,EAAEsiC,GAAE,GAAG,KAAa,KAARtiC,EAAE0R,OAAY,CAAC,IAAIzR,EAAED,EAAEwR,UAAU,IAAI,GAAG,KAAa,KAARxR,EAAE0R,OAAY,OAAO1R,EAAEkG,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAGi8B,IAAGS,GAAG,EAAE5iC,GAAG,MAAM,KAAK,EAAE,IAAIuB,EAAEvB,EAAE+P,UAAU,GAAW,EAAR/P,EAAE0R,QAAUywB,GAAE,GAAG,OAAOliC,EAAEsB,EAAEszB,wBAAwB,CAAC,IAAIrzB,EAAExB,EAAE6uB,cAAc7uB,EAAEiC,KAAKhC,EAAEwvB,cAAcK,GAAG9vB,EAAEiC,KAAKhC,EAAEwvB,eAAeluB,EAAE29B,mBAAmB19B,EAAEvB,EAAE2R,cAAcrQ,EAAEijC,qCAAqC,IAAI/iC,EAAEzB,EAAEyxB,YAAY,OAAOhwB,GAAGsxB,GAAG/yB,EAAEyB,EAAEF,GAAG,MAAM,KAAK,EAAE,IAAIG,EAAE1B,EAAEyxB,YAAY,GAAG,OAAO/vB,EAAE,CAAQ,GAAPzB,EAAE,KAAQ,OAAOD,EAAEgS,MAAM,OAAOhS,EAAEgS,MAAM9L,KAAK,KAAK,EACvf,KAAK,EAAEjG,EAAED,EAAEgS,MAAMjC,UAAUgjB,GAAG/yB,EAAE0B,EAAEzB,GAAG,MAAM,KAAK,EAAE,IAAI2F,EAAE5F,EAAE+P,UAAU,GAAG,OAAO9P,GAAW,EAARD,EAAE0R,MAAQ,CAACzR,EAAE2F,EAAE,IAAIC,EAAE7F,EAAEyvB,cAAc,OAAOzvB,EAAEiC,MAAM,IAAK,SAAS,IAAK,QAAQ,IAAK,SAAS,IAAK,WAAW4D,EAAE+7B,WAAW3hC,EAAEgmB,QAAQ,MAAM,IAAK,MAAMpgB,EAAE4+B,MAAMxkC,EAAEwkC,IAAI5+B,EAAE4+B,MAAM,MAAM,KAAK,EAAQ,KAAK,EAAQ,KAAK,GAAyJ,KAAK,GAAG,KAAK,GAAG,KAAK,GAAG,KAAK,GAAG,KAAK,GAAG,KAAK,GAAG,MAAhM,KAAK,GAAG,GAAG,OAAOzkC,EAAE4R,cAAc,CAAC,IAAIjM,EAAE3F,EAAEwR,UAAU,GAAG,OAAO7L,EAAE,CAAC,IAAIoL,EAAEpL,EAAEiM,cAAc,GAAG,OAAOb,EAAE,CAAC,IAAI4hB,EAAE5hB,EAAEc,WAAW,OAAO8gB,GAAGjb,GAAGib,KAAK,MAC5c,QAAQ,MAAM3tB,MAAMlF,EAAE,MAAOqiC,IAAW,IAARniC,EAAE0R,OAAWmxB,GAAG7iC,GAAG,MAAM4yB,GAAG4P,GAAExiC,EAAEA,EAAEyR,OAAOmhB,IAAI,GAAG5yB,IAAID,EAAE,CAACuiC,GAAE,KAAK,MAAkB,GAAG,QAAfriC,EAAED,EAAEiS,SAAoB,CAAChS,EAAEwR,OAAOzR,EAAEyR,OAAO6wB,GAAEriC,EAAE,MAAMqiC,GAAEtiC,EAAEyR,QAAQ,SAASyyB,GAAGnkC,GAAG,KAAK,OAAOuiC,IAAG,CAAC,IAAItiC,EAAEsiC,GAAE,GAAGtiC,IAAID,EAAE,CAACuiC,GAAE,KAAK,MAAM,IAAIriC,EAAED,EAAEiS,QAAQ,GAAG,OAAOhS,EAAE,CAACA,EAAEwR,OAAOzR,EAAEyR,OAAO6wB,GAAEriC,EAAE,MAAMqiC,GAAEtiC,EAAEyR,QAChS,SAAS6yB,GAAGvkC,GAAG,KAAK,OAAOuiC,IAAG,CAAC,IAAItiC,EAAEsiC,GAAE,IAAI,OAAOtiC,EAAEkG,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG,IAAIjG,EAAED,EAAEyR,OAAO,IAAImxB,GAAG,EAAE5iC,GAAG,MAAM6F,GAAG28B,GAAExiC,EAAEC,EAAE4F,GAAG,MAAM,KAAK,EAAE,IAAItE,EAAEvB,EAAE+P,UAAU,GAAG,oBAAoBxO,EAAEszB,kBAAkB,CAAC,IAAIrzB,EAAExB,EAAEyR,OAAO,IAAIlQ,EAAEszB,oBAAoB,MAAMhvB,GAAG28B,GAAExiC,EAAEwB,EAAEqE,IAAI,IAAIpE,EAAEzB,EAAEyR,OAAO,IAAIoxB,GAAG7iC,GAAG,MAAM6F,GAAG28B,GAAExiC,EAAEyB,EAAEoE,GAAG,MAAM,KAAK,EAAE,IAAInE,EAAE1B,EAAEyR,OAAO,IAAIoxB,GAAG7iC,GAAG,MAAM6F,GAAG28B,GAAExiC,EAAE0B,EAAEmE,KAAK,MAAMA,GAAG28B,GAAExiC,EAAEA,EAAEyR,OAAO5L,GAAG,GAAG7F,IAAID,EAAE,CAACuiC,GAAE,KAAK,MAAM,IAAI18B,EAAE5F,EAAEiS,QAAQ,GAAG,OAAOrM,EAAE,CAACA,EAAE6L,OAAOzR,EAAEyR,OAAO6wB,GAAE18B,EAAE,MAAM08B,GAAEtiC,EAAEyR,QACtd,IAwBkNizB,GAxB9MC,GAAG7wB,KAAK8wB,KAAKC,GAAGrhC,EAAGyzB,uBAAuB6N,GAAGthC,EAAGs6B,kBAAkBiH,GAAGvhC,EAAGoU,wBAAwB2a,GAAE,EAAEgH,GAAE,KAAKyL,GAAE,KAAKC,GAAE,EAAErG,GAAG,EAAED,GAAG1S,GAAG,GAAG6V,GAAE,EAAEoD,GAAG,KAAKpS,GAAG,EAAEqS,GAAG,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,KAAKrB,GAAG,EAAElC,GAAGwD,IAASC,GAAG,KAAKvI,IAAG,EAAGC,GAAG,KAAKI,GAAG,KAAKmI,IAAG,EAAGC,GAAG,KAAKC,GAAG,EAAEC,GAAG,EAAEC,GAAG,KAAKC,IAAI,EAAEC,GAAG,EAAE,SAASvS,KAAI,OAAO,KAAO,EAAFjB,IAAK1f,MAAK,IAAIizB,GAAGA,GAAGA,GAAGjzB,KAC7T,SAAS4gB,GAAG1zB,GAAG,OAAG,KAAY,EAAPA,EAAEsvB,MAAe,EAAK,KAAO,EAAFkD,KAAM,IAAI0S,GAASA,IAAGA,GAAK,OAAOpV,GAAG9X,YAAkB,IAAIguB,KAAKA,GAAGhxB,MAAMgxB,IAAU,KAAPhmC,EAAEqV,IAAkBrV,EAAiBA,OAAE,KAAjBA,EAAEa,OAAOohB,OAAmB,GAAG1J,GAAGvY,EAAEkC,MAAe,SAASyxB,GAAG3zB,EAAEC,EAAEC,EAAEsB,GAAG,GAAG,GAAGqkC,GAAG,MAAMA,GAAG,EAAEC,GAAG,KAAK7gC,MAAMlF,EAAE,MAAMmV,GAAGlV,EAAEE,EAAEsB,GAAM,KAAO,EAAFgxB,KAAMxyB,IAAIw5B,KAAEx5B,IAAIw5B,KAAI,KAAO,EAAFhH,MAAO4S,IAAIllC,GAAG,IAAI6hC,IAAGkE,GAAGjmC,EAAEklC,KAAIgB,GAAGlmC,EAAEwB,GAAG,IAAItB,GAAG,IAAIsyB,IAAG,KAAY,EAAPvyB,EAAEqvB,QAAU0S,GAAGlvB,KAAI,IAAIya,IAAIG,OACrY,SAASwY,GAAGlmC,EAAEC,GAAG,IAAIC,EAAEF,EAAEmmC,cA5MzB,SAAYnmC,EAAEC,GAAG,IAAI,IAAIC,EAAEF,EAAE0U,eAAelT,EAAExB,EAAE2U,YAAYlT,EAAEzB,EAAEomC,gBAAgB1kC,EAAE1B,EAAEyU,aAAa,EAAE/S,GAAG,CAAC,IAAIC,EAAE,GAAGmS,GAAGpS,GAAGmE,EAAE,GAAGlE,EAAEmE,EAAErE,EAAEE,IAAO,IAAImE,EAAM,KAAKD,EAAE3F,IAAI,KAAK2F,EAAErE,KAAGC,EAAEE,GAAGmT,GAAGjP,EAAE5F,IAAQ6F,GAAG7F,IAAID,EAAEqmC,cAAcxgC,GAAGnE,IAAImE,GA4MjLygC,CAAGtmC,EAAEC,GAAG,IAAIuB,EAAEgT,GAAGxU,EAAEA,IAAIw5B,GAAE0L,GAAE,GAAG,GAAG,IAAI1jC,EAAE,OAAOtB,GAAGsS,GAAGtS,GAAGF,EAAEmmC,aAAa,KAAKnmC,EAAEumC,iBAAiB,OAAO,GAAGtmC,EAAEuB,GAAGA,EAAExB,EAAEumC,mBAAmBtmC,EAAE,CAAgB,GAAf,MAAMC,GAAGsS,GAAGtS,GAAM,IAAID,EAAE,IAAID,EAAEmG,IA7IsJ,SAAYnG,GAAGutB,IAAG,EAAGE,GAAGztB,GA6I1KwmC,CAAGC,GAAG9d,KAAK,KAAK3oB,IAAIytB,GAAGgZ,GAAG9d,KAAK,KAAK3oB,IAAIirB,IAAG,WAAW,KAAO,EAAFuH,KAAM9E,QAAOxtB,EAAE,SAAS,CAAC,OAAOoV,GAAG9T,IAAI,KAAK,EAAEtB,EAAEgT,GAAG,MAAM,KAAK,EAAEhT,EAAEkT,GAAG,MAAM,KAAK,GAAwC,QAAQlT,EAAEoT,SAApC,KAAK,UAAUpT,EAAEwT,GAAsBxT,EAAEwmC,GAAGxmC,EAAEymC,GAAGhe,KAAK,KAAK3oB,IAAIA,EAAEumC,iBAAiBtmC,EAAED,EAAEmmC,aAAajmC,GAC3c,SAASymC,GAAG3mC,EAAEC,GAAc,GAAX8lC,IAAI,EAAEC,GAAG,EAAK,KAAO,EAAFxT,IAAK,MAAMvtB,MAAMlF,EAAE,MAAM,IAAIG,EAAEF,EAAEmmC,aAAa,GAAGS,MAAM5mC,EAAEmmC,eAAejmC,EAAE,OAAO,KAAK,IAAIsB,EAAEgT,GAAGxU,EAAEA,IAAIw5B,GAAE0L,GAAE,GAAG,GAAG,IAAI1jC,EAAE,OAAO,KAAK,GAAG,KAAO,GAAFA,IAAO,KAAKA,EAAExB,EAAEqmC,eAAepmC,EAAEA,EAAE4mC,GAAG7mC,EAAEwB,OAAO,CAACvB,EAAEuB,EAAE,IAAIC,EAAE+wB,GAAEA,IAAG,EAAE,IAAI9wB,EAAEolC,KAAgD,IAAxCtN,KAAIx5B,GAAGklC,KAAIjlC,IAAEwlC,GAAG,KAAKzD,GAAGlvB,KAAI,IAAIi0B,GAAG/mC,EAAEC,MAAM,IAAI+mC,KAAK,MAAM,MAAMnhC,GAAGohC,GAAGjnC,EAAE6F,GAAYwqB,KAAKyU,GAAG3yB,QAAQzQ,EAAE8wB,GAAE/wB,EAAE,OAAOwjC,GAAEhlC,EAAE,GAAGu5B,GAAE,KAAK0L,GAAE,EAAEjlC,EAAE8hC,IAAG,GAAG,IAAI9hC,EAAE,CAAyC,GAAxC,IAAIA,IAAY,KAARwB,EAAEsT,GAAG/U,MAAWwB,EAAEC,EAAExB,EAAEinC,GAAGlnC,EAAEyB,KAAQ,IAAIxB,EAAE,MAAMC,EAAEilC,GAAG4B,GAAG/mC,EAAE,GAAGimC,GAAGjmC,EAAEwB,GAAG0kC,GAAGlmC,EAAE8S,MAAK5S,EAAE,GAAG,IAAID,EAAEgmC,GAAGjmC,EAAEwB,OAChf,CAAuB,GAAtBC,EAAEzB,EAAEmS,QAAQV,UAAa,KAAO,GAAFjQ,KAGnC,SAAYxB,GAAG,IAAI,IAAIC,EAAED,IAAI,CAAC,GAAW,MAARC,EAAE0R,MAAY,CAAC,IAAIzR,EAAED,EAAEyxB,YAAY,GAAG,OAAOxxB,GAAe,QAAXA,EAAEA,EAAEy5B,QAAiB,IAAI,IAAIn4B,EAAE,EAAEA,EAAEtB,EAAEE,OAAOoB,IAAI,CAAC,IAAIC,EAAEvB,EAAEsB,GAAGE,EAAED,EAAE43B,YAAY53B,EAAEA,EAAEkG,MAAM,IAAI,IAAI4b,GAAG7hB,IAAID,GAAG,OAAM,EAAG,MAAME,GAAG,OAAM,IAAe,GAAVzB,EAAED,EAAEgS,MAAwB,MAAfhS,EAAEugC,cAAoB,OAAOtgC,EAAEA,EAAEwR,OAAOzR,EAAEA,EAAEC,MAAM,CAAC,GAAGD,IAAID,EAAE,MAAM,KAAK,OAAOC,EAAEiS,SAAS,CAAC,GAAG,OAAOjS,EAAEyR,QAAQzR,EAAEyR,SAAS1R,EAAE,OAAM,EAAGC,EAAEA,EAAEyR,OAAOzR,EAAEiS,QAAQR,OAAOzR,EAAEyR,OAAOzR,EAAEA,EAAEiS,SAAS,OAAM,EAHrXi1B,CAAG1lC,KAAe,KAAVxB,EAAE4mC,GAAG7mC,EAAEwB,MAAmB,KAARE,EAAEqT,GAAG/U,MAAWwB,EAAEE,EAAEzB,EAAEinC,GAAGlnC,EAAE0B,KAAK,IAAIzB,GAAG,MAAMC,EAAEilC,GAAG4B,GAAG/mC,EAAE,GAAGimC,GAAGjmC,EAAEwB,GAAG0kC,GAAGlmC,EAAE8S,MAAK5S,EAAqC,OAAnCF,EAAEonC,aAAa3lC,EAAEzB,EAAEqnC,cAAc7lC,EAASvB,GAAG,KAAK,EAAE,KAAK,EAAE,MAAMgF,MAAMlF,EAAE,MAAM,KAAK,EAC8B,KAAK,EAAEunC,GAAGtnC,EAAEulC,GAAGE,IAAI,MAD7B,KAAK,EAAU,GAARQ,GAAGjmC,EAAEwB,IAAS,UAAFA,KAAeA,GAAiB,IAAbvB,EAAEikC,GAAG,IAAIpxB,MAAU,CAAC,GAAG,IAAI0B,GAAGxU,EAAE,GAAG,MAAyB,KAAnByB,EAAEzB,EAAE0U,gBAAqBlT,KAAKA,EAAE,CAACiyB,KAAIzzB,EAAE2U,aAAa3U,EAAE0U,eAAejT,EAAE,MAAMzB,EAAEunC,cAAc5c,GAAG2c,GAAG3e,KAAK,KAAK3oB,EAAEulC,GAAGE,IAAIxlC,GAAG,MAAMqnC,GAAGtnC,EAAEulC,GAAGE,IAAI,MAAM,KAAK,EAAU,GAARQ,GAAGjmC,EAAEwB,IAAS,QAAFA,KAC9eA,EAAE,MAAqB,IAAfvB,EAAED,EAAEmV,WAAe1T,GAAG,EAAE,EAAED,GAAG,CAAC,IAAIG,EAAE,GAAGmS,GAAGtS,GAAGE,EAAE,GAAGC,GAAEA,EAAE1B,EAAE0B,IAAKF,IAAIA,EAAEE,GAAGH,IAAIE,EAAsG,GAApGF,EAAEC,EAAqG,IAA3FD,GAAG,KAAXA,EAAEsR,KAAItR,GAAW,IAAI,IAAIA,EAAE,IAAI,KAAKA,EAAE,KAAK,KAAKA,EAAE,KAAK,IAAIA,EAAE,IAAI,KAAKA,EAAE,KAAK,KAAKojC,GAAGpjC,EAAE,OAAOA,GAAU,CAACxB,EAAEunC,cAAc5c,GAAG2c,GAAG3e,KAAK,KAAK3oB,EAAEulC,GAAGE,IAAIjkC,GAAG,MAAM8lC,GAAGtnC,EAAEulC,GAAGE,IAAI,MAA+B,QAAQ,MAAMxgC,MAAMlF,EAAE,QAAmB,OAAVmmC,GAAGlmC,EAAE8S,MAAY9S,EAAEmmC,eAAejmC,EAAEymC,GAAGhe,KAAK,KAAK3oB,GAAG,KACjX,SAASknC,GAAGlnC,EAAEC,GAAG,IAAIC,EAAEolC,GAA2G,OAAxGtlC,EAAEmS,QAAQN,cAAcqF,eAAe6vB,GAAG/mC,EAAEC,GAAG0R,OAAO,KAAe,KAAV3R,EAAE6mC,GAAG7mC,EAAEC,MAAWA,EAAEslC,GAAGA,GAAGrlC,EAAE,OAAOD,GAAGohC,GAAGphC,IAAWD,EAAE,SAASqhC,GAAGrhC,GAAG,OAAOulC,GAAGA,GAAGvlC,EAAEulC,GAAGp1B,KAAKY,MAAMw0B,GAAGvlC,GAE1L,SAASimC,GAAGjmC,EAAEC,GAAuD,IAApDA,IAAIolC,GAAGplC,IAAImlC,GAAGplC,EAAE0U,gBAAgBzU,EAAED,EAAE2U,cAAc1U,EAAMD,EAAEA,EAAEomC,gBAAgB,EAAEnmC,GAAG,CAAC,IAAIC,EAAE,GAAG4T,GAAG7T,GAAGuB,EAAE,GAAGtB,EAAEF,EAAEE,IAAI,EAAED,IAAIuB,GAAG,SAASilC,GAAGzmC,GAAG,GAAG,KAAO,EAAFwyB,IAAK,MAAMvtB,MAAMlF,EAAE,MAAM6mC,KAAK,IAAI3mC,EAAEuU,GAAGxU,EAAE,GAAG,GAAG,KAAO,EAAFC,GAAK,OAAOimC,GAAGlmC,EAAE8S,MAAK,KAAK,IAAI5S,EAAE2mC,GAAG7mC,EAAEC,GAAG,GAAG,IAAID,EAAEmG,KAAK,IAAIjG,EAAE,CAAC,IAAIsB,EAAEuT,GAAG/U,GAAG,IAAIwB,IAAIvB,EAAEuB,EAAEtB,EAAEgnC,GAAGlnC,EAAEwB,IAAI,GAAG,IAAItB,EAAE,MAAMA,EAAEilC,GAAG4B,GAAG/mC,EAAE,GAAGimC,GAAGjmC,EAAEC,GAAGimC,GAAGlmC,EAAE8S,MAAK5S,EAAE,GAAG,IAAIA,EAAE,MAAM+E,MAAMlF,EAAE,MAAiF,OAA3EC,EAAEonC,aAAapnC,EAAEmS,QAAQV,UAAUzR,EAAEqnC,cAAcpnC,EAAEqnC,GAAGtnC,EAAEulC,GAAGE,IAAIS,GAAGlmC,EAAE8S,MAAY,KACnd,SAAS00B,GAAGxnC,EAAEC,GAAG,IAAIC,EAAEsyB,GAAEA,IAAG,EAAE,IAAI,OAAOxyB,EAAEC,GAAb,QAA4B,KAAJuyB,GAAEtyB,KAAU8hC,GAAGlvB,KAAI,IAAIya,IAAIG,OAAO,SAAS+Z,GAAGznC,GAAG,OAAO2lC,IAAI,IAAIA,GAAGx/B,KAAK,KAAO,EAAFqsB,KAAMoU,KAAK,IAAI3mC,EAAEuyB,GAAEA,IAAG,EAAE,IAAItyB,EAAE8kC,GAAGhtB,WAAWxW,EAAE6T,GAAE,IAAI,GAAG2vB,GAAGhtB,WAAW,KAAK3C,GAAE,EAAErV,EAAE,OAAOA,IAAvC,QAAmDqV,GAAE7T,EAAEwjC,GAAGhtB,WAAW9X,EAAM,KAAO,GAAXsyB,GAAEvyB,KAAaytB,MAAM,SAASuU,KAAKpD,GAAGD,GAAGzsB,QAAQga,GAAEyS,IAC7S,SAASmI,GAAG/mC,EAAEC,GAAGD,EAAEonC,aAAa,KAAKpnC,EAAEqnC,cAAc,EAAE,IAAInnC,EAAEF,EAAEunC,cAAiD,IAAlC,IAAIrnC,IAAIF,EAAEunC,eAAe,EAAE1c,GAAG3qB,IAAO,OAAO+kC,GAAE,IAAI/kC,EAAE+kC,GAAEvzB,OAAO,OAAOxR,GAAG,CAAC,IAAIsB,EAAEtB,EAAQ,OAANquB,GAAG/sB,GAAUA,EAAE2E,KAAK,KAAK,EAA6B,QAA3B3E,EAAEA,EAAEU,KAAK4qB,yBAA4B,IAAStrB,GAAGurB,KAAK,MAAM,KAAK,EAAEyJ,KAAKrK,GAAEI,IAAIJ,GAAEG,IAAGyK,KAAK,MAAM,KAAK,EAAEL,GAAGl1B,GAAG,MAAM,KAAK,EAAEg1B,KAAK,MAAM,KAAK,GAAc,KAAK,GAAGrK,GAAEwK,IAAG,MAAM,KAAK,GAAGrG,GAAG9uB,EAAEU,KAAKqE,UAAU,MAAM,KAAK,GAAG,KAAK,GAAG07B,KAAK/hC,EAAEA,EAAEwR,OAA2E,GAApE8nB,GAAEx5B,EAAEilC,GAAEjlC,EAAEw1B,GAAGx1B,EAAEmS,QAAQ,MAAM+yB,GAAErG,GAAG5+B,EAAE8hC,GAAE,EAAEoD,GAAG,KAAKE,GAAGD,GAAGrS,GAAG,EAAEwS,GAAGD,GAAG,KAAQ,OAAOnU,GAAG,CAAC,IAAIlxB,EAC1f,EAAEA,EAAEkxB,GAAG/wB,OAAOH,IAAI,GAA2B,QAAhBuB,GAARtB,EAAEixB,GAAGlxB,IAAOqxB,aAAqB,CAACpxB,EAAEoxB,YAAY,KAAK,IAAI7vB,EAAED,EAAE0vB,KAAKxvB,EAAExB,EAAE6xB,QAAQ,GAAG,OAAOrwB,EAAE,CAAC,IAAIC,EAAED,EAAEwvB,KAAKxvB,EAAEwvB,KAAKzvB,EAAED,EAAE0vB,KAAKvvB,EAAEzB,EAAE6xB,QAAQvwB,EAAE2vB,GAAG,KAAK,OAAOnxB,EAC1K,SAASinC,GAAGjnC,EAAEC,GAAG,OAAE,CAAC,IAAIC,EAAE+kC,GAAE,IAAuB,GAAnB5U,KAAK4G,GAAG9kB,QAAQ+lB,GAAMV,GAAG,CAAC,IAAI,IAAIh2B,EAAE61B,GAAExlB,cAAc,OAAOrQ,GAAG,CAAC,IAAIC,EAAED,EAAE82B,MAAM,OAAO72B,IAAIA,EAAEswB,QAAQ,MAAMvwB,EAAEA,EAAE0vB,KAAKsG,IAAG,EAA8C,GAA3CJ,GAAG,EAAEG,GAAED,GAAED,GAAE,KAAKI,IAAG,EAAGC,GAAG,EAAEqN,GAAG5yB,QAAQ,KAAQ,OAAOjS,GAAG,OAAOA,EAAEwR,OAAO,CAACqwB,GAAE,EAAEoD,GAAGllC,EAAEglC,GAAE,KAAK,MAAMjlC,EAAE,CAAC,IAAI0B,EAAE1B,EAAE2B,EAAEzB,EAAEwR,OAAO7L,EAAE3F,EAAE4F,EAAE7F,EAAqB,GAAnBA,EAAEilC,GAAEr/B,EAAE8L,OAAO,MAAS,OAAO7L,GAAG,kBAAkBA,GAAG,oBAAoBA,EAAEslB,KAAK,CAAC,IAAIxlB,EAAEE,EAAEkL,EAAEnL,EAAE+sB,EAAE5hB,EAAE7K,IAAI,GAAG,KAAY,EAAP6K,EAAEse,QAAU,IAAIsD,GAAG,KAAKA,GAAG,KAAKA,GAAG,CAAC,IAAIC,EAAE7hB,EAAES,UAAUohB,GAAG7hB,EAAE0gB,YAAYmB,EAAEnB,YAAY1gB,EAAEa,cAAcghB,EAAEhhB,cACxeb,EAAE6f,MAAMgC,EAAEhC,QAAQ7f,EAAE0gB,YAAY,KAAK1gB,EAAEa,cAAc,MAAM,IAAIihB,EAAE8K,GAAGj8B,GAAG,GAAG,OAAOmxB,EAAE,CAACA,EAAEnhB,QAAQ,IAAIksB,GAAG/K,EAAEnxB,EAAEkE,EAAEnE,EAAEzB,GAAU,EAAP6yB,EAAExD,MAAQmO,GAAG/7B,EAAEkE,EAAE3F,GAAO6F,EAAEF,EAAE,IAAIkjB,GAAZ7oB,EAAE6yB,GAAcpB,YAAY,GAAG,OAAO5I,EAAE,CAAC,IAAIC,EAAE,IAAIxoB,IAAIwoB,EAAEpoB,IAAImF,GAAG7F,EAAEyxB,YAAY3I,OAAOD,EAAEnoB,IAAImF,GAAG,MAAM9F,EAAO,GAAG,KAAO,EAAFC,GAAK,CAACw9B,GAAG/7B,EAAEkE,EAAE3F,GAAGmgC,KAAK,MAAMpgC,EAAE8F,EAAEb,MAAMlF,EAAE,WAAY,GAAG2uB,IAAU,EAAP7oB,EAAEypB,KAAO,CAAC,IAAItG,EAAE4U,GAAGj8B,GAAG,GAAG,OAAOqnB,EAAE,CAAC,KAAa,MAARA,EAAErX,SAAeqX,EAAErX,OAAO,KAAKksB,GAAG7U,EAAErnB,EAAEkE,EAAEnE,EAAEzB,GAAG4vB,GAAG2M,GAAG12B,EAAED,IAAI,MAAM7F,GAAG0B,EAAEoE,EAAE02B,GAAG12B,EAAED,GAAG,IAAIk8B,KAAIA,GAAE,GAAG,OAAOuD,GAAGA,GAAG,CAAC5jC,GAAG4jC,GAAGn1B,KAAKzO,GAAGA,EAAEC,EAAE,EAAE,CAAC,OAAOD,EAAEyE,KAAK,KAAK,EAAEzE,EAAEiQ,OAAO,MACpf1R,IAAIA,EAAEyB,EAAEmvB,OAAO5wB,EAAkByyB,GAAGhxB,EAAbu7B,GAAGv7B,EAAEoE,EAAE7F,IAAW,MAAMD,EAAE,KAAK,EAAE6F,EAAEC,EAAE,IAAIqjB,EAAEznB,EAAEQ,KAAKgnB,EAAExnB,EAAEsO,UAAU,GAAG,KAAa,IAARtO,EAAEiQ,SAAa,oBAAoBwX,EAAEkU,0BAA0B,OAAOnU,GAAG,oBAAoBA,EAAEoU,oBAAoB,OAAOC,KAAKA,GAAGlV,IAAIa,KAAK,CAACxnB,EAAEiQ,OAAO,MAAM1R,IAAIA,EAAEyB,EAAEmvB,OAAO5wB,EAAkByyB,GAAGhxB,EAAb07B,GAAG17B,EAAEmE,EAAE5F,IAAW,MAAMD,GAAG0B,EAAEA,EAAEgQ,aAAa,OAAOhQ,GAAGgmC,GAAGxnC,GAAG,MAAMwpB,GAAIzpB,EAAEypB,EAAGub,KAAI/kC,GAAG,OAAOA,IAAI+kC,GAAE/kC,EAAEA,EAAEwR,QAAQ,SAAS,OAAe,SAASo1B,KAAK,IAAI9mC,EAAE8kC,GAAG3yB,QAAsB,OAAd2yB,GAAG3yB,QAAQ+lB,GAAU,OAAOl4B,EAAEk4B,GAAGl4B,EACpd,SAASogC,KAAQ,IAAI2B,IAAG,IAAIA,IAAG,IAAIA,KAAEA,GAAE,GAAE,OAAOvI,IAAG,KAAQ,UAAHzG,KAAe,KAAQ,UAAHqS,KAAea,GAAGzM,GAAE0L,IAAG,SAAS2B,GAAG7mC,EAAEC,GAAG,IAAIC,EAAEsyB,GAAEA,IAAG,EAAE,IAAIhxB,EAAEslC,KAAqC,IAA7BtN,KAAIx5B,GAAGklC,KAAIjlC,IAAEwlC,GAAG,KAAKsB,GAAG/mC,EAAEC,MAAM,IAAI0nC,KAAK,MAAM,MAAMlmC,GAAGwlC,GAAGjnC,EAAEyB,GAAkC,GAAtB4uB,KAAKmC,GAAEtyB,EAAE4kC,GAAG3yB,QAAQ3Q,EAAK,OAAOyjC,GAAE,MAAMhgC,MAAMlF,EAAE,MAAiB,OAAXy5B,GAAE,KAAK0L,GAAE,EAASnD,GAAE,SAAS4F,KAAK,KAAK,OAAO1C,IAAG2C,GAAG3C,IAAG,SAAS+B,KAAK,KAAK,OAAO/B,KAAIvyB,MAAMk1B,GAAG3C,IAAG,SAAS2C,GAAG5nC,GAAG,IAAIC,EAAE0kC,GAAG3kC,EAAEyR,UAAUzR,EAAE6+B,IAAI7+B,EAAE0vB,cAAc1vB,EAAEivB,aAAa,OAAOhvB,EAAEynC,GAAG1nC,GAAGilC,GAAEhlC,EAAE8kC,GAAG5yB,QAAQ,KACtd,SAASu1B,GAAG1nC,GAAG,IAAIC,EAAED,EAAE,EAAE,CAAC,IAAIE,EAAED,EAAEwR,UAAqB,GAAXzR,EAAEC,EAAEyR,OAAU,KAAa,MAARzR,EAAE0R,QAAc,GAAgB,QAAbzR,EAAEkhC,GAAGlhC,EAAED,EAAE4+B,KAAkB,YAAJoG,GAAE/kC,OAAc,CAAW,GAAG,QAAbA,EAAEgiC,GAAGhiC,EAAED,IAAmC,OAAnBC,EAAEyR,OAAO,WAAMszB,GAAE/kC,GAAS,GAAG,OAAOF,EAAmE,OAAX+hC,GAAE,OAAEkD,GAAE,MAA5DjlC,EAAE2R,OAAO,MAAM3R,EAAEwgC,aAAa,EAAExgC,EAAE+uB,UAAU,KAAyC,GAAG,QAAf9uB,EAAEA,EAAEiS,SAAyB,YAAJ+yB,GAAEhlC,GAASglC,GAAEhlC,EAAED,QAAQ,OAAOC,GAAG,IAAI8hC,KAAIA,GAAE,GAAG,SAASuF,GAAGtnC,EAAEC,EAAEC,GAAG,IAAIsB,EAAE6T,GAAE5T,EAAEujC,GAAGhtB,WAAW,IAAIgtB,GAAGhtB,WAAW,KAAK3C,GAAE,EAC3Y,SAAYrV,EAAEC,EAAEC,EAAEsB,GAAG,GAAGolC,WAAW,OAAOjB,IAAI,GAAG,KAAO,EAAFnT,IAAK,MAAMvtB,MAAMlF,EAAE,MAAMG,EAAEF,EAAEonC,aAAa,IAAI3lC,EAAEzB,EAAEqnC,cAAc,GAAG,OAAOnnC,EAAE,OAAO,KAA2C,GAAtCF,EAAEonC,aAAa,KAAKpnC,EAAEqnC,cAAc,EAAKnnC,IAAIF,EAAEmS,QAAQ,MAAMlN,MAAMlF,EAAE,MAAMC,EAAEmmC,aAAa,KAAKnmC,EAAEumC,iBAAiB,EAAE,IAAI7kC,EAAExB,EAAE2wB,MAAM3wB,EAAEuwB,WAA8J,GA1NtT,SAAYzwB,EAAEC,GAAG,IAAIC,EAAEF,EAAEyU,cAAcxU,EAAED,EAAEyU,aAAaxU,EAAED,EAAE0U,eAAe,EAAE1U,EAAE2U,YAAY,EAAE3U,EAAEqmC,cAAcpmC,EAAED,EAAE6nC,kBAAkB5nC,EAAED,EAAE4U,gBAAgB3U,EAAEA,EAAED,EAAE6U,cAAc,IAAIrT,EAAExB,EAAEmV,WAAW,IAAInV,EAAEA,EAAEomC,gBAAgB,EAAElmC,GAAG,CAAC,IAAIuB,EAAE,GAAGqS,GAAG5T,GAAGwB,EAAE,GAAGD,EAAExB,EAAEwB,GAAG,EAAED,EAAEC,IAAI,EAAEzB,EAAEyB,IAAI,EAAEvB,IAAIwB,GA0N1GomC,CAAG9nC,EAAE0B,GAAG1B,IAAIw5B,KAAIyL,GAAEzL,GAAE,KAAK0L,GAAE,GAAG,KAAoB,KAAfhlC,EAAEsgC,eAAoB,KAAa,KAARtgC,EAAEyR,QAAa+zB,KAAKA,IAAG,EAAGgB,GAAGpzB,IAAG,WAAgB,OAALszB,KAAY,SAAQllC,EAAE,KAAa,MAARxB,EAAEyR,OAAgB,KAAoB,MAAfzR,EAAEsgC,eAAqB9+B,EAAE,CAACA,EAAEsjC,GAAGhtB,WAAWgtB,GAAGhtB,WAAW,KAChf,IAAIrW,EAAE0T,GAAEA,GAAE,EAAE,IAAIxP,EAAE2sB,GAAEA,IAAG,EAAEuS,GAAG5yB,QAAQ,KA1CpC,SAAYnS,EAAEC,GAAgB,GAAbsqB,GAAGzS,GAAauM,GAAVrkB,EAAEikB,MAAc,CAAC,GAAG,mBAAmBjkB,EAAE,IAAIE,EAAE,CAACykB,MAAM3kB,EAAE6kB,eAAeD,IAAI5kB,EAAE8kB,mBAAmB9kB,EAAE,CAA8C,IAAIwB,GAAjDtB,GAAGA,EAAEF,EAAE2I,gBAAgBzI,EAAE8kB,aAAankB,QAAeokB,cAAc/kB,EAAE+kB,eAAe,GAAGzjB,GAAG,IAAIA,EAAE2jB,WAAW,CAACjlB,EAAEsB,EAAE4jB,WAAW,IAAI3jB,EAAED,EAAE6jB,aAAa3jB,EAAEF,EAAE8jB,UAAU9jB,EAAEA,EAAE+jB,YAAY,IAAIrlB,EAAEwK,SAAShJ,EAAEgJ,SAAS,MAAM0e,GAAGlpB,EAAE,KAAK,MAAMF,EAAE,IAAI2B,EAAE,EAAEkE,GAAG,EAAEC,GAAG,EAAEF,EAAE,EAAEoL,EAAE,EAAE4hB,EAAE5yB,EAAE6yB,EAAE,KAAK5yB,EAAE,OAAO,CAAC,IAAI,IAAI6yB,EAAKF,IAAI1yB,GAAG,IAAIuB,GAAG,IAAImxB,EAAEloB,WAAW7E,EAAElE,EAAEF,GAAGmxB,IAAIlxB,GAAG,IAAIF,GAAG,IAAIoxB,EAAEloB,WAAW5E,EAAEnE,EAAEH,GAAG,IAAIoxB,EAAEloB,WAAW/I,GACnfixB,EAAEjoB,UAAUvK,QAAW,QAAQ0yB,EAAEF,EAAEzoB,aAAkB0oB,EAAED,EAAEA,EAAEE,EAAE,OAAO,CAAC,GAAGF,IAAI5yB,EAAE,MAAMC,EAA8C,GAA5C4yB,IAAI3yB,KAAK0F,IAAInE,IAAIoE,EAAElE,GAAGkxB,IAAInxB,KAAKsP,IAAIxP,IAAIsE,EAAEnE,GAAM,QAAQmxB,EAAEF,EAAE/O,aAAa,MAAUgP,GAAJD,EAAEC,GAAMnjB,WAAWkjB,EAAEE,EAAE5yB,GAAG,IAAI2F,IAAI,IAAIC,EAAE,KAAK,CAAC6e,MAAM9e,EAAE+e,IAAI9e,QAAQ5F,EAAE,KAAKA,EAAEA,GAAG,CAACykB,MAAM,EAAEC,IAAI,QAAQ1kB,EAAE,KAA+C,IAA1CsqB,GAAG,CAAChG,YAAYxkB,EAAEykB,eAAevkB,GAAG4X,IAAG,EAAOyqB,GAAEtiC,EAAE,OAAOsiC,IAAG,GAAOviC,GAAJC,EAAEsiC,IAAMtwB,MAAM,KAAoB,KAAfhS,EAAEugC,eAAoB,OAAOxgC,EAAEA,EAAE0R,OAAOzR,EAAEsiC,GAAEviC,OAAO,KAAK,OAAOuiC,IAAG,CAACtiC,EAAEsiC,GAAE,IAAI,IAAIzZ,EAAE7oB,EAAEwR,UAAU,GAAG,KAAa,KAARxR,EAAE0R,OAAY,OAAO1R,EAAEkG,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GACvK,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,GAAG,MAA3W,KAAK,EAAE,GAAG,OAAO2iB,EAAE,CAAC,IAAIC,EAAED,EAAE4G,cAAc1G,EAAEF,EAAEjX,cAAcoX,EAAEhpB,EAAE+P,UAAUmZ,EAAEF,EAAE0L,wBAAwB10B,EAAE6uB,cAAc7uB,EAAEiC,KAAK6mB,EAAEgH,GAAG9vB,EAAEiC,KAAK6mB,GAAGC,GAAGC,EAAEwb,oCAAoCtb,EAAE,MAAM,KAAK,EAAE,IAAID,EAAEjpB,EAAE+P,UAAUmH,cAAc,IAAI+R,EAAExe,SAASwe,EAAExf,YAAY,GAAG,IAAIwf,EAAExe,UAAUwe,EAAExE,iBAAiBwE,EAAE9e,YAAY8e,EAAExE,iBAAiB,MAAyC,QAAQ,MAAMzf,MAAMlF,EAAE,OAAQ,MAAMqpB,GAAGqZ,GAAExiC,EAAEA,EAAEyR,OAAO0X,GAAe,GAAG,QAAfppB,EAAEC,EAAEiS,SAAoB,CAAClS,EAAE0R,OAAOzR,EAAEyR,OAAO6wB,GAAEviC,EAAE,MAAMuiC,GAAEtiC,EAAEyR,OAAOoX,EAAE6Z,GAAGA,IAAG,EAwCvcoF,CAAG/nC,EAAEE,GAAG6jC,GAAG7jC,EAAEF,GAAGukB,GAAGiG,IAAI1S,KAAKyS,GAAGC,GAAGD,GAAG,KAAKvqB,EAAEmS,QAAQjS,EAAEmkC,GAAGnkC,EAAEF,EAAEyB,GAAGmR,KAAK4f,GAAE3sB,EAAEwP,GAAE1T,EAAEqjC,GAAGhtB,WAAWtW,OAAO1B,EAAEmS,QAAQjS,EAAsF,GAApFwlC,KAAKA,IAAG,EAAGC,GAAG3lC,EAAE4lC,GAAGnkC,GAAoB,KAAjBC,EAAE1B,EAAEyU,gBAAqB8oB,GAAG,MAjOmJ,SAAYv9B,GAAG,GAAG6T,IAAI,oBAAoBA,GAAGm0B,kBAAkB,IAAIn0B,GAAGm0B,kBAAkBp0B,GAAG5T,OAAE,EAAO,OAAuB,IAAhBA,EAAEmS,QAAQR,QAAY,MAAM1R,KAiOpRgoC,CAAG/nC,EAAE8P,WAAak2B,GAAGlmC,EAAE8S,MAAQ,OAAO7S,EAAE,IAAIuB,EAAExB,EAAEkoC,mBAAmBhoC,EAAE,EAAEA,EAAED,EAAEG,OAAOF,IAAWsB,GAAPC,EAAExB,EAAEC,IAAOyH,MAAM,CAAC61B,eAAe/7B,EAAEyD,MAAMw3B,OAAOj7B,EAAEi7B,SAAS,GAAGQ,GAAG,MAAMA,IAAG,EAAGl9B,EAAEm9B,GAAGA,GAAG,KAAKn9B,EAAE,KAAQ,EAAH4lC,KAAO,IAAI5lC,EAAEmG,KAAKygC,KAAsB,KAAO,GAAxBllC,EAAE1B,EAAEyU,eAAuBzU,IAAI8lC,GAAGD,MAAMA,GAAG,EAAEC,GAAG9lC,GAAG6lC,GAAG,EAAEnY,KAFxEya,CAAGnoC,EAAEC,EAAEC,EAAEsB,GAApC,QAA+CwjC,GAAGhtB,WAAWvW,EAAE4T,GAAE7T,EAAE,OAAO,KAG5b,SAASolC,KAAK,GAAG,OAAOjB,GAAG,CAAC,IAAI3lC,EAAEsV,GAAGswB,IAAI3lC,EAAE+kC,GAAGhtB,WAAW9X,EAAEmV,GAAE,IAAmC,GAA/B2vB,GAAGhtB,WAAW,KAAK3C,GAAE,GAAGrV,EAAE,GAAGA,EAAK,OAAO2lC,GAAG,IAAInkC,GAAE,MAAO,CAAmB,GAAlBxB,EAAE2lC,GAAGA,GAAG,KAAKC,GAAG,EAAK,KAAO,EAAFpT,IAAK,MAAMvtB,MAAMlF,EAAE,MAAM,IAAI0B,EAAE+wB,GAAO,IAALA,IAAG,EAAM+P,GAAEviC,EAAEmS,QAAQ,OAAOowB,IAAG,CAAC,IAAI7gC,EAAE6gC,GAAE5gC,EAAED,EAAEuQ,MAAM,GAAG,KAAa,GAARswB,GAAE5wB,OAAU,CAAC,IAAI9L,EAAEnE,EAAEqtB,UAAU,GAAG,OAAOlpB,EAAE,CAAC,IAAI,IAAIC,EAAE,EAAEA,EAAED,EAAEzF,OAAO0F,IAAI,CAAC,IAAIF,EAAEC,EAAEC,GAAG,IAAIy8B,GAAE38B,EAAE,OAAO28B,IAAG,CAAC,IAAIvxB,EAAEuxB,GAAE,OAAOvxB,EAAE7K,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAGy8B,GAAG,EAAE5xB,EAAEtP,GAAG,IAAIkxB,EAAE5hB,EAAEiB,MAAM,GAAG,OAAO2gB,EAAEA,EAAElhB,OAAOV,EAAEuxB,GAAE3P,OAAO,KAAK,OAAO2P,IAAG,CAAK,IAAI1P,GAAR7hB,EAAEuxB,IAAUrwB,QAAQ4gB,EAAE9hB,EAAEU,OAAa,GAANqxB,GAAG/xB,GAAMA,IACnfpL,EAAE,CAAC28B,GAAE,KAAK,MAAM,GAAG,OAAO1P,EAAE,CAACA,EAAEnhB,OAAOohB,EAAEyP,GAAE1P,EAAE,MAAM0P,GAAEzP,IAAI,IAAIhK,EAAEpnB,EAAE+P,UAAU,GAAG,OAAOqX,EAAE,CAAC,IAAIC,EAAED,EAAE7W,MAAM,GAAG,OAAO8W,EAAE,CAACD,EAAE7W,MAAM,KAAK,EAAE,CAAC,IAAI+W,EAAED,EAAE7W,QAAQ6W,EAAE7W,QAAQ,KAAK6W,EAAEC,QAAQ,OAAOD,IAAIwZ,GAAE7gC,GAAG,GAAG,KAAoB,KAAfA,EAAE8+B,eAAoB,OAAO7+B,EAAEA,EAAE+P,OAAOhQ,EAAE6gC,GAAE5gC,OAAO1B,EAAE,KAAK,OAAOsiC,IAAG,CAAK,GAAG,KAAa,MAApB7gC,EAAE6gC,IAAY5wB,OAAY,OAAOjQ,EAAEyE,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAGy8B,GAAG,EAAElhC,EAAEA,EAAEgQ,QAAQ,IAAIuX,EAAEvnB,EAAEwQ,QAAQ,GAAG,OAAO+W,EAAE,CAACA,EAAEvX,OAAOhQ,EAAEgQ,OAAO6wB,GAAEtZ,EAAE,MAAMhpB,EAAEsiC,GAAE7gC,EAAEgQ,QAAQ,IAAIyX,EAAEnpB,EAAEmS,QAAQ,IAAIowB,GAAEpZ,EAAE,OAAOoZ,IAAG,CAAK,IAAIrZ,GAARvnB,EAAE4gC,IAAUtwB,MAAM,GAAG,KAAoB,KAAftQ,EAAE6+B,eAAoB,OAClftX,EAAEA,EAAExX,OAAO/P,EAAE4gC,GAAErZ,OAAOjpB,EAAE,IAAI0B,EAAEwnB,EAAE,OAAOoZ,IAAG,CAAK,GAAG,KAAa,MAApB18B,EAAE08B,IAAY5wB,OAAY,IAAI,OAAO9L,EAAEM,KAAK,KAAK,EAAE,KAAK,GAAG,KAAK,GAAG08B,GAAG,EAAEh9B,IAAI,MAAM6jB,GAAI+Y,GAAE58B,EAAEA,EAAE6L,OAAOgY,GAAI,GAAG7jB,IAAIlE,EAAE,CAAC4gC,GAAE,KAAK,MAAMtiC,EAAE,IAAImpB,EAAEvjB,EAAEqM,QAAQ,GAAG,OAAOkX,EAAE,CAACA,EAAE1X,OAAO7L,EAAE6L,OAAO6wB,GAAEnZ,EAAE,MAAMnpB,EAAEsiC,GAAE18B,EAAE6L,QAAiB,GAAT8gB,GAAE/wB,EAAEisB,KAAQ7Z,IAAI,oBAAoBA,GAAGu0B,sBAAsB,IAAIv0B,GAAGu0B,sBAAsBx0B,GAAG5T,GAAG,MAAM0pB,IAAKloB,GAAE,EAAG,OAAOA,EAF5S,QAEsT6T,GAAEnV,EAAE8kC,GAAGhtB,WAAW/X,GAAG,OAAM,EAAG,SAASooC,GAAGroC,EAAEC,EAAEC,GAAyBF,EAAEuyB,GAAGvyB,EAAjBC,EAAEg9B,GAAGj9B,EAAfC,EAAEu8B,GAAGt8B,EAAED,GAAY,GAAY,GAAGA,EAAEwzB,KAAI,OAAOzzB,IAAIkV,GAAGlV,EAAE,EAAEC,GAAGimC,GAAGlmC,EAAEC,IACte,SAASwiC,GAAEziC,EAAEC,EAAEC,GAAG,GAAG,IAAIF,EAAEmG,IAAIkiC,GAAGroC,EAAEA,EAAEE,QAAQ,KAAK,OAAOD,GAAG,CAAC,GAAG,IAAIA,EAAEkG,IAAI,CAACkiC,GAAGpoC,EAAED,EAAEE,GAAG,MAAW,GAAG,IAAID,EAAEkG,IAAI,CAAC,IAAI3E,EAAEvB,EAAE+P,UAAU,GAAG,oBAAoB/P,EAAEiC,KAAKm7B,0BAA0B,oBAAoB77B,EAAE87B,oBAAoB,OAAOC,KAAKA,GAAGlV,IAAI7mB,IAAI,CAAuBvB,EAAEsyB,GAAGtyB,EAAjBD,EAAEo9B,GAAGn9B,EAAfD,EAAEw8B,GAAGt8B,EAAEF,GAAY,GAAY,GAAGA,EAAEyzB,KAAI,OAAOxzB,IAAIiV,GAAGjV,EAAE,EAAED,GAAGkmC,GAAGjmC,EAAED,IAAI,OAAOC,EAAEA,EAAEyR,QAC5U,SAASisB,GAAG39B,EAAEC,EAAEC,GAAG,IAAIsB,EAAExB,EAAE09B,UAAU,OAAOl8B,GAAGA,EAAE+U,OAAOtW,GAAGA,EAAEwzB,KAAIzzB,EAAE2U,aAAa3U,EAAE0U,eAAexU,EAAEs5B,KAAIx5B,IAAIklC,GAAEhlC,KAAKA,IAAI,IAAI6hC,IAAG,IAAIA,KAAM,UAAFmD,MAAeA,IAAG,IAAIpyB,KAAIoxB,GAAG6C,GAAG/mC,EAAE,GAAGqlC,IAAInlC,GAAGgmC,GAAGlmC,EAAEC,GAAG,SAASqoC,GAAGtoC,EAAEC,GAAG,IAAIA,IAAI,KAAY,EAAPD,EAAEsvB,MAAQrvB,EAAE,GAAGA,EAAEqU,GAAU,KAAQ,WAAfA,KAAK,MAAuBA,GAAG,WAAW,IAAIpU,EAAEuzB,KAAc,QAAVzzB,EAAEuxB,GAAGvxB,EAAEC,MAAciV,GAAGlV,EAAEC,EAAEC,GAAGgmC,GAAGlmC,EAAEE,IAAI,SAASmgC,GAAGrgC,GAAG,IAAIC,EAAED,EAAE6R,cAAc3R,EAAE,EAAE,OAAOD,IAAIC,EAAED,EAAEmvB,WAAWkZ,GAAGtoC,EAAEE,GAC/Y,SAAS2jC,GAAG7jC,EAAEC,GAAG,IAAIC,EAAE,EAAE,OAAOF,EAAEmG,KAAK,KAAK,GAAG,IAAI3E,EAAExB,EAAEgQ,UAAcvO,EAAEzB,EAAE6R,cAAc,OAAOpQ,IAAIvB,EAAEuB,EAAE2tB,WAAW,MAAM,KAAK,GAAG5tB,EAAExB,EAAEgQ,UAAU,MAAM,QAAQ,MAAM/K,MAAMlF,EAAE,MAAO,OAAOyB,GAAGA,EAAE+U,OAAOtW,GAAGqoC,GAAGtoC,EAAEE,GAQuK,SAASwmC,GAAG1mC,EAAEC,GAAG,OAAOqS,GAAGtS,EAAEC,GAC/Y,SAASsoC,GAAGvoC,EAAEC,EAAEC,EAAEsB,GAAGI,KAAKuE,IAAInG,EAAE4B,KAAKuc,IAAIje,EAAE0B,KAAKsQ,QAAQtQ,KAAKqQ,MAAMrQ,KAAK8P,OAAO9P,KAAKoO,UAAUpO,KAAKM,KAAKN,KAAKktB,YAAY,KAAKltB,KAAK2zB,MAAM,EAAE3zB,KAAKozB,IAAI,KAAKpzB,KAAKqtB,aAAahvB,EAAE2B,KAAK+uB,aAAa/uB,KAAKiQ,cAAcjQ,KAAK8vB,YAAY9vB,KAAK8tB,cAAc,KAAK9tB,KAAK0tB,KAAK9tB,EAAEI,KAAK4+B,aAAa5+B,KAAK+P,MAAM,EAAE/P,KAAKmtB,UAAU,KAAKntB,KAAK6uB,WAAW7uB,KAAKivB,MAAM,EAAEjvB,KAAK6P,UAAU,KAAK,SAASod,GAAG7uB,EAAEC,EAAEC,EAAEsB,GAAG,OAAO,IAAI+mC,GAAGvoC,EAAEC,EAAEC,EAAEsB,GAAG,SAAS48B,GAAGp+B,GAAiB,UAAdA,EAAEA,EAAEkB,aAAuBlB,EAAEwoC,kBAEnc,SAAShT,GAAGx1B,EAAEC,GAAG,IAAIC,EAAEF,EAAEyR,UACuB,OADb,OAAOvR,IAAGA,EAAE2uB,GAAG7uB,EAAEmG,IAAIlG,EAAED,EAAEme,IAAIne,EAAEsvB,OAAQR,YAAY9uB,EAAE8uB,YAAY5uB,EAAEgC,KAAKlC,EAAEkC,KAAKhC,EAAE8P,UAAUhQ,EAAEgQ,UAAU9P,EAAEuR,UAAUzR,EAAEA,EAAEyR,UAAUvR,IAAIA,EAAE+uB,aAAahvB,EAAEC,EAAEgC,KAAKlC,EAAEkC,KAAKhC,EAAEyR,MAAM,EAAEzR,EAAEsgC,aAAa,EAAEtgC,EAAE6uB,UAAU,MAAM7uB,EAAEyR,MAAc,SAAR3R,EAAE2R,MAAezR,EAAEuwB,WAAWzwB,EAAEywB,WAAWvwB,EAAE2wB,MAAM7wB,EAAE6wB,MAAM3wB,EAAE+R,MAAMjS,EAAEiS,MAAM/R,EAAEwvB,cAAc1vB,EAAE0vB,cAAcxvB,EAAE2R,cAAc7R,EAAE6R,cAAc3R,EAAEwxB,YAAY1xB,EAAE0xB,YAAYzxB,EAAED,EAAE2wB,aAAazwB,EAAEywB,aAAa,OAAO1wB,EAAE,KAAK,CAAC4wB,MAAM5wB,EAAE4wB,MAAMD,aAAa3wB,EAAE2wB,cAC/e1wB,EAAEgS,QAAQlS,EAAEkS,QAAQhS,EAAEq1B,MAAMv1B,EAAEu1B,MAAMr1B,EAAE80B,IAAIh1B,EAAEg1B,IAAW90B,EACvD,SAASw1B,GAAG11B,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,GAAG,IAAIC,EAAE,EAAM,GAAJH,EAAExB,EAAK,oBAAoBA,EAAEo+B,GAAGp+B,KAAK2B,EAAE,QAAQ,GAAG,kBAAkB3B,EAAE2B,EAAE,OAAO3B,EAAE,OAAOA,GAAG,KAAK+D,EAAG,OAAO8xB,GAAG31B,EAAEoJ,SAAS7H,EAAEC,EAAEzB,GAAG,KAAK+D,EAAGrC,EAAE,EAAEF,GAAG,EAAE,MAAM,KAAKwC,EAAG,OAAOjE,EAAE6uB,GAAG,GAAG3uB,EAAED,EAAI,EAAFwB,IAAOqtB,YAAY7qB,EAAGjE,EAAE6wB,MAAMnvB,EAAE1B,EAAE,KAAKqE,EAAG,OAAOrE,EAAE6uB,GAAG,GAAG3uB,EAAED,EAAEwB,IAAKqtB,YAAYzqB,EAAGrE,EAAE6wB,MAAMnvB,EAAE1B,EAAE,KAAKsE,EAAG,OAAOtE,EAAE6uB,GAAG,GAAG3uB,EAAED,EAAEwB,IAAKqtB,YAAYxqB,EAAGtE,EAAE6wB,MAAMnvB,EAAE1B,EAAE,KAAKyE,EAAG,OAAOs7B,GAAG7/B,EAAEuB,EAAEC,EAAEzB,GAAG,QAAQ,GAAG,kBAAkBD,GAAG,OAAOA,EAAE,OAAOA,EAAEsG,UAAU,KAAKpC,EAAGvC,EAAE,GAAG,MAAM3B,EAAE,KAAKmE,EAAGxC,EAAE,EAAE,MAAM3B,EAAE,KAAKoE,EAAGzC,EAAE,GACpf,MAAM3B,EAAE,KAAKuE,EAAG5C,EAAE,GAAG,MAAM3B,EAAE,KAAKwE,EAAG7C,EAAE,GAAGH,EAAE,KAAK,MAAMxB,EAAE,MAAMiF,MAAMlF,EAAE,IAAI,MAAMC,EAAEA,SAASA,EAAE,KAAuD,OAAjDC,EAAE4uB,GAAGltB,EAAEzB,EAAED,EAAEwB,IAAKqtB,YAAY9uB,EAAEC,EAAEiC,KAAKV,EAAEvB,EAAE4wB,MAAMnvB,EAASzB,EAAE,SAAS41B,GAAG71B,EAAEC,EAAEC,EAAEsB,GAA2B,OAAxBxB,EAAE6uB,GAAG,EAAE7uB,EAAEwB,EAAEvB,IAAK4wB,MAAM3wB,EAASF,EAAE,SAAS+/B,GAAG//B,EAAEC,EAAEC,EAAEsB,GAAuE,OAApExB,EAAE6uB,GAAG,GAAG7uB,EAAEwB,EAAEvB,IAAK6uB,YAAYrqB,EAAGzE,EAAE6wB,MAAM3wB,EAAEF,EAAEgQ,UAAU,CAACi0B,UAAS,GAAWjkC,EAAE,SAASy1B,GAAGz1B,EAAEC,EAAEC,GAA8B,OAA3BF,EAAE6uB,GAAG,EAAE7uB,EAAE,KAAKC,IAAK4wB,MAAM3wB,EAASF,EAC3W,SAAS41B,GAAG51B,EAAEC,EAAEC,GAA8J,OAA3JD,EAAE4uB,GAAG,EAAE,OAAO7uB,EAAEsJ,SAAStJ,EAAEsJ,SAAS,GAAGtJ,EAAEme,IAAIle,IAAK4wB,MAAM3wB,EAAED,EAAE+P,UAAU,CAACmH,cAAcnX,EAAEmX,cAAcsxB,gBAAgB,KAAK9S,eAAe31B,EAAE21B,gBAAuB11B,EACrL,SAASyoC,GAAG1oC,EAAEC,EAAEC,EAAEsB,EAAEC,GAAGG,KAAKuE,IAAIlG,EAAE2B,KAAKuV,cAAcnX,EAAE4B,KAAKwlC,aAAaxlC,KAAK87B,UAAU97B,KAAKuQ,QAAQvQ,KAAK6mC,gBAAgB,KAAK7mC,KAAK2lC,eAAe,EAAE3lC,KAAKukC,aAAavkC,KAAK09B,eAAe19B,KAAKovB,QAAQ,KAAKpvB,KAAK2kC,iBAAiB,EAAE3kC,KAAKuT,WAAWF,GAAG,GAAGrT,KAAKwkC,gBAAgBnxB,IAAI,GAAGrT,KAAKgT,eAAehT,KAAKylC,cAAczlC,KAAKimC,iBAAiBjmC,KAAKykC,aAAazkC,KAAK+S,YAAY/S,KAAK8S,eAAe9S,KAAK6S,aAAa,EAAE7S,KAAKiT,cAAcI,GAAG,GAAGrT,KAAK26B,iBAAiB/6B,EAAEI,KAAKsmC,mBAAmBzmC,EAAEG,KAAK+mC,gCAC/e,KAAK,SAASC,GAAG5oC,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,EAAEkE,EAAEC,GAAgN,OAA7M9F,EAAE,IAAI0oC,GAAG1oC,EAAEC,EAAEC,EAAE2F,EAAEC,GAAG,IAAI7F,GAAGA,EAAE,GAAE,IAAKyB,IAAIzB,GAAG,IAAIA,EAAE,EAAEyB,EAAEmtB,GAAG,EAAE,KAAK,KAAK5uB,GAAGD,EAAEmS,QAAQzQ,EAAEA,EAAEsO,UAAUhQ,EAAE0B,EAAEmQ,cAAc,CAACgU,QAAQrkB,EAAE0V,aAAahX,EAAE2oC,MAAM,KAAKlK,YAAY,KAAKmK,0BAA0B,MAAMrX,GAAG/vB,GAAU1B,EAAE,SAAS+oC,GAAG/oC,EAAEC,EAAEC,GAAG,IAAIsB,EAAE,EAAErB,UAAUC,aAAQ,IAASD,UAAU,GAAGA,UAAU,GAAG,KAAK,MAAM,CAACmG,SAASxC,EAAGqa,IAAI,MAAM3c,EAAE,KAAK,GAAGA,EAAE8H,SAAStJ,EAAEmX,cAAclX,EAAE01B,eAAez1B,GACla,SAAS8oC,GAAGhpC,GAAG,IAAIA,EAAE,OAAOqsB,GAAuBrsB,EAAE,CAAC,GAAGwR,GAA1BxR,EAAEA,EAAEuzB,mBAA8BvzB,GAAG,IAAIA,EAAEmG,IAAI,MAAMlB,MAAMlF,EAAE,MAAM,IAAIE,EAAED,EAAE,EAAE,CAAC,OAAOC,EAAEkG,KAAK,KAAK,EAAElG,EAAEA,EAAE+P,UAAUghB,QAAQ,MAAMhxB,EAAE,KAAK,EAAE,GAAG6sB,GAAG5sB,EAAEiC,MAAM,CAACjC,EAAEA,EAAE+P,UAAUod,0CAA0C,MAAMptB,GAAGC,EAAEA,EAAEyR,aAAa,OAAOzR,GAAG,MAAMgF,MAAMlF,EAAE,MAAO,GAAG,IAAIC,EAAEmG,IAAI,CAAC,IAAIjG,EAAEF,EAAEkC,KAAK,GAAG2qB,GAAG3sB,GAAG,OAAO+sB,GAAGjtB,EAAEE,EAAED,GAAG,OAAOA,EACnW,SAASgpC,GAAGjpC,EAAEC,EAAEC,EAAEsB,EAAEC,EAAEC,EAAEC,EAAEkE,EAAEC,GAAwK,OAArK9F,EAAE4oC,GAAG1oC,EAAEsB,GAAE,EAAGxB,EAAEyB,EAAEC,EAAEC,EAAEkE,EAAEC,IAAKkrB,QAAQgY,GAAG,MAAM9oC,EAAEF,EAAEmS,SAAsBzQ,EAAEwwB,GAAhB1wB,EAAEiyB,KAAIhyB,EAAEiyB,GAAGxzB,KAAeoyB,cAAS,IAASryB,GAAG,OAAOA,EAAEA,EAAE,KAAKsyB,GAAGryB,EAAEwB,EAAED,GAAGzB,EAAEmS,QAAQ0e,MAAMpvB,EAAEyT,GAAGlV,EAAEyB,EAAED,GAAG0kC,GAAGlmC,EAAEwB,GAAUxB,EAAE,SAASkpC,GAAGlpC,EAAEC,EAAEC,EAAEsB,GAAG,IAAIC,EAAExB,EAAEkS,QAAQzQ,EAAE+xB,KAAI9xB,EAAE+xB,GAAGjyB,GAAsL,OAAnLvB,EAAE8oC,GAAG9oC,GAAG,OAAOD,EAAE+wB,QAAQ/wB,EAAE+wB,QAAQ9wB,EAAED,EAAEq/B,eAAep/B,GAAED,EAAEiyB,GAAGxwB,EAAEC,IAAK0wB,QAAQ,CAACxM,QAAQ7lB,GAAuB,QAApBwB,OAAE,IAASA,EAAE,KAAKA,KAAavB,EAAEqyB,SAAS9wB,GAAe,QAAZxB,EAAEuyB,GAAG9wB,EAAExB,EAAE0B,MAAcgyB,GAAG3zB,EAAEyB,EAAEE,EAAED,GAAG+wB,GAAGzyB,EAAEyB,EAAEE,IAAWA,EAC1b,SAASwnC,GAAGnpC,GAAe,OAAZA,EAAEA,EAAEmS,SAAcF,OAAyBjS,EAAEiS,MAAM9L,IAAoDnG,EAAEiS,MAAMjC,WAAhF,KAA2F,SAASo5B,GAAGppC,EAAEC,GAAqB,GAAG,QAArBD,EAAEA,EAAE6R,gBAA2B,OAAO7R,EAAE8R,WAAW,CAAC,IAAI5R,EAAEF,EAAEovB,UAAUpvB,EAAEovB,UAAU,IAAIlvB,GAAGA,EAAED,EAAEC,EAAED,GAAG,SAASopC,GAAGrpC,EAAEC,GAAGmpC,GAAGppC,EAAEC,IAAID,EAAEA,EAAEyR,YAAY23B,GAAGppC,EAAEC,GAnB3S0kC,GAAG,SAAS3kC,EAAEC,EAAEC,GAAG,GAAG,OAAOF,EAAE,GAAGA,EAAE0vB,gBAAgBzvB,EAAEgvB,cAAc1C,GAAGpa,QAAQ2e,IAAG,MAAO,CAAC,GAAG,KAAK9wB,EAAE6wB,MAAM3wB,IAAI,KAAa,IAARD,EAAE0R,OAAW,OAAOmf,IAAG,EAzE1I,SAAY9wB,EAAEC,EAAEC,GAAG,OAAOD,EAAEkG,KAAK,KAAK,EAAEk5B,GAAGp/B,GAAG2vB,KAAK,MAAM,KAAK,EAAE6G,GAAGx2B,GAAG,MAAM,KAAK,EAAE4sB,GAAG5sB,EAAEiC,OAAOirB,GAAGltB,GAAG,MAAM,KAAK,EAAEq2B,GAAGr2B,EAAEA,EAAE+P,UAAUmH,eAAe,MAAM,KAAK,GAAG,IAAI3V,EAAEvB,EAAEiC,KAAKqE,SAAS9E,EAAExB,EAAEyvB,cAAc/nB,MAAMykB,GAAE6D,GAAGzuB,EAAE+uB,eAAe/uB,EAAE+uB,cAAc9uB,EAAE,MAAM,KAAK,GAAqB,GAAG,QAArBD,EAAEvB,EAAE4R,eAA2B,OAAG,OAAOrQ,EAAEsQ,YAAkBsa,GAAEuK,GAAY,EAAVA,GAAExkB,SAAWlS,EAAE0R,OAAO,IAAI,MAAQ,KAAKzR,EAAED,EAAEgS,MAAMwe,YAAmBoP,GAAG7/B,EAAEC,EAAEC,IAAGksB,GAAEuK,GAAY,EAAVA,GAAExkB,SAA8B,QAAnBnS,EAAEk+B,GAAGl+B,EAAEC,EAAEC,IAAmBF,EAAEkS,QAAQ,MAAKka,GAAEuK,GAAY,EAAVA,GAAExkB,SAAW,MAAM,KAAK,GAC7d,GADge3Q,EAAE,KAAKtB,EACrfD,EAAEwwB,YAAe,KAAa,IAARzwB,EAAE2R,OAAW,CAAC,GAAGnQ,EAAE,OAAOy/B,GAAGjhC,EAAEC,EAAEC,GAAGD,EAAE0R,OAAO,IAAgG,GAA1E,QAAlBlQ,EAAExB,EAAE4R,iBAAyBpQ,EAAEm/B,UAAU,KAAKn/B,EAAEs/B,KAAK,KAAKt/B,EAAEi4B,WAAW,MAAMtN,GAAEuK,GAAEA,GAAExkB,SAAY3Q,EAAE,MAAW,OAAO,KAAK,KAAK,GAAG,KAAK,GAAG,OAAOvB,EAAE4wB,MAAM,EAAE2N,GAAGx+B,EAAEC,EAAEC,GAAG,OAAOg+B,GAAGl+B,EAAEC,EAAEC,GAwE3GopC,CAAGtpC,EAAEC,EAAEC,GAAG4wB,GAAG,KAAa,OAAR9wB,EAAE2R,YAAyBmf,IAAG,EAAGpC,IAAG,KAAa,QAARzuB,EAAE0R,QAAgB0c,GAAGpuB,EAAE6tB,GAAG7tB,EAAEs1B,OAAiB,OAAVt1B,EAAE4wB,MAAM,EAAS5wB,EAAEkG,KAAK,KAAK,EAAE,IAAI3E,EAAEvB,EAAEiC,KAAK88B,GAAGh/B,EAAEC,GAAGD,EAAEC,EAAEgvB,aAAa,IAAIxtB,EAAEgrB,GAAGxsB,EAAEqsB,GAAEna,SAASue,GAAGzwB,EAAEC,GAAGuB,EAAEq2B,GAAG,KAAK73B,EAAEuB,EAAExB,EAAEyB,EAAEvB,GAAG,IAAIwB,EAAEy2B,KACvI,OAD4Il4B,EAAE0R,OAAO,EAAE,kBAAkBlQ,GAAG,OAAOA,GAAG,oBAAoBA,EAAE2E,aAAQ,IAAS3E,EAAE6E,UAAUrG,EAAEkG,IAAI,EAAElG,EAAE4R,cAAc,KAAK5R,EAAEyxB,YAC1e,KAAK7E,GAAGrrB,IAAIE,GAAE,EAAGyrB,GAAGltB,IAAIyB,GAAE,EAAGzB,EAAE4R,cAAc,OAAOpQ,EAAE0yB,YAAO,IAAS1yB,EAAE0yB,MAAM1yB,EAAE0yB,MAAM,KAAK1C,GAAGxxB,GAAGwB,EAAE2yB,QAAQf,GAAGpzB,EAAE+P,UAAUvO,EAAEA,EAAE8xB,gBAAgBtzB,EAAEu0B,GAAGv0B,EAAEuB,EAAExB,EAAEE,GAAGD,EAAEm/B,GAAG,KAAKn/B,EAAEuB,GAAE,EAAGE,EAAExB,KAAKD,EAAEkG,IAAI,EAAEuoB,IAAGhtB,GAAG4sB,GAAGruB,GAAG+9B,GAAG,KAAK/9B,EAAEwB,EAAEvB,GAAGD,EAAEA,EAAEgS,OAAchS,EAAE,KAAK,GAAGuB,EAAEvB,EAAE6uB,YAAY9uB,EAAE,CAAqF,OAApFg/B,GAAGh/B,EAAEC,GAAGD,EAAEC,EAAEgvB,aAAuBztB,GAAVC,EAAED,EAAEiF,OAAUjF,EAAEgF,UAAUvG,EAAEiC,KAAKV,EAAEC,EAAExB,EAAEkG,IAQtU,SAAYnG,GAAG,GAAG,oBAAoBA,EAAE,OAAOo+B,GAAGp+B,GAAG,EAAE,EAAE,QAAG,IAASA,GAAG,OAAOA,EAAE,CAAc,IAAbA,EAAEA,EAAEsG,YAAgBlC,EAAG,OAAO,GAAG,GAAGpE,IAAIuE,EAAG,OAAO,GAAG,OAAO,EAR4LglC,CAAG/nC,GAAGxB,EAAE+vB,GAAGvuB,EAAExB,GAAUyB,GAAG,KAAK,EAAExB,EAAEs+B,GAAG,KAAKt+B,EAAEuB,EAAExB,EAAEE,GAAG,MAAMF,EAAE,KAAK,EAAEC,EAAE8+B,GAAG,KAAK9+B,EAAEuB,EAAExB,EAAEE,GAAG,MAAMF,EAAE,KAAK,GAAGC,EAAEg+B,GAAG,KAAKh+B,EAAEuB,EAAExB,EAAEE,GAAG,MAAMF,EAAE,KAAK,GAAGC,EAAEk+B,GAAG,KAAKl+B,EAAEuB,EAAEuuB,GAAGvuB,EAAEU,KAAKlC,GAAGE,GAAG,MAAMF,EAAE,MAAMiF,MAAMlF,EAAE,IACvgByB,EAAE,KAAM,OAAOvB,EAAE,KAAK,EAAE,OAAOuB,EAAEvB,EAAEiC,KAAKT,EAAExB,EAAEgvB,aAA2CsP,GAAGv+B,EAAEC,EAAEuB,EAArCC,EAAExB,EAAE6uB,cAActtB,EAAEC,EAAEsuB,GAAGvuB,EAAEC,GAAcvB,GAAG,KAAK,EAAE,OAAOsB,EAAEvB,EAAEiC,KAAKT,EAAExB,EAAEgvB,aAA2C8P,GAAG/+B,EAAEC,EAAEuB,EAArCC,EAAExB,EAAE6uB,cAActtB,EAAEC,EAAEsuB,GAAGvuB,EAAEC,GAAcvB,GAAG,KAAK,EAAEF,EAAE,CAAO,GAANq/B,GAAGp/B,GAAM,OAAOD,EAAE,MAAMiF,MAAMlF,EAAE,MAAMyB,EAAEvB,EAAEgvB,aAA+BxtB,GAAlBC,EAAEzB,EAAE4R,eAAkBgU,QAAQoM,GAAGjyB,EAAEC,GAAG0yB,GAAG1yB,EAAEuB,EAAE,KAAKtB,GAAG,IAAIyB,EAAE1B,EAAE4R,cAA0B,GAAZrQ,EAAEG,EAAEkkB,QAAWnkB,EAAEwV,aAAL,CAAkB,GAAGxV,EAAE,CAACmkB,QAAQrkB,EAAE0V,cAAa,EAAG2xB,MAAMlnC,EAAEknC,MAAMC,0BAA0BnnC,EAAEmnC,0BAA0BnK,YAAYh9B,EAAEg9B,aAAa1+B,EAAEyxB,YAAYC,UAChfjwB,EAAEzB,EAAE4R,cAAcnQ,EAAU,IAARzB,EAAE0R,MAAU,CAAuB1R,EAAEs/B,GAAGv/B,EAAEC,EAAEuB,EAAEtB,EAAjCuB,EAAE+6B,GAAGv3B,MAAMlF,EAAE,MAAME,IAAmB,MAAMD,EAAO,GAAGwB,IAAIC,EAAE,CAAuBxB,EAAEs/B,GAAGv/B,EAAEC,EAAEuB,EAAEtB,EAAjCuB,EAAE+6B,GAAGv3B,MAAMlF,EAAE,MAAME,IAAmB,MAAMD,EAAO,IAAIyuB,GAAGjD,GAAGvrB,EAAE+P,UAAUmH,cAAchN,YAAYqkB,GAAGvuB,EAAEyuB,IAAE,EAAGC,GAAG,KAAKzuB,EAAE81B,GAAG/1B,EAAE,KAAKuB,EAAEtB,GAAGD,EAAEgS,MAAM/R,EAAEA,GAAGA,EAAEyR,OAAe,EAATzR,EAAEyR,MAAS,KAAKzR,EAAEA,EAAEgS,YAAY,CAAM,GAAL0d,KAAQpuB,IAAIC,EAAE,CAACxB,EAAEi+B,GAAGl+B,EAAEC,EAAEC,GAAG,MAAMF,EAAEg+B,GAAGh+B,EAAEC,EAAEuB,EAAEtB,GAAGD,EAAEA,EAAEgS,MAAM,OAAOhS,EAAE,KAAK,EAAE,OAAOw2B,GAAGx2B,GAAG,OAAOD,GAAGuvB,GAAGtvB,GAAGuB,EAAEvB,EAAEiC,KAAKT,EAAExB,EAAEgvB,aAAavtB,EAAE,OAAO1B,EAAEA,EAAE0vB,cAAc,KAAK/tB,EAAEF,EAAE6H,SAASmhB,GAAGjpB,EAAEC,GAAGE,EAAE,KAAK,OAAOD,GAAG+oB,GAAGjpB,EAAEE,KAAKzB,EAAE0R,OAAO,IACnfmtB,GAAG9+B,EAAEC,GAAG+9B,GAAGh+B,EAAEC,EAAE0B,EAAEzB,GAAGD,EAAEgS,MAAM,KAAK,EAAE,OAAO,OAAOjS,GAAGuvB,GAAGtvB,GAAG,KAAK,KAAK,GAAG,OAAO4/B,GAAG7/B,EAAEC,EAAEC,GAAG,KAAK,EAAE,OAAOo2B,GAAGr2B,EAAEA,EAAE+P,UAAUmH,eAAe3V,EAAEvB,EAAEgvB,aAAa,OAAOjvB,EAAEC,EAAEgS,MAAM8jB,GAAG91B,EAAE,KAAKuB,EAAEtB,GAAG89B,GAAGh+B,EAAEC,EAAEuB,EAAEtB,GAAGD,EAAEgS,MAAM,KAAK,GAAG,OAAOzQ,EAAEvB,EAAEiC,KAAKT,EAAExB,EAAEgvB,aAA2CgP,GAAGj+B,EAAEC,EAAEuB,EAArCC,EAAExB,EAAE6uB,cAActtB,EAAEC,EAAEsuB,GAAGvuB,EAAEC,GAAcvB,GAAG,KAAK,EAAE,OAAO89B,GAAGh+B,EAAEC,EAAEA,EAAEgvB,aAAa/uB,GAAGD,EAAEgS,MAAM,KAAK,EAAmD,KAAK,GAAG,OAAO+rB,GAAGh+B,EAAEC,EAAEA,EAAEgvB,aAAa3lB,SAASpJ,GAAGD,EAAEgS,MAAM,KAAK,GAAGjS,EAAE,CACxZ,GADyZwB,EAAEvB,EAAEiC,KAAKqE,SAAS9E,EAAExB,EAAEgvB,aAAavtB,EAAEzB,EAAEyvB,cAClf/tB,EAAEF,EAAEkG,MAAMykB,GAAE6D,GAAGzuB,EAAE+uB,eAAe/uB,EAAE+uB,cAAc5uB,EAAK,OAAOD,EAAE,GAAG6hB,GAAG7hB,EAAEiG,MAAMhG,IAAI,GAAGD,EAAE4H,WAAW7H,EAAE6H,WAAWijB,GAAGpa,QAAQ,CAAClS,EAAEi+B,GAAGl+B,EAAEC,EAAEC,GAAG,MAAMF,QAAQ,IAAc,QAAV0B,EAAEzB,EAAEgS,SAAiBvQ,EAAEgQ,OAAOzR,GAAG,OAAOyB,GAAG,CAAC,IAAImE,EAAEnE,EAAEivB,aAAa,GAAG,OAAO9qB,EAAE,CAAClE,EAAED,EAAEuQ,MAAM,IAAI,IAAInM,EAAED,EAAE+qB,aAAa,OAAO9qB,GAAG,CAAC,GAAGA,EAAEkrB,UAAUxvB,EAAE,CAAC,GAAG,IAAIE,EAAEyE,IAAI,EAACL,EAAEosB,IAAI,EAAEhyB,GAAGA,IAAKiG,IAAI,EAAE,IAAIP,EAAElE,EAAEgwB,YAAY,GAAG,OAAO9rB,EAAE,CAAY,IAAIoL,GAAfpL,EAAEA,EAAEksB,QAAeC,QAAQ,OAAO/gB,EAAElL,EAAEorB,KAAKprB,GAAGA,EAAEorB,KAAKlgB,EAAEkgB,KAAKlgB,EAAEkgB,KAAKprB,GAAGF,EAAEmsB,QAAQjsB,GAAGpE,EAAEmvB,OAAO3wB,EAAgB,QAAd4F,EAAEpE,EAAE+P,aAAqB3L,EAAE+qB,OAAO3wB,GAAGswB,GAAG9uB,EAAEgQ,OAClfxR,EAAED,GAAG4F,EAAEgrB,OAAO3wB,EAAE,MAAM4F,EAAEA,EAAEorB,WAAW,GAAG,KAAKxvB,EAAEyE,IAAIxE,EAAED,EAAEQ,OAAOjC,EAAEiC,KAAK,KAAKR,EAAEuQ,WAAW,GAAG,KAAKvQ,EAAEyE,IAAI,CAAY,GAAG,QAAdxE,EAAED,EAAEgQ,QAAmB,MAAMzM,MAAMlF,EAAE,MAAM4B,EAAEkvB,OAAO3wB,EAAgB,QAAd2F,EAAElE,EAAE8P,aAAqB5L,EAAEgrB,OAAO3wB,GAAGswB,GAAG7uB,EAAEzB,EAAED,GAAG0B,EAAED,EAAEwQ,aAAavQ,EAAED,EAAEuQ,MAAM,GAAG,OAAOtQ,EAAEA,EAAE+P,OAAOhQ,OAAO,IAAIC,EAAED,EAAE,OAAOC,GAAG,CAAC,GAAGA,IAAI1B,EAAE,CAAC0B,EAAE,KAAK,MAAkB,GAAG,QAAfD,EAAEC,EAAEuQ,SAAoB,CAACxQ,EAAEgQ,OAAO/P,EAAE+P,OAAO/P,EAAED,EAAE,MAAMC,EAAEA,EAAE+P,OAAOhQ,EAAEC,EAAEq8B,GAAGh+B,EAAEC,EAAEwB,EAAE6H,SAASpJ,GAAGD,EAAEA,EAAEgS,MAAM,OAAOhS,EAAE,KAAK,EAAE,OAAOwB,EAAExB,EAAEiC,KAAKV,EAAEvB,EAAEgvB,aAAa3lB,SAASonB,GAAGzwB,EAAEC,GAAWsB,EAAEA,EAAVC,EAAEsvB,GAAGtvB,IAAUxB,EAAE0R,OAAO,EAAEqsB,GAAGh+B,EAAEC,EAAEuB,EAAEtB,GACpfD,EAAEgS,MAAM,KAAK,GAAG,OAAgBxQ,EAAEsuB,GAAXvuB,EAAEvB,EAAEiC,KAAYjC,EAAEgvB,cAA6BkP,GAAGn+B,EAAEC,EAAEuB,EAAtBC,EAAEsuB,GAAGvuB,EAAEU,KAAKT,GAAcvB,GAAG,KAAK,GAAG,OAAOo+B,GAAGt+B,EAAEC,EAAEA,EAAEiC,KAAKjC,EAAEgvB,aAAa/uB,GAAG,KAAK,GAAG,OAAOsB,EAAEvB,EAAEiC,KAAKT,EAAExB,EAAEgvB,aAAaxtB,EAAExB,EAAE6uB,cAActtB,EAAEC,EAAEsuB,GAAGvuB,EAAEC,GAAGu9B,GAAGh/B,EAAEC,GAAGA,EAAEkG,IAAI,EAAE0mB,GAAGrrB,IAAIxB,GAAE,EAAGmtB,GAAGltB,IAAID,GAAE,EAAG0wB,GAAGzwB,EAAEC,GAAG+zB,GAAGh0B,EAAEuB,EAAEC,GAAG+yB,GAAGv0B,EAAEuB,EAAEC,EAAEvB,GAAGk/B,GAAG,KAAKn/B,EAAEuB,GAAE,EAAGxB,EAAEE,GAAG,KAAK,GAAG,OAAO+gC,GAAGjhC,EAAEC,EAAEC,GAAG,KAAK,GAAG,OAAOs+B,GAAGx+B,EAAEC,EAAEC,GAAG,MAAM+E,MAAMlF,EAAE,IAAIE,EAAEkG,OAYlC,IAAIqjC,GAAG,oBAAoBC,YAAYA,YAAY,SAASzpC,GAAG68B,QAAQC,MAAM98B,IAAI,SAAS0pC,GAAG1pC,GAAG4B,KAAK+nC,cAAc3pC,EAChI,SAAS4pC,GAAG5pC,GAAG4B,KAAK+nC,cAAc3pC,EAC3J,SAAS6pC,GAAG7pC,GAAG,SAASA,GAAG,IAAIA,EAAE0K,UAAU,IAAI1K,EAAE0K,UAAU,KAAK1K,EAAE0K,UAAU,SAASo/B,GAAG9pC,GAAG,SAASA,GAAG,IAAIA,EAAE0K,UAAU,IAAI1K,EAAE0K,UAAU,KAAK1K,EAAE0K,WAAW,IAAI1K,EAAE0K,UAAU,iCAAiC1K,EAAE2K,YAAY,SAASo/B,MAEna,SAASC,GAAGhqC,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,IAAIC,EAAExB,EAAEkjC,oBAAoB,GAAG1hC,EAAE,CAAC,IAAIC,EAAED,EAAE,GAAG,oBAAoBD,EAAE,CAAC,IAAIoE,EAAEpE,EAAEA,EAAE,WAAW,IAAIzB,EAAEmpC,GAAGxnC,GAAGkE,EAAE5C,KAAKjD,IAAIkpC,GAAGjpC,EAAE0B,EAAE3B,EAAEyB,QAAQE,EADxJ,SAAY3B,EAAEC,EAAEC,EAAEsB,EAAEC,GAAG,GAAGA,EAAE,CAAC,GAAG,oBAAoBD,EAAE,CAAC,IAAIE,EAAEF,EAAEA,EAAE,WAAW,IAAIxB,EAAEmpC,GAAGxnC,GAAGD,EAAEuB,KAAKjD,IAAI,IAAI2B,EAAEsnC,GAAGhpC,EAAEuB,EAAExB,EAAE,EAAE,MAAK,EAAG,EAAG,GAAG+pC,IAAmF,OAA/E/pC,EAAEojC,oBAAoBzhC,EAAE3B,EAAEspB,IAAI3nB,EAAEwQ,QAAQuW,GAAG,IAAI1oB,EAAE0K,SAAS1K,EAAE0P,WAAW1P,GAAGynC,KAAY9lC,EAAE,KAAKF,EAAEzB,EAAEyK,WAAWzK,EAAEoK,YAAY3I,GAAG,GAAG,oBAAoBD,EAAE,CAAC,IAAIqE,EAAErE,EAAEA,EAAE,WAAW,IAAIxB,EAAEmpC,GAAGrjC,GAAGD,EAAE5C,KAAKjD,IAAI,IAAI8F,EAAE8iC,GAAG5oC,EAAE,GAAE,EAAG,KAAK,GAAK,EAAG,EAAG,GAAG+pC,IAA0G,OAAtG/pC,EAAEojC,oBAAoBt9B,EAAE9F,EAAEspB,IAAIxjB,EAAEqM,QAAQuW,GAAG,IAAI1oB,EAAE0K,SAAS1K,EAAE0P,WAAW1P,GAAGynC,IAAG,WAAWyB,GAAGjpC,EAAE6F,EAAE5F,EAAEsB,MAAYsE,EACnUmkC,CAAG/pC,EAAED,EAAED,EAAEyB,EAAED,GAAG,OAAO2nC,GAAGxnC,GAHlLioC,GAAG1oC,UAAUkF,OAAOsjC,GAAGxoC,UAAUkF,OAAO,SAASpG,GAAG,IAAIC,EAAE2B,KAAK+nC,cAAc,GAAG,OAAO1pC,EAAE,MAAMgF,MAAMlF,EAAE,MAAMmpC,GAAGlpC,EAAEC,EAAE,KAAK,OAAO2pC,GAAG1oC,UAAUgpC,QAAQR,GAAGxoC,UAAUgpC,QAAQ,WAAW,IAAIlqC,EAAE4B,KAAK+nC,cAAc,GAAG,OAAO3pC,EAAE,CAAC4B,KAAK+nC,cAAc,KAAK,IAAI1pC,EAAED,EAAEmX,cAAcswB,IAAG,WAAWyB,GAAG,KAAKlpC,EAAE,KAAK,SAAQC,EAAEqpB,IAAI,OACpTsgB,GAAG1oC,UAAUipC,2BAA2B,SAASnqC,GAAG,GAAGA,EAAE,CAAC,IAAIC,EAAEyV,KAAK1V,EAAE,CAAC2W,UAAU,KAAKpH,OAAOvP,EAAEiX,SAAShX,GAAG,IAAI,IAAIC,EAAE,EAAEA,EAAEkW,GAAGhW,QAAQ,IAAIH,GAAGA,EAAEmW,GAAGlW,GAAG+W,SAAS/W,KAAKkW,GAAGg0B,OAAOlqC,EAAE,EAAEF,GAAG,IAAIE,GAAG6W,GAAG/W,KAERuV,GAAG,SAASvV,GAAG,OAAOA,EAAEmG,KAAK,KAAK,EAAE,IAAIlG,EAAED,EAAEgQ,UAAU,GAAG/P,EAAEkS,QAAQN,cAAcqF,aAAa,CAAC,IAAIhX,EAAEqU,GAAGtU,EAAEwU,cAAc,IAAIvU,IAAIkV,GAAGnV,EAAI,EAAFC,GAAKgmC,GAAGjmC,EAAE6S,MAAK,KAAO,EAAF0f,MAAOwP,GAAGlvB,KAAI,IAAI4a,OAAO,MAAM,KAAK,GAAG+Z,IAAG,WAAW,IAAIxnC,EAAEsxB,GAAGvxB,EAAE,GAAG,GAAG,OAAOC,EAAE,CAAC,IAAIC,EAAEuzB,KAAIE,GAAG1zB,EAAED,EAAE,EAAEE,OAAMmpC,GAAGrpC,EAAE,KAC5bwV,GAAG,SAASxV,GAAG,GAAG,KAAKA,EAAEmG,IAAI,CAAC,IAAIlG,EAAEsxB,GAAGvxB,EAAE,WAAW,GAAG,OAAOC,EAAa0zB,GAAG1zB,EAAED,EAAE,UAAXyzB,MAAwB4V,GAAGrpC,EAAE,aAAayV,GAAG,SAASzV,GAAG,GAAG,KAAKA,EAAEmG,IAAI,CAAC,IAAIlG,EAAEyzB,GAAG1zB,GAAGE,EAAEqxB,GAAGvxB,EAAEC,GAAG,GAAG,OAAOC,EAAayzB,GAAGzzB,EAAEF,EAAEC,EAAXwzB,MAAgB4V,GAAGrpC,EAAEC,KAAKyV,GAAG,WAAW,OAAOL,IAAGM,GAAG,SAAS3V,EAAEC,GAAG,IAAIC,EAAEmV,GAAE,IAAI,OAAOA,GAAErV,EAAEC,IAAf,QAA2BoV,GAAEnV,IAChSyP,GAAG,SAAS3P,EAAEC,EAAEC,GAAG,OAAOD,GAAG,IAAK,QAAyB,GAAjBuI,EAAGxI,EAAEE,GAAGD,EAAEC,EAAE+F,KAAQ,UAAU/F,EAAEgC,MAAM,MAAMjC,EAAE,CAAC,IAAIC,EAAEF,EAAEE,EAAEwP,YAAYxP,EAAEA,EAAEwP,WAAsF,IAA3ExP,EAAEA,EAAEmqC,iBAAiB,cAAcC,KAAKC,UAAU,GAAGtqC,GAAG,mBAAuBA,EAAE,EAAEA,EAAEC,EAAEE,OAAOH,IAAI,CAAC,IAAIuB,EAAEtB,EAAED,GAAG,GAAGuB,IAAIxB,GAAGwB,EAAEgpC,OAAOxqC,EAAEwqC,KAAK,CAAC,IAAI/oC,EAAEwO,GAAGzO,GAAG,IAAIC,EAAE,MAAMwD,MAAMlF,EAAE,KAAK0H,EAAGjG,GAAGgH,EAAGhH,EAAEC,KAAK,MAAM,IAAK,WAAW+H,GAAGxJ,EAAEE,GAAG,MAAM,IAAK,SAAmB,OAAVD,EAAEC,EAAEyH,QAAeoB,GAAG/I,IAAIE,EAAEqhC,SAASthC,GAAE,KAAMoQ,GAAGm3B,GAAGl3B,GAAGm3B,GACpa,IAAIgD,GAAG,CAACC,uBAAsB,EAAGC,OAAO,CAAC56B,GAAGyS,GAAGvS,GAAGC,GAAGE,GAAGo3B,KAAKoD,GAAG,CAACC,wBAAwB7zB,GAAG8zB,WAAW,EAAEC,QAAQ,SAASC,oBAAoB,aAC1IC,GAAG,CAACH,WAAWF,GAAGE,WAAWC,QAAQH,GAAGG,QAAQC,oBAAoBJ,GAAGI,oBAAoBE,eAAeN,GAAGM,eAAeC,kBAAkB,KAAKC,4BAA4B,KAAKC,4BAA4B,KAAKC,cAAc,KAAKC,wBAAwB,KAAKC,wBAAwB,KAAKC,gBAAgB,KAAKC,mBAAmB,KAAKC,eAAe,KAAKC,qBAAqBnoC,EAAGyzB,uBAAuB2U,wBAAwB,SAAS7rC,GAAW,OAAO,QAAfA,EAAEgS,GAAGhS,IAAmB,KAAKA,EAAEgQ,WAAW66B,wBAAwBD,GAAGC,yBARjN,WAAc,OAAO,MAShUiB,4BAA4B,KAAKC,gBAAgB,KAAKC,aAAa,KAAKC,kBAAkB,KAAKC,gBAAgB,KAAKC,kBAAkB,kCAAkC,GAAG,qBAAqBC,+BAA+B,CAAC,IAAIC,GAAGD,+BAA+B,IAAIC,GAAGC,YAAYD,GAAGE,cAAc,IAAI34B,GAAGy4B,GAAGG,OAAOvB,IAAIp3B,GAAGw4B,GAAG,MAAMrsC,MAAKysC,EAAQ/oC,mDAAmD+mC,GAC9YgC,EAAQC,aAAa,SAAS1sC,EAAEC,GAAG,IAAIC,EAAE,EAAEC,UAAUC,aAAQ,IAASD,UAAU,GAAGA,UAAU,GAAG,KAAK,IAAI0pC,GAAG5pC,GAAG,MAAMgF,MAAMlF,EAAE,MAAM,OAAOgpC,GAAG/oC,EAAEC,EAAE,KAAKC,IAAIusC,EAAQE,WAAW,SAAS3sC,EAAEC,GAAG,IAAI4pC,GAAG7pC,GAAG,MAAMiF,MAAMlF,EAAE,MAAM,IAAIG,GAAE,EAAGsB,EAAE,GAAGC,EAAE+nC,GAA4P,OAAzP,OAAOvpC,QAAG,IAASA,KAAI,IAAKA,EAAE2sC,sBAAsB1sC,GAAE,QAAI,IAASD,EAAEs8B,mBAAmB/6B,EAAEvB,EAAEs8B,uBAAkB,IAASt8B,EAAEioC,qBAAqBzmC,EAAExB,EAAEioC,qBAAqBjoC,EAAE2oC,GAAG5oC,EAAE,GAAE,EAAG,KAAK,EAAKE,EAAE,EAAGsB,EAAEC,GAAGzB,EAAEspB,IAAIrpB,EAAEkS,QAAQuW,GAAG,IAAI1oB,EAAE0K,SAAS1K,EAAE0P,WAAW1P,GAAU,IAAI0pC,GAAGzpC,IACnfwsC,EAAQI,YAAY,SAAS7sC,GAAG,GAAG,MAAMA,EAAE,OAAO,KAAK,GAAG,IAAIA,EAAE0K,SAAS,OAAO1K,EAAE,IAAIC,EAAED,EAAEuzB,gBAAgB,QAAG,IAAStzB,EAAE,CAAC,GAAG,oBAAoBD,EAAEoG,OAAO,MAAMnB,MAAMlF,EAAE,MAAiC,MAA3BC,EAAEiB,OAAO6M,KAAK9N,GAAGo1B,KAAK,KAAWnwB,MAAMlF,EAAE,IAAIC,IAAyC,OAA5BA,EAAE,QAAVA,EAAEgS,GAAG/R,IAAc,KAAKD,EAAEgQ,WAAoBy8B,EAAQK,UAAU,SAAS9sC,GAAG,OAAOynC,GAAGznC,IAAIysC,EAAQM,QAAQ,SAAS/sC,EAAEC,EAAEC,GAAG,IAAI4pC,GAAG7pC,GAAG,MAAMgF,MAAMlF,EAAE,MAAM,OAAOiqC,GAAG,KAAKhqC,EAAEC,GAAE,EAAGC,IAC7YusC,EAAQO,YAAY,SAAShtC,EAAEC,EAAEC,GAAG,IAAI2pC,GAAG7pC,GAAG,MAAMiF,MAAMlF,EAAE,MAAM,IAAIyB,EAAE,MAAMtB,GAAGA,EAAE+sC,iBAAiB,KAAKxrC,GAAE,EAAGC,EAAE,GAAGC,EAAE6nC,GAAyO,GAAtO,OAAOtpC,QAAG,IAASA,KAAI,IAAKA,EAAE0sC,sBAAsBnrC,GAAE,QAAI,IAASvB,EAAEq8B,mBAAmB76B,EAAExB,EAAEq8B,uBAAkB,IAASr8B,EAAEgoC,qBAAqBvmC,EAAEzB,EAAEgoC,qBAAqBjoC,EAAEgpC,GAAGhpC,EAAE,KAAKD,EAAE,EAAE,MAAME,EAAEA,EAAE,KAAKuB,EAAE,EAAGC,EAAEC,GAAG3B,EAAEspB,IAAIrpB,EAAEkS,QAAQuW,GAAG1oB,GAAMwB,EAAE,IAAIxB,EAAE,EAAEA,EAAEwB,EAAEpB,OAAOJ,IAA2ByB,GAAhBA,GAAPvB,EAAEsB,EAAExB,IAAOktC,aAAgBhtC,EAAEitC,SAAS,MAAMltC,EAAE0oC,gCAAgC1oC,EAAE0oC,gCAAgC,CAACzoC,EAAEuB,GAAGxB,EAAE0oC,gCAAgCx4B,KAAKjQ,EACvhBuB,GAAG,OAAO,IAAImoC,GAAG3pC,IAAIwsC,EAAQrmC,OAAO,SAASpG,EAAEC,EAAEC,GAAG,IAAI4pC,GAAG7pC,GAAG,MAAMgF,MAAMlF,EAAE,MAAM,OAAOiqC,GAAG,KAAKhqC,EAAEC,GAAE,EAAGC,IAAIusC,EAAQW,uBAAuB,SAASptC,GAAG,IAAI8pC,GAAG9pC,GAAG,MAAMiF,MAAMlF,EAAE,KAAK,QAAOC,EAAEojC,sBAAqBqE,IAAG,WAAWuC,GAAG,KAAK,KAAKhqC,GAAE,GAAG,WAAWA,EAAEojC,oBAAoB,KAAKpjC,EAAEspB,IAAI,YAAS,IAAQmjB,EAAQY,wBAAwB7F,GAC/UiF,EAAQa,oCAAoC,SAASttC,EAAEC,EAAEC,EAAEsB,GAAG,IAAIsoC,GAAG5pC,GAAG,MAAM+E,MAAMlF,EAAE,MAAM,GAAG,MAAMC,QAAG,IAASA,EAAEuzB,gBAAgB,MAAMtuB,MAAMlF,EAAE,KAAK,OAAOiqC,GAAGhqC,EAAEC,EAAEC,GAAE,EAAGsB,IAAIirC,EAAQ1B,QAAQ,mEChU7L,IAAI/5B,EAAInR,EAAQ,KAEd4sC,EAAQE,WAAa37B,EAAE27B,WACvBF,EAAQO,YAAch8B,EAAEg8B,+CCH1B,SAASO,IAEP,GAC4C,qBAAnCnB,gCAC4C,oBAA5CA,+BAA+BmB,SAcxC,IAEEnB,+BAA+BmB,SAASA,GACxC,MAAOC,GAGP3Q,QAAQC,MAAM0Q,IAOhBD,GACAE,EAAOhB,QAAU,EAAjBgB,qSChCF,IAAIC,EAAS7Q,QACN,SAAS8Q,IACd,OAAOD,EAEF,SAASE,EAAUC,GACxBH,EAASG,kFCJAC,EAA6B,WACtC,SAASA,IACPlsC,KAAK02B,MAAQ,GACb12B,KAAKmsC,aAAe,EAEpBnsC,KAAKosC,SAAW,SAAU1b,GACxBA,KAGF1wB,KAAKqsC,cAAgB,SAAU3b,GAC7BA,KAIJ,IAAI4b,EAASJ,EAAc5sC,UAoF3B,OAlFAgtC,EAAOC,MAAQ,SAAe7b,GAC5B,IAAI8b,EACJxsC,KAAKmsC,eAEL,IACEK,EAAS9b,IADX,QAGE1wB,KAAKmsC,eAEAnsC,KAAKmsC,cACRnsC,KAAKysC,QAIT,OAAOD,GAGTF,EAAOI,SAAW,SAAkBhc,GAClC,IAAIic,EAAQ3sC,KAERA,KAAKmsC,aACPnsC,KAAK02B,MAAMnoB,KAAKmiB,IAEhBkc,EAAAA,EAAAA,KAAkB,WAChBD,EAAMP,SAAS1b,OASrB4b,EAAOO,WAAa,SAAoBnc,GACtC,IAAIoc,EAAS9sC,KAEb,OAAO,WACL,IAAK,IAAI+sC,EAAOxuC,UAAUC,OAAQwuC,EAAO,IAAI/lC,MAAM8lC,GAAOE,EAAO,EAAGA,EAAOF,EAAME,IAC/ED,EAAKC,GAAQ1uC,UAAU0uC,GAGzBH,EAAOJ,UAAS,WACdhc,EAASvhB,WAAM,EAAQ69B,QAK7BV,EAAOG,MAAQ,WACb,IAAIS,EAASltC,KAET02B,EAAQ12B,KAAK02B,MACjB12B,KAAK02B,MAAQ,GAETA,EAAMl4B,SACRouC,EAAAA,EAAAA,KAAkB,WAChBM,EAAOb,eAAc,WACnB3V,EAAM/1B,SAAQ,SAAU+vB,GACtBwc,EAAOd,SAAS1b,aAY1B4b,EAAOa,kBAAoB,SAA2BC,GACpDptC,KAAKosC,SAAWgB,GAQlBd,EAAOe,uBAAyB,SAAgCD,GAC9DptC,KAAKqsC,cAAgBe,GAGhBlB,EAlG+B,GAqG7BoB,EAAgB,IAAIpB,0FCxGhB,SAASqB,EAAgBC,EAAGrvC,GAKzC,OAJAovC,EAAkBluC,OAAOouC,eAAiBpuC,OAAOouC,eAAe1mB,OAAS,SAAyBymB,EAAGrvC,GAEnG,OADAqvC,EAAEE,UAAYvvC,EACPqvC,GAEFD,EAAgBC,EAAGrvC,GCJb,SAASwvC,EAAeC,EAAUC,GAC/CD,EAAStuC,UAAYD,OAAO+4B,OAAOyV,EAAWvuC,WAC9CsuC,EAAStuC,UAAU+F,YAAcuoC,EACjC,EAAeA,EAAUC,yBCJhBC,EAA4B,WACrC,SAASA,IACP9tC,KAAKsgB,UAAY,GAGnB,IAAIgsB,EAASwB,EAAaxuC,UA8B1B,OA5BAgtC,EAAOyB,UAAY,SAAmBznB,GACpC,IAAIqmB,EAAQ3sC,KAER0wB,EAAWpK,GAAY,aAM3B,OAFAtmB,KAAKsgB,UAAU/R,KAAKmiB,GACpB1wB,KAAKguC,cACE,WACLrB,EAAMrsB,UAAYqsB,EAAMrsB,UAAU2tB,QAAO,SAAU5mB,GACjD,OAAOA,IAAMqJ,KAGfic,EAAMuB,kBAIV5B,EAAO6B,aAAe,WACpB,OAAOnuC,KAAKsgB,UAAU9hB,OAAS,GAGjC8tC,EAAO0B,YAAc,aAGrB1B,EAAO4B,cAAgB,aAGhBJ,EAnC8B,GC8F5BM,EAAe,IA3Fa,SAAUC,GAG/C,SAASC,IACP,IAAI3B,EAuBJ,OArBAA,EAAQ0B,EAAchtC,KAAKrB,OAASA,MAE9BuuC,MAAQ,SAAUC,GACtB,IAAIC,EAEJ,IAAKC,EAAAA,KAAmC,OAArBD,EAAUxvC,aAAkB,EAASwvC,EAAQz/B,kBAAmB,CACjF,IAAIsX,EAAW,WACb,OAAOkoB,KAMT,OAFAvvC,OAAO+P,iBAAiB,mBAAoBsX,GAAU,GACtDrnB,OAAO+P,iBAAiB,QAASsX,GAAU,GACpC,WAELrnB,OAAOgQ,oBAAoB,mBAAoBqX,GAC/CrnB,OAAOgQ,oBAAoB,QAASqX,MAKnCqmB,EA1BTgB,EAAeW,EAAcD,GA6B7B,IAAI/B,EAASgC,EAAahvC,UA2D1B,OAzDAgtC,EAAO0B,YAAc,WACdhuC,KAAK2uC,SACR3uC,KAAK4uC,iBAAiB5uC,KAAKuuC,QAI/BjC,EAAO4B,cAAgB,WAEnB,IAAIW,EADD7uC,KAAKmuC,iBAG0B,OAAjCU,EAAgB7uC,KAAK2uC,UAA4BE,EAAcxtC,KAAKrB,MACrEA,KAAK2uC,aAAUG,IAInBxC,EAAOsC,iBAAmB,SAA0BL,GAClD,IAAIQ,EACAjC,EAAS9sC,KAEbA,KAAKuuC,MAAQA,EACsB,OAAlCQ,EAAiB/uC,KAAK2uC,UAA4BI,EAAe1tC,KAAKrB,MACvEA,KAAK2uC,QAAUJ,GAAM,SAAUS,GACN,mBAAZA,EACTlC,EAAOmC,WAAWD,GAElBlC,EAAO0B,cAKblC,EAAO2C,WAAa,SAAoBD,GACtChvC,KAAKgvC,QAAUA,EAEXA,GACFhvC,KAAKwuC,WAITlC,EAAOkC,QAAU,WACfxuC,KAAKsgB,UAAU3f,SAAQ,SAAU2lB,GAC/BA,QAIJgmB,EAAO4C,UAAY,WACjB,MAA4B,mBAAjBlvC,KAAKgvC,QACPhvC,KAAKgvC,QAIU,qBAAb9vC,UAIJ,MAAC4vC,EAAW,UAAW,aAAa1qC,SAASlF,SAASiwC,kBAGxDb,EAzF8B,CA0FrCR,ICASsB,EAAgB,IA1Fa,SAAUf,GAGhD,SAASgB,IACP,IAAI1C,EAuBJ,OArBAA,EAAQ0B,EAAchtC,KAAKrB,OAASA,MAE9BuuC,MAAQ,SAAUe,GACtB,IAAIb,EAEJ,IAAKC,EAAAA,KAAmC,OAArBD,EAAUxvC,aAAkB,EAASwvC,EAAQz/B,kBAAmB,CACjF,IAAIsX,EAAW,WACb,OAAOgpB,KAMT,OAFArwC,OAAO+P,iBAAiB,SAAUsX,GAAU,GAC5CrnB,OAAO+P,iBAAiB,UAAWsX,GAAU,GACtC,WAELrnB,OAAOgQ,oBAAoB,SAAUqX,GACrCrnB,OAAOgQ,oBAAoB,UAAWqX,MAKrCqmB,EA1BTgB,EAAe0B,EAAehB,GA6B9B,IAAI/B,EAAS+C,EAAc/vC,UA0D3B,OAxDAgtC,EAAO0B,YAAc,WACdhuC,KAAK2uC,SACR3uC,KAAK4uC,iBAAiB5uC,KAAKuuC,QAI/BjC,EAAO4B,cAAgB,WAEnB,IAAIW,EADD7uC,KAAKmuC,iBAG0B,OAAjCU,EAAgB7uC,KAAK2uC,UAA4BE,EAAcxtC,KAAKrB,MACrEA,KAAK2uC,aAAUG,IAInBxC,EAAOsC,iBAAmB,SAA0BL,GAClD,IAAIQ,EACAjC,EAAS9sC,KAEbA,KAAKuuC,MAAQA,EACsB,OAAlCQ,EAAiB/uC,KAAK2uC,UAA4BI,EAAe1tC,KAAKrB,MACvEA,KAAK2uC,QAAUJ,GAAM,SAAUgB,GACP,mBAAXA,EACTzC,EAAO0C,UAAUD,GAEjBzC,EAAOwC,eAKbhD,EAAOkD,UAAY,SAAmBD,GACpCvvC,KAAKuvC,OAASA,EAEVA,GACFvvC,KAAKsvC,YAIThD,EAAOgD,SAAW,WAChBtvC,KAAKsgB,UAAU3f,SAAQ,SAAU2lB,GAC/BA,QAIJgmB,EAAOmD,SAAW,WAChB,MAA2B,mBAAhBzvC,KAAKuvC,OACPvvC,KAAKuvC,OAGW,qBAAdG,WAAyD,qBAArBA,UAAUC,QAIlDD,UAAUC,QAGZN,EAxF+B,CAyFtCvB,ICxFF,SAAS8B,EAAkBC,GACzB,OAAO19B,KAAKgR,IAAI,IAAOhR,KAAK29B,IAAI,EAAGD,GAAe,KAG7C,SAASE,EAAahqC,GAC3B,MAA0D,oBAAlC,MAATA,OAAgB,EAASA,EAAMiqC,QAEzC,IAAIC,EAAiB,SAAwB7oC,GAClDpH,KAAKkwC,OAAoB,MAAX9oC,OAAkB,EAASA,EAAQ8oC,OACjDlwC,KAAKmwC,OAAoB,MAAX/oC,OAAkB,EAASA,EAAQ+oC,QAE5C,SAASC,EAAiBrqC,GAC/B,OAAOA,aAAiBkqC,EAGnB,IAAII,EAAU,SAAiBC,GACpC,IAGIC,EACAC,EACAC,EACAC,EANA/D,EAAQ3sC,KAER2wC,GAAc,EAKlB3wC,KAAK4wC,MAAQN,EAAOM,MAEpB5wC,KAAKgwC,OAAS,SAAUa,GACtB,OAAmB,MAAZN,OAAmB,EAASA,EAASM,IAG9C7wC,KAAK2wC,YAAc,WACjBA,GAAc,GAGhB3wC,KAAK8wC,cAAgB,WACnBH,GAAc,GAGhB3wC,KAAK+wC,SAAW,WACd,OAAqB,MAAdP,OAAqB,EAASA,KAGvCxwC,KAAK6vC,aAAe,EACpB7vC,KAAKgxC,UAAW,EAChBhxC,KAAKixC,YAAa,EAClBjxC,KAAKkxC,uBAAwB,EAC7BlxC,KAAKmxC,QAAU,IAAI/nB,SAAQ,SAAUgoB,EAAcC,GACjDZ,EAAiBW,EACjBV,EAAgBW,KAGlB,IAAI9nB,EAAU,SAAiBxjB,GACxB4mC,EAAMsE,aACTtE,EAAMsE,YAAa,EACC,MAApBX,EAAOgB,WAA6BhB,EAAOgB,UAAUvrC,GACvC,MAAdyqC,GAA8BA,IAC9BC,EAAe1qC,KAIfwrC,EAAS,SAAgBxrC,GACtB4mC,EAAMsE,aACTtE,EAAMsE,YAAa,EACD,MAAlBX,EAAOjhC,SAA2BihC,EAAOjhC,QAAQtJ,GACnC,MAAdyqC,GAA8BA,IAC9BE,EAAc3qC,MAiBR,SAASyrC,IAEjB,IAAI7E,EAAMsE,WAAV,CAIA,IAAIQ,EAEJ,IACEA,EAAiBnB,EAAOlD,KACxB,MAAOlS,GACPuW,EAAiBroB,QAAQmoB,OAAOrW,GAIlCqV,EAAW,SAAkBM,GAC3B,IAAKlE,EAAMsE,aACTM,EAAO,IAAItB,EAAeY,IACX,MAAflE,EAAMiE,OAAyBjE,EAAMiE,QAEjCb,EAAa0B,IACf,IACEA,EAAezB,SACf,MAAO0B,MAMf/E,EAAMuE,sBAAwBnB,EAAa0B,GAC3CroB,QAAQG,QAAQkoB,GAAgBjoB,KAAKD,GAASE,OAAM,SAAUyR,GAC5D,IAAIyW,EAAeC,EAGnB,IAAIjF,EAAMsE,WAAV,CAKA,IAAIY,EAA0C,OAAjCF,EAAgBrB,EAAOuB,OAAiBF,EAAgB,EACjEG,EAAyD,OAA3CF,EAAqBtB,EAAOwB,YAAsBF,EAAqBhC,EACrFmC,EAA8B,oBAAfD,EAA4BA,EAAWnF,EAAMkD,aAAc3U,GAAS4W,EACnFE,GAAwB,IAAVH,GAAmC,kBAAVA,GAAsBlF,EAAMkD,aAAegC,GAA0B,oBAAVA,GAAwBA,EAAMlF,EAAMkD,aAAc3U,IAEpJyV,GAAgBqB,GAMpBrF,EAAMkD,eAEW,MAAjBS,EAAO2B,QAA0B3B,EAAO2B,OAAOtF,EAAMkD,aAAc3U,IAEnEgX,EAAAA,EAAAA,IAAMH,GACLvoB,MAAK,WACJ,IAAK4kB,EAAac,cAAgBE,EAAcK,WAC9C,OArEC,IAAIrmB,SAAQ,SAAU+oB,GAC3B3B,EAAa2B,EACbxF,EAAMqE,UAAW,EACC,MAAlBV,EAAO8B,SAA2B9B,EAAO8B,aACxC5oB,MAAK,WACNgnB,OAAa1B,EACbnC,EAAMqE,UAAW,EACI,MAArBV,EAAO+B,YAA8B/B,EAAO+B,mBAgEzC7oB,MAAK,WACFmnB,EACFY,EAAOrW,GAEPsW,QAjBFD,EAAOrW,QAwBbsW,ICpJSc,EAAqB,WAC9B,SAASA,EAAMhC,GACbtwC,KAAKuyC,qBAAsB,EAC3BvyC,KAAKwyC,cAAe,EACpBxyC,KAAKyyC,eAAiBnC,EAAOmC,eAC7BzyC,KAAK0yC,WAAWpC,EAAOlpC,SACvBpH,KAAK2yC,UAAY,GACjB3yC,KAAKinC,MAAQqJ,EAAOrJ,MACpBjnC,KAAK4yC,SAAWtC,EAAOsC,SACvB5yC,KAAK6yC,UAAYvC,EAAOuC,UACxB7yC,KAAK8yC,aAAexC,EAAO/d,OAASvyB,KAAK+yC,gBAAgB/yC,KAAKoH,SAC9DpH,KAAKuyB,MAAQvyB,KAAK8yC,aAClB9yC,KAAKiN,KAAOqjC,EAAOrjC,KACnBjN,KAAKgzC,aAGP,IAAI1G,EAASgG,EAAMhzC,UAydnB,OAvdAgtC,EAAOoG,WAAa,SAAoBtrC,GACtC,IAAI6rC,EAEJjzC,KAAKoH,SAAU8rC,EAAAA,EAAAA,GAAS,GAAIlzC,KAAKyyC,eAAgBrrC,GACjDpH,KAAKiN,KAAkB,MAAX7F,OAAkB,EAASA,EAAQ6F,KAE/CjN,KAAKmzC,UAAYhhC,KAAKihC,IAAIpzC,KAAKmzC,WAAa,EAAuD,OAAnDF,EAAwBjzC,KAAKoH,QAAQ+rC,WAAqBF,EAAwB,MAGpI3G,EAAO+G,kBAAoB,SAA2BjsC,GACpDpH,KAAKyyC,eAAiBrrC,GAGxBklC,EAAO0G,WAAa,WAClB,IAAIrG,EAAQ3sC,KAEZA,KAAKszC,kBAEDC,EAAAA,EAAAA,IAAevzC,KAAKmzC,aACtBnzC,KAAKwzC,UAAYxqB,YAAW,WAC1B2jB,EAAM8G,mBACLzzC,KAAKmzC,aAIZ7G,EAAOgH,eAAiB,WACtBpqB,aAAalpB,KAAKwzC,WAClBxzC,KAAKwzC,eAAY1E,GAGnBxC,EAAOmH,eAAiB,WACjBzzC,KAAK2yC,UAAUn0C,SACdwB,KAAKuyB,MAAMmhB,WACT1zC,KAAKwyC,cACPxyC,KAAKgzC,aAGPhzC,KAAKinC,MAAM0M,OAAO3zC,QAKxBssC,EAAOsH,QAAU,SAAiBphB,EAASprB,GACzC,IAAIysC,EAAuBC,EAEvBC,EAAW/zC,KAAKuyB,MAAMtX,KAEtBA,GAAO+4B,EAAAA,EAAAA,IAAiBxhB,EAASuhB,GAerC,OAb4E,OAAvEF,GAAyBC,EAAgB9zC,KAAKoH,SAAS6sC,kBAAuB,EAASJ,EAAsBxyC,KAAKyyC,EAAeC,EAAU94B,IAC9IA,EAAO84B,GACqC,IAAnC/zC,KAAKoH,QAAQ8sC,oBAEtBj5B,GAAOk5B,EAAAA,EAAAA,IAAiBJ,EAAU94B,IAIpCjb,KAAKm3B,SAAS,CACZlc,KAAMA,EACN3a,KAAM,UACN8zC,cAA0B,MAAXhtC,OAAkB,EAASA,EAAQitC,YAE7Cp5B,GAGTqxB,EAAOgI,SAAW,SAAkB/hB,EAAOgiB,GACzCv0C,KAAKm3B,SAAS,CACZ72B,KAAM,WACNiyB,MAAOA,EACPgiB,gBAAiBA,KAIrBjI,EAAO0D,OAAS,SAAgB5oC,GAC9B,IAAIotC,EAEArD,EAAUnxC,KAAKmxC,QAEnB,OADkC,OAAjCqD,EAAgBx0C,KAAKy0C,UAA4BD,EAAcxE,OAAO5oC,GAChE+pC,EAAUA,EAAQ3nB,KAAKkrB,EAAAA,IAAMjrB,MAAMirB,EAAAA,IAAQtrB,QAAQG,WAG5D+iB,EAAOjU,QAAU,WACfr4B,KAAKszC,iBACLtzC,KAAKgwC,OAAO,CACVG,QAAQ,KAIZ7D,EAAOqI,MAAQ,WACb30C,KAAKq4B,UACLr4B,KAAKs0C,SAASt0C,KAAK8yC,eAGrBxG,EAAOsI,SAAW,WAChB,OAAO50C,KAAK2yC,UAAUkC,MAAK,SAAUC,GACnC,OAAoC,IAA7BA,EAAS1tC,QAAQ2tC,YAI5BzI,EAAOoH,WAAa,WAClB,OAAO1zC,KAAKuyB,MAAMmhB,YAGpBpH,EAAO0I,QAAU,WACf,OAAOh1C,KAAKuyB,MAAM0iB,gBAAkBj1C,KAAKuyB,MAAM6hB,eAAiBp0C,KAAK2yC,UAAUkC,MAAK,SAAUC,GAC5F,OAAOA,EAASI,mBAAmBF,YAIvC1I,EAAO6I,cAAgB,SAAuBC,GAK5C,YAJkB,IAAdA,IACFA,EAAY,GAGPp1C,KAAKuyB,MAAM0iB,gBAAkBj1C,KAAKuyB,MAAM6hB,iBAAkBiB,EAAAA,EAAAA,IAAer1C,KAAKuyB,MAAM6hB,cAAegB,IAG5G9I,EAAOkC,QAAU,WACf,IAAI8G,EAEAR,EAAW90C,KAAK2yC,UAAU4C,MAAK,SAAUluB,GAC3C,OAAOA,EAAEmuB,8BAGPV,GACFA,EAASW,UAIwB,OAAlCH,EAAiBt1C,KAAKy0C,UAA4Ba,EAAevE,YAGpEzE,EAAOgD,SAAW,WAChB,IAAIoG,EAEAZ,EAAW90C,KAAK2yC,UAAU4C,MAAK,SAAUluB,GAC3C,OAAOA,EAAEsuB,4BAGPb,GACFA,EAASW,UAIwB,OAAlCC,EAAiB11C,KAAKy0C,UAA4BiB,EAAe3E,YAGpEzE,EAAOsJ,YAAc,SAAqBd,IACE,IAAtC90C,KAAK2yC,UAAU3mC,QAAQ8oC,KACzB90C,KAAK2yC,UAAUpkC,KAAKumC,GACpB90C,KAAKwyC,cAAe,EAEpBxyC,KAAKszC,iBACLtzC,KAAKinC,MAAM4O,OAAO,CAChBv1C,KAAM,gBACNw1C,MAAO91C,KACP80C,SAAUA,MAKhBxI,EAAOyJ,eAAiB,SAAwBjB,IACJ,IAAtC90C,KAAK2yC,UAAU3mC,QAAQ8oC,KACzB90C,KAAK2yC,UAAY3yC,KAAK2yC,UAAU1E,QAAO,SAAU5mB,GAC/C,OAAOA,IAAMytB,KAGV90C,KAAK2yC,UAAUn0C,SAGdwB,KAAKy0C,UACHz0C,KAAKy0C,QAAQvD,uBAAyBlxC,KAAKuyC,oBAC7CvyC,KAAKy0C,QAAQzE,OAAO,CAClBE,QAAQ,IAGVlwC,KAAKy0C,QAAQ9D,eAIb3wC,KAAKmzC,UACPnzC,KAAKgzC,aAELhzC,KAAKinC,MAAM0M,OAAO3zC,OAItBA,KAAKinC,MAAM4O,OAAO,CAChBv1C,KAAM,kBACNw1C,MAAO91C,KACP80C,SAAUA,MAKhBxI,EAAO0J,kBAAoB,WACzB,OAAOh2C,KAAK2yC,UAAUn0C,QAGxB8tC,EAAO2J,WAAa,WACbj2C,KAAKuyB,MAAM0iB,eACdj1C,KAAKm3B,SAAS,CACZ72B,KAAM,gBAKZgsC,EAAO4J,MAAQ,SAAe9uC,EAAS+uC,GACrC,IACIC,EACAC,EACAC,EAHAxJ,EAAS9sC,KAKb,GAAIA,KAAKuyB,MAAMmhB,WACb,GAAI1zC,KAAKuyB,MAAM6hB,gBAAkC,MAAhB+B,OAAuB,EAASA,EAAaI,eAE5Ev2C,KAAKgwC,OAAO,CACVG,QAAQ,SAEL,GAAInwC,KAAKmxC,QAAS,CACvB,IAAIqF,EAKJ,OAFmC,OAAlCA,EAAiBx2C,KAAKy0C,UAA4B+B,EAAe1F,gBAE3D9wC,KAAKmxC,QAWhB,GANI/pC,GACFpH,KAAK0yC,WAAWtrC,IAKbpH,KAAKoH,QAAQqvC,QAAS,CACzB,IAAI3B,EAAW90C,KAAK2yC,UAAU4C,MAAK,SAAUluB,GAC3C,OAAOA,EAAEjgB,QAAQqvC,WAGf3B,GACF90C,KAAK0yC,WAAWoC,EAAS1tC,SAI7B,IAAIwrC,GAAW8D,EAAAA,EAAAA,IAAoB12C,KAAK4yC,UACpC+D,GAAkBC,EAAAA,EAAAA,MAElBC,EAAiB,CACnBjE,SAAUA,EACVkE,eAAWhI,EACX7hC,KAAMjN,KAAKiN,MAEb5N,OAAOuE,eAAeizC,EAAgB,SAAU,CAC9CrxC,YAAY,EACZF,IAAK,WACH,GAAIqxC,EAEF,OADA7J,EAAOyF,qBAAsB,EACtBoE,EAAgBI,UAO7B,IAoBMC,EASAC,EAnBF7nB,EAAU,CACZ+mB,aAAcA,EACd/uC,QAASpH,KAAKoH,QACdwrC,SAAUA,EACVrgB,MAAOvyB,KAAKuyB,MACZ2kB,QAfY,WACZ,OAAKpK,EAAO1lC,QAAQqvC,SAIpB3J,EAAOyF,qBAAsB,EACtBzF,EAAO1lC,QAAQqvC,QAAQI,IAJrBztB,QAAQmoB,OAAO,oBAcxBtkC,KAAMjN,KAAKiN,OAG0C,OAAlDmpC,EAAwBp2C,KAAKoH,QAAQ+vC,eAAoB,EAASf,EAAsBgB,WAGvC,OAAnDJ,EAAyBh3C,KAAKoH,QAAQ+vC,WAA6BH,EAAuBI,QAAQhoB,KAIrGpvB,KAAKq3C,YAAcr3C,KAAKuyB,MAEnBvyB,KAAKuyB,MAAMmhB,YAAc1zC,KAAKuyB,MAAM+kB,aAAiE,OAAjDjB,EAAwBjnB,EAAQ+mB,mBAAwB,EAASE,EAAsBppC,QAG9IjN,KAAKm3B,SAAS,CACZ72B,KAAM,QACN2M,KAAyD,OAAlDgqC,EAAyB7nB,EAAQ+mB,mBAAwB,EAASc,EAAuBhqC,OA0DpG,OArDAjN,KAAKy0C,QAAU,IAAIpE,EAAQ,CACzBjD,GAAIhe,EAAQ8nB,QACZtG,MAA0B,MAAnB+F,GAAsF,OAAlDL,EAAwBK,EAAgB/F,YAAlD,EAA4E0F,EAAsBvvB,KAAK4vB,GACxIrF,UAAW,SAAmBr2B,GAC5B6xB,EAAO8G,QAAQ34B,GAGkB,MAAjC6xB,EAAO7F,MAAMqJ,OAAOgB,WAA6BxE,EAAO7F,MAAMqJ,OAAOgB,UAAUr2B,EAAM6xB,GAE5D,IAArBA,EAAOqG,WACTrG,EAAO2G,kBAGXpkC,QAAS,SAAiB6rB,GAElBkV,EAAiBlV,IAAUA,EAAMiV,QACrCrD,EAAO3V,SAAS,CACd72B,KAAM,QACN46B,MAAOA,IAINkV,EAAiBlV,KAEW,MAA/B4R,EAAO7F,MAAMqJ,OAAOjhC,SAA2By9B,EAAO7F,MAAMqJ,OAAOjhC,QAAQ6rB,EAAO4R,IAElFf,EAAAA,EAAAA,KAAY7Q,MAAMA,IAIK,IAArB4R,EAAOqG,WACTrG,EAAO2G,kBAGXxB,OAAQ,WACNnF,EAAO3V,SAAS,CACd72B,KAAM,YAGV8xC,QAAS,WACPtF,EAAO3V,SAAS,CACd72B,KAAM,WAGV+xC,WAAY,WACVvF,EAAO3V,SAAS,CACd72B,KAAM,cAGVuxC,MAAOziB,EAAQhoB,QAAQyqC,MACvBC,WAAY1iB,EAAQhoB,QAAQ0qC,aAE9B9xC,KAAKmxC,QAAUnxC,KAAKy0C,QAAQtD,QACrBnxC,KAAKmxC,SAGd7E,EAAOnV,SAAW,SAAkBJ,GAClC,IAAImW,EAASltC,KAEbA,KAAKuyB,MAAQvyB,KAAKu3C,QAAQv3C,KAAKuyB,MAAOwE,GACtCuW,EAAAA,EAAAA,OAAoB,WAClBJ,EAAOyF,UAAUhyC,SAAQ,SAAUm0C,GACjCA,EAAS0C,cAAczgB,MAGzBmW,EAAOjG,MAAM4O,OAAO,CAClBC,MAAO5I,EACP5sC,KAAM,eACNy2B,OAAQA,QAKduV,EAAOyG,gBAAkB,SAAyB3rC,GAChD,IAAI6T,EAAsC,oBAAxB7T,EAAQqwC,YAA6BrwC,EAAQqwC,cAAgBrwC,EAAQqwC,YAEnFC,EADgD,qBAAxBtwC,EAAQqwC,YACgD,oBAAjCrwC,EAAQswC,qBAAsCtwC,EAAQswC,uBAAyBtwC,EAAQswC,qBAAuB,EAC7JC,EAA0B,qBAAT18B,EACrB,MAAO,CACLA,KAAMA,EACN28B,gBAAiB,EACjBxD,cAAeuD,EAAkC,MAAxBD,EAA+BA,EAAuBj/B,KAAKC,MAAQ,EAC5FwiB,MAAO,KACP2c,iBAAkB,EAClBC,eAAgB,EAChBC,kBAAmB,EACnBT,UAAW,KACX5D,YAAY,EACZuB,eAAe,EACfjE,UAAU,EACVgH,OAAQL,EAAU,UAAY,SAIlCrL,EAAOiL,QAAU,SAAiBhlB,EAAOwE,GACvC,IAAIkhB,EAAcC,EAElB,OAAQnhB,EAAOz2B,MACb,IAAK,SACH,OAAO4yC,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBwlB,kBAAmBxlB,EAAMwlB,kBAAoB,IAGjD,IAAK,QACH,OAAO7E,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBye,UAAU,IAGd,IAAK,WACH,OAAOkC,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBye,UAAU,IAGd,IAAK,QACH,OAAOkC,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBwlB,kBAAmB,EACnBT,UAA2C,OAA/BW,EAAelhB,EAAO9pB,MAAgBgrC,EAAe,KACjEvE,YAAY,EACZ1C,UAAU,IACRze,EAAM6hB,eAAiB,CACzBlZ,MAAO,KACP8c,OAAQ,YAGZ,IAAK,UACH,OAAO9E,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBtX,KAAM8b,EAAO9b,KACb28B,gBAAiBrlB,EAAMqlB,gBAAkB,EACzCxD,cAAiE,OAAjD8D,EAAwBnhB,EAAOqd,eAAyB8D,EAAwBz/B,KAAKC,MACrGwiB,MAAO,KACP6c,kBAAmB,EACnBrE,YAAY,EACZuB,eAAe,EACfjE,UAAU,EACVgH,OAAQ,YAGZ,IAAK,QACH,IAAI9c,EAAQnE,EAAOmE,MAEnB,OAAIkV,EAAiBlV,IAAUA,EAAMgV,QAAUlwC,KAAKq3C,aAC3CnE,EAAAA,EAAAA,GAAS,GAAIlzC,KAAKq3C,cAGpBnE,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzB2I,MAAOA,EACP2c,iBAAkBtlB,EAAMslB,iBAAmB,EAC3CC,eAAgBr/B,KAAKC,MACrBq/B,kBAAmBxlB,EAAMwlB,kBAAoB,EAC7CrE,YAAY,EACZ1C,UAAU,EACVgH,OAAQ,UAGZ,IAAK,aACH,OAAO9E,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzB0iB,eAAe,IAGnB,IAAK,WACH,OAAO/B,EAAAA,EAAAA,GAAS,GAAI3gB,EAAOwE,EAAOxE,OAEpC,QACE,OAAOA,IAIN+f,EAzeuB,GCDrB6F,EAA0B,SAAU9J,GAG7C,SAAS8J,EAAW7H,GAClB,IAAI3D,EAMJ,OAJAA,EAAQ0B,EAAchtC,KAAKrB,OAASA,MAC9BswC,OAASA,GAAU,GACzB3D,EAAMyL,QAAU,GAChBzL,EAAM0L,WAAa,GACZ1L,EATTgB,EAAewK,EAAY9J,GAY3B,IAAI/B,EAAS6L,EAAW74C,UA8HxB,OA5HAgtC,EAAOgM,MAAQ,SAAeC,EAAQnxC,EAASmrB,GAC7C,IAAIimB,EAEA5F,EAAWxrC,EAAQwrC,SACnBC,EAAwD,OAA3C2F,EAAqBpxC,EAAQyrC,WAAqB2F,GAAqBC,EAAAA,EAAAA,IAAsB7F,EAAUxrC,GACpH0uC,EAAQ91C,KAAKsF,IAAIutC,GAerB,OAbKiD,IACHA,EAAQ,IAAIxD,EAAM,CAChBrL,MAAOjnC,KACP4yC,SAAUA,EACVC,UAAWA,EACXzrC,QAASmxC,EAAOG,oBAAoBtxC,GACpCmrB,MAAOA,EACPkgB,eAAgB8F,EAAOI,iBAAiB/F,GACxC3lC,KAAM7F,EAAQ6F,OAEhBjN,KAAKjB,IAAI+2C,IAGJA,GAGTxJ,EAAOvtC,IAAM,SAAa+2C,GACnB91C,KAAKq4C,WAAWvC,EAAMjD,aACzB7yC,KAAKq4C,WAAWvC,EAAMjD,WAAaiD,EACnC91C,KAAKo4C,QAAQ7pC,KAAKunC,GAClB91C,KAAK61C,OAAO,CACVv1C,KAAM,aACNw1C,MAAOA,MAKbxJ,EAAOqH,OAAS,SAAgBmC,GAC9B,IAAI8C,EAAa54C,KAAKq4C,WAAWvC,EAAMjD,WAEnC+F,IACF9C,EAAMzd,UACNr4B,KAAKo4C,QAAUp4C,KAAKo4C,QAAQnK,QAAO,SAAU5mB,GAC3C,OAAOA,IAAMyuB,KAGX8C,IAAe9C,UACV91C,KAAKq4C,WAAWvC,EAAMjD,WAG/B7yC,KAAK61C,OAAO,CACVv1C,KAAM,eACNw1C,MAAOA,MAKbxJ,EAAOuM,MAAQ,WACb,IAAI/L,EAAS9sC,KAEbstC,EAAAA,EAAAA,OAAoB,WAClBR,EAAOsL,QAAQz3C,SAAQ,SAAUm1C,GAC/BhJ,EAAO6G,OAAOmC,UAKpBxJ,EAAOhnC,IAAM,SAAautC,GACxB,OAAO7yC,KAAKq4C,WAAWxF,IAGzBvG,EAAOwM,OAAS,WACd,OAAO94C,KAAKo4C,SAGd9L,EAAOiJ,KAAO,SAAcwD,EAAMC,GAChC,IACIC,GADmBC,EAAAA,EAAAA,IAAgBH,EAAMC,GACd,GAM/B,MAJ6B,qBAAlBC,EAAQE,QACjBF,EAAQE,OAAQ,GAGXn5C,KAAKo4C,QAAQ7C,MAAK,SAAUO,GACjC,OAAOsD,EAAAA,EAAAA,IAAWH,EAASnD,OAI/BxJ,EAAO+M,QAAU,SAAiBN,EAAMC,GACtC,IACIC,GADoBC,EAAAA,EAAAA,IAAgBH,EAAMC,GACd,GAEhC,OAAO35C,OAAO6M,KAAK+sC,GAASz6C,OAAS,EAAIwB,KAAKo4C,QAAQnK,QAAO,SAAU6H,GACrE,OAAOsD,EAAAA,EAAAA,IAAWH,EAASnD,MACxB91C,KAAKo4C,SAGZ9L,EAAOuJ,OAAS,SAAgBx1B,GAC9B,IAAI6sB,EAASltC,KAEbstC,EAAAA,EAAAA,OAAoB,WAClBJ,EAAO5sB,UAAU3f,SAAQ,SAAU2lB,GACjCA,EAASjG,UAKfisB,EAAOkC,QAAU,WACf,IAAI8K,EAASt5C,KAEbstC,EAAAA,EAAAA,OAAoB,WAClBgM,EAAOlB,QAAQz3C,SAAQ,SAAUm1C,GAC/BA,EAAMtH,iBAKZlC,EAAOgD,SAAW,WAChB,IAAIiK,EAASv5C,KAEbstC,EAAAA,EAAAA,OAAoB,WAClBiM,EAAOnB,QAAQz3C,SAAQ,SAAUm1C,GAC/BA,EAAMxG,kBAKL6I,EA3I4B,CA4InCrK,GC3IS0L,EAAwB,WACjC,SAASA,EAASlJ,GAChBtwC,KAAKoH,SAAU8rC,EAAAA,EAAAA,GAAS,GAAI5C,EAAOmC,eAAgBnC,EAAOlpC,SAC1DpH,KAAKy5C,WAAanJ,EAAOmJ,WACzBz5C,KAAK05C,cAAgBpJ,EAAOoJ,cAC5B15C,KAAK2yC,UAAY,GACjB3yC,KAAKuyB,MAAQ+d,EAAO/d,OA6Jf,CACLnD,aAAS0f,EACT7zB,UAAM6zB,EACN5T,MAAO,KACP2U,aAAc,EACdmB,UAAU,EACVgH,OAAQ,OACR2B,eAAW7K,GAnKX9uC,KAAKiN,KAAOqjC,EAAOrjC,KAGrB,IAAIq/B,EAASkN,EAASl6C,UAsJtB,OApJAgtC,EAAOgI,SAAW,SAAkB/hB,GAClCvyB,KAAKm3B,SAAS,CACZ72B,KAAM,WACNiyB,MAAOA,KAIX+Z,EAAOsJ,YAAc,SAAqBd,IACE,IAAtC90C,KAAK2yC,UAAU3mC,QAAQ8oC,IACzB90C,KAAK2yC,UAAUpkC,KAAKumC,IAIxBxI,EAAOyJ,eAAiB,SAAwBjB,GAC9C90C,KAAK2yC,UAAY3yC,KAAK2yC,UAAU1E,QAAO,SAAU5mB,GAC/C,OAAOA,IAAMytB,MAIjBxI,EAAO0D,OAAS,WACd,OAAIhwC,KAAKy0C,SACPz0C,KAAKy0C,QAAQzE,SACNhwC,KAAKy0C,QAAQtD,QAAQ3nB,KAAKkrB,EAAAA,IAAMjrB,MAAMirB,EAAAA,KAGxCtrB,QAAQG,WAGjB+iB,EAAOyE,SAAW,WAChB,OAAI/wC,KAAKy0C,SACPz0C,KAAKy0C,QAAQ1D,WACN/wC,KAAKy0C,QAAQtD,SAGfnxC,KAAK45C,WAGdtN,EAAOsN,QAAU,WACf,IAEI3+B,EAFA0xB,EAAQ3sC,KAGR65C,EAAiC,YAAtB75C,KAAKuyB,MAAMylB,OACtB7G,EAAU/nB,QAAQG,UAuBtB,OArBKswB,IACH75C,KAAKm3B,SAAS,CACZ72B,KAAM,UACNq5C,UAAW35C,KAAKoH,QAAQuyC,YAE1BxI,EAAUA,EAAQ3nB,MAAK,WAEkB,MAAvCmjB,EAAM+M,cAAcpJ,OAAOwJ,UAA4BnN,EAAM+M,cAAcpJ,OAAOwJ,SAASnN,EAAMpa,MAAMonB,UAAWhN,MACjHnjB,MAAK,WACN,OAAiC,MAA1BmjB,EAAMvlC,QAAQ0yC,cAAmB,EAASnN,EAAMvlC,QAAQ0yC,SAASnN,EAAMpa,MAAMonB,cACnFnwB,MAAK,SAAU4F,GACZA,IAAYud,EAAMpa,MAAMnD,SAC1Bud,EAAMxV,SAAS,CACb72B,KAAM,UACN8uB,QAASA,EACTuqB,UAAWhN,EAAMpa,MAAMonB,gBAMxBxI,EAAQ3nB,MAAK,WAClB,OAAOmjB,EAAMoN,qBACZvwB,MAAK,SAAUgjB,GAChBvxB,EAAOuxB,EAEiC,MAAxCG,EAAM+M,cAAcpJ,OAAOgB,WAA6B3E,EAAM+M,cAAcpJ,OAAOgB,UAAUr2B,EAAM0xB,EAAMpa,MAAMonB,UAAWhN,EAAMpa,MAAMnD,QAASud,MAC9InjB,MAAK,WACN,OAAkC,MAA3BmjB,EAAMvlC,QAAQkqC,eAAoB,EAAS3E,EAAMvlC,QAAQkqC,UAAUr2B,EAAM0xB,EAAMpa,MAAMonB,UAAWhN,EAAMpa,MAAMnD,YAClH5F,MAAK,WACN,OAAkC,MAA3BmjB,EAAMvlC,QAAQ4yC,eAAoB,EAASrN,EAAMvlC,QAAQ4yC,UAAU/+B,EAAM,KAAM0xB,EAAMpa,MAAMonB,UAAWhN,EAAMpa,MAAMnD,YACxH5F,MAAK,WAMN,OALAmjB,EAAMxV,SAAS,CACb72B,KAAM,UACN2a,KAAMA,IAGDA,KACNwO,OAAM,SAAUyR,GAKjB,OAHsC,MAAtCyR,EAAM+M,cAAcpJ,OAAOjhC,SAA2Bs9B,EAAM+M,cAAcpJ,OAAOjhC,QAAQ6rB,EAAOyR,EAAMpa,MAAMonB,UAAWhN,EAAMpa,MAAMnD,QAASud,IAE5IZ,EAAAA,EAAAA,KAAY7Q,MAAMA,GACX9R,QAAQG,UAAUC,MAAK,WAC5B,OAAgC,MAAzBmjB,EAAMvlC,QAAQiI,aAAkB,EAASs9B,EAAMvlC,QAAQiI,QAAQ6rB,EAAOyR,EAAMpa,MAAMonB,UAAWhN,EAAMpa,MAAMnD,YAC/G5F,MAAK,WACN,OAAkC,MAA3BmjB,EAAMvlC,QAAQ4yC,eAAoB,EAASrN,EAAMvlC,QAAQ4yC,eAAUlL,EAAW5T,EAAOyR,EAAMpa,MAAMonB,UAAWhN,EAAMpa,MAAMnD,YAC9H5F,MAAK,WAMN,MALAmjB,EAAMxV,SAAS,CACb72B,KAAM,QACN46B,MAAOA,IAGHA,SAKZoR,EAAOyN,gBAAkB,WACvB,IACIE,EADAnN,EAAS9sC,KA6Bb,OA1BAA,KAAKy0C,QAAU,IAAIpE,EAAQ,CACzBjD,GAAI,WACF,OAAKN,EAAO1lC,QAAQ8yC,WAIbpN,EAAO1lC,QAAQ8yC,WAAWpN,EAAOva,MAAMonB,WAHrCvwB,QAAQmoB,OAAO,wBAK1BU,OAAQ,WACNnF,EAAO3V,SAAS,CACd72B,KAAM,YAGV8xC,QAAS,WACPtF,EAAO3V,SAAS,CACd72B,KAAM,WAGV+xC,WAAY,WACVvF,EAAO3V,SAAS,CACd72B,KAAM,cAGVuxC,MAAqD,OAA7CoI,EAAsBj6C,KAAKoH,QAAQyqC,OAAiBoI,EAAsB,EAClFnI,WAAY9xC,KAAKoH,QAAQ0qC,aAEpB9xC,KAAKy0C,QAAQtD,SAGtB7E,EAAOnV,SAAW,SAAkBJ,GAClC,IAAImW,EAASltC,KAEbA,KAAKuyB,MAwBT,SAAiBA,EAAOwE,GACtB,OAAQA,EAAOz2B,MACb,IAAK,SACH,OAAO4yC,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBsd,aAActd,EAAMsd,aAAe,IAGvC,IAAK,QACH,OAAOqD,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBye,UAAU,IAGd,IAAK,WACH,OAAOkC,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBye,UAAU,IAGd,IAAK,UACH,OAAOkC,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBnD,QAAS2H,EAAO3H,QAChBnU,UAAM6zB,EACN5T,MAAO,KACP8V,UAAU,EACVgH,OAAQ,UACR2B,UAAW5iB,EAAO4iB,YAGtB,IAAK,UACH,OAAOzG,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBtX,KAAM8b,EAAO9b,KACbigB,MAAO,KACP8c,OAAQ,UACRhH,UAAU,IAGd,IAAK,QACH,OAAOkC,EAAAA,EAAAA,GAAS,GAAI3gB,EAAO,CACzBtX,UAAM6zB,EACN5T,MAAOnE,EAAOmE,MACd2U,aAActd,EAAMsd,aAAe,EACnCmB,UAAU,EACVgH,OAAQ,UAGZ,IAAK,WACH,OAAO9E,EAAAA,EAAAA,GAAS,GAAI3gB,EAAOwE,EAAOxE,OAEpC,QACE,OAAOA,GAxEIglB,CAAQv3C,KAAKuyB,MAAOwE,GACjCuW,EAAAA,EAAAA,OAAoB,WAClBJ,EAAOyF,UAAUhyC,SAAQ,SAAUm0C,GACjCA,EAASqF,iBAAiBpjB,MAG5BmW,EAAOwM,cAAc7D,OAAO3I,OAIzBsM,EAhK0B,GCA5B,IAAIY,EAA6B,SAAU/L,GAGhD,SAAS+L,EAAc9J,GACrB,IAAI3D,EAMJ,OAJAA,EAAQ0B,EAAchtC,KAAKrB,OAASA,MAC9BswC,OAASA,GAAU,GACzB3D,EAAM0N,UAAY,GAClB1N,EAAM8M,WAAa,EACZ9M,EATTgB,EAAeyM,EAAe/L,GAY9B,IAAI/B,EAAS8N,EAAc96C,UAyF3B,OAvFAgtC,EAAOgM,MAAQ,SAAeC,EAAQnxC,EAASmrB,GAC7C,IAAI+nB,EAAW,IAAId,EAAS,CAC1BE,cAAe15C,KACfy5C,aAAcz5C,KAAKy5C,WACnBryC,QAASmxC,EAAOgC,uBAAuBnzC,GACvCmrB,MAAOA,EACPkgB,eAAgBrrC,EAAQozC,YAAcjC,EAAOkC,oBAAoBrzC,EAAQozC,kBAAe1L,EACxF7hC,KAAM7F,EAAQ6F,OAGhB,OADAjN,KAAKjB,IAAIu7C,GACFA,GAGThO,EAAOvtC,IAAM,SAAau7C,GACxBt6C,KAAKq6C,UAAU9rC,KAAK+rC,GACpBt6C,KAAK61C,OAAOyE,IAGdhO,EAAOqH,OAAS,SAAgB2G,GAC9Bt6C,KAAKq6C,UAAYr6C,KAAKq6C,UAAUpM,QAAO,SAAU5mB,GAC/C,OAAOA,IAAMizB,KAEfA,EAAStK,SACThwC,KAAK61C,OAAOyE,IAGdhO,EAAOuM,MAAQ,WACb,IAAI/L,EAAS9sC,KAEbstC,EAAAA,EAAAA,OAAoB,WAClBR,EAAOuN,UAAU15C,SAAQ,SAAU25C,GACjCxN,EAAO6G,OAAO2G,UAKpBhO,EAAOwM,OAAS,WACd,OAAO94C,KAAKq6C,WAGd/N,EAAOiJ,KAAO,SAAc0D,GAK1B,MAJ6B,qBAAlBA,EAAQE,QACjBF,EAAQE,OAAQ,GAGXn5C,KAAKq6C,UAAU9E,MAAK,SAAU+E,GACnC,OAAOI,EAAAA,EAAAA,IAAczB,EAASqB,OAIlChO,EAAO+M,QAAU,SAAiBJ,GAChC,OAAOj5C,KAAKq6C,UAAUpM,QAAO,SAAUqM,GACrC,OAAOI,EAAAA,EAAAA,IAAczB,EAASqB,OAIlChO,EAAOuJ,OAAS,SAAgByE,GAC9B,IAAIpN,EAASltC,KAEbstC,EAAAA,EAAAA,OAAoB,WAClBJ,EAAO5sB,UAAU3f,SAAQ,SAAU2lB,GACjCA,EAASg0B,UAKfhO,EAAOkC,QAAU,WACfxuC,KAAK26C,yBAGPrO,EAAOgD,SAAW,WAChBtvC,KAAK26C,yBAGPrO,EAAOqO,sBAAwB,WAC7B,IAAIC,EAAkB56C,KAAKq6C,UAAUpM,QAAO,SAAU5mB,GACpD,OAAOA,EAAEkL,MAAMye,YAEjB,OAAO1D,EAAAA,EAAAA,OAAoB,WACzB,OAAOsN,EAAgBC,QAAO,SAAU1J,EAASmJ,GAC/C,OAAOnJ,EAAQ3nB,MAAK,WAClB,OAAO8wB,EAASvJ,WAAWtnB,MAAMirB,EAAAA,SAElCtrB,QAAQG,eAIR6wB,EAtG+B,CAuGtCtM,GCeK,SAASgN,EAAiB1zC,EAAS2zC,GACxC,OAAmC,MAA5B3zC,EAAQ0zC,sBAA2B,EAAS1zC,EAAQ0zC,iBAAiBC,EAAMA,EAAMv8C,OAAS,GAAIu8C,GAEhG,SAASC,EAAqB5zC,EAAS2zC,GAC5C,OAAuC,MAAhC3zC,EAAQ4zC,0BAA+B,EAAS5zC,EAAQ4zC,qBAAqBD,EAAM,GAAIA,GCxHzF,IAAIE,EAA2B,WACpC,SAASA,EAAY3K,QACJ,IAAXA,IACFA,EAAS,IAGXtwC,KAAKk7C,WAAa5K,EAAO4K,YAAc,IAAI/C,EAC3Cn4C,KAAK05C,cAAgBpJ,EAAOoJ,eAAiB,IAAIU,EACjDp6C,KAAKyyC,eAAiBnC,EAAOmC,gBAAkB,GAC/CzyC,KAAKm7C,cAAgB,GACrBn7C,KAAKo7C,iBAAmB,GAG1B,IAAI9O,EAAS2O,EAAY37C,UAsUzB,OApUAgtC,EAAO+O,MAAQ,WACb,IAAI1O,EAAQ3sC,KAEZA,KAAKs7C,iBAAmBlN,EAAaL,WAAU,WACzCK,EAAac,aAAeE,EAAcK,aAC5C9C,EAAM+M,cAAclL,UAEpB7B,EAAMuO,WAAW1M,cAGrBxuC,KAAKu7C,kBAAoBnM,EAAcrB,WAAU,WAC3CK,EAAac,aAAeE,EAAcK,aAC5C9C,EAAM+M,cAAcpK,WAEpB3C,EAAMuO,WAAW5L,gBAKvBhD,EAAOhE,QAAU,WACf,IAAIkT,EAAuBC,EAEwB,OAAlDD,EAAwBx7C,KAAKs7C,mBAAqCE,EAAsBn6C,KAAKrB,MAC1C,OAAnDy7C,EAAwBz7C,KAAKu7C,oBAAsCE,EAAsBp6C,KAAKrB,OAGjGssC,EAAOoH,WAAa,SAAoBqF,EAAMC,GAC5C,IACIC,GADmBC,EAAAA,EAAAA,IAAgBH,EAAMC,GACd,GAG/B,OADAC,EAAQyC,UAAW,EACZ17C,KAAKk7C,WAAW7B,QAAQJ,GAASz6C,QAG1C8tC,EAAOqP,WAAa,SAAoB1C,GACtC,OAAOj5C,KAAK05C,cAAcL,SAAQnG,EAAAA,EAAAA,GAAS,GAAI+F,EAAS,CACtDyC,UAAU,KACRl9C,QAGN8tC,EAAOsP,aAAe,SAAsBhJ,EAAUqG,GACpD,IAAI4C,EAEJ,OAA4E,OAApEA,EAAwB77C,KAAKk7C,WAAW3F,KAAK3C,EAAUqG,SAAoB,EAAS4C,EAAsBtpB,MAAMtX,MAG1HqxB,EAAOwP,eAAiB,SAAwBC,GAC9C,OAAO/7C,KAAKg8C,gBAAgB3C,QAAQ0C,GAAmBE,KAAI,SAAUC,GAInE,MAAO,CAHQA,EAAKtJ,SACRsJ,EAAK3pB,MACAtX,UAKrBqxB,EAAO6P,aAAe,SAAsBvJ,EAAUpgB,EAASprB,GAC7D,IAAIg1C,GAAgBC,EAAAA,EAAAA,IAAezJ,GAC/B0J,EAAmBt8C,KAAK04C,oBAAoB0D,GAChD,OAAOp8C,KAAKk7C,WAAW5C,MAAMt4C,KAAMs8C,GAAkB1I,QAAQphB,EAASprB,IAGxEklC,EAAOiQ,eAAiB,SAAwBR,EAAmBvpB,EAASprB,GAC1E,IAAI0lC,EAAS9sC,KAEb,OAAOstC,EAAAA,EAAAA,OAAoB,WACzB,OAAOR,EAAOkP,gBAAgB3C,QAAQ0C,GAAmBE,KAAI,SAAUO,GACrE,IAAI5J,EAAW4J,EAAM5J,SACrB,MAAO,CAACA,EAAU9F,EAAOqP,aAAavJ,EAAUpgB,EAASprB,WAK/DklC,EAAOmQ,cAAgB,SAAuB7J,EAAUqG,GACtD,IAAIyD,EAEJ,OAA6E,OAArEA,EAAyB18C,KAAKk7C,WAAW3F,KAAK3C,EAAUqG,SAAoB,EAASyD,EAAuBnqB,OAGtH+Z,EAAOqQ,cAAgB,SAAuB5D,EAAMC,GAClD,IACIC,GADoBC,EAAAA,EAAAA,IAAgBH,EAAMC,GACd,GAE5BkC,EAAal7C,KAAKk7C,WACtB5N,EAAAA,EAAAA,OAAoB,WAClB4N,EAAW7B,QAAQJ,GAASt4C,SAAQ,SAAUm1C,GAC5CoF,EAAWvH,OAAOmC,UAKxBxJ,EAAOsQ,aAAe,SAAsB7D,EAAMC,EAAM6D,GACtD,IAAI3P,EAASltC,KAET88C,GAAoB5D,EAAAA,EAAAA,IAAgBH,EAAMC,EAAM6D,GAChD5D,EAAU6D,EAAkB,GAC5B11C,EAAU01C,EAAkB,GAE5B5B,EAAal7C,KAAKk7C,WAElB6B,GAAiB7J,EAAAA,EAAAA,GAAS,GAAI+F,EAAS,CACzC+D,QAAQ,IAGV,OAAO1P,EAAAA,EAAAA,OAAoB,WAIzB,OAHA4N,EAAW7B,QAAQJ,GAASt4C,SAAQ,SAAUm1C,GAC5CA,EAAMnB,WAEDzH,EAAO+P,eAAeF,EAAgB31C,OAIjDklC,EAAO4Q,cAAgB,SAAuBnE,EAAMC,EAAM6D,GACxD,IAAIvD,EAASt5C,KAETm9C,GAAoBjE,EAAAA,EAAAA,IAAgBH,EAAMC,EAAM6D,GAChD5D,EAAUkE,EAAkB,GAC5BC,EAAqBD,EAAkB,GACvCtM,OAAuC,IAAvBuM,EAAgC,GAAKA,EAErB,qBAAzBvM,EAAcX,SACvBW,EAAcX,QAAS,GAGzB,IAAImN,EAAW/P,EAAAA,EAAAA,OAAoB,WACjC,OAAOgM,EAAO4B,WAAW7B,QAAQJ,GAASgD,KAAI,SAAUnG,GACtD,OAAOA,EAAM9F,OAAOa,SAGxB,OAAOznB,QAAQk0B,IAAID,GAAU7zB,KAAKkrB,EAAAA,IAAMjrB,MAAMirB,EAAAA,KAGhDpI,EAAOiR,kBAAoB,SAA2BxE,EAAMC,EAAM6D,GAChE,IAAIW,EACAC,EACAC,EACAnE,EAASv5C,KAET29C,GAAoBzE,EAAAA,EAAAA,IAAgBH,EAAMC,EAAM6D,GAChD5D,EAAU0E,EAAkB,GAC5Bv2C,EAAUu2C,EAAkB,GAE5BZ,GAAiB7J,EAAAA,EAAAA,GAAS,GAAI+F,EAAS,CAGzC+D,OAAsH,OAA7GQ,EAA2D,OAAlDC,EAAwBxE,EAAQ2E,eAAyBH,EAAwBxE,EAAQ+D,SAAkBQ,EAC7HK,SAA+D,OAApDH,EAAwBzE,EAAQ6E,kBAA2BJ,IAGxE,OAAOpQ,EAAAA,EAAAA,OAAoB,WAKzB,OAJAiM,EAAO2B,WAAW7B,QAAQJ,GAASt4C,SAAQ,SAAUm1C,GACnDA,EAAMG,gBAGDsD,EAAO0D,eAAeF,EAAgB31C,OAIjDklC,EAAO2Q,eAAiB,SAAwBlE,EAAMC,EAAM6D,GAC1D,IAAIkB,EAAS/9C,KAETg+C,GAAoB9E,EAAAA,EAAAA,IAAgBH,EAAMC,EAAM6D,GAChD5D,EAAU+E,EAAkB,GAC5B52C,EAAU42C,EAAkB,GAE5BX,EAAW/P,EAAAA,EAAAA,OAAoB,WACjC,OAAOyQ,EAAO7C,WAAW7B,QAAQJ,GAASgD,KAAI,SAAUnG,GACtD,OAAOA,EAAMI,WAAMpH,GAAWoE,EAAAA,EAAAA,GAAS,GAAI9rC,EAAS,CAClD6F,KAAM,CACJgxC,YAAwB,MAAXhF,OAAkB,EAASA,EAAQgF,sBAKpD9M,EAAU/nB,QAAQk0B,IAAID,GAAU7zB,KAAKkrB,EAAAA,IAMzC,OAJiB,MAAXttC,OAAkB,EAASA,EAAQ82C,gBACvC/M,EAAUA,EAAQ1nB,MAAMirB,EAAAA,KAGnBvD,GAGT7E,EAAO6R,WAAa,SAAoBpF,EAAMC,EAAM6D,GAClD,IAAIT,GAAgBC,EAAAA,EAAAA,IAAetD,EAAMC,EAAM6D,GAC3CP,EAAmBt8C,KAAK04C,oBAAoB0D,GAEV,qBAA3BE,EAAiBzK,QAC1ByK,EAAiBzK,OAAQ,GAG3B,IAAIiE,EAAQ91C,KAAKk7C,WAAW5C,MAAMt4C,KAAMs8C,GACxC,OAAOxG,EAAMX,cAAcmH,EAAiBlH,WAAaU,EAAMI,MAAMoG,GAAoBlzB,QAAQG,QAAQusB,EAAMvjB,MAAMtX,OAGvHqxB,EAAO8R,cAAgB,SAAuBrF,EAAMC,EAAM6D,GACxD,OAAO78C,KAAKm+C,WAAWpF,EAAMC,EAAM6D,GAAMrzB,KAAKkrB,EAAAA,IAAMjrB,MAAMirB,EAAAA,KAG5DpI,EAAO+R,mBAAqB,SAA4BtF,EAAMC,EAAM6D,GAClE,IAAIT,GAAgBC,EAAAA,EAAAA,IAAetD,EAAMC,EAAM6D,GAE/C,OADAT,EAAcjF,SD7NT,CACLC,QAAS,SAAiBhoB,GACxBA,EAAQ8nB,QAAU,WAChB,IAAIb,EAAuBY,EAAwBqH,EAAwBC,EAAwBC,EAAqBC,EAoDpHtN,EAlDA8M,EAAgE,OAAjD5H,EAAwBjnB,EAAQ+mB,eAA0F,OAAxDc,EAAyBZ,EAAsBppC,WAAzD,EAAkFgqC,EAAuBgH,YAChLS,EAA+D,OAAlDJ,EAAyBlvB,EAAQ+mB,eAA2F,OAAzDoI,EAAyBD,EAAuBrxC,WAA1D,EAAmFsxC,EAAuBG,UAChL5H,EAAyB,MAAb4H,OAAoB,EAASA,EAAU5H,UACnD6H,EAA4E,aAAzC,MAAbD,OAAoB,EAASA,EAAUE,WAC7DC,EAAgF,cAAzC,MAAbH,OAAoB,EAASA,EAAUE,WACjEE,GAA0D,OAA7CN,EAAsBpvB,EAAQmD,MAAMtX,WAAgB,EAASujC,EAAoBzD,QAAU,GACxGgE,GAAgE,OAA9CN,EAAuBrvB,EAAQmD,MAAMtX,WAAgB,EAASwjC,EAAqBO,aAAe,GACpHrI,GAAkBC,EAAAA,EAAAA,MAClBqI,EAAiC,MAAnBtI,OAA0B,EAASA,EAAgBI,OACjEmI,EAAgBH,EAChBI,GAAY,EAEZ1I,EAAUrnB,EAAQhoB,QAAQqvC,SAAW,WACvC,OAAOrtB,QAAQmoB,OAAO,oBAGpB6N,EAAgB,SAAuBrE,EAAO7tC,EAAOmyC,EAAMC,GAE7D,OADAJ,EAAgBI,EAAW,CAACpyC,GAAOgZ,OAAOg5B,GAAiB,GAAGh5B,OAAOg5B,EAAe,CAAChyC,IAC9EoyC,EAAW,CAACD,GAAMn5B,OAAO60B,GAAS,GAAG70B,OAAO60B,EAAO,CAACsE,KAIzDE,EAAY,SAAmBxE,EAAOyE,EAAQtyC,EAAOoyC,GACvD,GAAIH,EACF,OAAO/1B,QAAQmoB,OAAO,aAGxB,GAAqB,qBAAVrkC,IAA0BsyC,GAAUzE,EAAMv8C,OACnD,OAAO4qB,QAAQG,QAAQwxB,GAGzB,IAAIlE,EAAiB,CACnBjE,SAAUxjB,EAAQwjB,SAClBmE,OAAQkI,EACRnI,UAAW5pC,EACXD,KAAMmiB,EAAQniB,MAEZwyC,EAAgBhJ,EAAQI,GACxB1F,EAAU/nB,QAAQG,QAAQk2B,GAAej2B,MAAK,SAAU61B,GAC1D,OAAOD,EAAcrE,EAAO7tC,EAAOmyC,EAAMC,MAQ3C,OALIvP,EAAa0P,KACItO,EACNnB,OAASyP,EAAczP,QAG/BmB,GAKT,GAAK2N,EAAStgD,OAGT,GAAImgD,EAAoB,CACzB,IAAIa,EAA8B,qBAAd1I,EAChB5pC,EAAQsyC,EAAS1I,EAAYgE,EAAiB1rB,EAAQhoB,QAAS03C,GACnE3N,EAAUoO,EAAUT,EAAUU,EAAQtyC,QAEnC,GAAI2xC,EAAwB,CAC7B,IAAIa,EAA+B,qBAAd5I,EAEjB6I,EAASD,EAAU5I,EAAYkE,EAAqB5rB,EAAQhoB,QAAS03C,GAEzE3N,EAAUoO,EAAUT,EAAUY,EAASC,GAAQ,QAG7C,WACET,EAAgB,GAChB,IAAIM,EAAqD,qBAArCpwB,EAAQhoB,QAAQ0zC,iBAChC8E,GAAuB3B,IAAea,EAAS,IAAKb,EAAYa,EAAS,GAAI,EAAGA,GAEpF3N,EAAUyO,EAAuBL,EAAU,GAAIC,EAAQT,EAAc,IAAM31B,QAAQG,QAAQ61B,EAAc,GAAIL,EAAc,GAAID,EAAS,KAgBxI,IAdA,IAAIe,EAAQ,SAAeC,GACzB3O,EAAUA,EAAQ3nB,MAAK,SAAUuxB,GAG/B,IAF0BkD,IAAea,EAASgB,IAAK7B,EAAYa,EAASgB,GAAIA,EAAGhB,GAE1D,CACvB,IAAIiB,EAAUP,EAAST,EAAce,GAAKhF,EAAiB1rB,EAAQhoB,QAAS2zC,GAE5E,OAAOwE,EAAUxE,EAAOyE,EAAQO,GAGlC,OAAO32B,QAAQG,QAAQ61B,EAAcrE,EAAOgE,EAAce,GAAIhB,EAASgB,SAIlEA,EAAI,EAAGA,EAAIhB,EAAStgD,OAAQshD,IACnCD,EAAMC,GAtBV,QAfN3O,EAAUoO,EAAU,IA0CtB,IAAIS,EAAe7O,EAAQ3nB,MAAK,SAAUuxB,GACxC,MAAO,CACLA,MAAOA,EACPiE,WAAYE,MAchB,OAXwBc,EAENhQ,OAAS,WACzBmP,GAAY,EACO,MAAnBxI,GAAmCA,EAAgB/F,QAE/Cb,EAAaoB,IACfA,EAAQnB,UAILgQ,KCyGJhgD,KAAKm+C,WAAW/B,IAGzB9P,EAAO2T,sBAAwB,SAA+BlH,EAAMC,EAAM6D,GACxE,OAAO78C,KAAKq+C,mBAAmBtF,EAAMC,EAAM6D,GAAMrzB,KAAKkrB,EAAAA,IAAMjrB,MAAMirB,EAAAA,KAGpEpI,EAAO4T,gBAAkB,WACvB,IAAIC,EAASngD,KAETq9C,EAAW/P,EAAAA,EAAAA,OAAoB,WACjC,OAAO6S,EAAOzG,cAAcZ,SAASmD,KAAI,SAAU3B,GACjD,OAAOA,EAAStK,eAGpB,OAAO5mB,QAAQk0B,IAAID,GAAU7zB,KAAKkrB,EAAAA,IAAMjrB,MAAMirB,EAAAA,KAGhDpI,EAAOqO,sBAAwB,WAC7B,OAAO36C,KAAKogD,mBAAmBzF,yBAGjCrO,EAAOyN,gBAAkB,SAAyB3yC,GAChD,OAAOpH,KAAK05C,cAAcpB,MAAMt4C,KAAMoH,GAASwyC,WAGjDtN,EAAO0P,cAAgB,WACrB,OAAOh8C,KAAKk7C,YAGd5O,EAAO8T,iBAAmB,WACxB,OAAOpgD,KAAK05C,eAGdpN,EAAO+T,kBAAoB,WACzB,OAAOrgD,KAAKyyC,gBAGdnG,EAAO+G,kBAAoB,SAA2BjsC,GACpDpH,KAAKyyC,eAAiBrrC,GAGxBklC,EAAOgU,iBAAmB,SAA0B1N,EAAUxrC,GAC5D,IAAIolC,EAASxsC,KAAKm7C,cAAc5F,MAAK,SAAUluB,GAC7C,OAAOk5B,EAAAA,EAAAA,IAAa3N,MAAc2N,EAAAA,EAAAA,IAAal5B,EAAEurB,aAG/CpG,EACFA,EAAOiG,eAAiBrrC,EAExBpH,KAAKm7C,cAAc5sC,KAAK,CACtBqkC,SAAUA,EACVH,eAAgBrrC,KAKtBklC,EAAOqM,iBAAmB,SAA0B/F,GAClD,IAAI4N,EAEJ,OAAO5N,EAEA,OAFY4N,EAAwBxgD,KAAKm7C,cAAc5F,MAAK,SAAUluB,GAC3E,OAAOo5B,EAAAA,EAAAA,IAAgB7N,EAAUvrB,EAAEurB,mBACvB,EAAS4N,EAAsB/N,oBAAiB3D,GAGhExC,EAAOoU,oBAAsB,SAA6BlG,EAAapzC,GACrE,IAAIolC,EAASxsC,KAAKo7C,iBAAiB7F,MAAK,SAAUluB,GAChD,OAAOk5B,EAAAA,EAAAA,IAAa/F,MAAiB+F,EAAAA,EAAAA,IAAal5B,EAAEmzB,gBAGlDhO,EACFA,EAAOiG,eAAiBrrC,EAExBpH,KAAKo7C,iBAAiB7sC,KAAK,CACzBisC,YAAaA,EACb/H,eAAgBrrC,KAKtBklC,EAAOmO,oBAAsB,SAA6BD,GACxD,IAAImG,EAEJ,OAAOnG,EAEA,OAFemG,EAAwB3gD,KAAKo7C,iBAAiB7F,MAAK,SAAUluB,GACjF,OAAOo5B,EAAAA,EAAAA,IAAgBjG,EAAanzB,EAAEmzB,sBAC1B,EAASmG,EAAsBlO,oBAAiB3D,GAGhExC,EAAOoM,oBAAsB,SAA6BtxC,GACxD,GAAe,MAAXA,OAAkB,EAASA,EAAQw5C,WACrC,OAAOx5C,EAGT,IAAIk1C,GAAmBpJ,EAAAA,EAAAA,GAAS,GAAIlzC,KAAKyyC,eAAe2F,QAASp4C,KAAK24C,iBAA4B,MAAXvxC,OAAkB,EAASA,EAAQwrC,UAAWxrC,EAAS,CAC5Iw5C,YAAY,IAOd,OAJKtE,EAAiBzJ,WAAayJ,EAAiB1J,WAClD0J,EAAiBzJ,WAAY4F,EAAAA,EAAAA,IAAsB6D,EAAiB1J,SAAU0J,IAGzEA,GAGThQ,EAAOuU,4BAA8B,SAAqCz5C,GACxE,OAAOpH,KAAK04C,oBAAoBtxC,IAGlCklC,EAAOiO,uBAAyB,SAAgCnzC,GAC9D,OAAe,MAAXA,OAAkB,EAASA,EAAQw5C,YAC9Bx5C,GAGF8rC,EAAAA,EAAAA,GAAS,GAAIlzC,KAAKyyC,eAAe4H,UAAWr6C,KAAKy6C,oBAA+B,MAAXrzC,OAAkB,EAASA,EAAQozC,aAAcpzC,EAAS,CACpIw5C,YAAY,KAIhBtU,EAAOuM,MAAQ,WACb74C,KAAKk7C,WAAWrC,QAChB74C,KAAK05C,cAAcb,SAGdoC,EAnV6B,meCN3BvM,EAA6B,qBAAXzvC,OACtB,SAASy1C,KAGT,SAASV,EAAiBxhB,EAAS1lB,GACxC,MAA0B,oBAAZ0lB,EAAyBA,EAAQ1lB,GAAS0lB,EAEnD,SAAS+gB,EAAextC,GAC7B,MAAwB,kBAAVA,GAAsBA,GAAS,GAAKA,IAAU69B,IAEvD,SAAS8S,EAAoB3wC,GAClC,OAAOkB,MAAMC,QAAQnB,GAASA,EAAQ,CAACA,GAYlC,SAASsvC,EAAehB,EAAWe,GACxC,OAAOjjC,KAAKihC,IAAIiB,GAAae,GAAa,GAAK38B,KAAKC,MAAO,GAEtD,SAAS2jC,EAAetD,EAAMC,EAAM6D,GACzC,OAAKiE,EAAW/H,GAII,oBAATC,GACF9F,EAAAA,EAAAA,GAAS,GAAI2J,EAAM,CACxBjK,SAAUmG,EACVtC,QAASuC,KAIN9F,EAAAA,EAAAA,GAAS,GAAI8F,EAAM,CACxBpG,SAAUmG,IAXHA,EAoCJ,SAASG,EAAgBH,EAAMC,EAAM6D,GAC1C,OAAOiE,EAAW/H,GAAQ,EAAC7F,EAAAA,EAAAA,GAAS,GAAI8F,EAAM,CAC5CpG,SAAUmG,IACR8D,GAAQ,CAAC9D,GAAQ,GAAIC,GAmBpB,SAASI,EAAWH,EAASnD,GAClC,IAAIkH,EAAS/D,EAAQ+D,OACjB7D,EAAQF,EAAQE,MAChBuC,EAAWzC,EAAQyC,SACnBmC,EAAW5E,EAAQ4E,SACnBkD,EAAY9H,EAAQ8H,UACpBnO,EAAWqG,EAAQrG,SACnBoO,EAAQ/H,EAAQ+H,MAEpB,GAAIF,EAAWlO,GACb,GAAIuG,GACF,GAAIrD,EAAMjD,YAAc4F,EAAsB7F,EAAUkD,EAAM1uC,SAC5D,OAAO,OAEJ,IAAKq5C,EAAgB3K,EAAMlD,SAAUA,GAC1C,OAAO,EAIX,IAAIqO,EA/BC,SAA8BjE,EAAQa,GAC3C,OAAe,IAAXb,IAAgC,IAAba,GAA+B,MAAVb,GAA8B,MAAZa,EACrD,OACa,IAAXb,IAAiC,IAAba,EACtB,QAIkB,MAAVb,EAAiBA,GAAUa,GACxB,SAAW,WAsBPqD,CAAqBlE,EAAQa,GAErD,GAA0B,SAAtBoD,EACF,OAAO,EACF,GAA0B,QAAtBA,EAA6B,CACtC,IAAIrM,EAAWkB,EAAMlB,WAErB,GAA0B,WAAtBqM,IAAmCrM,EACrC,OAAO,EAGT,GAA0B,aAAtBqM,GAAoCrM,EACtC,OAAO,EAIX,OAAqB,mBAAVoM,GAAuBlL,EAAMd,YAAcgM,MAI9B,mBAAbtF,GAA0B5F,EAAMpC,eAAiBgI,MAIxDqF,IAAcA,EAAUjL,KAMvB,SAAS4E,EAAczB,EAASqB,GACrC,IAAInB,EAAQF,EAAQE,MAChBuC,EAAWzC,EAAQyC,SACnBqF,EAAY9H,EAAQ8H,UACpBvG,EAAcvB,EAAQuB,YAE1B,GAAIsG,EAAWtG,GAAc,CAC3B,IAAKF,EAASlzC,QAAQozC,YACpB,OAAO,EAGT,GAAIrB,GACF,GAAIoH,EAAajG,EAASlzC,QAAQozC,eAAiB+F,EAAa/F,GAC9D,OAAO,OAEJ,IAAKiG,EAAgBnG,EAASlzC,QAAQozC,YAAaA,GACxD,OAAO,EAIX,OAAwB,mBAAbkB,GAAoD,YAA1BpB,EAAS/nB,MAAMylB,SAAyB0D,MAIzEqF,IAAcA,EAAUzG,IAMvB,SAAS7B,EAAsB7F,EAAUxrC,GAE9C,QADyB,MAAXA,OAAkB,EAASA,EAAQ+5C,iBAAmBZ,GACtD3N,GAMT,SAAS2N,EAAa3N,GAC3B,IAO8B7sC,EAP1Bq7C,EAAU1K,EAAoB9D,GAClC,OAM8B7sC,EANPq7C,EAOhB1Y,KAAKC,UAAU5iC,GAAO,SAAUs7C,EAAGC,GACxC,OAAOC,EAAcD,GAAOjiD,OAAO6M,KAAKo1C,GAAKE,OAAO3G,QAAO,SAAUrO,EAAQjwB,GAE3E,OADAiwB,EAAOjwB,GAAO+kC,EAAI/kC,GACXiwB,IACN,IAAM8U,KAON,SAASb,EAAgBriD,EAAGC,GACjC,OAAOojD,EAAiB/K,EAAoBt4C,GAAIs4C,EAAoBr4C,IAM/D,SAASojD,EAAiBrjD,EAAGC,GAClC,OAAID,IAAMC,UAICD,WAAaC,OAIpBD,IAAKC,GAAkB,kBAAND,GAA+B,kBAANC,KACpCgB,OAAO6M,KAAK7N,GAAGw2C,MAAK,SAAUt4B,GACpC,OAAQklC,EAAiBrjD,EAAEme,GAAMle,EAAEke,QAYlC,SAAS43B,EAAiB/1C,EAAGC,GAClC,GAAID,IAAMC,EACR,OAAOD,EAGT,IAAIsjD,EAAQz6C,MAAMC,QAAQ9I,IAAM6I,MAAMC,QAAQ7I,GAE9C,GAAIqjD,GAASH,EAAcnjD,IAAMmjD,EAAcljD,GAAI,CAOjD,IANA,IAAIsjD,EAAQD,EAAQtjD,EAAEI,OAASa,OAAO6M,KAAK9N,GAAGI,OAC1CojD,EAASF,EAAQrjD,EAAIgB,OAAO6M,KAAK7N,GACjCwjD,EAAQD,EAAOpjD,OACfsjD,EAAOJ,EAAQ,GAAK,GACpBK,EAAa,EAERjC,EAAI,EAAGA,EAAI+B,EAAO/B,IAAK,CAC9B,IAAIvjC,EAAMmlC,EAAQ5B,EAAI8B,EAAO9B,GAC7BgC,EAAKvlC,GAAO43B,EAAiB/1C,EAAEme,GAAMle,EAAEke,IAEnCulC,EAAKvlC,KAASne,EAAEme,IAClBwlC,IAIJ,OAAOJ,IAAUE,GAASE,IAAeJ,EAAQvjD,EAAI0jD,EAGvD,OAAOzjD,EAoBF,SAASkjD,EAAc/T,GAC5B,IAAKwU,EAAmBxU,GACtB,OAAO,EAIT,IAAIyU,EAAOzU,EAAEnoC,YAEb,GAAoB,qBAAT48C,EACT,OAAO,EAIT,IAAIC,EAAOD,EAAK3iD,UAEhB,QAAK0iD,EAAmBE,MAKnBA,EAAK3iD,eAAe,iBAQ3B,SAASyiD,EAAmBxU,GAC1B,MAA6C,oBAAtCnuC,OAAOC,UAAUgJ,SAASjH,KAAKmsC,GAGjC,SAASsT,EAAW/6C,GACzB,MAAwB,kBAAVA,GAAsBkB,MAAMC,QAAQnB,GAK7C,SAASmsC,EAAMiQ,GACpB,OAAO,IAAI/4B,SAAQ,SAAUG,GAC3BP,WAAWO,EAAS44B,MAQjB,SAASvV,EAAkBlc,GAChCtH,QAAQG,UAAUC,KAAKkH,GAAUjH,OAAM,SAAUyR,GAC/C,OAAOlS,YAAW,WAChB,MAAMkS,QAIL,SAAS0b,IACd,GAA+B,oBAApBwL,gBACT,OAAO,IAAIA,qYCxUJ3W,SAA0B4W,wBCCrC/U,EAAAA,EAAAA,uBAAqC7B,gBCF1BK,EAAS7Q,SCEpB+Q,EAAAA,EAAAA,GAAUF,gBCDNwW,EAA8BC,EAAAA,mBAAoBzT,GAClD0T,EAAyCD,EAAAA,eAAoB,GAOjE,SAASE,EAAsBC,GAC7B,OAAIA,GAAoC,qBAAXzjD,QACtBA,OAAO0jD,0BACV1jD,OAAO0jD,wBAA0BL,GAG5BrjD,OAAO0jD,yBAGTL,EAGF,IASIM,EAAsB,SAA6B1G,GAC5D,IAAI3D,EAAS2D,EAAK3D,OACdsK,EAAsB3G,EAAKwG,eAC3BA,OAAyC,IAAxBG,GAAyCA,EAC1Dn7C,EAAWw0C,EAAKx0C,SACpB66C,EAAAA,WAAgB,WAEd,OADAhK,EAAO8C,QACA,WACL9C,EAAOjQ,aAER,CAACiQ,IACJ,IAAIuK,EAAUL,EAAsBC,GACpC,OAAoBH,EAAAA,cAAoBC,EAA0BO,SAAU,CAC1Eh9C,MAAO28C,GACOH,EAAAA,cAAoBO,EAAQC,SAAU,CACpDh9C,MAAOwyC,GACN7wC,2CCrCY5H,EAAE7B,EAAQ,KAASiG,EAAElC,OAAOC,IAAI,iBAAiB+B,EAAEhC,OAAOC,IAAI,kBAAkBmN,EAAE/P,OAAOC,UAAUC,eAAe2nB,EAAEpnB,EAAEgC,mDAAmDq6B,kBAAkBh+B,EAAE,CAACoe,KAAI,EAAG6W,KAAI,EAAG4vB,QAAO,EAAGC,UAAS,GAChP,SAASjyB,EAAE1yB,EAAEF,EAAE2B,GAAG,IAAI1B,EAAEuB,EAAE,GAAGC,EAAE,KAAKoE,EAAE,KAAiF,IAAI5F,UAAhF,IAAS0B,IAAIF,EAAE,GAAGE,QAAG,IAAS3B,EAAEme,MAAM1c,EAAE,GAAGzB,EAAEme,UAAK,IAASne,EAAEg1B,MAAMnvB,EAAE7F,EAAEg1B,KAAch1B,EAAEgR,EAAE/N,KAAKjD,EAAEC,KAAKF,EAAEoB,eAAelB,KAAKuB,EAAEvB,GAAGD,EAAEC,IAAI,GAAGC,GAAGA,EAAE8vB,aAAa,IAAI/vB,KAAKD,EAAEE,EAAE8vB,kBAAe,IAASxuB,EAAEvB,KAAKuB,EAAEvB,GAAGD,EAAEC,IAAI,MAAM,CAACqG,SAASR,EAAE5D,KAAKhC,EAAEie,IAAI1c,EAAEuzB,IAAInvB,EAAE4uB,MAAMjzB,EAAEyzB,OAAOnM,EAAE3W,SAA4Bs6B,EAAQqY,IAAIlyB,EAAE6Z,EAAQsY,KAAKnyB,kCCD7V,IAAIhtB,EAAEhC,OAAOC,IAAI,iBAAiBilB,EAAEllB,OAAOC,IAAI,gBAAgB9D,EAAE6D,OAAOC,IAAI,kBAAkB+uB,EAAEhvB,OAAOC,IAAI,qBAAqBgvB,EAAEjvB,OAAOC,IAAI,kBAAkBklB,EAAEnlB,OAAOC,IAAI,kBAAkBqlB,EAAEtlB,OAAOC,IAAI,iBAAiBtC,EAAEqC,OAAOC,IAAI,qBAAqBslB,EAAEvlB,OAAOC,IAAI,kBAAkBolB,EAAErlB,OAAOC,IAAI,cAAcivB,EAAElvB,OAAOC,IAAI,cAAcxB,EAAEuB,OAAOe,SACzW,IAAImO,EAAE,CAACwgB,UAAU,WAAW,OAAM,GAAIO,mBAAmB,aAAaD,oBAAoB,aAAaJ,gBAAgB,cAAcne,EAAEpU,OAAO8D,OAAOojB,EAAE,GAAG,SAASgE,EAAEnsB,EAAEC,EAAEwB,GAAGG,KAAK6yB,MAAMz0B,EAAE4B,KAAKovB,QAAQ/wB,EAAE2B,KAAKuxB,KAAKhL,EAAEvmB,KAAKwyB,QAAQ3yB,GAAGqR,EACyI,SAASsW,KAA6B,SAASgD,EAAEpsB,EAAEC,EAAEwB,GAAGG,KAAK6yB,MAAMz0B,EAAE4B,KAAKovB,QAAQ/wB,EAAE2B,KAAKuxB,KAAKhL,EAAEvmB,KAAKwyB,QAAQ3yB,GAAGqR,EADvPqZ,EAAEjrB,UAAUsnC,iBAAiB,GACnQrc,EAAEjrB,UAAUg1C,SAAS,SAASl2C,EAAEC,GAAG,GAAG,kBAAkBD,GAAG,oBAAoBA,GAAG,MAAMA,EAAE,MAAMiF,MAAM,yHAAyHrD,KAAKwyB,QAAQZ,gBAAgB5xB,KAAK5B,EAAEC,EAAE,aAAaksB,EAAEjrB,UAAU8jD,YAAY,SAAShlD,GAAG4B,KAAKwyB,QAAQP,mBAAmBjyB,KAAK5B,EAAE,gBAA8BopB,EAAEloB,UAAUirB,EAAEjrB,UAAsF,IAAIorB,EAAEF,EAAElrB,UAAU,IAAIkoB,EACrfkD,EAAErlB,YAAYmlB,EAAE/W,EAAEiX,EAAEH,EAAEjrB,WAAWorB,EAAE0H,sBAAqB,EAAG,IAAItF,EAAE7lB,MAAMC,QAAQkgB,EAAE/nB,OAAOC,UAAUC,eAAeqxB,EAAE,CAACrgB,QAAQ,MAAMshB,EAAE,CAACtV,KAAI,EAAG6W,KAAI,EAAG4vB,QAAO,EAAGC,UAAS,GACtK,SAASluB,EAAE32B,EAAEC,EAAEwB,GAAG,IAAID,EAAEtB,EAAE,GAAG4F,EAAE,KAAKD,EAAE,KAAK,GAAG,MAAM5F,EAAE,IAAIuB,UAAK,IAASvB,EAAE+0B,MAAMnvB,EAAE5F,EAAE+0B,UAAK,IAAS/0B,EAAEke,MAAMrY,EAAE,GAAG7F,EAAEke,KAAKle,EAAE+oB,EAAE/lB,KAAKhD,EAAEuB,KAAKiyB,EAAEtyB,eAAeK,KAAKtB,EAAEsB,GAAGvB,EAAEuB,IAAI,IAAIG,EAAExB,UAAUC,OAAO,EAAE,GAAG,IAAIuB,EAAEzB,EAAEoJ,SAAS7H,OAAO,GAAG,EAAEE,EAAE,CAAC,IAAI,IAAID,EAAEmH,MAAMlH,GAAGqP,EAAE,EAAEA,EAAErP,EAAEqP,IAAItP,EAAEsP,GAAG7Q,UAAU6Q,EAAE,GAAG9Q,EAAEoJ,SAAS5H,EAAE,GAAG1B,GAAGA,EAAEgwB,aAAa,IAAIxuB,KAAKG,EAAE3B,EAAEgwB,kBAAe,IAAS9vB,EAAEsB,KAAKtB,EAAEsB,GAAGG,EAAEH,IAAI,MAAM,CAAC8E,SAASV,EAAE1D,KAAKlC,EAAEme,IAAIrY,EAAEkvB,IAAInvB,EAAE4uB,MAAMv0B,EAAE+0B,OAAOzC,EAAErgB,SACxU,SAASmlB,EAAEt3B,GAAG,MAAM,kBAAkBA,GAAG,OAAOA,GAAGA,EAAEsG,WAAWV,EAAqG,IAAI2xB,EAAE,OAAO,SAASK,EAAE53B,EAAEC,GAAG,MAAM,kBAAkBD,GAAG,OAAOA,GAAG,MAAMA,EAAEme,IAA7K,SAAgBne,GAAG,IAAIC,EAAE,CAAC,IAAI,KAAK,IAAI,MAAM,MAAM,IAAID,EAAEuD,QAAQ,SAAQ,SAASvD,GAAG,OAAOC,EAAED,MAAmFilD,CAAO,GAAGjlD,EAAEme,KAAKle,EAAEiK,SAAS,IAC5W,SAASsvB,EAAEx5B,EAAEC,EAAEwB,EAAED,EAAEtB,GAAG,IAAI4F,SAAS9F,EAAK,cAAc8F,GAAG,YAAYA,IAAE9F,EAAE,MAAK,IAAI6F,GAAE,EAAG,GAAG,OAAO7F,EAAE6F,GAAE,OAAQ,OAAOC,GAAG,IAAK,SAAS,IAAK,SAASD,GAAE,EAAG,MAAM,IAAK,SAAS,OAAO7F,EAAEsG,UAAU,KAAKV,EAAE,KAAKkjB,EAAEjjB,GAAE,GAAI,GAAGA,EAAE,OAAW3F,EAAEA,EAAN2F,EAAE7F,GAASA,EAAE,KAAKwB,EAAE,IAAIo2B,EAAE/xB,EAAE,GAAGrE,EAAEktB,EAAExuB,IAAIuB,EAAE,GAAG,MAAMzB,IAAIyB,EAAEzB,EAAEuD,QAAQg0B,EAAE,OAAO,KAAKiC,EAAEt5B,EAAED,EAAEwB,EAAE,IAAG,SAASzB,GAAG,OAAOA,MAAK,MAAME,IAAIo3B,EAAEp3B,KAAKA,EADnW,SAAWF,EAAEC,GAAG,MAAM,CAACqG,SAASV,EAAE1D,KAAKlC,EAAEkC,KAAKic,IAAIle,EAAE+0B,IAAIh1B,EAAEg1B,IAAIP,MAAMz0B,EAAEy0B,MAAMQ,OAAOj1B,EAAEi1B,QACgRoC,CAAEn3B,EAAEuB,IAAIvB,EAAEie,KAAKtY,GAAGA,EAAEsY,MAAMje,EAAEie,IAAI,IAAI,GAAGje,EAAEie,KAAK5a,QAAQg0B,EAAE,OAAO,KAAKv3B,IAAIC,EAAEkQ,KAAKjQ,IAAI,EAAyB,GAAvB2F,EAAE,EAAErE,EAAE,KAAKA,EAAE,IAAIA,EAAE,IAAOktB,EAAE1uB,GAAG,IAAI,IAAI2B,EAAE,EAAEA,EAAE3B,EAAEI,OAAOuB,IAAI,CAC/e,IAAID,EAAEF,EAAEo2B,EADwe9xB,EACrf9F,EAAE2B,GAAeA,GAAGkE,GAAG2zB,EAAE1zB,EAAE7F,EAAEwB,EAAEC,EAAExB,QAAQ,GAAGwB,EAPsU,SAAW1B,GAAG,OAAG,OAAOA,GAAG,kBAAkBA,EAAS,KAAsC,oBAAjCA,EAAEqC,GAAGrC,EAAEqC,IAAIrC,EAAE,eAA0CA,EAAE,KAOxb8E,CAAE9E,GAAG,oBAAoB0B,EAAE,IAAI1B,EAAE0B,EAAEuB,KAAKjD,GAAG2B,EAAE,IAAImE,EAAE9F,EAAEkxB,QAAQ4E,MAA6BjwB,GAAG2zB,EAA1B1zB,EAAEA,EAAE6B,MAA0B1H,EAAEwB,EAAtBC,EAAEF,EAAEo2B,EAAE9xB,EAAEnE,KAAkBzB,QAAQ,GAAG,WAAW4F,EAAE,MAAM7F,EAAEme,OAAOpe,GAAGiF,MAAM,mDAAmD,oBAAoBhF,EAAE,qBAAqBgB,OAAO6M,KAAK9N,GAAGo1B,KAAK,MAAM,IAAIn1B,GAAG,6EAA6E,OAAO4F,EACxZ,SAASs7B,EAAEnhC,EAAEC,EAAEwB,GAAG,GAAG,MAAMzB,EAAE,OAAOA,EAAE,IAAIwB,EAAE,GAAGtB,EAAE,EAAmD,OAAjDs5B,EAAEx5B,EAAEwB,EAAE,GAAG,IAAG,SAASxB,GAAG,OAAOC,EAAEgD,KAAKxB,EAAEzB,EAAEE,QAAcsB,EAAE,SAASugC,EAAE/hC,GAAG,IAAI,IAAIA,EAAEklD,QAAQ,CAAC,IAAIjlD,EAAED,EAAEmlD,SAAQllD,EAAEA,KAAMmrB,MAAK,SAASnrB,GAAM,IAAID,EAAEklD,UAAU,IAAIllD,EAAEklD,UAAQllD,EAAEklD,QAAQ,EAAEllD,EAAEmlD,QAAQllD,MAAG,SAASA,GAAM,IAAID,EAAEklD,UAAU,IAAIllD,EAAEklD,UAAQllD,EAAEklD,QAAQ,EAAEllD,EAAEmlD,QAAQllD,OAAK,IAAID,EAAEklD,UAAUllD,EAAEklD,QAAQ,EAAEllD,EAAEmlD,QAAQllD,GAAG,GAAG,IAAID,EAAEklD,QAAQ,OAAOllD,EAAEmlD,QAAQC,QAAQ,MAAMplD,EAAEmlD,QACpZ,IAAI/iB,EAAE,CAACjwB,QAAQ,MAAMowB,EAAE,CAACvqB,WAAW,MAAMyqB,EAAE,CAACvL,uBAAuBkL,EAAEvqB,wBAAwB0qB,EAAExE,kBAAkBvL,GAAGia,EAAQ4Y,SAAS,CAACxH,IAAI1c,EAAE5+B,QAAQ,SAASvC,EAAEC,EAAEwB,GAAG0/B,EAAEnhC,GAAE,WAAWC,EAAE8Q,MAAMnP,KAAKzB,aAAYsB,IAAI6jD,MAAM,SAAStlD,GAAG,IAAIC,EAAE,EAAuB,OAArBkhC,EAAEnhC,GAAE,WAAWC,OAAaA,GAAGslD,QAAQ,SAASvlD,GAAG,OAAOmhC,EAAEnhC,GAAE,SAASA,GAAG,OAAOA,MAAK,IAAIwlD,KAAK,SAASxlD,GAAG,IAAIs3B,EAAEt3B,GAAG,MAAMiF,MAAM,yEAAyE,OAAOjF,IAAIysC,EAAQvZ,UAAU/G,EAAEsgB,EAAQgZ,SAAS1lD,EACne0sC,EAAQiZ,SAAS7yB,EAAE4Z,EAAQkZ,cAAcv5B,EAAEqgB,EAAQmZ,WAAWhzB,EAAE6Z,EAAQoZ,SAAS18B,EAAEsjB,EAAQ/oC,mDAAmD++B,EAC9IgK,EAAQqZ,aAAa,SAAS9lD,EAAEC,EAAEwB,GAAG,GAAG,OAAOzB,QAAG,IAASA,EAAE,MAAMiF,MAAM,iFAAiFjF,EAAE,KAAK,IAAIwB,EAAE6T,EAAE,GAAGrV,EAAEy0B,OAAOv0B,EAAEF,EAAEme,IAAIrY,EAAE9F,EAAEg1B,IAAInvB,EAAE7F,EAAEi1B,OAAO,GAAG,MAAMh1B,EAAE,CAAoE,QAAnE,IAASA,EAAE+0B,MAAMlvB,EAAE7F,EAAE+0B,IAAInvB,EAAE2sB,EAAErgB,cAAS,IAASlS,EAAEke,MAAMje,EAAE,GAAGD,EAAEke,KAAQne,EAAEkC,MAAMlC,EAAEkC,KAAK8tB,aAAa,IAAIruB,EAAE3B,EAAEkC,KAAK8tB,aAAa,IAAItuB,KAAKzB,EAAE+oB,EAAE/lB,KAAKhD,EAAEyB,KAAK+xB,EAAEtyB,eAAeO,KAAKF,EAAEE,QAAG,IAASzB,EAAEyB,SAAI,IAASC,EAAEA,EAAED,GAAGzB,EAAEyB,IAAI,IAAIA,EAAEvB,UAAUC,OAAO,EAAE,GAAG,IAAIsB,EAAEF,EAAE8H,SAAS7H,OAAO,GAAG,EAAEC,EAAE,CAACC,EAAEkH,MAAMnH,GACrf,IAAI,IAAIsP,EAAE,EAAEA,EAAEtP,EAAEsP,IAAIrP,EAAEqP,GAAG7Q,UAAU6Q,EAAE,GAAGxP,EAAE8H,SAAS3H,EAAE,MAAM,CAAC2E,SAASV,EAAE1D,KAAKlC,EAAEkC,KAAKic,IAAIje,EAAE80B,IAAIlvB,EAAE2uB,MAAMjzB,EAAEyzB,OAAOpvB,IAAI4mC,EAAQsZ,cAAc,SAAS/lD,GAAqK,OAAlKA,EAAE,CAACsG,SAAS4iB,EAAEqH,cAAcvwB,EAAEgmD,eAAehmD,EAAEimD,aAAa,EAAEtB,SAAS,KAAKuB,SAAS,KAAKC,cAAc,KAAKC,YAAY,OAAQzB,SAAS,CAACr+C,SAASyiB,EAAExiB,SAASvG,GAAUA,EAAEkmD,SAASlmD,GAAGysC,EAAQ1rC,cAAc41B,EAAE8V,EAAQ4Z,cAAc,SAASrmD,GAAG,IAAIC,EAAE02B,EAAEhO,KAAK,KAAK3oB,GAAY,OAATC,EAAEiC,KAAKlC,EAASC,GAAGwsC,EAAQ6Z,UAAU,WAAW,MAAM,CAACn0C,QAAQ,OACzds6B,EAAQ8Z,WAAW,SAASvmD,GAAG,MAAM,CAACsG,SAAS/E,EAAE6E,OAAOpG,IAAIysC,EAAQ+Z,eAAelvB,EAAEmV,EAAQga,KAAK,SAASzmD,GAAG,MAAM,CAACsG,SAASwsB,EAAEtsB,SAAS,CAAC0+C,SAAS,EAAEC,QAAQnlD,GAAGyG,MAAMs7B,IAAI0K,EAAQia,KAAK,SAAS1mD,EAAEC,GAAG,MAAM,CAACqG,SAAS2iB,EAAE/mB,KAAKlC,EAAEq+B,aAAQ,IAASp+B,EAAE,KAAKA,IAAIwsC,EAAQka,gBAAgB,SAAS3mD,GAAG,IAAIC,EAAEsiC,EAAEvqB,WAAWuqB,EAAEvqB,WAAW,GAAG,IAAIhY,IAAJ,QAAgBuiC,EAAEvqB,WAAW/X,IAAIwsC,EAAQma,aAAa,WAAW,MAAM3hD,MAAM,6DAC9YwnC,EAAQnR,YAAY,SAASt7B,EAAEC,GAAG,OAAOmiC,EAAEjwB,QAAQmpB,YAAYt7B,EAAEC,IAAIwsC,EAAQlR,WAAW,SAASv7B,GAAG,OAAOoiC,EAAEjwB,QAAQopB,WAAWv7B,IAAIysC,EAAQzQ,cAAc,aAAayQ,EAAQxQ,iBAAiB,SAASj8B,GAAG,OAAOoiC,EAAEjwB,QAAQ8pB,iBAAiBj8B,IAAIysC,EAAQjR,UAAU,SAASx7B,EAAEC,GAAG,OAAOmiC,EAAEjwB,QAAQqpB,UAAUx7B,EAAEC,IAAIwsC,EAAQpQ,MAAM,WAAW,OAAO+F,EAAEjwB,QAAQkqB,SAASoQ,EAAQhR,oBAAoB,SAASz7B,EAAEC,EAAEwB,GAAG,OAAO2gC,EAAEjwB,QAAQspB,oBAAoBz7B,EAAEC,EAAEwB,IAC3bgrC,EAAQ/Q,mBAAmB,SAAS17B,EAAEC,GAAG,OAAOmiC,EAAEjwB,QAAQupB,mBAAmB17B,EAAEC,IAAIwsC,EAAQ9Q,gBAAgB,SAAS37B,EAAEC,GAAG,OAAOmiC,EAAEjwB,QAAQwpB,gBAAgB37B,EAAEC,IAAIwsC,EAAQ7Q,QAAQ,SAAS57B,EAAEC,GAAG,OAAOmiC,EAAEjwB,QAAQypB,QAAQ57B,EAAEC,IAAIwsC,EAAQ5Q,WAAW,SAAS77B,EAAEC,EAAEwB,GAAG,OAAO2gC,EAAEjwB,QAAQ0pB,WAAW77B,EAAEC,EAAEwB,IAAIgrC,EAAQ3Q,OAAO,SAAS97B,GAAG,OAAOoiC,EAAEjwB,QAAQ2pB,OAAO97B,IAAIysC,EAAQ1Q,SAAS,SAAS/7B,GAAG,OAAOoiC,EAAEjwB,QAAQ4pB,SAAS/7B,IAAIysC,EAAQrQ,qBAAqB,SAASp8B,EAAEC,EAAEwB,GAAG,OAAO2gC,EAAEjwB,QAAQiqB,qBAAqBp8B,EAAEC,EAAEwB,IAC7egrC,EAAQvQ,cAAc,WAAW,OAAOkG,EAAEjwB,QAAQ+pB,iBAAiBuQ,EAAQ1B,QAAQ,2CCtBjF0C,EAAOhB,QAAU,EAAjBgB,uCCAAA,EAAOhB,QAAU,EAAjBgB,qCCMW,SAAS/rC,EAAE1B,EAAEC,GAAG,IAAIC,EAAEF,EAAEI,OAAOJ,EAAEmQ,KAAKlQ,GAAGD,EAAE,KAAK,EAAEE,GAAG,CAAC,IAAIsB,EAAEtB,EAAE,IAAI,EAAEuB,EAAEzB,EAAEwB,GAAG,KAAG,EAAEG,EAAEF,EAAExB,IAA0B,MAAMD,EAA7BA,EAAEwB,GAAGvB,EAAED,EAAEE,GAAGuB,EAAEvB,EAAEsB,GAAgB,SAASqE,EAAE7F,GAAG,OAAO,IAAIA,EAAEI,OAAO,KAAKJ,EAAE,GAAG,SAAS8F,EAAE9F,GAAG,GAAG,IAAIA,EAAEI,OAAO,OAAO,KAAK,IAAIH,EAAED,EAAE,GAAGE,EAAEF,EAAE6mD,MAAM,GAAG3mD,IAAID,EAAE,CAACD,EAAE,GAAGE,EAAEF,EAAE,IAAI,IAAIwB,EAAE,EAAEC,EAAEzB,EAAEI,OAAO+oB,EAAE1nB,IAAI,EAAED,EAAE2nB,GAAG,CAAC,IAAInY,EAAE,GAAGxP,EAAE,GAAG,EAAE6T,EAAErV,EAAEgR,GAAG8X,EAAE9X,EAAE,EAAEiY,EAAEjpB,EAAE8oB,GAAG,GAAG,EAAEnnB,EAAE0T,EAAEnV,GAAG4oB,EAAErnB,GAAG,EAAEE,EAAEsnB,EAAE5T,IAAIrV,EAAEwB,GAAGynB,EAAEjpB,EAAE8oB,GAAG5oB,EAAEsB,EAAEsnB,IAAI9oB,EAAEwB,GAAG6T,EAAErV,EAAEgR,GAAG9Q,EAAEsB,EAAEwP,OAAQ,MAAG8X,EAAErnB,GAAG,EAAEE,EAAEsnB,EAAE/oB,IAA0B,MAAMF,EAA7BA,EAAEwB,GAAGynB,EAAEjpB,EAAE8oB,GAAG5oB,EAAEsB,EAAEsnB,IAAgB,OAAO7oB,EAC1c,SAAS0B,EAAE3B,EAAEC,GAAG,IAAIC,EAAEF,EAAE8mD,UAAU7mD,EAAE6mD,UAAU,OAAO,IAAI5mD,EAAEA,EAAEF,EAAEoY,GAAGnY,EAAEmY,GAAG,GAAG,kBAAkB2uC,aAAa,oBAAoBA,YAAYzsC,IAAI,CAAC,IAAI1U,EAAEmhD,YAAYta,EAAQ15B,aAAa,WAAW,OAAOnN,EAAE0U,WAAW,CAAC,IAAIva,EAAEsa,KAAKuY,EAAE7yB,EAAEua,MAAMmyB,EAAQ15B,aAAa,WAAW,OAAOhT,EAAEua,MAAMsY,GAAG,IAAIC,EAAE,GAAG9J,EAAE,GAAGG,EAAE,EAAE3nB,EAAE,KAAKuxB,EAAE,EAAEzwB,GAAE,EAAGyC,GAAE,EAAGgO,GAAE,EAAGqV,EAAE,oBAAoByC,WAAWA,WAAW,KAAKuB,EAAE,oBAAoBrB,aAAaA,aAAa,KAAK1B,EAAE,qBAAqB49B,aAAaA,aAAa,KACnT,SAAS56B,EAAEpsB,GAAG,IAAI,IAAIC,EAAE4F,EAAEkjB,GAAG,OAAO9oB,GAAG,CAAC,GAAG,OAAOA,EAAEqyB,SAASxsB,EAAEijB,OAAQ,MAAG9oB,EAAEgnD,WAAWjnD,GAAgD,MAA9C8F,EAAEijB,GAAG9oB,EAAE6mD,UAAU7mD,EAAEinD,eAAexlD,EAAEmxB,EAAE5yB,GAAcA,EAAE4F,EAAEkjB,IAAI,SAASuD,EAAEtsB,GAAa,GAAV8S,GAAE,EAAGsZ,EAAEpsB,IAAO8E,EAAE,GAAG,OAAOe,EAAEgtB,GAAG/tB,GAAE,EAAG4pB,EAAE1F,OAAO,CAAC,IAAI/oB,EAAE4F,EAAEkjB,GAAG,OAAO9oB,GAAGuyB,EAAElG,EAAErsB,EAAEgnD,UAAUjnD,IACla,SAASgpB,EAAEhpB,EAAEC,GAAG6E,GAAE,EAAGgO,IAAIA,GAAE,EAAGqZ,EAAEsH,GAAGA,GAAG,GAAGpxB,GAAE,EAAG,IAAInC,EAAE4yB,EAAE,IAAS,IAAL1G,EAAEnsB,GAAOsB,EAAEsE,EAAEgtB,GAAG,OAAOtxB,MAAMA,EAAE2lD,eAAejnD,IAAID,IAAI22B,MAAM,CAAC,IAAIn1B,EAAED,EAAE+wB,SAAS,GAAG,oBAAoB9wB,EAAE,CAACD,EAAE+wB,SAAS,KAAKQ,EAAEvxB,EAAE4lD,cAAc,IAAI1lD,EAAED,EAAED,EAAE2lD,gBAAgBjnD,GAAGA,EAAEwsC,EAAQ15B,eAAe,oBAAoBtR,EAAEF,EAAE+wB,SAAS7wB,EAAEF,IAAIsE,EAAEgtB,IAAI/sB,EAAE+sB,GAAGzG,EAAEnsB,QAAQ6F,EAAE+sB,GAAGtxB,EAAEsE,EAAEgtB,GAAG,GAAG,OAAOtxB,EAAE,IAAI4nB,GAAE,MAAO,CAAC,IAAInY,EAAEnL,EAAEkjB,GAAG,OAAO/X,GAAGwhB,EAAElG,EAAEtb,EAAEi2C,UAAUhnD,GAAGkpB,GAAE,EAAG,OAAOA,EAA1V,QAAoW5nB,EAAE,KAAKuxB,EAAE5yB,EAAEmC,GAAE,GADva,qBAAqBivC,gBAAW,IAASA,UAAU8V,iBAAY,IAAS9V,UAAU8V,WAAWC,gBAAgB/V,UAAU8V,WAAWC,eAAe1+B,KAAK2oB,UAAU8V,YAC2Q,IACzPjmB,EAD6P9J,GAAE,EAAGC,EAAE,KAAK7D,GAAG,EAAE8D,EAAE,EAAEK,GAAG,EACvc,SAASjB,IAAI,QAAO8V,EAAQ15B,eAAe6kB,EAAEL,GAAQ,SAASiC,IAAI,GAAG,OAAOlC,EAAE,CAAC,IAAIt3B,EAAEysC,EAAQ15B,eAAe6kB,EAAE53B,EAAE,IAAIC,GAAE,EAAG,IAAIA,EAAEq3B,GAAE,EAAGt3B,GAAX,QAAsBC,EAAEkhC,KAAK9J,GAAE,EAAGC,EAAE,YAAYD,GAAE,EAAS,GAAG,oBAAoBjO,EAAE+X,EAAE,WAAW/X,EAAEoQ,SAAS,GAAG,qBAAqB8tB,eAAe,CAAC,IAAIvlB,EAAE,IAAIulB,eAAellB,EAAEL,EAAEwlB,MAAMxlB,EAAEylB,MAAMC,UAAUjuB,EAAE2H,EAAE,WAAWiB,EAAEslB,YAAY,YAAYvmB,EAAE,WAAWhZ,EAAEqR,EAAE,IAAI,SAAS9K,EAAE1uB,GAAGs3B,EAAEt3B,EAAEq3B,IAAIA,GAAE,EAAG8J,KAAK,SAAS3O,EAAExyB,EAAEC,GAAGwzB,EAAEtL,GAAE,WAAWnoB,EAAEysC,EAAQ15B,kBAAiB9S,GAC1dwsC,EAAQ94B,sBAAsB,EAAE84B,EAAQt5B,2BAA2B,EAAEs5B,EAAQh5B,qBAAqB,EAAEg5B,EAAQl5B,wBAAwB,EAAEk5B,EAAQkb,mBAAmB,KAAKlb,EAAQp5B,8BAA8B,EAAEo5B,EAAQh6B,wBAAwB,SAASzS,GAAGA,EAAEsyB,SAAS,MAAMma,EAAQmb,2BAA2B,WAAW9iD,GAAGzC,IAAIyC,GAAE,EAAG4pB,EAAE1F,KACvUyjB,EAAQob,wBAAwB,SAAS7nD,GAAG,EAAEA,GAAG,IAAIA,EAAE68B,QAAQC,MAAM,mHAAmHvF,EAAE,EAAEv3B,EAAE+T,KAAK+zC,MAAM,IAAI9nD,GAAG,GAAGysC,EAAQx5B,iCAAiC,WAAW,OAAO6f,GAAG2Z,EAAQsb,8BAA8B,WAAW,OAAOliD,EAAEgtB,IAAI4Z,EAAQub,cAAc,SAAShoD,GAAG,OAAO8yB,GAAG,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI7yB,EAAE,EAAE,MAAM,QAAQA,EAAE6yB,EAAE,IAAI5yB,EAAE4yB,EAAEA,EAAE7yB,EAAE,IAAI,OAAOD,IAAX,QAAuB8yB,EAAE5yB,IAAIusC,EAAQwb,wBAAwB,aACnfxb,EAAQ55B,sBAAsB,aAAa45B,EAAQyb,yBAAyB,SAASloD,EAAEC,GAAG,OAAOD,GAAG,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,MAAM,QAAQA,EAAE,EAAE,IAAIE,EAAE4yB,EAAEA,EAAE9yB,EAAE,IAAI,OAAOC,IAAX,QAAuB6yB,EAAE5yB,IAC9LusC,EAAQl6B,0BAA0B,SAASvS,EAAEC,EAAEC,GAAG,IAAIsB,EAAEirC,EAAQ15B,eAA8F,OAA/E,kBAAkB7S,GAAG,OAAOA,EAAaA,EAAE,kBAAZA,EAAEA,EAAEyzC,QAA6B,EAAEzzC,EAAEsB,EAAEtB,EAAEsB,EAAGtB,EAAEsB,EAASxB,GAAG,KAAK,EAAE,IAAIyB,GAAG,EAAE,MAAM,KAAK,EAAEA,EAAE,IAAI,MAAM,KAAK,EAAEA,EAAE,WAAW,MAAM,KAAK,EAAEA,EAAE,IAAI,MAAM,QAAQA,EAAE,IAAmN,OAAzMzB,EAAE,CAACoY,GAAG8Q,IAAIoJ,SAASryB,EAAEknD,cAAcnnD,EAAEinD,UAAU/mD,EAAEgnD,eAAvDzlD,EAAEvB,EAAEuB,EAAoEqlD,WAAW,GAAG5mD,EAAEsB,GAAGxB,EAAE8mD,UAAU5mD,EAAEwB,EAAEqnB,EAAE/oB,GAAG,OAAO6F,EAAEgtB,IAAI7yB,IAAI6F,EAAEkjB,KAAKjW,GAAGqZ,EAAEsH,GAAGA,GAAG,GAAG3gB,GAAE,EAAG0f,EAAElG,EAAEpsB,EAAEsB,MAAMxB,EAAE8mD,UAAUrlD,EAAEC,EAAEmxB,EAAE7yB,GAAG8E,GAAGzC,IAAIyC,GAAE,EAAG4pB,EAAE1F,KAAYhpB,GACleysC,EAAQ95B,qBAAqBgkB,EAAE8V,EAAQ0b,sBAAsB,SAASnoD,GAAG,IAAIC,EAAE6yB,EAAE,OAAO,WAAW,IAAI5yB,EAAE4yB,EAAEA,EAAE7yB,EAAE,IAAI,OAAOD,EAAE+Q,MAAMnP,KAAKzB,WAAxB,QAA2C2yB,EAAE5yB,uCCf1JutC,EAAOhB,QAAU,EAAjBgB,uCCHa,SAASqH,IActB,OAbAA,EAAW7zC,OAAO8D,OAAS9D,OAAO8D,OAAO4jB,OAAS,SAAUpZ,GAC1D,IAAK,IAAImyC,EAAI,EAAGA,EAAIvhD,UAAUC,OAAQshD,IAAK,CACzC,IAAI3yC,EAAS5O,UAAUuhD,GAEvB,IAAK,IAAIvjC,KAAOpP,EACV9N,OAAOC,UAAUC,eAAe8B,KAAK8L,EAAQoP,KAC/C5O,EAAO4O,GAAOpP,EAAOoP,IAK3B,OAAO5O,GAEFulC,EAAS/jC,MAAMnP,KAAMzB,6CCb1BioD,EAA2B,GAG/B,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqB5X,IAAjB6X,EACH,OAAOA,EAAa9b,QAGrB,IAAIgB,EAAS2a,EAAyBE,GAAY,CAGjD7b,QAAS,IAOV,OAHA+b,EAAoBF,GAAU7a,EAAQA,EAAOhB,QAAS4b,GAG/C5a,EAAOhB,QAIf4b,EAAoBr3C,EAAIw3C,ECxBxBH,EAAoBv/B,EAAI,SAAS2kB,GAChC,IAAIgb,EAAShb,GAAUA,EAAOib,WAC7B,WAAa,OAAOjb,EAAgB,SACpC,WAAa,OAAOA,GAErB,OADA4a,EAAoB7mD,EAAEinD,EAAQ,CAAEzoD,EAAGyoD,IAC5BA,GCLRJ,EAAoB7mD,EAAI,SAASirC,EAASkc,GACzC,IAAI,IAAIxqC,KAAOwqC,EACXN,EAAoBjZ,EAAEuZ,EAAYxqC,KAASkqC,EAAoBjZ,EAAE3C,EAAStuB,IAC5Eld,OAAOuE,eAAeinC,EAAStuB,EAAK,CAAE/W,YAAY,EAAMF,IAAKyhD,EAAWxqC,MCJ3EkqC,EAAoB3mD,EAAI,GAGxB2mD,EAAoB5mD,EAAI,SAASmnD,GAChC,OAAO59B,QAAQk0B,IAAIj+C,OAAO6M,KAAKu6C,EAAoB3mD,GAAG+6C,QAAO,SAASwC,EAAU9gC,GAE/E,OADAkqC,EAAoB3mD,EAAEyc,GAAKyqC,EAAS3J,GAC7BA,IACL,MCNJoJ,EAAoBn/B,EAAI,SAAS0/B,GAEhC,MAAO,aAAeA,EAAf,sBCFRP,EAAoBQ,SAAW,SAASD,KCDxCP,EAAoBjZ,EAAI,SAAS0Z,EAAKC,GAAQ,OAAO9nD,OAAOC,UAAUC,eAAe8B,KAAK6lD,EAAKC,eCA/F,IAAIC,EAAa,GACbC,EAAoB,YAExBZ,EAAoBziD,EAAI,SAASgc,EAAKkU,EAAM3X,EAAKyqC,GAChD,GAAGI,EAAWpnC,GAAQonC,EAAWpnC,GAAKzR,KAAK2lB,OAA3C,CACA,IAAIozB,EAAQC,EACZ,QAAWzY,IAARvyB,EAEF,IADA,IAAIirC,EAAUtoD,SAASuoD,qBAAqB,UACpC3H,EAAI,EAAGA,EAAI0H,EAAQhpD,OAAQshD,IAAK,CACvC,IAAI4H,EAAIF,EAAQ1H,GAChB,GAAG4H,EAAEC,aAAa,QAAU3nC,GAAO0nC,EAAEC,aAAa,iBAAmBN,EAAoB9qC,EAAK,CAAE+qC,EAASI,EAAG,OAG1GJ,IACHC,GAAa,GACbD,EAASpoD,SAASC,cAAc,WAEzByoD,QAAU,QACjBN,EAAOnF,QAAU,IACbsE,EAAoBoB,IACvBP,EAAO7lD,aAAa,QAASglD,EAAoBoB,IAElDP,EAAO7lD,aAAa,eAAgB4lD,EAAoB9qC,GACxD+qC,EAAOxkB,IAAM9iB,GAEdonC,EAAWpnC,GAAO,CAACkU,GACnB,IAAI4zB,EAAmB,SAASC,EAAM1nC,GAErCinC,EAAOU,QAAUV,EAAOW,OAAS,KACjC/+B,aAAai5B,GACb,IAAI+F,EAAUd,EAAWpnC,GAIzB,UAHOonC,EAAWpnC,GAClBsnC,EAAOx5C,YAAcw5C,EAAOx5C,WAAWtF,YAAY8+C,GACnDY,GAAWA,EAAQvnD,SAAQ,SAASysC,GAAM,OAAOA,EAAG/sB,MACjD0nC,EAAM,OAAOA,EAAK1nC,IAGlB8hC,EAAUn5B,WAAW8+B,EAAiB/gC,KAAK,UAAM+nB,EAAW,CAAExuC,KAAM,UAAWqN,OAAQ25C,IAAW,MACtGA,EAAOU,QAAUF,EAAiB/gC,KAAK,KAAMugC,EAAOU,SACpDV,EAAOW,OAASH,EAAiB/gC,KAAK,KAAMugC,EAAOW,QACnDV,GAAcroD,SAASipD,KAAK1/C,YAAY6+C,QCvCzCb,EAAoBx1B,EAAI,SAAS4Z,GACX,qBAAX7oC,QAA0BA,OAAOomD,aAC1C/oD,OAAOuE,eAAeinC,EAAS7oC,OAAOomD,YAAa,CAAEriD,MAAO,WAE7D1G,OAAOuE,eAAeinC,EAAS,aAAc,CAAE9kC,OAAO,KCLvD0gD,EAAoBtoD,EAAI,mBCKxB,IAAIkqD,EAAkB,CACrB,IAAK,GAGN5B,EAAoB3mD,EAAEwoD,EAAI,SAAStB,EAAS3J,GAE1C,IAAIkL,EAAqB9B,EAAoBjZ,EAAE6a,EAAiBrB,GAAWqB,EAAgBrB,QAAWlY,EACtG,GAA0B,IAAvByZ,EAGF,GAAGA,EACFlL,EAAS9uC,KAAKg6C,EAAmB,QAC3B,CAGL,IAAIpX,EAAU,IAAI/nB,SAAQ,SAASG,EAASgoB,GAAUgX,EAAqBF,EAAgBrB,GAAW,CAACz9B,EAASgoB,MAChH8L,EAAS9uC,KAAKg6C,EAAmB,GAAKpX,GAGtC,IAAInxB,EAAMymC,EAAoBtoD,EAAIsoD,EAAoBn/B,EAAE0/B,GAEpD9rB,EAAQ,IAAI73B,MAgBhBojD,EAAoBziD,EAAEgc,GAfH,SAASK,GAC3B,GAAGomC,EAAoBjZ,EAAE6a,EAAiBrB,KAEf,KAD1BuB,EAAqBF,EAAgBrB,MACRqB,EAAgBrB,QAAWlY,GACrDyZ,GAAoB,CACtB,IAAIC,EAAYnoC,IAAyB,SAAfA,EAAM/f,KAAkB,UAAY+f,EAAM/f,MAChEmoD,EAAUpoC,GAASA,EAAM1S,QAAU0S,EAAM1S,OAAOm1B,IACpD5H,EAAML,QAAU,iBAAmBmsB,EAAU,cAAgBwB,EAAY,KAAOC,EAAU,IAC1FvtB,EAAM72B,KAAO,iBACb62B,EAAM56B,KAAOkoD,EACbttB,EAAMwtB,QAAUD,EAChBF,EAAmB,GAAGrtB,MAIgB,SAAW8rB,EAASA,KAiBlE,IAAI2B,EAAuB,SAASC,EAA4B3tC,GAC/D,IAKIyrC,EAAUM,EALV6B,EAAW5tC,EAAK,GAChB6tC,EAAc7tC,EAAK,GACnB8tC,EAAU9tC,EAAK,GAGI6kC,EAAI,EAC3B,GAAG+I,EAAShU,MAAK,SAASr+B,GAAM,OAA+B,IAAxB6xC,EAAgB7xC,MAAe,CACrE,IAAIkwC,KAAYoC,EACZrC,EAAoBjZ,EAAEsb,EAAapC,KACrCD,EAAoBr3C,EAAEs3C,GAAYoC,EAAYpC,IAGhD,GAAGqC,EAAsBA,EAAQtC,GAGlC,IADGmC,GAA4BA,EAA2B3tC,GACrD6kC,EAAI+I,EAASrqD,OAAQshD,IACzBkH,EAAU6B,EAAS/I,GAChB2G,EAAoBjZ,EAAE6a,EAAiBrB,IAAYqB,EAAgBrB,IACrEqB,EAAgBrB,GAAS,KAE1BqB,EAAgBrB,GAAW,GAKzBgC,EAAqBC,KAA2B,qBAAIA,KAA2B,sBAAK,GACxFD,EAAmBroD,QAAQgoD,EAAqB5hC,KAAK,KAAM,IAC3DiiC,EAAmBz6C,KAAOo6C,EAAqB5hC,KAAK,KAAMiiC,EAAmBz6C,KAAKwY,KAAKiiC,qDCvFxE,SAASE,EAAkBC,EAAKC,IAClC,MAAPA,GAAeA,EAAMD,EAAI3qD,UAAQ4qD,EAAMD,EAAI3qD,QAE/C,IAAK,IAAIshD,EAAI,EAAGuJ,EAAO,IAAIpiD,MAAMmiD,GAAMtJ,EAAIsJ,EAAKtJ,IAC9CuJ,EAAKvJ,GAAKqJ,EAAIrJ,GAGhB,OAAOuJ,ECHM,SAAS,EAAeF,EAAKrJ,GAC1C,OCLa,SAAyBqJ,GACtC,GAAIliD,MAAMC,QAAQiiD,GAAM,OAAOA,EDIxB,CAAeA,IELT,SAA+BA,EAAKrJ,GACjD,IAAIwJ,EAAY,MAAPH,EAAc,KAAyB,qBAAXnnD,QAA0BmnD,EAAInnD,OAAOe,WAAaomD,EAAI,cAE3F,GAAU,MAANG,EAAJ,CACA,IAIIC,EAAIC,EAJJC,EAAO,GACPC,GAAK,EACLC,GAAK,EAIT,IACE,IAAKL,EAAKA,EAAGjoD,KAAK8nD,KAAQO,GAAMH,EAAKD,EAAGh6B,QAAQ4E,QAC9Cu1B,EAAKl7C,KAAKg7C,EAAGxjD,QAET+5C,GAAK2J,EAAKjrD,SAAWshD,GAH4B4J,GAAK,IAK5D,MAAO9d,GACP+d,GAAK,EACLH,EAAK5d,EACL,QACA,IACO8d,GAAsB,MAAhBJ,EAAW,QAAWA,EAAW,SAC5C,QACA,GAAIK,EAAI,MAAMH,GAIlB,OAAOC,GFtBuB,CAAqBN,EAAKrJ,IGJ3C,SAAqCtS,EAAGoc,GACrD,GAAKpc,EAAL,CACA,GAAiB,kBAANA,EAAgB,OAAO,EAAiBA,EAAGoc,GACtD,IAAI1iC,EAAI7nB,OAAOC,UAAUgJ,SAASjH,KAAKmsC,GAAGvsC,MAAM,GAAI,GAEpD,MADU,WAANimB,GAAkBsmB,EAAEnoC,cAAa6hB,EAAIsmB,EAAEnoC,YAAYhB,MAC7C,QAAN6iB,GAAqB,QAANA,EAAoBjgB,MAAM4iD,KAAKrc,GACxC,cAANtmB,GAAqB,2CAA2C5lB,KAAK4lB,GAAW,EAAiBsmB,EAAGoc,QAAxG,GHF8D,CAA2BT,EAAKrJ,IILjF,WACb,MAAM,IAAIgK,UAAU,6IJIgF,y1BKkBzFC,GAAoBxH,EAAAA,EAAAA,eAC/B,UAYWyH,GAAkBzH,EAAAA,EAAAA,eAC7B,UAYW0H,GAAe1H,EAAAA,EAAAA,eAAwC,CAClE2H,OAAQ,KACRC,QAAS,KChDJ,SAASC,EAAUC,EAAWxvB,GACnC,IAAKwvB,EAAM,MAAM,IAAIhnD,MAAMw3B,GAwI7B,SAAgByvB,EACdC,EACAC,EACAC,QACqB,IADrBA,IAAAA,EAAW,KAEX,IAGIC,EAAWC,GAFU,kBAAhBH,EAA2BI,EAAUJ,GAAeA,GAEvBE,UAAY,IAAKD,GAEvD,GAAgB,MAAZC,EACF,OAAO,KAGT,IAAIG,EAAWC,EAAcP,IA6E/B,SAA2BM,GACzBA,EAASrJ,MAAK,SAACpjD,EAAGC,GAAJ,OACZD,EAAE2sD,QAAU1sD,EAAE0sD,MACV1sD,EAAE0sD,MAAQ3sD,EAAE2sD,MAyCpB,SAAwB3sD,EAAaC,GACnC,IAAI2sD,EACF5sD,EAAEI,SAAWH,EAAEG,QAAUJ,EAAE6C,MAAM,GAAI,GAAGgqD,OAAM,SAAC/jC,EAAG44B,GAAJ,OAAU54B,IAAM7oB,EAAEyhD,MAElE,OAAOkL,EAKH5sD,EAAEA,EAAEI,OAAS,GAAKH,EAAEA,EAAEG,OAAS,GAG/B,EApDE0sD,CACE9sD,EAAE+sD,WAAWlP,KAAKhvC,SAAAA,GAAD,OAAUA,EAAKm+C,iBAChC/sD,EAAE8sD,WAAWlP,KAAKhvC,SAAAA,GAAD,OAAUA,EAAKm+C,qBAlFxCC,CAAkBR,GAGlB,IADA,IAAIV,EAAU,KACLrK,EAAI,EAAc,MAAXqK,GAAmBrK,EAAI+K,EAASrsD,SAAUshD,EACxDqK,EAAUmB,EAAiBT,EAAS/K,GAAI4K,GAG1C,OAAOP,EAgBT,SAASW,EACPP,EACAM,EACAU,EACAC,GA8CA,YA7Ce,IAHfX,IAAAA,EAA0B,SAGX,IAFfU,IAAAA,EAA2B,SAEZ,IADfC,IAAAA,EAAa,IAEbjB,EAAO5pD,SAAQ,SAAC8qD,EAAO93B,GACrB,IAAI1mB,EAAkB,CACpBy+C,aAAcD,EAAME,MAAQ,GAC5BC,eAAuC,IAAxBH,EAAMG,cACrBR,cAAez3B,EACf83B,MAAAA,GAGEx+C,EAAKy+C,aAAaG,WAAW,OAE7B5+C,EAAKy+C,aAAaG,WAAWL,IAD/BpB,GAAU,GAOVn9C,EAAKy+C,aAAez+C,EAAKy+C,aAAazqD,MAAMuqD,EAAWhtD,SAGzD,IAAImtD,EAAOG,EAAU,CAACN,EAAYv+C,EAAKy+C,eACnCP,EAAaI,EAAYrlC,OAAOjZ,GAKhCw+C,EAAM/jD,UAAY+jD,EAAM/jD,SAASlJ,OAAS,KAE1B,IAAhBitD,EAAM93B,OADRy2B,GAAU,GAMVU,EAAcW,EAAM/jD,SAAUmjD,EAAUM,EAAYQ,KAKpC,MAAdF,EAAME,MAAiBF,EAAM93B,QAIjCk3B,EAASt8C,KAAK,CAAEo9C,KAAAA,EAAMZ,MAAOgB,EAAaJ,EAAMF,EAAM93B,OAAQw3B,WAAAA,OAGzDN,EAcT,IAAMmB,EAAU,SAMVC,EAAWvE,SAAAA,GAAD,MAAqB,MAANA,GAE/B,SAASqE,EAAaJ,EAAch4B,GAClC,IAAIu4B,EAAWP,EAAKjrD,MAAM,KACtByrD,EAAeD,EAAS1tD,OAS5B,OARI0tD,EAASrX,KAAKoX,KAChBE,IAPiB,GAUfx4B,IACFw4B,GAdoB,GAiBfD,EACJje,QAAQyZ,SAAAA,GAAD,OAAQuE,EAAQvE,MACvB7M,QACC,SAACkQ,EAAOqB,GAAR,OACErB,GACCiB,EAAQ1qD,KAAK8qD,GAvBM,EAyBJ,KAAZA,EAvBc,EACC,MAyBrBD,GAmBN,SAASb,EACPe,EACA3B,GAOA,IALA,IAAMS,EAAekB,EAAflB,WAEFmB,EAAgB,GAChBC,EAAkB,IAClBpC,EAAwB,GACnBrK,EAAI,EAAGA,EAAIqL,EAAW3sD,SAAUshD,EAAG,CAC1C,IAAI7yC,EAAOk+C,EAAWrL,GAClB98B,EAAM88B,IAAMqL,EAAW3sD,OAAS,EAChCguD,EACkB,MAApBD,EACI7B,EACAA,EAASzpD,MAAMsrD,EAAgB/tD,SAAW,IAC5CgF,EAAQipD,EACV,CAAEd,KAAM1+C,EAAKy+C,aAAcE,cAAe3+C,EAAK2+C,cAAe5oC,IAAAA,GAC9DwpC,GAGF,IAAKhpD,EAAO,OAAO,KAEnBnE,OAAO8D,OAAOmpD,EAAe9oD,EAAMkpD,QAEnC,IAAIjB,EAAQx+C,EAAKw+C,MAEjBtB,EAAQ57C,KAAK,CACXm+C,OAAQJ,EACR5B,SAAUoB,EAAU,CAACS,EAAiB/oD,EAAMknD,WAC5CiC,aAAcC,EACZd,EAAU,CAACS,EAAiB/oD,EAAMmpD,gBAEpClB,MAAAA,IAGyB,MAAvBjoD,EAAMmpD,eACRJ,EAAkBT,EAAU,CAACS,EAAiB/oD,EAAMmpD,gBAIxD,OAAOxC,EAwDT,SAAgBsC,EAIdI,EACAnC,GAEuB,kBAAZmC,IACTA,EAAU,CAAElB,KAAMkB,EAASjB,eAAe,EAAO5oC,KAAK,IAGxD,MAwCF,SACE2oC,EACAC,EACA5oC,QACoB,IAFpB4oC,IAAAA,GAAgB,QAEI,IADpB5oC,IAAAA,GAAM,GAUN,IAAI8pC,EAAuB,GACvBC,EACF,IACApB,EACGhqD,QAAQ,UAAW,IACnBA,QAAQ,OAAQ,KAChBA,QAAQ,sBAAuB,QAC/BA,QAAQ,WAAW,SAAC0/C,EAAW2L,GAE9B,OADAF,EAAWv+C,KAAKy+C,GACT,eAGTrB,EAAKsB,SAAS,MAChBH,EAAWv+C,KAAK,KAChBw+C,GACW,MAATpB,GAAyB,OAATA,EACZ,QACA,qBAENoB,GAAgB/pC,EACZ,QAOA,uCAKN,MAAO,CAFO,IAAIkqC,OAAOH,EAAcnB,OAAgB9c,EAAY,KAElDge,GArFWK,CAC1BN,EAAQlB,KACRkB,EAAQjB,cACRiB,EAAQ7pC,KAHV,SAAKoqC,EAAL,KAAcN,EAAd,KAMItpD,EAAQknD,EAASlnD,MAAM4pD,GAC3B,IAAK5pD,EAAO,OAAO,KAEnB,IAAI+oD,EAAkB/oD,EAAM,GACxBmpD,EAAeJ,EAAgB5qD,QAAQ,UAAW,MAClD0rD,EAAgB7pD,EAAMvC,MAAM,GAqBhC,MAAO,CACLyrD,OArBmBI,EAAWjS,QAC9B,SAACiK,EAAMkI,EAAWr5B,GAGhB,GAAkB,MAAdq5B,EAAmB,CACrB,IAAIM,EAAaD,EAAc15B,IAAU,GACzCg5B,EAAeJ,EACZtrD,MAAM,EAAGsrD,EAAgB/tD,OAAS8uD,EAAW9uD,QAC7CmD,QAAQ,UAAW,MAOxB,OAJAmjD,EAAKkI,GAiEX,SAAkCjnD,EAAeinD,GAC/C,IACE,OAAOO,mBAAmBxnD,GAC1B,MAAOm1B,GAQP,OAAOn1B,GA5EaynD,CAChBH,EAAc15B,IAAU,IAGnBmxB,IAET,IAKA4F,SAAU6B,EACVI,aAAAA,EACAE,QAAAA,GA4GJ,SAAgBY,EACdC,EACAC,EACAC,GAEA,IAUI/D,EAVAgE,EAAsB,kBAAVH,EAAqB9C,EAAU8C,GAASA,EACpDI,EAAuB,KAAVJ,GAAgC,KAAhBG,EAAGnD,SAAkB,IAAMmD,EAAGnD,SAU/D,GAAkB,MAAdoD,EACFjE,EAAO+D,MACF,CACL,IAAIG,EAAqBJ,EAAenvD,OAAS,EAEjD,GAAIsvD,EAAWjC,WAAW,MAAO,CAM/B,IALA,IAAImC,EAAaF,EAAWptD,MAAM,KAKT,OAAlBstD,EAAW,IAChBA,EAAWr4C,QACXo4C,GAAsB,EAGxBF,EAAGnD,SAAWsD,EAAWx6B,KAAK,KAKhCq2B,EAAOkE,GAAsB,EAAIJ,EAAeI,GAAsB,IAGxE,IAAIpC,EA5EN,SAA4BkC,EAAQI,QAA0B,IAA1BA,IAAAA,EAAe,KACjD,MAIkB,kBAAPJ,EAAkBjD,EAAUiD,GAAMA,EAHjCC,EADZ,EACEpD,SADF,IAEE9qC,OAAAA,OAFF,MAEW,GAFX,MAGEsuC,KAAAA,OAHF,MAGS,GAHT,EAMIxD,EAAWoD,EACXA,EAAWjC,WAAW,KACpBiC,EAWR,SAAyBpC,EAAsBuC,GAC7C,IAAI/B,EAAW+B,EAAatsD,QAAQ,OAAQ,IAAIjB,MAAM,KAYtD,OAXuBgrD,EAAahrD,MAAM,KAEzBC,SAASyrD,SAAAA,GACR,OAAZA,EAEEF,EAAS1tD,OAAS,GAAG0tD,EAASjH,MACb,MAAZmH,GACTF,EAAS39C,KAAK69C,MAIXF,EAAS1tD,OAAS,EAAI0tD,EAAS14B,KAAK,KAAO,IAvB5C26B,CAAgBL,EAAYG,GAC9BA,EAEJ,MAAO,CACLvD,SAAAA,EACA9qC,OAAQwuC,EAAgBxuC,GACxBsuC,KAAMG,EAAcH,IA4DXI,CAAYT,EAAIhE,GAY3B,OAREiE,GACe,MAAfA,GACAA,EAAWb,SAAS,OACnBtB,EAAKjB,SAASuC,SAAS,OAExBtB,EAAKjB,UAAY,KAGZiB,EAYT,SAAgBhB,EACdD,EACAD,GAEA,GAAiB,MAAbA,EAAkB,OAAOC,EAE7B,IAAKA,EAAS9pD,cAAcirD,WAAWpB,EAAS7pD,eAC9C,OAAO,KAGT,IAAI2tD,EAAW7D,EAASv+C,OAAOs+C,EAASjsD,QACxC,OAAI+vD,GAAyB,MAAbA,EAEP,KAGF7D,EAASzpD,MAAMwpD,EAASjsD,SAAW,IAG5C,IAAastD,EAAa0C,SAAAA,GAAD,OACvBA,EAAMh7B,KAAK,KAAK7xB,QAAQ,SAAU,MAEvBirD,EAAqBlC,SAAAA,GAAD,OAC/BA,EAAS/oD,QAAQ,OAAQ,IAAIA,QAAQ,OAAQ,MAEzCysD,EAAmBxuC,SAAAA,GAAD,OACrBA,GAAqB,MAAXA,EAEPA,EAAOisC,WAAW,KAClBjsC,EACA,IAAMA,EAHN,IAKAyuC,EAAiBH,SAAAA,GAAD,OACnBA,GAAiB,MAATA,EAAoBA,EAAKrC,WAAW,KAAOqC,EAAO,IAAMA,EAAzC,ICjmB1B,SAAgBO,EAAQZ,GAEpBa,KADFtE,GAAU,GAOV,OAA8B7H,EAAAA,EAAAA,YAAiBwH,GAAzCU,EAAN,EAAMA,SAAU/a,EAAhB,EAAgBA,UAChB,EAAiCif,EAAgBd,GAA3CK,EAAN,EAAMA,KAAMxD,EAAZ,EAAYA,SAAU9qC,EAAtB,EAAsBA,OAElBgvC,EAAiBlE,EACrB,GAAiB,MAAbD,EAAkB,CACpB,IAAIqD,ED0iBR,SAA8BD,GAE5B,MAAc,KAAPA,GAAuC,KAAzBA,EAAYnD,SAC7B,IACc,kBAAPmD,EACPjD,EAAUiD,GAAInD,SACdmD,EAAGnD,SChjBYmE,CAAchB,GAC3BiB,EAA8B,MAAdhB,GAAsBA,EAAWb,SAAS,KAC9D2B,EACe,MAAblE,EACID,GAAYqE,EAAgB,IAAM,IAClChD,EAAU,CAACrB,EAAUC,IAG7B,OAAOhb,EAAUqf,WAAW,CAAErE,SAAUkE,EAAgBhvC,OAAAA,EAAQsuC,KAAAA,IAQlE,SAAgBQ,IACd,OAA4C,OAArCnM,EAAAA,EAAAA,YAAiByH,GAa1B,SAAgBgF,IAQd,OANEN,KADFtE,GAAU,IAOH7H,EAAAA,EAAAA,YAAiByH,GAAiBrtC,SAyD3C,SAAgBsyC,IAEZP,KADFtE,GAAU,GAOV,OAA8B7H,EAAAA,EAAAA,YAAiBwH,GAAzCU,EAAN,EAAMA,SAAU/a,EAAhB,EAAgBA,UACVya,GAAY5H,EAAAA,EAAAA,YAAiB0H,GAA7BE,QACUyD,EAAqBoB,IAA/BtE,SAEFwE,EAAqBxmB,KAAKC,UAC5BwhB,EAAQlO,KAAKz4C,SAAAA,GAAD,OAAWA,EAAMmpD,iBAG3BwC,GAAY5M,EAAAA,EAAAA,SAAa,GAsC7B,OArCAA,EAAAA,EAAAA,YAAgB,WACd4M,EAAU5+C,SAAU,MAGWgyC,EAAAA,EAAAA,cAC/B,SAACsL,EAAiBzmD,GAOhB,QAPkD,IAAlCA,IAAAA,EAA2B,IAOtC+nD,EAAU5+C,QAEf,GAAkB,kBAAPs9C,EAAX,CAKA,IAAIlC,EAAO8B,EACTI,EACAnlB,KAAK0mB,MAAMF,GACXtB,GAGe,MAAbnD,IACFkB,EAAKjB,SAAWoB,EAAU,CAACrB,EAAUkB,EAAKjB,aAGzCtjD,EAAQzF,QAAU+tC,EAAU/tC,QAAU+tC,EAAUnhC,MACjDo9C,EACAvkD,EAAQmrB,YAhBRmd,EAAU2f,GAAGxB,KAmBjB,CAACpD,EAAU/a,EAAWwf,EAAoBtB,IAsD9C,SAAgBe,EAAgBd,GAC9B,IAAM1D,GAAY5H,EAAAA,EAAAA,YAAiB0H,GAA7BE,QACUyD,EAAqBoB,IAA/BtE,SAEFwE,EAAqBxmB,KAAKC,UAC5BwhB,EAAQlO,KAAKz4C,SAAAA,GAAD,OAAWA,EAAMmpD,iBAG/B,OAAOpK,EAAAA,EAAAA,UACL,kBAAMkL,EAAUI,EAAInlB,KAAK0mB,MAAMF,GAAqBtB,KACpD,CAACC,EAAIqB,EAAoBtB,IA2H7B,SAAgB0B,EACdnF,EACAoF,GAEA,YAD2B,IAD3BA,IAAAA,EAA8B,IAEf,MAAXpF,EAAwB,KAErBA,EAAQqF,aAAY,SAACtF,EAAQ1mD,EAAOmwB,GACzC,OACE87B,EAAAA,EAAAA,eAACxF,EAAalH,SAAd0M,CACE/nD,cAC0BonC,IAAxBtrC,EAAMioD,MAAMxnC,QAAwBzgB,EAAMioD,MAAMxnC,QAAUimC,EAE5DnkD,MAAO,CACLmkD,OAAAA,EACAC,QAASoF,EAAcrpC,OAAOikC,EAAQlpD,MAAM,EAAG0yB,EAAQ,SAI5D,MC3PL,SAAgB+7B,EACdC,GAEAvF,GAAU,GAyBZ,SAAgBwF,EAATpS,GAOoC,QANzCiN,SAAUoF,OAM+B,MANhB,IAMgB,MALzCnoD,SAAAA,OAKyC,MAL9B,KAK8B,EAJ/BooD,EAI+B,EAJzCnzC,SAIyC,IAHzCozC,eAAAA,OAGyC,MAHxBC,EAAAA,IAGwB,EAFzCtgB,EAEyC,EAFzCA,UAEyC,IADzCugB,OAAQC,OACiC,SAEtCxB,KADHtE,GAAU,GAMV,IAAIK,EAAWmC,EAAkBiD,GAC7BM,GAAoB5N,EAAAA,EAAAA,UACtB,iBAAO,CAAEkI,SAAAA,EAAU/a,UAAAA,EAAWugB,OAAQC,KACtC,CAACzF,EAAU/a,EAAWwgB,IAGI,kBAAjBJ,IACTA,EAAelF,EAAUkF,IAG3B,MAMIA,EANJ,IACEpF,SAAAA,OADF,MACa,IADb,MAEE9qC,OAAAA,OAFF,MAEW,GAFX,MAGEsuC,KAAAA,OAHF,MAGS,GAHT,MAIE37B,MAAAA,OAJF,MAIU,KAJV,MAKEhW,IAAAA,OALF,MAKQ,UALR,EAQII,GAAW4lC,EAAAA,EAAAA,UAAc,WAC3B,IAAI6N,EAAmBzF,EAAcD,EAAUD,GAE/C,OAAwB,MAApB2F,EACK,KAGF,CACL1F,SAAU0F,EACVxwC,OAAAA,EACAsuC,KAAAA,EACA37B,MAAAA,EACAhW,IAAAA,KAED,CAACkuC,EAAUC,EAAU9qC,EAAQsuC,EAAM37B,EAAOhW,IAS7C,OAAgB,MAAZI,EACK,MAIP8yC,EAAAA,EAAAA,eAAC1F,EAAkBhH,SAAnB0M,CAA4B1pD,MAAOoqD,IACjCV,EAAAA,EAAAA,eAACzF,EAAgBjH,SAAjB0M,CACE/nD,SAAUA,EACV3B,MAAO,CAAE4W,SAAAA,EAAUozC,eAAAA,MAiB3B,SAAgBM,EAATC,GAGoC,IAFzC5oD,EAEyC,EAFzCA,SACAiV,EACyC,EADzCA,SAEA,ODUF,SACE4tC,EACAC,GAGEkE,KADFtE,GAAU,GAOV,IA4CIztC,EA5CW4yC,GAAkBhN,EAAAA,EAAAA,YAAiB0H,GAA5CE,QACFoG,EAAahB,EAAcA,EAAc/wD,OAAS,GAClDgyD,EAAeD,EAAaA,EAAW7D,OAAS,GAEhD+D,GADiBF,GAAaA,EAAW7F,SACpB6F,EAAaA,EAAW5D,aAAe,KAsC5D+D,GArCcH,GAAcA,EAAW9E,MAqCjBuD,KAG1B,GAAIxE,EAAa,OACXmG,EACqB,kBAAhBnG,EAA2BI,EAAUJ,GAAeA,EAGpC,MAAvBiG,IAAA,OAAAA,EACEE,EAAkBjG,eADpB,EACEkG,EAA4B/E,WAAW4E,KAF3CrG,GAAU,GASVztC,EAAWg0C,OAEXh0C,EAAW+zC,EAGb,IAAIhG,EAAW/tC,EAAS+tC,UAAY,IAKhCP,EAAUG,EAAYC,EAAQ,CAAEG,SAHX,MAAvB+F,EACI/F,EACAA,EAASzpD,MAAMwvD,EAAmBjyD,SAAW,MAiBnD,OAAO8wD,EACLnF,GACEA,EAAQlO,KAAKz4C,SAAAA,GAAD,OACVnE,OAAO8D,OAAO,GAAIK,EAAO,CACvBkpD,OAAQrtD,OAAO8D,OAAO,GAAIqtD,EAAchtD,EAAMkpD,QAC9ChC,SAAUoB,EAAU,CAAC2E,EAAoBjtD,EAAMknD,WAC/CiC,aACyB,MAAvBnpD,EAAMmpD,aACF8D,EACA3E,EAAU,CAAC2E,EAAoBjtD,EAAMmpD,oBAGjD4C,GCrHKsB,CAAUC,EAAyBppD,GAAWiV,GAcvD,SAAgBm0C,EACdppD,GAEA,IAAI6iD,EAAwB,GAuC5B,OArCAhI,EAAAA,SAAAA,QAAuB76C,GAAWuc,SAAAA,GAChC,IAAKs+B,EAAAA,EAAAA,gBAAqBt+B,GAM1B,GAAIA,EAAQ3jB,OAASiiD,EAAAA,SAArB,CAUEt+B,EAAQ3jB,OAASovD,GADnBtF,GAAU,GAOV,IAAIqB,EAAqB,CACvBG,cAAe3nC,EAAQ4O,MAAM+4B,cAC7B3nC,QAASA,EAAQ4O,MAAM5O,QACvB0P,MAAO1P,EAAQ4O,MAAMc,MACrBg4B,KAAM1nC,EAAQ4O,MAAM84B,MAGlB1nC,EAAQ4O,MAAMnrB,WAChB+jD,EAAM/jD,SAAWopD,EAAyB7sC,EAAQ4O,MAAMnrB,WAG1D6iD,EAAOh8C,KAAKk9C,QAzBVlB,EAAOh8C,KAAKY,MACVo7C,EACAuG,EAAyB7sC,EAAQ4O,MAAMnrB,cA0BtC6iD,2ZCtKF,SAASwG,EAAT,GAIgB,IAHrBtG,EAGqB,EAHrBA,SACA/iD,EAEqB,EAFrBA,SACAzI,EACqB,EADrBA,OAEI+xD,GAAazO,EAAAA,EAAAA,UACS,MAAtByO,EAAWzgD,UACbygD,EAAWzgD,skDAAU0gD,CAAqB,CAAEhyD,OAAAA,KAG9C,IAAIiyD,EAAUF,EAAWzgD,QACzB,KAAwBgyC,EAAAA,EAAAA,UAAe,CACrCxrB,OAAQm6B,EAAQn6B,OAChBpa,SAAUu0C,EAAQv0C,WAFpB,GAAK4V,EAAL,KAAY+hB,EAAZ,KAOA,OAFAiO,EAAAA,EAAAA,kBAAsB,kBAAM2O,EAAQC,OAAO7c,KAAW,CAAC4c,KAGrDzB,EAAAA,EAAAA,eAACG,EAADH,CACEhF,SAAUA,EACV/iD,SAAUA,EACViV,SAAU4V,EAAM5V,SAChBozC,eAAgBx9B,EAAMwE,OACtB2Y,UAAWwhB,QA4FJE,GAAO7O,EAAAA,EAAAA,aAClB,WAEEnvB,GACA,IAFEyM,EAEF,EAFEA,QAASwxB,EAEX,EAFWA,eAEX,IAF2B1vD,QAAAA,OAE3B,SAF4C4wB,EAE5C,EAF4CA,MAAO5kB,EAEnD,EAFmDA,OAAQkgD,EAE3D,EAF2DA,GAAOyD,EAElE,OACI9uC,EAAOisC,EAAQZ,GACf0D,EAwHD,SACL1D,EADK,GAW6C,iBAD9C,GAC8C,EARhDlgD,EAQgD,EARhDA,OACS6jD,EAOuC,EAPhD7vD,QACA4wB,EAMgD,EANhDA,MAOEk/B,EAAWxC,IACXtyC,EAAWqyC,IACXrD,EAAOgD,EAAgBd,GAE3B,OAAOtL,EAAAA,EAAAA,cACJliC,SAAAA,GACC,GACmB,IAAjBA,EAAMvG,UACJnM,GAAqB,UAAXA,KAjKpB,SAAyB0S,GACvB,SAAUA,EAAM1G,SAAW0G,EAAM3G,QAAU2G,EAAM7G,SAAW6G,EAAM5G,UAiK3Di4C,CAAgBrxC,GACjB,CACAA,EAAMxI,iBAIN,IAAIlW,IACA6vD,GAAeG,EAAWh1C,KAAcg1C,EAAWhG,GAEvD8F,EAAS5D,EAAI,CAAElsD,QAAAA,EAAS4wB,MAAAA,OAG5B,CAAC5V,EAAU80C,EAAU9F,EAAM6F,EAAaj/B,EAAO5kB,EAAQkgD,IAzJjC+D,CAAoB/D,EAAI,CAAElsD,QAAAA,EAAS4wB,MAAAA,EAAO5kB,OAAAA,IAUhE,OAEExO,EAAAA,EAAAA,eAAAA,IAAAA,EAAAA,GACMmyD,EADN,CAEE9uC,KAAMA,EACNqd,QAdJ,SACExf,GAEIwf,GAASA,EAAQxf,GAChBA,EAAM3I,kBAAqB25C,GAC9BE,EAAgBlxC,IAUhB+S,IAAKA,EACLzlB,OAAQA,QC5RT,IAAMsN,EAAM,CAAC,CAAC,qqDAAmiB,+1BAAg2B,gXACx5C,CAAC,smEAA6hB,o7BAAq7B,0KACn9C,CAAC,44DAAqhB,40BAA60B,QACn2C,CAAC,gtDAAmb,2wBAA4wB,gNAChsC,CAAC,otGAAyzB,+uCAAgvC,KAC1iE,CAAC,i6CAAoX,inBAAknB,KACv+B,CAAC,usDAAyb,6vBAA8vB,uFACxrC,CAAC,utBAAiM,qWAAsW,MACxiB,CAAC,s0EAAqtB,ilCAAklC,8TACxyD,CAAC,g9CAA8Z,usBAAwsB,MACvmC,CAAC,ypDAAkc,iwBAAkwB,8EACrsC,CAAC,s1CAA+W,yoBAA0oB,4MAC1/B,CAAC,k7EAA+1B,6tCAA8tC,sMAC9jE,CAAC,smFAA+wB,4tCAA6tC,yKAC7+D,CAAC,s7BAAwS,ydAA0d,KACnwB,CAAC,glDAAoc,8pBAA+pB,wJACpmC,CAAC,i+CAAob,ktBAAmtB,iJACxoC,CAAC,slDAAmZ,wrBAAyrB,gLAC7kC,CAAC,kwCAAsW,wnBAAynB,KACh+B,CAAC,4zCAA0V,slBAAulB,KACl7B,CAAC,6hCAAyU,ofAAqf,4NAC/zB,CAAC,4yEAA4lB,y9BAA09B,KACvjD,CAAC,ovFAA2sB,mwCAAowC,KACh9D,CAAC,m1CAAgY,6qBAA8qB,oFAC/iC,CAAC,+uDAA6c,8zBAA+zB,KAC7wC,CAAC,wqDAA6gB,+wBAAgxB,QAC9xC,CAAC,6hDAAqa,ytBAA0tB,KAChoC,CAAC,g+EAAotB,+nCAAgoC,MACr1D,CAAC,+sDAAgd,2xBAA4xB,KAC7uC,CAAC,+gEAAmf,6zBAA8zB,yTAClzC,CAAC,64CAA+W,0oBAA2oB,MAC3/B,CAAC,8+BAA6T,yfAA0f,qOACxzB,CAAC,++DAA2kB,q8BAAs8B,KAClhD,CAAC,4tBAA0N,yVAA0V,mUACrjB,CAAC,0tDAAgZ,qvBAAsvB,mpBACvoC,CAAC,ixFAAy3B,m3CAAo3C,KAC9uE,CAAC,ujDAAgb,4sBAA6sB,KAC9nC,CAAC,i4CAA0Z,yoBAA0oB,yjBACriC,CAAC,0sEAAgpB,+kCAAglC,oHACjuD,CAAC,0lDAAwY,2yBAA4yB,mQACrrC,CAAC,++FAAy0B,kvCAAmvC,mMAC7jE,CAAC,wpFAA4zB,q0CAAs0C,KACnoE,CAAC,+/CAA6X,wrBAAyrB,KACvjC,CAAC,q4DAAolB,g3BAAi3B,wOACt8C,CAAC,w7DAA6iB,o5BAAq5B,4UACn8C,CAAC,0uDAA2e,oyBAAqyB,+NACjxC,CAAC,mlEAA4oB,qkCAAskC,QACntD,CAAC,4+CAAmiB,kxBAAmxB,sRACvzC,CAAC,4iEAA2lB,m6BAAo6B,KAChgD,CAAC,gvFAA2tB,0wCAA2wC,KACv+D,CAAC,40EAA2jB,8hCAA+hC,KAC3lD,CAAC,6vEAAgqB,wlCAAylC,yLAC1vD,CAAC,8oCAA0W,2iBAA4iB,KACv5B,CAAC,ysDAAua,mzBAAozB,iGAC5tC,CAAC,mmDAAiZ,isBAAksB,+PACplC,CAAC,2rCAA6Y,qlBAAslB,KACp+B,CAAC,2vCAA0V,kkBAAmkB,KAC95B,CAAC,koEAAqnB,6jCAA8jC,KACprD,CAAC,gyCAAme,8tBAA+tB,6bACnsC,CAAC,u1DAAqjB,o4BAAq4B,KAC37C,CAAC,oxBAAkR,iYAAkY,KACrpB,CAAC,gkEAAqhB,q3BAAs3B,QAC54C,CAAC,w1EAAonB,+iCAAgjC,qPACrqD,CAAC,g3DAA+e,2zBAA4zB,KAC5yC,CAAC,wjCAAyR,oaAAqa,KAC/rB,CAAC,48DAA8mB,27BAA47B,qNAC3iD,CAAC,+mDAAod,8uBAA+uB,uFACpsC,CAAC,03EAA0vB,wnCAAynC,KACp3D,CAAC,uyDAAskB,m2BAAo2B,KAC36C,CAAC,4zCAA+a,kpBAAmpB,mlBACnkC,CAAC,w9EAAsoB,moCAAooC,wLAC3wD,CAAC,wyDAA+hB,g5BAAi5B,KACj7C,CAAC,q9CAAiX,irBAAkrB,0hDACpiC,CAAC,0vEAA+nB,s8BAAu8B,kSACvkD,CAAC,kjDAAoc,42BAA62B,gQAClzC,CAAC,ixGAAg4B,8kDAA+kD,OACh9E,CAAC,g9BAA8S,0cAA2c,KAC1vB,CAAC,o4EAAwnB,wgCAAygC,4NACloD,CAAC,+sGAA60B,i+CAAk+C,sKAChzE,CAAC,6nEAA4lB,27BAA47B,yDACzhD,CAAC,i8BAA2Q,kdAAmd,KAC/tB,CAAC,m9CAA0b,6tBAA8tB,KACzpC,CAAC,glEAA4lB,6/BAA8/B,MAC3lD,CAAC,40BAAiO,yWAA0W,kDAC5kB,CAAC,+8DAA+jB,q8BAAs8B,KACtgD,CAAC,koCAAoV,wgBAAygB,KAC91B,CAAC,gtGAAu2B,68CAA88C,0EACtzE,CAAC,2uEAAgiB,k+BAAm+B,yFACpgD,CAAC,2yEAAkuB,2pCAA4pC,4EAC/3D,CAAC,ypGAA2yB,01CAA21C,KACvoE,CAAC,4jFAAyqB,koCAAmoC,KAC7yD,CAAC,mxFAAu7B,u7CAAw7C,KACh3E,CAAC,8tEAA2jB,q/BAAs/B,KACljD,CAAC,+hEAA6gB,u1BAAw1B,KACt2C,CAAC,oyCAA6Y,4lBAA6lB,KAC3+B,CAAC,g5DAA4e,05BAA25B,KACx4C,CAAC,6yDAAkf,+1BAAg2B,KACn1C,CAAC,qtHAAsjC,00DAA20D,KACl4F,CAAC,gzFAAmqB,8uCAA+uC,KACn5D,CAAC,2hDAA4b,0qBAA2qB,KACxmC,CAAC,m+EAAomB,m8BAAo8B,mJACziD,CAAC,2mDAAgY,qrBAAsrB,KACvjC,CAAC,gtEAAomB,ulCAAwlC,QAC7rD,CAAC,mmGAAq+B,mnDAAonD,KAC1lF,CAAC,0jGAAw1B,u4CAAw4C,KACjuE,CAAC,kwEAAmsB,6nCAA8nC,KACl0D,CAAC,omEAAojB,u+BAAw+B,KAC7hD,CAAC,2pFAAguB,0zCAA2zC,KAC5hE,CAAC,+kGAA6sB,w2CAAy2C,KACvjE,CAAC,o3FAAkuB,66CAA86C,KACjpE,CAAC,+1BAA6Q,2cAA4c,KAC1tB,CAAC,21CAAyX,qoBAAsoB,uNAChgC,CAAC,m8DAA+c,81BAA+1B,KAC/yC,CAAC,k+EAAwrB,qsCAAssC,KAC/3D,CAAC,iwDAAsc,iwBAAkwB,KACzsC,CAAC,qqEAA0nB,yiCAA0iC,KACrqD,CAAC,omEAAwkB,65BAA85B,KACv+C,CAAC,ulCAAoS,mhBAAohB,KACzzB,CAAC,88CAAwY,gqBAAiqB,6EAC1iC,CAAC,08CAAgX,4rBAA6rB,KAC9iC,CAAC,gyDAAge,sxBAAuxB,KACxvC,CAAC,iiDAAkX,0rBAA2rB,KAC9iC,CAAC,mtCAA6X,0oBAA2oB,0QACzgC,CAAC,o7CAAob,yuBAA0uB,KAC/pC,CAAC,whCAAoU,yiBAA0iB,KAC/2B,CAAC,8oDAA4b,k2BAAm2B,KAChyC,CAAC,+6FAA62B,uzCAAwzC,KACtqE,CAAC,yoFAAosB,41CAA61C,oJACliE,CAAC,+kDAAyb,wrBAAyrB,KACnnC,CAAC,uqDAA+Y,qtBAAstB,6YACtmC,CAAC,w1CAAqY,+mBAAgnB,KACt/B,CAAC,quDAAie,kvBAAmvB,KACrtC,CAAC,4mFAAkqB,ylCAA0lC,KAC7vD,CAAC,shHAAg5B,gnDAAinD,KAClgF,CAAC,m/HAA8mC,21DAA41D,KAC38F,CAAC,suEAAyoB,qiCAAsiC,KAChrD,CAAC,k5DAA0iB,k/BAAm/B,0HAC9hD,CAAC,ghDAAsgB,gyBAAiyB,KACxyC,CAAC,wmFAA+yB,oyCAAqyC,KACrlE,CAAC,stFAAuwB,muCAAouC,KAC5+D,CAAC,y+CAAgd,wuBAAyuB,qBAC1rC,CAAC,ixDAAmgB,4zBAA6zB,KACj0C,CAAC,yjEAAqf,48BAA68B,KACn8C,CAAC,s9DAAohB,80BAA+0B,KACp2C,CAAC,0oEAAmnB,i8BAAk8B,KACtjD,CAAC,kzDAAkpB,27BAA47B,KAC/kD,CAAC,4iEAAoiB,q3BAAs3B,KAC35C,CAAC,m3EAA2xB,wvCAAyvC,wNACrhE,CAAC,qwDAAod,6uBAA8uB,KACnsC,CAAC,q7CAA6Y,moBAAooB,KAClhC,CAAC,svCAA2U,mhBAAohB,KACh2B,CAAC,+mCAA2U,giBAAiiB,KAC72B,CAAC,qtGAAk2B,05CAA25C,KAC9vE,CAAC,0iCAA4U,sfAAuf,uEACp0B,CAAC,w9CAAue,yvBAA0vB,4IACluC,CAAC,mkEAAqpB,yiCAA0iC,KAChsD,CAAC,yhGAAmhC,2lDAA4lD,qKAChnF,CAAC,2/CAAwY,yoBAA0oB,QACnhC,CAAC,wmCAA4R,0fAA2f,KACxxB,CAAC,inEAA0lB,iiCAAkiC,KAC7nD,CAAC,0vEAAiwB,qoCAAsoC,KACx4D,CAAC,42CAAiX,2lBAA4lB,KAC98B,CAAC,2+EAA6vB,iuCAAkuC,KACh+D,CAAC,05DAAkjB,ohCAAqhC,KACxkD,CAAC,2jDAAsZ,mtBAAotB,KAC3mC,CAAC,kiDAA+a,uvBAAwvB,uGACxqC,CAAC,irCAAkU,2gBAA4gB,QAC/0B,CAAC,myDAA8iB,m7BAAo7B,KACn+C,CAAC,skCAAqU,6eAA8e,KACpzB,CAAC,kuEAA2nB,0lCAA2lC,KACvtD,CAAC,ozBAA8M,4YAA6Y,0GAC5lB,CAAC,u4DAAilB,+6BAAg7B,KAClgD,CAAC,o4CAA+c,6tBAA8tB,KAC9qC,CAAC,2jBAA6O,uVAAwV,mKACtkB,CAAC,07EAA0pB,6yCAA8yC,QACz8D,CAAC,gkDAA0a,0vBAA2vB,KACtqC,CAAC,qkDAA8gB,owBAAqwB,KACpxC,CAAC,upDAAmjB,85BAA+5B,KACn9C,CAAC,w0CAAka,0pBAA2pB,8gBAC9jC,CAAC,wlGAAqzB,+uCAAgvC,KACtiE,CAAC,2xDAAid,szBAAuzB,QACzwC,CAAC,uoEAA+iB,+9BAAg+B,KAChhD,CAAC,8tEAAitB,uoCAAwoC,KAC11D,CAAC,svCAA2Z,skBAAukB,KACn+B,CAAC,moEAA8pB,68BAA88B,KAC7mD,CAAC,k0DAAugB,+4BAAg5B,KACx5C,CAAC,ymEAAgiB,q/BAAs/B,wWACvhD,CAAC,i4BAAwP,ocAAqc,uGAC9rB,CAAC,25FAAszB,84CAA+4C,0LACtsE,CAAC,uzDAAua,4rBAA6rB,KACrmC,CAAC,+nDAAgd,kyBAAmyB,+PACpvC,CAAC,4hGAA2tB,4sCAA6sC,KACz6D,CAAC,4qEAA+kB,ikCAAkkC,KAClpD,CAAC,szDAAif,qzBAAszB,kCACxyC,CAAC,0kDAAmc,qxBAAsxB,OAC1tC,CAAC,koFAA8vB,ixCAAkxC,KACjhE,CAAC,65CAA2W,+lBAAgmB,QAC58B,CAAC,slFAAmxB,myCAAoyC,KACxjE,CAAC,w0CAA6U,mjBAAojB,QACl4B,CAAC,siEAA0lB,2hCAA4hC,KACvnD,CAAC,04BAAsQ,kcAAmc,KAC1sB,CAAC,0jDAA+Z,ytBAA0tB,KAC1nC,CAAC,uyFAA0uB,yyCAA0yC,KACrhE,CAAC,itEAA8nB,+jCAAgkC,QAC/rD,CAAC,ooCAA0W,ikBAAkkB,8KAC76B,CAAC,gsDAAqd,ovBAAqvB,KAC3sC,CAAC,2gDAA4a,mrBAAorB,KACjmC,CAAC,g6EAAwvB,qlCAAslC,8HAC/0D,CAAC,g3BAAgQ,gZAAiZ,KAClpB,CAAC,0iEAA+pB,ogCAAqgC,KACrqD,CAAC,olCAAwQ,ugBAAwgB,KACjxB,CAAC,q/CAAmc,usBAAwsB,KAC5oC,CAAC,u1FAA8tB,s2CAAu2C,KACtkE,CAAC,w2DAAwiB,67BAA87B,KACv+C,CAAC,yqFAAqoB,8mCAA+mC,KACrvD,CAAC,2iEAA0lB,o/BAAq/B,KAChlD,CAAC,quCAA2S,wgBAAygB,KACrzB,CAAC,y1DAAikB,mzBAAozB,KACt3C,CAAC,iuCAA0U,8hBAA+hB,QAC12B,CAAC,o0CAA8U,4kBAA6kB,QAC55B,CAAC,63DAAilB,+6BAAg7B,KAClgD,CAAC,snGAAk2B,46CAA66C,KAChxE,CAAC,+iDAAgY,ssBAAusB,kTACxkC,CAAC,k2CAA6a,wrBAAyrB,KACvmC,CAAC,8oDAAmf,2sBAA4sB,KAChsC,CAAC,o2CAA2U,wiBAAyiB,KACr3B,CAAC,0qDAA6d,ywBAA0wB,KACxuC,CAAC,+4CAA2X,qpBAAspB,+JAClhC,CAAC,+vFAAgzB,kyCAAmyC,KACplE,CAAC,u4CAA4Y,ksBAAmsB,QAChlC,CAAC,u0BAA0P,4WAA6W,KACxmB,CAAC,yzDAA4mB,67BAA87B,KAC3iD,CAAC,26EAA2oB,2nCAA4nC,KACxwD,CAAC,0hEAAykB,q6BAAs6B,QACh/C,CAAC,08FAAqxB,0uCAA2uC,+HACjgE,CAAC,wmFAA+oB,mrCAAorC,KACp0D,CAAC,+vEAAqnB,ulCAAwlC,KAC9sD,CAAC,siCAA+S,+eAAgf,qIAChyB,CAAC,myDAA6jB,q7BAAs7B,oFACp/C,CAAC,m5CAA6Z,isBAAksB,KAChmC,CAAC,mlDAAof,8yBAA+yB,KACpyC,CAAC,6sHAAyiC,owDAAqwD,KAC/yF,CAAC,gyEAAwnB,gkCAAikC,KAC1rD,CAAC,42DAA+f,w0BAAy0B,QACz0C,CAAC,4lCAA2V,ukBAAwkB,QACp6B,CAAC,w4CAA2V,6nBAA8nB,oBAC19B,CAAC,qkEAA8nB,ykCAA0kC,qHACzsD,CAAC,i1DAA6f,21BAA41B,KAC11C,CAAC,6oEAA2iB,67BAA87B,KAC1+C,CAAC,szBAA0S,ydAA0d,8CACrwB,CAAC,8vCAA6a,wpBAAypB,KACvkC,CAAC,6rBAAwO,iVAAkV,KAC3jB,CAAC,6xDAAikB,62BAA82B,KACh7C,CAAC,i/FAA0wB,8xCAA+xC,KAC1iE,CAAC,qwCAA+V,8jBAA+jB,KAC/5B,CAAC,4kFAAywB,uqCAAwqC,KACl7D,CAAC,o8CAA+b,ytBAA0tB,QAC1pC,CAAC,ksDAAolB,+5BAAg6B,KACr/C,CAAC,qmDAA0c,+wBAAgxB,wZAC3tC,CAAC,8xCAA2Z,ksBAAmsB,qBAC/lC,CAAC,i1FAAo2B,o1CAAq1C,KAC1rE,CAAC,kmFAAiwB,orCAAqrC,KACv7D,CAAC,qjCAAyT,ueAAwe,KAClyB,CAAC,glDAA4e,qrBAAsrB,KACnqC,CAAC,41EAA2kB,gkCAAikC,KAC7oD,CAAC,0qCAA4S,oiBAAqiB,KACl1B,CAAC,kgDAAqY,8qBAA+qB,KACrjC,CAAC,suBAAmP,mZAAoZ,KACxoB,CAAC,q2CAAgW,0pBAA2pB,sNAC5/B,CAAC,mxFAA8vB,wrCAAyrC,KACx7D,CAAC,q+CAA0e,2uBAA4uB,KACvtC,CAAC,yrCAA4X,4lBAA6lB,KAC19B,CAAC,22EAA4jB,qhCAAshC,KACnlD,CAAC,yrEAA6kB,u8BAAw8B,KACthD,CAAC,0/CAA8W,wlBAAylB,QACx8B,CAAC,09FAAw0B,06CAA26C,KACpvE,CAAC,k1DAA6b,o1BAAq1B,KACnxC,CAAC,qzCAA0Y,omBAAqmB,KACh/B,CAAC,qhFAA6sB,6uCAA8uC,KAC57D,CAAC,0uFAAqtB,qvCAAsvC,KAC58D,CAAC,oxGAAq7B,m9CAAo9C,KAC14E,CAAC,msCAAkS,+kBAAglB,iDACn3B,CAAC,qkEAA2gB,+6BAAg7B,KAC57C,CAAC,y6DAAkjB,k7BAAm7B,KACt+C,CAAC,ipIAAokC,w9DAAy9D,+FAC9hG,CAAC,qvDAAif,02BAA22B,KAC71C,CAAC,8iCAA0V,mhBAAohB,QAC/2B,CAAC,8sEAAurB,+/BAAggC,KACxrD,CAAC,syGAAk3B,6+CAA8+C,0FACj2E,CAAC,62EAA4lB,s/BAAu/B,KACplD,CAAC,q/BAAsS,2dAA4d,KACnwB,CAAC,izDAA+gB,82BAA+2B,KAC/3C,CAAC,otEAAmmB,s9BAAu9B,QAC3jD,CAAC,yvBAA+R,4ZAA6Z,KAC7rB,CAAC,q/CAA8W,2qBAA4qB,KAC3hC,CAAC,oiFAAsuB,uoCAAwoC,iDAC/2D,CAAC,6sGAA44B,qiDAAsiD,KACn7E,CAAC,o+DAA+kB,+/BAAggC,qBAChlD,CAAC,usGAAy1B,ygDAA0gD,KACp2E,CAAC,qmCAAyW,kiBAAmiB,KAC74B,CAAC,m1EAAkuB,wpCAAypC,KAC53D,CAAC,4vEAAunB,q9BAAs9B,QAC9kD,CAAC,o9CAAqX,6oBAA8oB,iCACpgC,CAAC,0kEAAmjB,m/BAAo/B,KACxiD,CAAC,4vDAA4gB,q0BAAs0B,KACn1C,CAAC,0sCAAkU,4lBAA6lB,0RACh6B,CAAC,sjDAAie,+xBAAgyB,QAClwC,CAAC,oqEAA8sB,y/BAA0/B,QACzsD,CAAC,kzGAA6iC,qlDAAslD,KACpoF,CAAC,w9CAAyX,gqBAAiqB,KAC3hC,CAAC,inDAAmb,mtBAAotB,KACxoC,CAAC,i3FAAqtB,swCAAuwC,KAC79D,CAAC,w9CAAgb,wvBAAyvB,QAC1qC,CAAC,qrEAA0jB,whCAAyhC,KACplD,CAAC,6+FAAiwB,w3CAAy3C,KAC3nE,CAAC,20EAAkrB,6jCAA8jC,KACjvD,CAAC,ooDAAkgB,4xBAA6xB,KAChyC,CAAC,4pDAA4f,w2BAAy2B,QACt2C,CAAC,+tFAAiwB,ytCAA0tC,KAC59D,CAAC,mxCAA+U,2jBAA4jB,KAC54B,CAAC,m2CAAgZ,inBAAknB,sqBACngC,CAAC,4jEAA4lB,kgCAAmgC,KAChmD,CAAC,8iHAAq9B,wlDAAylD,KAC/iF,CAAC,2vDAAuf,6tBAA8tB,KACttC,CAAC,snDAA2Y,quBAAsuB,KAClnC,CAAC,46EAAkjB,8hCAA+hC,KACllD,CAAC,sgFAAktB,isCAAksC,2FACr5D,CAAC,4mDAAoa,urBAAwrB,KAC7lC,CAAC,wqFAAoyB,iyCAAkyC,KACvkE,CAAC,ixCAAiW,glBAAilB,KACn7B,CAAC,svGAAw4B,+5CAAg6C,KACzyE,CAAC,u4DAA+hB,g5BAAi5B,KACj7C,CAAC,mvDAAmlB,s5BAAu5B,KAC3+C,CAAC,iqCAA+V,2jBAA4jB,KAC55B,CAAC,yxGAA83B,ghDAAihD,2NACh5E,CAAC,0uCAAsS,+jBAAgkB,KACv2B,CAAC,koFAAgpB,skCAAukC,KACxtD,CAAC,2gEAAyf,o7BAAq7B,KAC/6C,CAAC,8jDAAof,63BAAu1B,KAC50C,CAAC,qsDAA+iB,wzBAAyzB,KACz2C,CAAC,imEAAunB,49BAA69B,0LACrlD,CAAC,0uDAAgf,yyBAA0yB,KAC3xC,CAAC,ssDAAof,01BAA21B,KACh1C,CAAC,koFAAitB,qwCAAswC,KACx9D,CAAC,+wCAAmX,+nBAAgoB,KACp/B,CAAC,ixEAAskB,0iCAA2iC,QAClnD,CAAC,urDAA+Z,itBAAktB,KAClnC,CAAC,y8CAAuZ,0mBAA2mB,+IACngC,CAAC,i4CAA4X,stBAAutB,KACplC,CAAC,osDAAyd,qvBAAsvB,KAChtC,CAAC,s0EAA+oB,mgCAAogC,KACppD,CAAC,skFAA8vB,wwCAAywC,+JACxgE,CAAC,yhFAA6rB,iuCAAkuC,KACh6D,CAAC,qiDAAic,gwBAAiwB,KACnsC,CAAC,01EAAmlB,yhCAA0hC,KAC9mD,CAAC,8/EAA2rB,kqCAAmqC,KAC/1D,CAAC,uwCAAyY,moBAAooB,KAC9gC,CAAC,yvGAAg+B,4gDAA6gD,8LAC9+E,CAAC,4rFAAqsB,stCAAutC,KAC75D,CAAC,8oEAA6mB,gjCAAijC,KAC/pD,CAAC,usGAAs4B,mzCAAozC,oIAC3rE,CAAC,kxFAAsxB,01CAA21C,KAClnE,CAAC,yzCAAoY,ioBAAkoB,yEACvgC,CAAC,8nFAAuoB,spCAAupC,KAC/xD,CAAC,y4DAAkhB,63BAA83B,KACj5C,CAAC,81CAA0e,sxBAAuxB,uCAClwC,CAAC,i7DAA8f,k1BAAm1B,KACl1C,CAAC,oyDAAmf,s1BAAu1B,KAC30C,CAAC,6sDAAue,q4BAAs4B,KAC92C,CAAC,+rDAAqc,iuBAAkuB,KACxqC,CAAC,ypDAAmb,uuBAAwuB,QAC5pC,CAAC,u8CAA2Y,koBAAmoB,KAC/gC,CAAC,g7CAAyX,0rBAA2rB,KACrjC,CAAC,w4FAAq1B,07CAA27C,KACjxE,CAAC,6vDAA+e,+3BAAg4B,KACh3C,CAAC,6jCAAuY,qcAAsc,KAC90B,CAAC,snCAA8T,qgBAAsgB,QACr0B,CAAC,+tDAAqe,8vBAA+vB,KACruC,CAAC,g5CAA6W,goBAAioB,KAC/+B,CAAC,4/FAAmzB,q0DAA0gB,KAC9zC,CAAC,miDAA8X,uqBAAwqB,KACviC,CAAC,00DAA6d,o1BAAq1B,QACnzC,CAAC,6/FAAyzB,i+CAAk+C,uEAC5xE,CAAC,u9CAA0a,0sBAA2sB,KACtnC,CAAC,ukDAA4a,6uBAA8uB,KAC3pC,CAAC,i7CAAod,8sBAA+sB,QACpqC,CAAC,khGAAk2B,02CAA22C,+GAC9sE,CAAC,+tFAAk0B,q5CAAs5C,KACztE,CAAC,q0DAA0gB,s5BAAu5B,KACl6C,CAAC,+jCAA+S,qeAAse,KACtxB,CAAC,8yBAA+P,wYAAyY,KACzoB,CAAC,84DAAsd,0wBAA2wB,KACluC,CAAC,osDAAyd,o2BAAq2B,+EAC/zC,CAAC,isEAAikB,sjCAAujC,KACznD,CAAC,ooCAA0R,8iBAA+iB,KAC10B,CAAC,quDAAygB,6xBAA8xB,KACxyC,CAAC,o3CAA2a,sqBAAuqB,kUACnlC,CAAC,y4BAAqQ,oeAAqe,kLAC3uB,CAAC,ivEAAmgB,o7BAAq7B,KACz7C,CAAC,stEAAynB,ikCAAkkC,QAC5rD,CAAC,i1FAAiqB,kxCAAmxC,QACr7D,CAAC,o3DAAkgB,i6BAAk6B,KACr6C,CAAC,kvEAAksB,ioCAAkoC,kiBACr0D,CAAC,+2GAAo9B,ogDAAqgD,KAC19E,CAAC,y4CAA+X,kqBAAmqB,iFACniC,CAAC,i9DAAggB,+0BAAg1B,KACj1C,CAAC,wvEAAwnB,2gCAA4gC,KACroD,CAAC,+yCAA0X,wpBAAypB,KACphC,CAAC,o/FAAy5B,66CAA86C,KACx0E,CAAC,o7EAAqoB,smCAAumC,KAC7uD,CAAC,goDAAkc,2uBAA4uB,QAC/qC,CAAC,klDAAsX,guBAAiuB,6MACxlC,CAAC,69BAA+U,sjBAAujB,QACv4B,CAAC,q/GAAm9B,8pDAA+pD,KACnnF,CAAC,q6CAAqa,yqBAA0qB,KAChlC,CAAC,s3CAAwV,2oBAA4oB,KACr+B,CAAC,yyEAA4nB,shCAAuhC,KACppD,CAAC,ipDAAia,+xBAAgyB,KAClsC,CAAC,w1EAAsqB,4nCAA6nC,KACpyD,CAAC,67BAAoT,qdAAsd,KAC3wB,CAAC,++CAA2Y,2oBAA4oB,KACxhC,CAAC,+wCAAgV,kmBAAmmB,KACp7B,CAAC,g7EAAylB,ijCAAkjC,KAC5oD,CAAC,uqCAAmT,4fAA6f,iFACjzB,CAAC,g0CAA4X,ioBAAkoB,KAC//B,CAAC,0+BAA6P,0dAA2d,QACztB,CAAC,yzEAAmnB,onCAAqnC,KACzuD,CAAC,0qFAAstB,isCAAksC,KACz5D,CAAC,ypDAAoa,2xBAA4xB,KACjsC,CAAC,+lFAAgpB,ioCAAkoC,8EACnxD,CAAC,o7BAAqO,0cAA2c,6jBACjrB,CAAC,k+CAAuZ,8tBAA+tB,KACvnC,CAAC,utCAAwW,ikBAAkkB,KAC36B,CAAC,yvCAAuW,0mBAA2mB,wDACn9B,CAAC,q+CAAkX,ssBAAusB,KAC1jC,CAAC,6gCAA+S,yfAA0f,qCAC1yB,CAAC,qmDAAgc,guBAAiuB,KAClqC,CAAC,mhDAA2Z,qsBAAssB,KAClmC,CAAC,m4BAA2O,8aAA+a,KAC3pB,CAAC,wsEAAytB,spCAAupC,KACj3D,CAAC,q/CAA2Z,uqBAAwqB,KACpkC,CAAC,+9HAAipC,+5DAAg6D,KACljG,CAAC,wtCAAmX,6mBAA8mB,KACl+B,CAAC,ujCAAsd,0nBAA2nB,KACllC,CAAC,k7DAAogB,m3BAAo3B,KACz3C,CAAC,opCAA2R,ifAAkf,QAC9wB,CAAC,2pDAA2f,kxBAAmxB,KAC/wC,CAAC,k4CAA+a,yoBAA0oB,KAC1jC,CAAC,86CAAkc,0qBAA2qB,KAC9mC,CAAC,owEAAytB,mjCAAojC,KAC9wD,CAAC,mqCAA2R,uhBAAwhB,KACpzB,CAAC,wjDAA2b,+sBAAgtB,QAC5oC,CAAC,snDAA6gB,+yBAAgzB,KAC9zC,CAAC,kiEAAoiB,w7BAAy7B,KAC99C,CAAC,moDAAyd,i0BAAk0B,QAC5xC,CAAC,uuCAA+V,skBAAukB,KACv6B,CAAC,wnEAAimB,m+BAAo+B,oHACtkD,CAAC,qyEAA2uB,slCAAulC,KACn0D,CAAC,y0CAA2X,olBAAqlB,KACj9B,CAAC,k2EAA6oB,0rCAA2rC,KACz0D,CAAC,8xFAAowB,izCAAkzC,0MACvjE,CAAC,s9CAAsY,qpBAAspB,QAC7hC,CAAC,0gEAAyjB,s6BAAu6B,QACj+C,CAAC,klGAA8zB,m+CAAo+C,KACnyE,CAAC,+jEAA4oB,qmCAAsmC,KACnvD,CAAC,kiFAAmvB,0uCAA2uC,QAC/9D,CAAC,y6DAA+lB,o4BAAq4B,KACr+C,CAAC,2sCAA6U,4jBAA6jB,KAC34B,CAAC,wkEAAylB,+/BAAggC,QAC1lD,CAAC,shEAAknB,6gCAA8gC,KACjoD,CAAC,goFAAytB,yuCAA0uC,KACp8D,CAAC,w1DAAgf,65BAA85B,qGAC/4C,CAAC,0lFAAwwB,sxCAAuxC,KAChiE,CAAC,ovBAAsQ,4YAA6Y,KACppB,CAAC,6oEAAmgB,ohCAAqhC,KACzhD,CAAC,+zBAA2Q,iaAAka,KAC9qB,CAAC,+hDAA+X,+rBAAgsB,KAChkC,CAAC,ktDAA8mB,m6BAAo6B,KACnhD,CAAC,0/EAAkrB,ilCAAklC,QACrwD,CAAC,+vEAAulB,ghCAAihC,KACzmD,CAAC,6wCAAqY,+kBAAglB,KACt9B,CAAC,mvEAA4jB,o3BAAq3B,KACl7C,CAAC,+tCAA+X,6jBAA8jB,KAC97B,CAAC,+zCAA8U,8mBAA+mB,uEAC97B,CAAC,8vDAA8gB,kzBAAmzB,KACl0C,CAAC,omCAA4S,sfAAuf,KACpyB,CAAC,4yCAA8V,4mBAA6mB,KAC58B,CAAC,m2DAA4e,uyBAAwyB,KACrxC,CAAC,05BAAgS,+ZAAga,KACjsB,CAAC,wmDAA0f,4yBAA6yB,KACxyC,CAAC,srCAAgW,imBAAkmB,0VACn8B,CAAC,02CAA4Z,urBAAwrB,KACrlC,CAAC,y2EAA+tB,opCAAqpC,KACr3D,CAAC,83DAA0nB,+6BAAg7B,KAC3iD,CAAC,i9DAA+gB,izBAAkzB,KACl0C,CAAC,kxDAAqf,s3BAAu3B,KAC72C,CAAC,6mCAA+T,kiBAAmiB,KACn2B,CAAC,6tDAA+hB,64BAA84B,oGAC96C,CAAC,otDAAub,m1BAAo1B,KAC5wC,CAAC,w4EAA4sB,kqCAAmqC,KACh3D,CAAC,wrCAA4W,ojBAAqjB,KACl6B,CAAC,ytFAA2vB,orCAAqrC,KACj7D,CAAC,s1DAAihB,i1BAAk1B,KACp2C,CAAC,shEAAyqB,skCAAukC,KACjvD,CAAC,mkEAAkiB,g4BAAi4B,KACp6C,CAAC,43DAA2f,u3BAAw3B,KACp3C,CAAC,6iDAAif,8xBAA+xB,KACjxC,CAAC,45EAAknB,kjCAAmjC,KACtqD,CAAC,4mGAAk2B,w3CAAy3C,QAC5tE,CAAC,mkCAA2Q,ueAAwe,KACpvB,CAAC,+iEAAolB,2+BAA4+B,KACjkD,CAAC,+uDAAie,wzBAAyzB,kGAC3xC,CAAC,+lEAAwkB,6gCAA8gC,KACvlD,CAAC,wgDAA6b,uvBAAwvB,KACtrC,CAAC,osDAAuf,kuBAAmuB,KAC3tC,CAAC,wgGAAmwB,ytCAA0tC,KAC99D,CAAC,i5FAAizB,s0CAAu0C,oDACznE,CAAC,sxCAAsW,4nBAA6nB,KACp+B,CAAC,myEAA8kB,q/BAAs/B,KACrkD,CAAC,2rDAA4b,stBAAutB,mFACppC,CAAC,ooDAA8e,q6BAAs6B,KACr5C,CAAC,wtEAAsnB,yjCAA0jC,mGACjrD,CAAC,qzFAA41B,i2CAAk2C,KAC/rE,CAAC,wkDAAic,ywBAA0wB,2OAC5sC,CAAC,0+DAA4jB,uhCAAwhC,KACrlD,CAAC,+zEAAoiB,mgCAAogC,KACziD,CAAC,qmEAA0oB,6iCAA8iC,QACzrD,CAAC,45CAAsV,4oBAA6oB,sGACp+B,CAAC,swBAAyQ,yXAA0X,KACpoB,CAAC,skDAAkZ,srBAAurB,KAC1kC,CAAC,yiEAAgtB,ylCAA0lC,KAC3yD,CAAC,w1DAA4d,i3BAAk3B,KAC/0C,CAAC,44DAA8iB,u6BAAw6B,KACv9C,CAAC,8iCAAuT,kfAAmf,KAC3yB,CAAC,6oEAAgoB,ihCAAkhC,KACnpD,CAAC,0nDAA8jB,g0BAAi0B,KACh4C,CAAC,8tDAAoe,quBAAsuB,KAC3sC,CAAC,0/BAAwQ,2eAA4e,KACrvB,CAAC,89BAA4O,qYAAsY,KACnnB,CAAC,0lEAA4qB,4hCAA6hC,KAC1sD,CAAC,2wDAAye,s3BAAu3B,KACj2C,CAAC,yxDAAgc,mwBAAowB,+OACrsC,CAAC,6zDAAihB,86BAAg6B,yJACl7C,CAAC,otEAA4iB,+hCAAgiC,KAC7kD,CAAC,q8DAAsnB,6/BAA8/B,KACrnD,CAAC,y/EAAmpB,8mCAA+mC,KACnwD,CAAC,ymFAAusB,0uCAA2uC,KACn7D,CAAC,4qEAAqkB,8+BAA++B,KACrjD,CAAC,ioHAAk+B,iiDAAkiD,KACrgF,CAAC,ytCAAoX,0pBAA2pB,KAChhC,CAAC,8nCAAmS,6hBAA8hB,KACl0B,CAAC,uxEAA+rB,ooCAAqoC,KACr0D,CAAC,2oCAAwV,ooCAAqoC,KAC99C,CAAC,ssDAAkhB,g5BAAi5B,KACp6C,CAAC,41DAAge,o3BAAq3B,KACt1C,CAAC,s8CAA8Z,4vBAA6vB,mFAC5pC,CAAC,yrCAAuX,+lBAAgmB,QACx9B,CAAC,2zDAA4e,o8BAAq8B,KACl7C,CAAC,swFAA01B,o2CAAq2C,KAChsE,CAAC,0xDAAihB,qzBAAszB,iNACx0C,CAAC,woDAAqc,wwBAAywB,KAC/sC,CAAC,+7BAAuS,weAAye,KACjxB,CAAC,kmCAA2R,+hBAAgiB,mhBAC5zB,CAAC,u8CAA6b,qrBAAkqB,8EAChmC,CAAC,4qEAAqkB,u/BAAw/B,KAC9jD,CAAC,ikBAAiM,8SAA+S,0GACjf,CAAC,kwHAA2+B,ipDAAmoD,QAC/mF,CAAC,q5EAAsrB,goCAAioC,QACxzD,CAAC,wtBAA0T,oQAAqQ,KAChkB,CAAC,68CAAwc,+vBAAgwB,KACzsC,CAAC,2/CAAif,qvBAAsvB,KACxuC,CAAC,00CAAmb,8mBAA+mB,MCtjB7hCA,EAAOrb,EAKAiyD,EAAW,kBAHb52C,EAAKghC,KAAI,SAACp8C,EAAGigD,GAAJ,OAAUA,EAAE,MCF1B7kC,EAAOrb,EAGAkyD,EAAa,SAACt7C,GAAD,OAFP,SAACA,GAAD,OAAeyE,EAAKzE,EAAG,GAEAu7C,CAAWv7C,aCwDrD,MAxDA,WACI,IAAQA,EN2NZ,WAKE,IAAM2zC,GAAY5H,EAAAA,EAAAA,YAAiB0H,GAA7BE,QACFoG,EAAapG,EAAQA,EAAQ3rD,OAAS,GAC1C,OAAO+xD,EAAcA,EAAW7D,OAAiB,GMlOhCsF,GAAPx7C,GACF6oC,EAAOwS,IAEP52C,EAAO62C,EAAWG,OAAOz7C,IAC/B,KAA4B2jB,EAAAA,EAAAA,YAA5B,GAAO+3B,EAAP,KAAeC,EAAf,KACA,KAAgCh4B,EAAAA,EAAAA,WAAkB,GAAlD,GAAOi4B,EAAP,KAAiBC,EAAjB,KACAp3B,QAAQ1oB,IAAI8sC,EAAMpkC,GAElB,IAAMq3C,GAAiB54B,EAAAA,EAAAA,cAAY,kBAAM24B,GAAaD,KAAU,CAACA,IAC3DG,GAAiB74B,EAAAA,EAAAA,cAAY,kBAAMy4B,GAAWD,KAAS,CAACA,IAK9D,OAJAt4B,EAAAA,EAAAA,YAAU,WACNu4B,GAAU,GACVE,GAAY,KACd,CAAC77C,KAEC,iBAAKg8C,UAAU,UAAf,WACI,iBAAKA,UAAU,WAAf,WACI,iBAAKA,UAAU,QAAf,WACI,SAACpB,EAAD,CAAMvD,GAAG,IAAI9hD,MAAO,CAACy2B,QAAQ,SAA7B,qBACA,gBAAKz2B,MAAO,CAACpC,KAAK,EAAG8oD,UAAU,UAA/B,+BACWj8C,MAEX,gBAAKqpB,QAAS,kBAAMyyB,KAApB,0CAGJ,gBAAKE,UAAU,OAAf,SAEQJ,EAAWn3C,EAAK,GAAGva,MAAM,MAAMu7C,KAAI,SAACyW,GAChC,OAAQ,iBAAK3mD,MAAO,CAAC4mD,aAAa,QAA1B,UAAoCD,GAAK,wBAC/Cz3C,EAAK,GAAGva,MAAM,MAAMu7C,KAAK,SAACyW,GAC5B,OAAQ,iBAAK3mD,MAAO,CAAC4mD,aAAa,QAA1B,UAAoCD,GAAK,2BAI7D,mBACA,kBAEIR,IAAU,yBAAMj3C,EAAK,SAK7B,iBAAKu3C,UAAU,SAASzmD,MAAO,CAAEy2B,QAAS,QAA1C,UAEmByvB,OAAOz7C,GAAM,IAAM,SAAC46C,EAAD,CAAMrlD,MAAO,CAACy2B,QAAQ,QAASowB,QAAQ,OAAQjpD,KAAM,EAAE8oD,UAAU,SAAUI,WAAW,UAAUhF,GAAE,oBAAeoE,OAAOz7C,GAAM,GAA9H,mBAE9B,gBAAKqpB,QAAS,kBAAM0yB,KAAkBxmD,MAAO,CAACpC,KAAK,EAAE8oD,UAAU,UAA/D,sCAEQpT,EAAK7gD,OAAO,IAAOyzD,OAAOz7C,KAAS,SAAC46C,EAAD,CAAMrlD,MAAO,CAAEpC,KAAM,EAAE8oD,UAAU,SAAUI,WAAW,SAASrwB,QAAQ,QAASowB,QAAQ,QAAQ/E,GAAE,oBAAeoE,OAAOz7C,GAAK,GAA7H,yBCnDzDyE,GAAOrb,EAab,OAXA,WACI,OAAQ,yBAEAqb,GAAKghC,KAAI,SAACp8C,EAAEigD,GACR,OAAO,SAACsR,EAAD,CAAMvD,GAAE,oBAAe/N,EAAE,GAAK0S,UAAU,OAAxC,SAAgD1S,EAAE,UCOzE,OAVA,WACE,OACE,UAACuQ,EAAD,YACE,SAACX,EAAD,CAAO/D,KAAK,IAAI1nC,SAAS,SAAC,GAAD,OACzB,SAACyrC,EAAD,CAAO/D,KAAK,YAAY1nC,SAAS,SAAC,GAAD,OACjC,SAACyrC,EAAD,CAAO/D,KAAK,gBAAgB1nC,SAAS,SAAC,EAAD,UCA3C,GAZwB,SAAC6uC,GACnBA,GAAeA,aAAuBC,UACxC,6BAAqBvpC,MAAK,YAAkD,IAA/CwpC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,iBCDRO,GAAOhR,EAAAA,WACXnjD,SAASo0D,eAAe,SAGpBC,GAAc,IAAItY,GAAAA,YAExBoY,GAAK7uD,QACH,SAAC,aAAD,WACE,SAAC,GAAAo+C,oBAAD,CAAqBrK,OAAQgb,GAA7B,UACE,SAACxC,EAAD,CAAetG,SAAU+I,OAAzB,UACE,SAAC,GAAD,WASRC","sources":["../node_modules/react-dom/cjs/react-dom.production.min.js","../node_modules/react-dom/client.js","../node_modules/react-dom/index.js","../node_modules/react-query/es/core/logger.js","../node_modules/react-query/es/core/notifyManager.js","../node_modules/@babel/runtime/helpers/esm/setPrototypeOf.js","../node_modules/@babel/runtime/helpers/esm/inheritsLoose.js","../node_modules/react-query/es/core/subscribable.js","../node_modules/react-query/es/core/focusManager.js","../node_modules/react-query/es/core/onlineManager.js","../node_modules/react-query/es/core/retryer.js","../node_modules/react-query/es/core/query.js","../node_modules/react-query/es/core/queryCache.js","../node_modules/react-query/es/core/mutation.js","../node_modules/react-query/es/core/mutationCache.js","../node_modules/react-query/es/core/infiniteQueryBehavior.js","../node_modules/react-query/es/core/queryClient.js","../node_modules/react-query/es/core/utils.js","../node_modules/react-query/es/react/reactBatchedUpdates.js","../node_modules/react-query/es/react/setBatchUpdatesFn.js","../node_modules/react-query/es/react/logger.js","../node_modules/react-query/es/react/setLogger.js","../node_modules/react-query/es/react/QueryClientProvider.js","../node_modules/react/cjs/react-jsx-runtime.production.min.js","../node_modules/react/cjs/react.production.min.js","../node_modules/react/index.js","../node_modules/react/jsx-runtime.js","../node_modules/scheduler/cjs/scheduler.production.min.js","../node_modules/scheduler/index.js","../node_modules/@babel/runtime/helpers/esm/extends.js","../webpack/bootstrap","../webpack/runtime/compat get default export","../webpack/runtime/define property getters","../webpack/runtime/ensure chunk","../webpack/runtime/get javascript chunk filename","../webpack/runtime/get mini-css chunk filename","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/load script","../webpack/runtime/make namespace object","../webpack/runtime/publicPath","../webpack/runtime/jsonp chunk loading","../node_modules/@babel/runtime/helpers/esm/arrayLikeToArray.js","../node_modules/@babel/runtime/helpers/esm/slicedToArray.js","../node_modules/@babel/runtime/helpers/esm/arrayWithHoles.js","../node_modules/@babel/runtime/helpers/esm/iterableToArrayLimit.js","../node_modules/@babel/runtime/helpers/esm/unsupportedIterableToArray.js","../node_modules/@babel/runtime/helpers/esm/nonIterableRest.js","../../packages/react-router/lib/context.ts","../../packages/react-router/lib/router.ts","../../packages/react-router/lib/hooks.tsx","../../packages/react-router/lib/components.tsx","../../packages/react-router-dom/index.tsx","datas/data.ts","hooks/usePage.ts","hooks/useProblem.ts","pages/Problem.tsx","pages/Main.tsx","App.tsx","reportWebVitals.ts","index.tsx"],"sourcesContent":["/**\n * @license React\n * react-dom.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n/*\n Modernizr 3.0.0pre (Custom Build) | MIT\n*/\n'use strict';var aa=require(\"react\"),ca=require(\"scheduler\");function p(a){for(var b=\"https://reactjs.org/docs/error-decoder.html?invariant=\"+a,c=1;c<arguments.length;c++)b+=\"&args[]=\"+encodeURIComponent(arguments[c]);return\"Minified React error #\"+a+\"; visit \"+b+\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\"}var da=new Set,ea={};function fa(a,b){ha(a,b);ha(a+\"Capture\",b)}\nfunction ha(a,b){ea[a]=b;for(a=0;a<b.length;a++)da.add(b[a])}\nvar ia=!(\"undefined\"===typeof window||\"undefined\"===typeof window.document||\"undefined\"===typeof window.document.createElement),ja=Object.prototype.hasOwnProperty,ka=/^[:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$/,la=\n{},ma={};function oa(a){if(ja.call(ma,a))return!0;if(ja.call(la,a))return!1;if(ka.test(a))return ma[a]=!0;la[a]=!0;return!1}function pa(a,b,c,d){if(null!==c&&0===c.type)return!1;switch(typeof b){case \"function\":case \"symbol\":return!0;case \"boolean\":if(d)return!1;if(null!==c)return!c.acceptsBooleans;a=a.toLowerCase().slice(0,5);return\"data-\"!==a&&\"aria-\"!==a;default:return!1}}\nfunction qa(a,b,c,d){if(null===b||\"undefined\"===typeof b||pa(a,b,c,d))return!0;if(d)return!1;if(null!==c)switch(c.type){case 3:return!b;case 4:return!1===b;case 5:return isNaN(b);case 6:return isNaN(b)||1>b}return!1}function v(a,b,c,d,e,f,g){this.acceptsBooleans=2===b||3===b||4===b;this.attributeName=d;this.attributeNamespace=e;this.mustUseProperty=c;this.propertyName=a;this.type=b;this.sanitizeURL=f;this.removeEmptyString=g}var z={};\n\"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style\".split(\" \").forEach(function(a){z[a]=new v(a,0,!1,a,null,!1,!1)});[[\"acceptCharset\",\"accept-charset\"],[\"className\",\"class\"],[\"htmlFor\",\"for\"],[\"httpEquiv\",\"http-equiv\"]].forEach(function(a){var b=a[0];z[b]=new v(b,1,!1,a[1],null,!1,!1)});[\"contentEditable\",\"draggable\",\"spellCheck\",\"value\"].forEach(function(a){z[a]=new v(a,2,!1,a.toLowerCase(),null,!1,!1)});\n[\"autoReverse\",\"externalResourcesRequired\",\"focusable\",\"preserveAlpha\"].forEach(function(a){z[a]=new v(a,2,!1,a,null,!1,!1)});\"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope\".split(\" \").forEach(function(a){z[a]=new v(a,3,!1,a.toLowerCase(),null,!1,!1)});\n[\"checked\",\"multiple\",\"muted\",\"selected\"].forEach(function(a){z[a]=new v(a,3,!0,a,null,!1,!1)});[\"capture\",\"download\"].forEach(function(a){z[a]=new v(a,4,!1,a,null,!1,!1)});[\"cols\",\"rows\",\"size\",\"span\"].forEach(function(a){z[a]=new v(a,6,!1,a,null,!1,!1)});[\"rowSpan\",\"start\"].forEach(function(a){z[a]=new v(a,5,!1,a.toLowerCase(),null,!1,!1)});var ra=/[\\-:]([a-z])/g;function sa(a){return a[1].toUpperCase()}\n\"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height\".split(\" \").forEach(function(a){var b=a.replace(ra,\nsa);z[b]=new v(b,1,!1,a,null,!1,!1)});\"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type\".split(\" \").forEach(function(a){var b=a.replace(ra,sa);z[b]=new v(b,1,!1,a,\"http://www.w3.org/1999/xlink\",!1,!1)});[\"xml:base\",\"xml:lang\",\"xml:space\"].forEach(function(a){var b=a.replace(ra,sa);z[b]=new v(b,1,!1,a,\"http://www.w3.org/XML/1998/namespace\",!1,!1)});[\"tabIndex\",\"crossOrigin\"].forEach(function(a){z[a]=new v(a,1,!1,a.toLowerCase(),null,!1,!1)});\nz.xlinkHref=new v(\"xlinkHref\",1,!1,\"xlink:href\",\"http://www.w3.org/1999/xlink\",!0,!1);[\"src\",\"href\",\"action\",\"formAction\"].forEach(function(a){z[a]=new v(a,1,!1,a.toLowerCase(),null,!0,!0)});\nfunction ta(a,b,c,d){var e=z.hasOwnProperty(b)?z[b]:null;if(null!==e?0!==e.type:d||!(2<b.length)||\"o\"!==b[0]&&\"O\"!==b[0]||\"n\"!==b[1]&&\"N\"!==b[1])qa(b,c,e,d)&&(c=null),d||null===e?oa(b)&&(null===c?a.removeAttribute(b):a.setAttribute(b,\"\"+c)):e.mustUseProperty?a[e.propertyName]=null===c?3===e.type?!1:\"\":c:(b=e.attributeName,d=e.attributeNamespace,null===c?a.removeAttribute(b):(e=e.type,c=3===e||4===e&&!0===c?\"\":\"\"+c,d?a.setAttributeNS(d,b,c):a.setAttribute(b,c)))}\nvar ua=aa.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,va=Symbol.for(\"react.element\"),wa=Symbol.for(\"react.portal\"),ya=Symbol.for(\"react.fragment\"),za=Symbol.for(\"react.strict_mode\"),Aa=Symbol.for(\"react.profiler\"),Ba=Symbol.for(\"react.provider\"),Ca=Symbol.for(\"react.context\"),Da=Symbol.for(\"react.forward_ref\"),Ea=Symbol.for(\"react.suspense\"),Fa=Symbol.for(\"react.suspense_list\"),Ga=Symbol.for(\"react.memo\"),Ha=Symbol.for(\"react.lazy\");Symbol.for(\"react.scope\");Symbol.for(\"react.debug_trace_mode\");\nvar Ia=Symbol.for(\"react.offscreen\");Symbol.for(\"react.legacy_hidden\");Symbol.for(\"react.cache\");Symbol.for(\"react.tracing_marker\");var Ja=Symbol.iterator;function Ka(a){if(null===a||\"object\"!==typeof a)return null;a=Ja&&a[Ja]||a[\"@@iterator\"];return\"function\"===typeof a?a:null}var A=Object.assign,La;function Ma(a){if(void 0===La)try{throw Error();}catch(c){var b=c.stack.trim().match(/\\n( *(at )?)/);La=b&&b[1]||\"\"}return\"\\n\"+La+a}var Na=!1;\nfunction Oa(a,b){if(!a||Na)return\"\";Na=!0;var c=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(b)if(b=function(){throw Error();},Object.defineProperty(b.prototype,\"props\",{set:function(){throw Error();}}),\"object\"===typeof Reflect&&Reflect.construct){try{Reflect.construct(b,[])}catch(l){var d=l}Reflect.construct(a,[],b)}else{try{b.call()}catch(l){d=l}a.call(b.prototype)}else{try{throw Error();}catch(l){d=l}a()}}catch(l){if(l&&d&&\"string\"===typeof l.stack){for(var e=l.stack.split(\"\\n\"),\nf=d.stack.split(\"\\n\"),g=e.length-1,h=f.length-1;1<=g&&0<=h&&e[g]!==f[h];)h--;for(;1<=g&&0<=h;g--,h--)if(e[g]!==f[h]){if(1!==g||1!==h){do if(g--,h--,0>h||e[g]!==f[h]){var k=\"\\n\"+e[g].replace(\" at new \",\" at \");a.displayName&&k.includes(\"<anonymous>\")&&(k=k.replace(\"<anonymous>\",a.displayName));return k}while(1<=g&&0<=h)}break}}}finally{Na=!1,Error.prepareStackTrace=c}return(a=a?a.displayName||a.name:\"\")?Ma(a):\"\"}\nfunction Pa(a){switch(a.tag){case 5:return Ma(a.type);case 16:return Ma(\"Lazy\");case 13:return Ma(\"Suspense\");case 19:return Ma(\"SuspenseList\");case 0:case 2:case 15:return a=Oa(a.type,!1),a;case 11:return a=Oa(a.type.render,!1),a;case 1:return a=Oa(a.type,!0),a;default:return\"\"}}\nfunction Qa(a){if(null==a)return null;if(\"function\"===typeof a)return a.displayName||a.name||null;if(\"string\"===typeof a)return a;switch(a){case ya:return\"Fragment\";case wa:return\"Portal\";case Aa:return\"Profiler\";case za:return\"StrictMode\";case Ea:return\"Suspense\";case Fa:return\"SuspenseList\"}if(\"object\"===typeof a)switch(a.$$typeof){case Ca:return(a.displayName||\"Context\")+\".Consumer\";case Ba:return(a._context.displayName||\"Context\")+\".Provider\";case Da:var b=a.render;a=a.displayName;a||(a=b.displayName||\nb.name||\"\",a=\"\"!==a?\"ForwardRef(\"+a+\")\":\"ForwardRef\");return a;case Ga:return b=a.displayName||null,null!==b?b:Qa(a.type)||\"Memo\";case Ha:b=a._payload;a=a._init;try{return Qa(a(b))}catch(c){}}return null}\nfunction Ra(a){var b=a.type;switch(a.tag){case 24:return\"Cache\";case 9:return(b.displayName||\"Context\")+\".Consumer\";case 10:return(b._context.displayName||\"Context\")+\".Provider\";case 18:return\"DehydratedFragment\";case 11:return a=b.render,a=a.displayName||a.name||\"\",b.displayName||(\"\"!==a?\"ForwardRef(\"+a+\")\":\"ForwardRef\");case 7:return\"Fragment\";case 5:return b;case 4:return\"Portal\";case 3:return\"Root\";case 6:return\"Text\";case 16:return Qa(b);case 8:return b===za?\"StrictMode\":\"Mode\";case 22:return\"Offscreen\";\ncase 12:return\"Profiler\";case 21:return\"Scope\";case 13:return\"Suspense\";case 19:return\"SuspenseList\";case 25:return\"TracingMarker\";case 1:case 0:case 17:case 2:case 14:case 15:if(\"function\"===typeof b)return b.displayName||b.name||null;if(\"string\"===typeof b)return b}return null}function Sa(a){switch(typeof a){case \"boolean\":case \"number\":case \"string\":case \"undefined\":return a;case \"object\":return a;default:return\"\"}}\nfunction Ta(a){var b=a.type;return(a=a.nodeName)&&\"input\"===a.toLowerCase()&&(\"checkbox\"===b||\"radio\"===b)}\nfunction Ua(a){var b=Ta(a)?\"checked\":\"value\",c=Object.getOwnPropertyDescriptor(a.constructor.prototype,b),d=\"\"+a[b];if(!a.hasOwnProperty(b)&&\"undefined\"!==typeof c&&\"function\"===typeof c.get&&\"function\"===typeof c.set){var e=c.get,f=c.set;Object.defineProperty(a,b,{configurable:!0,get:function(){return e.call(this)},set:function(a){d=\"\"+a;f.call(this,a)}});Object.defineProperty(a,b,{enumerable:c.enumerable});return{getValue:function(){return d},setValue:function(a){d=\"\"+a},stopTracking:function(){a._valueTracker=\nnull;delete a[b]}}}}function Va(a){a._valueTracker||(a._valueTracker=Ua(a))}function Wa(a){if(!a)return!1;var b=a._valueTracker;if(!b)return!0;var c=b.getValue();var d=\"\";a&&(d=Ta(a)?a.checked?\"true\":\"false\":a.value);a=d;return a!==c?(b.setValue(a),!0):!1}function Xa(a){a=a||(\"undefined\"!==typeof document?document:void 0);if(\"undefined\"===typeof a)return null;try{return a.activeElement||a.body}catch(b){return a.body}}\nfunction Ya(a,b){var c=b.checked;return A({},b,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=c?c:a._wrapperState.initialChecked})}function Za(a,b){var c=null==b.defaultValue?\"\":b.defaultValue,d=null!=b.checked?b.checked:b.defaultChecked;c=Sa(null!=b.value?b.value:c);a._wrapperState={initialChecked:d,initialValue:c,controlled:\"checkbox\"===b.type||\"radio\"===b.type?null!=b.checked:null!=b.value}}function ab(a,b){b=b.checked;null!=b&&ta(a,\"checked\",b,!1)}\nfunction bb(a,b){ab(a,b);var c=Sa(b.value),d=b.type;if(null!=c)if(\"number\"===d){if(0===c&&\"\"===a.value||a.value!=c)a.value=\"\"+c}else a.value!==\"\"+c&&(a.value=\"\"+c);else if(\"submit\"===d||\"reset\"===d){a.removeAttribute(\"value\");return}b.hasOwnProperty(\"value\")?cb(a,b.type,c):b.hasOwnProperty(\"defaultValue\")&&cb(a,b.type,Sa(b.defaultValue));null==b.checked&&null!=b.defaultChecked&&(a.defaultChecked=!!b.defaultChecked)}\nfunction db(a,b,c){if(b.hasOwnProperty(\"value\")||b.hasOwnProperty(\"defaultValue\")){var d=b.type;if(!(\"submit\"!==d&&\"reset\"!==d||void 0!==b.value&&null!==b.value))return;b=\"\"+a._wrapperState.initialValue;c||b===a.value||(a.value=b);a.defaultValue=b}c=a.name;\"\"!==c&&(a.name=\"\");a.defaultChecked=!!a._wrapperState.initialChecked;\"\"!==c&&(a.name=c)}\nfunction cb(a,b,c){if(\"number\"!==b||Xa(a.ownerDocument)!==a)null==c?a.defaultValue=\"\"+a._wrapperState.initialValue:a.defaultValue!==\"\"+c&&(a.defaultValue=\"\"+c)}var eb=Array.isArray;\nfunction fb(a,b,c,d){a=a.options;if(b){b={};for(var e=0;e<c.length;e++)b[\"$\"+c[e]]=!0;for(c=0;c<a.length;c++)e=b.hasOwnProperty(\"$\"+a[c].value),a[c].selected!==e&&(a[c].selected=e),e&&d&&(a[c].defaultSelected=!0)}else{c=\"\"+Sa(c);b=null;for(e=0;e<a.length;e++){if(a[e].value===c){a[e].selected=!0;d&&(a[e].defaultSelected=!0);return}null!==b||a[e].disabled||(b=a[e])}null!==b&&(b.selected=!0)}}\nfunction gb(a,b){if(null!=b.dangerouslySetInnerHTML)throw Error(p(91));return A({},b,{value:void 0,defaultValue:void 0,children:\"\"+a._wrapperState.initialValue})}function hb(a,b){var c=b.value;if(null==c){c=b.children;b=b.defaultValue;if(null!=c){if(null!=b)throw Error(p(92));if(eb(c)){if(1<c.length)throw Error(p(93));c=c[0]}b=c}null==b&&(b=\"\");c=b}a._wrapperState={initialValue:Sa(c)}}\nfunction ib(a,b){var c=Sa(b.value),d=Sa(b.defaultValue);null!=c&&(c=\"\"+c,c!==a.value&&(a.value=c),null==b.defaultValue&&a.defaultValue!==c&&(a.defaultValue=c));null!=d&&(a.defaultValue=\"\"+d)}function jb(a){var b=a.textContent;b===a._wrapperState.initialValue&&\"\"!==b&&null!==b&&(a.value=b)}function kb(a){switch(a){case \"svg\":return\"http://www.w3.org/2000/svg\";case \"math\":return\"http://www.w3.org/1998/Math/MathML\";default:return\"http://www.w3.org/1999/xhtml\"}}\nfunction lb(a,b){return null==a||\"http://www.w3.org/1999/xhtml\"===a?kb(b):\"http://www.w3.org/2000/svg\"===a&&\"foreignObject\"===b?\"http://www.w3.org/1999/xhtml\":a}\nvar mb,nb=function(a){return\"undefined\"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(b,c,d,e){MSApp.execUnsafeLocalFunction(function(){return a(b,c,d,e)})}:a}(function(a,b){if(\"http://www.w3.org/2000/svg\"!==a.namespaceURI||\"innerHTML\"in a)a.innerHTML=b;else{mb=mb||document.createElement(\"div\");mb.innerHTML=\"<svg>\"+b.valueOf().toString()+\"</svg>\";for(b=mb.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;b.firstChild;)a.appendChild(b.firstChild)}});\nfunction ob(a,b){if(b){var c=a.firstChild;if(c&&c===a.lastChild&&3===c.nodeType){c.nodeValue=b;return}}a.textContent=b}\nvar pb={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,\nzoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},qb=[\"Webkit\",\"ms\",\"Moz\",\"O\"];Object.keys(pb).forEach(function(a){qb.forEach(function(b){b=b+a.charAt(0).toUpperCase()+a.substring(1);pb[b]=pb[a]})});function rb(a,b,c){return null==b||\"boolean\"===typeof b||\"\"===b?\"\":c||\"number\"!==typeof b||0===b||pb.hasOwnProperty(a)&&pb[a]?(\"\"+b).trim():b+\"px\"}\nfunction sb(a,b){a=a.style;for(var c in b)if(b.hasOwnProperty(c)){var d=0===c.indexOf(\"--\"),e=rb(c,b[c],d);\"float\"===c&&(c=\"cssFloat\");d?a.setProperty(c,e):a[c]=e}}var tb=A({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});\nfunction ub(a,b){if(b){if(tb[a]&&(null!=b.children||null!=b.dangerouslySetInnerHTML))throw Error(p(137,a));if(null!=b.dangerouslySetInnerHTML){if(null!=b.children)throw Error(p(60));if(\"object\"!==typeof b.dangerouslySetInnerHTML||!(\"__html\"in b.dangerouslySetInnerHTML))throw Error(p(61));}if(null!=b.style&&\"object\"!==typeof b.style)throw Error(p(62));}}\nfunction vb(a,b){if(-1===a.indexOf(\"-\"))return\"string\"===typeof b.is;switch(a){case \"annotation-xml\":case \"color-profile\":case \"font-face\":case \"font-face-src\":case \"font-face-uri\":case \"font-face-format\":case \"font-face-name\":case \"missing-glyph\":return!1;default:return!0}}var wb=null;function xb(a){a=a.target||a.srcElement||window;a.correspondingUseElement&&(a=a.correspondingUseElement);return 3===a.nodeType?a.parentNode:a}var yb=null,zb=null,Ab=null;\nfunction Bb(a){if(a=Cb(a)){if(\"function\"!==typeof yb)throw Error(p(280));var b=a.stateNode;b&&(b=Db(b),yb(a.stateNode,a.type,b))}}function Eb(a){zb?Ab?Ab.push(a):Ab=[a]:zb=a}function Fb(){if(zb){var a=zb,b=Ab;Ab=zb=null;Bb(a);if(b)for(a=0;a<b.length;a++)Bb(b[a])}}function Gb(a,b){return a(b)}function Hb(){}var Ib=!1;function Jb(a,b,c){if(Ib)return a(b,c);Ib=!0;try{return Gb(a,b,c)}finally{if(Ib=!1,null!==zb||null!==Ab)Hb(),Fb()}}\nfunction Kb(a,b){var c=a.stateNode;if(null===c)return null;var d=Db(c);if(null===d)return null;c=d[b];a:switch(b){case \"onClick\":case \"onClickCapture\":case \"onDoubleClick\":case \"onDoubleClickCapture\":case \"onMouseDown\":case \"onMouseDownCapture\":case \"onMouseMove\":case \"onMouseMoveCapture\":case \"onMouseUp\":case \"onMouseUpCapture\":case \"onMouseEnter\":(d=!d.disabled)||(a=a.type,d=!(\"button\"===a||\"input\"===a||\"select\"===a||\"textarea\"===a));a=!d;break a;default:a=!1}if(a)return null;if(c&&\"function\"!==\ntypeof c)throw Error(p(231,b,typeof c));return c}var Lb=!1;if(ia)try{var Mb={};Object.defineProperty(Mb,\"passive\",{get:function(){Lb=!0}});window.addEventListener(\"test\",Mb,Mb);window.removeEventListener(\"test\",Mb,Mb)}catch(a){Lb=!1}function Nb(a,b,c,d,e,f,g,h,k){var l=Array.prototype.slice.call(arguments,3);try{b.apply(c,l)}catch(m){this.onError(m)}}var Ob=!1,Pb=null,Qb=!1,Rb=null,Sb={onError:function(a){Ob=!0;Pb=a}};function Tb(a,b,c,d,e,f,g,h,k){Ob=!1;Pb=null;Nb.apply(Sb,arguments)}\nfunction Ub(a,b,c,d,e,f,g,h,k){Tb.apply(this,arguments);if(Ob){if(Ob){var l=Pb;Ob=!1;Pb=null}else throw Error(p(198));Qb||(Qb=!0,Rb=l)}}function Vb(a){var b=a,c=a;if(a.alternate)for(;b.return;)b=b.return;else{a=b;do b=a,0!==(b.flags&4098)&&(c=b.return),a=b.return;while(a)}return 3===b.tag?c:null}function Wb(a){if(13===a.tag){var b=a.memoizedState;null===b&&(a=a.alternate,null!==a&&(b=a.memoizedState));if(null!==b)return b.dehydrated}return null}function Xb(a){if(Vb(a)!==a)throw Error(p(188));}\nfunction Yb(a){var b=a.alternate;if(!b){b=Vb(a);if(null===b)throw Error(p(188));return b!==a?null:a}for(var c=a,d=b;;){var e=c.return;if(null===e)break;var f=e.alternate;if(null===f){d=e.return;if(null!==d){c=d;continue}break}if(e.child===f.child){for(f=e.child;f;){if(f===c)return Xb(e),a;if(f===d)return Xb(e),b;f=f.sibling}throw Error(p(188));}if(c.return!==d.return)c=e,d=f;else{for(var g=!1,h=e.child;h;){if(h===c){g=!0;c=e;d=f;break}if(h===d){g=!0;d=e;c=f;break}h=h.sibling}if(!g){for(h=f.child;h;){if(h===\nc){g=!0;c=f;d=e;break}if(h===d){g=!0;d=f;c=e;break}h=h.sibling}if(!g)throw Error(p(189));}}if(c.alternate!==d)throw Error(p(190));}if(3!==c.tag)throw Error(p(188));return c.stateNode.current===c?a:b}function Zb(a){a=Yb(a);return null!==a?$b(a):null}function $b(a){if(5===a.tag||6===a.tag)return a;for(a=a.child;null!==a;){var b=$b(a);if(null!==b)return b;a=a.sibling}return null}\nvar ac=ca.unstable_scheduleCallback,bc=ca.unstable_cancelCallback,cc=ca.unstable_shouldYield,dc=ca.unstable_requestPaint,B=ca.unstable_now,ec=ca.unstable_getCurrentPriorityLevel,fc=ca.unstable_ImmediatePriority,gc=ca.unstable_UserBlockingPriority,hc=ca.unstable_NormalPriority,ic=ca.unstable_LowPriority,jc=ca.unstable_IdlePriority,kc=null,lc=null;function mc(a){if(lc&&\"function\"===typeof lc.onCommitFiberRoot)try{lc.onCommitFiberRoot(kc,a,void 0,128===(a.current.flags&128))}catch(b){}}\nvar oc=Math.clz32?Math.clz32:nc,pc=Math.log,qc=Math.LN2;function nc(a){a>>>=0;return 0===a?32:31-(pc(a)/qc|0)|0}var rc=64,sc=4194304;\nfunction tc(a){switch(a&-a){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return a&4194240;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return a&130023424;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;\ndefault:return a}}function uc(a,b){var c=a.pendingLanes;if(0===c)return 0;var d=0,e=a.suspendedLanes,f=a.pingedLanes,g=c&268435455;if(0!==g){var h=g&~e;0!==h?d=tc(h):(f&=g,0!==f&&(d=tc(f)))}else g=c&~e,0!==g?d=tc(g):0!==f&&(d=tc(f));if(0===d)return 0;if(0!==b&&b!==d&&0===(b&e)&&(e=d&-d,f=b&-b,e>=f||16===e&&0!==(f&4194240)))return b;0!==(d&4)&&(d|=c&16);b=a.entangledLanes;if(0!==b)for(a=a.entanglements,b&=d;0<b;)c=31-oc(b),e=1<<c,d|=a[c],b&=~e;return d}\nfunction vc(a,b){switch(a){case 1:case 2:case 4:return b+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return b+5E3;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return-1;case 134217728:case 268435456:case 536870912:case 1073741824:return-1;default:return-1}}\nfunction wc(a,b){for(var c=a.suspendedLanes,d=a.pingedLanes,e=a.expirationTimes,f=a.pendingLanes;0<f;){var g=31-oc(f),h=1<<g,k=e[g];if(-1===k){if(0===(h&c)||0!==(h&d))e[g]=vc(h,b)}else k<=b&&(a.expiredLanes|=h);f&=~h}}function xc(a){a=a.pendingLanes&-1073741825;return 0!==a?a:a&1073741824?1073741824:0}function yc(){var a=rc;rc<<=1;0===(rc&4194240)&&(rc=64);return a}function zc(a){for(var b=[],c=0;31>c;c++)b.push(a);return b}\nfunction Ac(a,b,c){a.pendingLanes|=b;536870912!==b&&(a.suspendedLanes=0,a.pingedLanes=0);a=a.eventTimes;b=31-oc(b);a[b]=c}function Bc(a,b){var c=a.pendingLanes&~b;a.pendingLanes=b;a.suspendedLanes=0;a.pingedLanes=0;a.expiredLanes&=b;a.mutableReadLanes&=b;a.entangledLanes&=b;b=a.entanglements;var d=a.eventTimes;for(a=a.expirationTimes;0<c;){var e=31-oc(c),f=1<<e;b[e]=0;d[e]=-1;a[e]=-1;c&=~f}}\nfunction Cc(a,b){var c=a.entangledLanes|=b;for(a=a.entanglements;c;){var d=31-oc(c),e=1<<d;e&b|a[d]&b&&(a[d]|=b);c&=~e}}var C=0;function Dc(a){a&=-a;return 1<a?4<a?0!==(a&268435455)?16:536870912:4:1}var Ec,Fc,Gc,Hc,Ic,Jc=!1,Kc=[],Lc=null,Mc=null,Nc=null,Oc=new Map,Pc=new Map,Qc=[],Rc=\"mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit\".split(\" \");\nfunction Sc(a,b){switch(a){case \"focusin\":case \"focusout\":Lc=null;break;case \"dragenter\":case \"dragleave\":Mc=null;break;case \"mouseover\":case \"mouseout\":Nc=null;break;case \"pointerover\":case \"pointerout\":Oc.delete(b.pointerId);break;case \"gotpointercapture\":case \"lostpointercapture\":Pc.delete(b.pointerId)}}\nfunction Tc(a,b,c,d,e,f){if(null===a||a.nativeEvent!==f)return a={blockedOn:b,domEventName:c,eventSystemFlags:d,nativeEvent:f,targetContainers:[e]},null!==b&&(b=Cb(b),null!==b&&Fc(b)),a;a.eventSystemFlags|=d;b=a.targetContainers;null!==e&&-1===b.indexOf(e)&&b.push(e);return a}\nfunction Uc(a,b,c,d,e){switch(b){case \"focusin\":return Lc=Tc(Lc,a,b,c,d,e),!0;case \"dragenter\":return Mc=Tc(Mc,a,b,c,d,e),!0;case \"mouseover\":return Nc=Tc(Nc,a,b,c,d,e),!0;case \"pointerover\":var f=e.pointerId;Oc.set(f,Tc(Oc.get(f)||null,a,b,c,d,e));return!0;case \"gotpointercapture\":return f=e.pointerId,Pc.set(f,Tc(Pc.get(f)||null,a,b,c,d,e)),!0}return!1}\nfunction Vc(a){var b=Wc(a.target);if(null!==b){var c=Vb(b);if(null!==c)if(b=c.tag,13===b){if(b=Wb(c),null!==b){a.blockedOn=b;Ic(a.priority,function(){Gc(c)});return}}else if(3===b&&c.stateNode.current.memoizedState.isDehydrated){a.blockedOn=3===c.tag?c.stateNode.containerInfo:null;return}}a.blockedOn=null}\nfunction Xc(a){if(null!==a.blockedOn)return!1;for(var b=a.targetContainers;0<b.length;){var c=Yc(a.domEventName,a.eventSystemFlags,b[0],a.nativeEvent);if(null===c){c=a.nativeEvent;var d=new c.constructor(c.type,c);wb=d;c.target.dispatchEvent(d);wb=null}else return b=Cb(c),null!==b&&Fc(b),a.blockedOn=c,!1;b.shift()}return!0}function Zc(a,b,c){Xc(a)&&c.delete(b)}function $c(){Jc=!1;null!==Lc&&Xc(Lc)&&(Lc=null);null!==Mc&&Xc(Mc)&&(Mc=null);null!==Nc&&Xc(Nc)&&(Nc=null);Oc.forEach(Zc);Pc.forEach(Zc)}\nfunction ad(a,b){a.blockedOn===b&&(a.blockedOn=null,Jc||(Jc=!0,ca.unstable_scheduleCallback(ca.unstable_NormalPriority,$c)))}\nfunction bd(a){function b(b){return ad(b,a)}if(0<Kc.length){ad(Kc[0],a);for(var c=1;c<Kc.length;c++){var d=Kc[c];d.blockedOn===a&&(d.blockedOn=null)}}null!==Lc&&ad(Lc,a);null!==Mc&&ad(Mc,a);null!==Nc&&ad(Nc,a);Oc.forEach(b);Pc.forEach(b);for(c=0;c<Qc.length;c++)d=Qc[c],d.blockedOn===a&&(d.blockedOn=null);for(;0<Qc.length&&(c=Qc[0],null===c.blockedOn);)Vc(c),null===c.blockedOn&&Qc.shift()}var cd=ua.ReactCurrentBatchConfig,dd=!0;\nfunction ed(a,b,c,d){var e=C,f=cd.transition;cd.transition=null;try{C=1,fd(a,b,c,d)}finally{C=e,cd.transition=f}}function gd(a,b,c,d){var e=C,f=cd.transition;cd.transition=null;try{C=4,fd(a,b,c,d)}finally{C=e,cd.transition=f}}\nfunction fd(a,b,c,d){if(dd){var e=Yc(a,b,c,d);if(null===e)hd(a,b,d,id,c),Sc(a,d);else if(Uc(e,a,b,c,d))d.stopPropagation();else if(Sc(a,d),b&4&&-1<Rc.indexOf(a)){for(;null!==e;){var f=Cb(e);null!==f&&Ec(f);f=Yc(a,b,c,d);null===f&&hd(a,b,d,id,c);if(f===e)break;e=f}null!==e&&d.stopPropagation()}else hd(a,b,d,null,c)}}var id=null;\nfunction Yc(a,b,c,d){id=null;a=xb(d);a=Wc(a);if(null!==a)if(b=Vb(a),null===b)a=null;else if(c=b.tag,13===c){a=Wb(b);if(null!==a)return a;a=null}else if(3===c){if(b.stateNode.current.memoizedState.isDehydrated)return 3===b.tag?b.stateNode.containerInfo:null;a=null}else b!==a&&(a=null);id=a;return null}\nfunction jd(a){switch(a){case \"cancel\":case \"click\":case \"close\":case \"contextmenu\":case \"copy\":case \"cut\":case \"auxclick\":case \"dblclick\":case \"dragend\":case \"dragstart\":case \"drop\":case \"focusin\":case \"focusout\":case \"input\":case \"invalid\":case \"keydown\":case \"keypress\":case \"keyup\":case \"mousedown\":case \"mouseup\":case \"paste\":case \"pause\":case \"play\":case \"pointercancel\":case \"pointerdown\":case \"pointerup\":case \"ratechange\":case \"reset\":case \"resize\":case \"seeked\":case \"submit\":case \"touchcancel\":case \"touchend\":case \"touchstart\":case \"volumechange\":case \"change\":case \"selectionchange\":case \"textInput\":case \"compositionstart\":case \"compositionend\":case \"compositionupdate\":case \"beforeblur\":case \"afterblur\":case \"beforeinput\":case \"blur\":case \"fullscreenchange\":case \"focus\":case \"hashchange\":case \"popstate\":case \"select\":case \"selectstart\":return 1;case \"drag\":case \"dragenter\":case \"dragexit\":case \"dragleave\":case \"dragover\":case \"mousemove\":case \"mouseout\":case \"mouseover\":case \"pointermove\":case \"pointerout\":case \"pointerover\":case \"scroll\":case \"toggle\":case \"touchmove\":case \"wheel\":case \"mouseenter\":case \"mouseleave\":case \"pointerenter\":case \"pointerleave\":return 4;\ncase \"message\":switch(ec()){case fc:return 1;case gc:return 4;case hc:case ic:return 16;case jc:return 536870912;default:return 16}default:return 16}}var kd=null,ld=null,md=null;function nd(){if(md)return md;var a,b=ld,c=b.length,d,e=\"value\"in kd?kd.value:kd.textContent,f=e.length;for(a=0;a<c&&b[a]===e[a];a++);var g=c-a;for(d=1;d<=g&&b[c-d]===e[f-d];d++);return md=e.slice(a,1<d?1-d:void 0)}\nfunction od(a){var b=a.keyCode;\"charCode\"in a?(a=a.charCode,0===a&&13===b&&(a=13)):a=b;10===a&&(a=13);return 32<=a||13===a?a:0}function pd(){return!0}function qd(){return!1}\nfunction rd(a){function b(b,d,e,f,g){this._reactName=b;this._targetInst=e;this.type=d;this.nativeEvent=f;this.target=g;this.currentTarget=null;for(var c in a)a.hasOwnProperty(c)&&(b=a[c],this[c]=b?b(f):f[c]);this.isDefaultPrevented=(null!=f.defaultPrevented?f.defaultPrevented:!1===f.returnValue)?pd:qd;this.isPropagationStopped=qd;return this}A(b.prototype,{preventDefault:function(){this.defaultPrevented=!0;var a=this.nativeEvent;a&&(a.preventDefault?a.preventDefault():\"unknown\"!==typeof a.returnValue&&\n(a.returnValue=!1),this.isDefaultPrevented=pd)},stopPropagation:function(){var a=this.nativeEvent;a&&(a.stopPropagation?a.stopPropagation():\"unknown\"!==typeof a.cancelBubble&&(a.cancelBubble=!0),this.isPropagationStopped=pd)},persist:function(){},isPersistent:pd});return b}\nvar sd={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(a){return a.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},td=rd(sd),ud=A({},sd,{view:0,detail:0}),vd=rd(ud),wd,xd,yd,Ad=A({},ud,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:zd,button:0,buttons:0,relatedTarget:function(a){return void 0===a.relatedTarget?a.fromElement===a.srcElement?a.toElement:a.fromElement:a.relatedTarget},movementX:function(a){if(\"movementX\"in\na)return a.movementX;a!==yd&&(yd&&\"mousemove\"===a.type?(wd=a.screenX-yd.screenX,xd=a.screenY-yd.screenY):xd=wd=0,yd=a);return wd},movementY:function(a){return\"movementY\"in a?a.movementY:xd}}),Bd=rd(Ad),Cd=A({},Ad,{dataTransfer:0}),Dd=rd(Cd),Ed=A({},ud,{relatedTarget:0}),Fd=rd(Ed),Gd=A({},sd,{animationName:0,elapsedTime:0,pseudoElement:0}),Hd=rd(Gd),Id=A({},sd,{clipboardData:function(a){return\"clipboardData\"in a?a.clipboardData:window.clipboardData}}),Jd=rd(Id),Kd=A({},sd,{data:0}),Ld=rd(Kd),Md={Esc:\"Escape\",\nSpacebar:\" \",Left:\"ArrowLeft\",Up:\"ArrowUp\",Right:\"ArrowRight\",Down:\"ArrowDown\",Del:\"Delete\",Win:\"OS\",Menu:\"ContextMenu\",Apps:\"ContextMenu\",Scroll:\"ScrollLock\",MozPrintableKey:\"Unidentified\"},Nd={8:\"Backspace\",9:\"Tab\",12:\"Clear\",13:\"Enter\",16:\"Shift\",17:\"Control\",18:\"Alt\",19:\"Pause\",20:\"CapsLock\",27:\"Escape\",32:\" \",33:\"PageUp\",34:\"PageDown\",35:\"End\",36:\"Home\",37:\"ArrowLeft\",38:\"ArrowUp\",39:\"ArrowRight\",40:\"ArrowDown\",45:\"Insert\",46:\"Delete\",112:\"F1\",113:\"F2\",114:\"F3\",115:\"F4\",116:\"F5\",117:\"F6\",118:\"F7\",\n119:\"F8\",120:\"F9\",121:\"F10\",122:\"F11\",123:\"F12\",144:\"NumLock\",145:\"ScrollLock\",224:\"Meta\"},Od={Alt:\"altKey\",Control:\"ctrlKey\",Meta:\"metaKey\",Shift:\"shiftKey\"};function Pd(a){var b=this.nativeEvent;return b.getModifierState?b.getModifierState(a):(a=Od[a])?!!b[a]:!1}function zd(){return Pd}\nvar Qd=A({},ud,{key:function(a){if(a.key){var b=Md[a.key]||a.key;if(\"Unidentified\"!==b)return b}return\"keypress\"===a.type?(a=od(a),13===a?\"Enter\":String.fromCharCode(a)):\"keydown\"===a.type||\"keyup\"===a.type?Nd[a.keyCode]||\"Unidentified\":\"\"},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:zd,charCode:function(a){return\"keypress\"===a.type?od(a):0},keyCode:function(a){return\"keydown\"===a.type||\"keyup\"===a.type?a.keyCode:0},which:function(a){return\"keypress\"===\na.type?od(a):\"keydown\"===a.type||\"keyup\"===a.type?a.keyCode:0}}),Rd=rd(Qd),Sd=A({},Ad,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0}),Td=rd(Sd),Ud=A({},ud,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:zd}),Vd=rd(Ud),Wd=A({},sd,{propertyName:0,elapsedTime:0,pseudoElement:0}),Xd=rd(Wd),Yd=A({},Ad,{deltaX:function(a){return\"deltaX\"in a?a.deltaX:\"wheelDeltaX\"in a?-a.wheelDeltaX:0},\ndeltaY:function(a){return\"deltaY\"in a?a.deltaY:\"wheelDeltaY\"in a?-a.wheelDeltaY:\"wheelDelta\"in a?-a.wheelDelta:0},deltaZ:0,deltaMode:0}),Zd=rd(Yd),$d=[9,13,27,32],ae=ia&&\"CompositionEvent\"in window,be=null;ia&&\"documentMode\"in document&&(be=document.documentMode);var ce=ia&&\"TextEvent\"in window&&!be,de=ia&&(!ae||be&&8<be&&11>=be),ee=String.fromCharCode(32),fe=!1;\nfunction ge(a,b){switch(a){case \"keyup\":return-1!==$d.indexOf(b.keyCode);case \"keydown\":return 229!==b.keyCode;case \"keypress\":case \"mousedown\":case \"focusout\":return!0;default:return!1}}function he(a){a=a.detail;return\"object\"===typeof a&&\"data\"in a?a.data:null}var ie=!1;function je(a,b){switch(a){case \"compositionend\":return he(b);case \"keypress\":if(32!==b.which)return null;fe=!0;return ee;case \"textInput\":return a=b.data,a===ee&&fe?null:a;default:return null}}\nfunction ke(a,b){if(ie)return\"compositionend\"===a||!ae&&ge(a,b)?(a=nd(),md=ld=kd=null,ie=!1,a):null;switch(a){case \"paste\":return null;case \"keypress\":if(!(b.ctrlKey||b.altKey||b.metaKey)||b.ctrlKey&&b.altKey){if(b.char&&1<b.char.length)return b.char;if(b.which)return String.fromCharCode(b.which)}return null;case \"compositionend\":return de&&\"ko\"!==b.locale?null:b.data;default:return null}}\nvar le={color:!0,date:!0,datetime:!0,\"datetime-local\":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function me(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return\"input\"===b?!!le[a.type]:\"textarea\"===b?!0:!1}function ne(a,b,c,d){Eb(d);b=oe(b,\"onChange\");0<b.length&&(c=new td(\"onChange\",\"change\",null,c,d),a.push({event:c,listeners:b}))}var pe=null,qe=null;function re(a){se(a,0)}function te(a){var b=ue(a);if(Wa(b))return a}\nfunction ve(a,b){if(\"change\"===a)return b}var we=!1;if(ia){var xe;if(ia){var ye=\"oninput\"in document;if(!ye){var ze=document.createElement(\"div\");ze.setAttribute(\"oninput\",\"return;\");ye=\"function\"===typeof ze.oninput}xe=ye}else xe=!1;we=xe&&(!document.documentMode||9<document.documentMode)}function Ae(){pe&&(pe.detachEvent(\"onpropertychange\",Be),qe=pe=null)}function Be(a){if(\"value\"===a.propertyName&&te(qe)){var b=[];ne(b,qe,a,xb(a));Jb(re,b)}}\nfunction Ce(a,b,c){\"focusin\"===a?(Ae(),pe=b,qe=c,pe.attachEvent(\"onpropertychange\",Be)):\"focusout\"===a&&Ae()}function De(a){if(\"selectionchange\"===a||\"keyup\"===a||\"keydown\"===a)return te(qe)}function Ee(a,b){if(\"click\"===a)return te(b)}function Fe(a,b){if(\"input\"===a||\"change\"===a)return te(b)}function Ge(a,b){return a===b&&(0!==a||1/a===1/b)||a!==a&&b!==b}var He=\"function\"===typeof Object.is?Object.is:Ge;\nfunction Ie(a,b){if(He(a,b))return!0;if(\"object\"!==typeof a||null===a||\"object\"!==typeof b||null===b)return!1;var c=Object.keys(a),d=Object.keys(b);if(c.length!==d.length)return!1;for(d=0;d<c.length;d++){var e=c[d];if(!ja.call(b,e)||!He(a[e],b[e]))return!1}return!0}function Je(a){for(;a&&a.firstChild;)a=a.firstChild;return a}\nfunction Ke(a,b){var c=Je(a);a=0;for(var d;c;){if(3===c.nodeType){d=a+c.textContent.length;if(a<=b&&d>=b)return{node:c,offset:b-a};a=d}a:{for(;c;){if(c.nextSibling){c=c.nextSibling;break a}c=c.parentNode}c=void 0}c=Je(c)}}function Le(a,b){return a&&b?a===b?!0:a&&3===a.nodeType?!1:b&&3===b.nodeType?Le(a,b.parentNode):\"contains\"in a?a.contains(b):a.compareDocumentPosition?!!(a.compareDocumentPosition(b)&16):!1:!1}\nfunction Me(){for(var a=window,b=Xa();b instanceof a.HTMLIFrameElement;){try{var c=\"string\"===typeof b.contentWindow.location.href}catch(d){c=!1}if(c)a=b.contentWindow;else break;b=Xa(a.document)}return b}function Ne(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return b&&(\"input\"===b&&(\"text\"===a.type||\"search\"===a.type||\"tel\"===a.type||\"url\"===a.type||\"password\"===a.type)||\"textarea\"===b||\"true\"===a.contentEditable)}\nfunction Oe(a){var b=Me(),c=a.focusedElem,d=a.selectionRange;if(b!==c&&c&&c.ownerDocument&&Le(c.ownerDocument.documentElement,c)){if(null!==d&&Ne(c))if(b=d.start,a=d.end,void 0===a&&(a=b),\"selectionStart\"in c)c.selectionStart=b,c.selectionEnd=Math.min(a,c.value.length);else if(a=(b=c.ownerDocument||document)&&b.defaultView||window,a.getSelection){a=a.getSelection();var e=c.textContent.length,f=Math.min(d.start,e);d=void 0===d.end?f:Math.min(d.end,e);!a.extend&&f>d&&(e=d,d=f,f=e);e=Ke(c,f);var g=Ke(c,\nd);e&&g&&(1!==a.rangeCount||a.anchorNode!==e.node||a.anchorOffset!==e.offset||a.focusNode!==g.node||a.focusOffset!==g.offset)&&(b=b.createRange(),b.setStart(e.node,e.offset),a.removeAllRanges(),f>d?(a.addRange(b),a.extend(g.node,g.offset)):(b.setEnd(g.node,g.offset),a.addRange(b)))}b=[];for(a=c;a=a.parentNode;)1===a.nodeType&&b.push({element:a,left:a.scrollLeft,top:a.scrollTop});\"function\"===typeof c.focus&&c.focus();for(c=0;c<b.length;c++)a=b[c],a.element.scrollLeft=a.left,a.element.scrollTop=a.top}}\nvar Pe=ia&&\"documentMode\"in document&&11>=document.documentMode,Qe=null,Re=null,Se=null,Te=!1;\nfunction Ue(a,b,c){var d=c.window===c?c.document:9===c.nodeType?c:c.ownerDocument;Te||null==Qe||Qe!==Xa(d)||(d=Qe,\"selectionStart\"in d&&Ne(d)?d={start:d.selectionStart,end:d.selectionEnd}:(d=(d.ownerDocument&&d.ownerDocument.defaultView||window).getSelection(),d={anchorNode:d.anchorNode,anchorOffset:d.anchorOffset,focusNode:d.focusNode,focusOffset:d.focusOffset}),Se&&Ie(Se,d)||(Se=d,d=oe(Re,\"onSelect\"),0<d.length&&(b=new td(\"onSelect\",\"select\",null,b,c),a.push({event:b,listeners:d}),b.target=Qe)))}\nfunction Ve(a,b){var c={};c[a.toLowerCase()]=b.toLowerCase();c[\"Webkit\"+a]=\"webkit\"+b;c[\"Moz\"+a]=\"moz\"+b;return c}var We={animationend:Ve(\"Animation\",\"AnimationEnd\"),animationiteration:Ve(\"Animation\",\"AnimationIteration\"),animationstart:Ve(\"Animation\",\"AnimationStart\"),transitionend:Ve(\"Transition\",\"TransitionEnd\")},Xe={},Ye={};\nia&&(Ye=document.createElement(\"div\").style,\"AnimationEvent\"in window||(delete We.animationend.animation,delete We.animationiteration.animation,delete We.animationstart.animation),\"TransitionEvent\"in window||delete We.transitionend.transition);function Ze(a){if(Xe[a])return Xe[a];if(!We[a])return a;var b=We[a],c;for(c in b)if(b.hasOwnProperty(c)&&c in Ye)return Xe[a]=b[c];return a}var $e=Ze(\"animationend\"),af=Ze(\"animationiteration\"),bf=Ze(\"animationstart\"),cf=Ze(\"transitionend\"),df=new Map,ef=\"abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel\".split(\" \");\nfunction ff(a,b){df.set(a,b);fa(b,[a])}for(var gf=0;gf<ef.length;gf++){var hf=ef[gf],jf=hf.toLowerCase(),kf=hf[0].toUpperCase()+hf.slice(1);ff(jf,\"on\"+kf)}ff($e,\"onAnimationEnd\");ff(af,\"onAnimationIteration\");ff(bf,\"onAnimationStart\");ff(\"dblclick\",\"onDoubleClick\");ff(\"focusin\",\"onFocus\");ff(\"focusout\",\"onBlur\");ff(cf,\"onTransitionEnd\");ha(\"onMouseEnter\",[\"mouseout\",\"mouseover\"]);ha(\"onMouseLeave\",[\"mouseout\",\"mouseover\"]);ha(\"onPointerEnter\",[\"pointerout\",\"pointerover\"]);\nha(\"onPointerLeave\",[\"pointerout\",\"pointerover\"]);fa(\"onChange\",\"change click focusin focusout input keydown keyup selectionchange\".split(\" \"));fa(\"onSelect\",\"focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange\".split(\" \"));fa(\"onBeforeInput\",[\"compositionend\",\"keypress\",\"textInput\",\"paste\"]);fa(\"onCompositionEnd\",\"compositionend focusout keydown keypress keyup mousedown\".split(\" \"));fa(\"onCompositionStart\",\"compositionstart focusout keydown keypress keyup mousedown\".split(\" \"));\nfa(\"onCompositionUpdate\",\"compositionupdate focusout keydown keypress keyup mousedown\".split(\" \"));var lf=\"abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting\".split(\" \"),mf=new Set(\"cancel close invalid load scroll toggle\".split(\" \").concat(lf));\nfunction nf(a,b,c){var d=a.type||\"unknown-event\";a.currentTarget=c;Ub(d,b,void 0,a);a.currentTarget=null}\nfunction se(a,b){b=0!==(b&4);for(var c=0;c<a.length;c++){var d=a[c],e=d.event;d=d.listeners;a:{var f=void 0;if(b)for(var g=d.length-1;0<=g;g--){var h=d[g],k=h.instance,l=h.currentTarget;h=h.listener;if(k!==f&&e.isPropagationStopped())break a;nf(e,h,l);f=k}else for(g=0;g<d.length;g++){h=d[g];k=h.instance;l=h.currentTarget;h=h.listener;if(k!==f&&e.isPropagationStopped())break a;nf(e,h,l);f=k}}}if(Qb)throw a=Rb,Qb=!1,Rb=null,a;}\nfunction D(a,b){var c=b[of];void 0===c&&(c=b[of]=new Set);var d=a+\"__bubble\";c.has(d)||(pf(b,a,2,!1),c.add(d))}function qf(a,b,c){var d=0;b&&(d|=4);pf(c,a,d,b)}var rf=\"_reactListening\"+Math.random().toString(36).slice(2);function sf(a){if(!a[rf]){a[rf]=!0;da.forEach(function(b){\"selectionchange\"!==b&&(mf.has(b)||qf(b,!1,a),qf(b,!0,a))});var b=9===a.nodeType?a:a.ownerDocument;null===b||b[rf]||(b[rf]=!0,qf(\"selectionchange\",!1,b))}}\nfunction pf(a,b,c,d){switch(jd(b)){case 1:var e=ed;break;case 4:e=gd;break;default:e=fd}c=e.bind(null,b,c,a);e=void 0;!Lb||\"touchstart\"!==b&&\"touchmove\"!==b&&\"wheel\"!==b||(e=!0);d?void 0!==e?a.addEventListener(b,c,{capture:!0,passive:e}):a.addEventListener(b,c,!0):void 0!==e?a.addEventListener(b,c,{passive:e}):a.addEventListener(b,c,!1)}\nfunction hd(a,b,c,d,e){var f=d;if(0===(b&1)&&0===(b&2)&&null!==d)a:for(;;){if(null===d)return;var g=d.tag;if(3===g||4===g){var h=d.stateNode.containerInfo;if(h===e||8===h.nodeType&&h.parentNode===e)break;if(4===g)for(g=d.return;null!==g;){var k=g.tag;if(3===k||4===k)if(k=g.stateNode.containerInfo,k===e||8===k.nodeType&&k.parentNode===e)return;g=g.return}for(;null!==h;){g=Wc(h);if(null===g)return;k=g.tag;if(5===k||6===k){d=f=g;continue a}h=h.parentNode}}d=d.return}Jb(function(){var d=f,e=xb(c),g=[];\na:{var h=df.get(a);if(void 0!==h){var k=td,n=a;switch(a){case \"keypress\":if(0===od(c))break a;case \"keydown\":case \"keyup\":k=Rd;break;case \"focusin\":n=\"focus\";k=Fd;break;case \"focusout\":n=\"blur\";k=Fd;break;case \"beforeblur\":case \"afterblur\":k=Fd;break;case \"click\":if(2===c.button)break a;case \"auxclick\":case \"dblclick\":case \"mousedown\":case \"mousemove\":case \"mouseup\":case \"mouseout\":case \"mouseover\":case \"contextmenu\":k=Bd;break;case \"drag\":case \"dragend\":case \"dragenter\":case \"dragexit\":case \"dragleave\":case \"dragover\":case \"dragstart\":case \"drop\":k=\nDd;break;case \"touchcancel\":case \"touchend\":case \"touchmove\":case \"touchstart\":k=Vd;break;case $e:case af:case bf:k=Hd;break;case cf:k=Xd;break;case \"scroll\":k=vd;break;case \"wheel\":k=Zd;break;case \"copy\":case \"cut\":case \"paste\":k=Jd;break;case \"gotpointercapture\":case \"lostpointercapture\":case \"pointercancel\":case \"pointerdown\":case \"pointermove\":case \"pointerout\":case \"pointerover\":case \"pointerup\":k=Td}var t=0!==(b&4),J=!t&&\"scroll\"===a,x=t?null!==h?h+\"Capture\":null:h;t=[];for(var w=d,u;null!==\nw;){u=w;var F=u.stateNode;5===u.tag&&null!==F&&(u=F,null!==x&&(F=Kb(w,x),null!=F&&t.push(tf(w,F,u))));if(J)break;w=w.return}0<t.length&&(h=new k(h,n,null,c,e),g.push({event:h,listeners:t}))}}if(0===(b&7)){a:{h=\"mouseover\"===a||\"pointerover\"===a;k=\"mouseout\"===a||\"pointerout\"===a;if(h&&c!==wb&&(n=c.relatedTarget||c.fromElement)&&(Wc(n)||n[uf]))break a;if(k||h){h=e.window===e?e:(h=e.ownerDocument)?h.defaultView||h.parentWindow:window;if(k){if(n=c.relatedTarget||c.toElement,k=d,n=n?Wc(n):null,null!==\nn&&(J=Vb(n),n!==J||5!==n.tag&&6!==n.tag))n=null}else k=null,n=d;if(k!==n){t=Bd;F=\"onMouseLeave\";x=\"onMouseEnter\";w=\"mouse\";if(\"pointerout\"===a||\"pointerover\"===a)t=Td,F=\"onPointerLeave\",x=\"onPointerEnter\",w=\"pointer\";J=null==k?h:ue(k);u=null==n?h:ue(n);h=new t(F,w+\"leave\",k,c,e);h.target=J;h.relatedTarget=u;F=null;Wc(e)===d&&(t=new t(x,w+\"enter\",n,c,e),t.target=u,t.relatedTarget=J,F=t);J=F;if(k&&n)b:{t=k;x=n;w=0;for(u=t;u;u=vf(u))w++;u=0;for(F=x;F;F=vf(F))u++;for(;0<w-u;)t=vf(t),w--;for(;0<u-w;)x=\nvf(x),u--;for(;w--;){if(t===x||null!==x&&t===x.alternate)break b;t=vf(t);x=vf(x)}t=null}else t=null;null!==k&&wf(g,h,k,t,!1);null!==n&&null!==J&&wf(g,J,n,t,!0)}}}a:{h=d?ue(d):window;k=h.nodeName&&h.nodeName.toLowerCase();if(\"select\"===k||\"input\"===k&&\"file\"===h.type)var na=ve;else if(me(h))if(we)na=Fe;else{na=De;var xa=Ce}else(k=h.nodeName)&&\"input\"===k.toLowerCase()&&(\"checkbox\"===h.type||\"radio\"===h.type)&&(na=Ee);if(na&&(na=na(a,d))){ne(g,na,c,e);break a}xa&&xa(a,h,d);\"focusout\"===a&&(xa=h._wrapperState)&&\nxa.controlled&&\"number\"===h.type&&cb(h,\"number\",h.value)}xa=d?ue(d):window;switch(a){case \"focusin\":if(me(xa)||\"true\"===xa.contentEditable)Qe=xa,Re=d,Se=null;break;case \"focusout\":Se=Re=Qe=null;break;case \"mousedown\":Te=!0;break;case \"contextmenu\":case \"mouseup\":case \"dragend\":Te=!1;Ue(g,c,e);break;case \"selectionchange\":if(Pe)break;case \"keydown\":case \"keyup\":Ue(g,c,e)}var $a;if(ae)b:{switch(a){case \"compositionstart\":var ba=\"onCompositionStart\";break b;case \"compositionend\":ba=\"onCompositionEnd\";\nbreak b;case \"compositionupdate\":ba=\"onCompositionUpdate\";break b}ba=void 0}else ie?ge(a,c)&&(ba=\"onCompositionEnd\"):\"keydown\"===a&&229===c.keyCode&&(ba=\"onCompositionStart\");ba&&(de&&\"ko\"!==c.locale&&(ie||\"onCompositionStart\"!==ba?\"onCompositionEnd\"===ba&&ie&&($a=nd()):(kd=e,ld=\"value\"in kd?kd.value:kd.textContent,ie=!0)),xa=oe(d,ba),0<xa.length&&(ba=new Ld(ba,a,null,c,e),g.push({event:ba,listeners:xa}),$a?ba.data=$a:($a=he(c),null!==$a&&(ba.data=$a))));if($a=ce?je(a,c):ke(a,c))d=oe(d,\"onBeforeInput\"),\n0<d.length&&(e=new Ld(\"onBeforeInput\",\"beforeinput\",null,c,e),g.push({event:e,listeners:d}),e.data=$a)}se(g,b)})}function tf(a,b,c){return{instance:a,listener:b,currentTarget:c}}function oe(a,b){for(var c=b+\"Capture\",d=[];null!==a;){var e=a,f=e.stateNode;5===e.tag&&null!==f&&(e=f,f=Kb(a,c),null!=f&&d.unshift(tf(a,f,e)),f=Kb(a,b),null!=f&&d.push(tf(a,f,e)));a=a.return}return d}function vf(a){if(null===a)return null;do a=a.return;while(a&&5!==a.tag);return a?a:null}\nfunction wf(a,b,c,d,e){for(var f=b._reactName,g=[];null!==c&&c!==d;){var h=c,k=h.alternate,l=h.stateNode;if(null!==k&&k===d)break;5===h.tag&&null!==l&&(h=l,e?(k=Kb(c,f),null!=k&&g.unshift(tf(c,k,h))):e||(k=Kb(c,f),null!=k&&g.push(tf(c,k,h))));c=c.return}0!==g.length&&a.push({event:b,listeners:g})}var xf=/\\r\\n?/g,yf=/\\u0000|\\uFFFD/g;function zf(a){return(\"string\"===typeof a?a:\"\"+a).replace(xf,\"\\n\").replace(yf,\"\")}function Af(a,b,c){b=zf(b);if(zf(a)!==b&&c)throw Error(p(425));}function Bf(){}\nvar Cf=null,Df=null;function Ef(a,b){return\"textarea\"===a||\"noscript\"===a||\"string\"===typeof b.children||\"number\"===typeof b.children||\"object\"===typeof b.dangerouslySetInnerHTML&&null!==b.dangerouslySetInnerHTML&&null!=b.dangerouslySetInnerHTML.__html}\nvar Ff=\"function\"===typeof setTimeout?setTimeout:void 0,Gf=\"function\"===typeof clearTimeout?clearTimeout:void 0,Hf=\"function\"===typeof Promise?Promise:void 0,Jf=\"function\"===typeof queueMicrotask?queueMicrotask:\"undefined\"!==typeof Hf?function(a){return Hf.resolve(null).then(a).catch(If)}:Ff;function If(a){setTimeout(function(){throw a;})}\nfunction Kf(a,b){var c=b,d=0;do{var e=c.nextSibling;a.removeChild(c);if(e&&8===e.nodeType)if(c=e.data,\"/$\"===c){if(0===d){a.removeChild(e);bd(b);return}d--}else\"$\"!==c&&\"$?\"!==c&&\"$!\"!==c||d++;c=e}while(c);bd(b)}function Lf(a){for(;null!=a;a=a.nextSibling){var b=a.nodeType;if(1===b||3===b)break;if(8===b){b=a.data;if(\"$\"===b||\"$!\"===b||\"$?\"===b)break;if(\"/$\"===b)return null}}return a}\nfunction Mf(a){a=a.previousSibling;for(var b=0;a;){if(8===a.nodeType){var c=a.data;if(\"$\"===c||\"$!\"===c||\"$?\"===c){if(0===b)return a;b--}else\"/$\"===c&&b++}a=a.previousSibling}return null}var Nf=Math.random().toString(36).slice(2),Of=\"__reactFiber$\"+Nf,Pf=\"__reactProps$\"+Nf,uf=\"__reactContainer$\"+Nf,of=\"__reactEvents$\"+Nf,Qf=\"__reactListeners$\"+Nf,Rf=\"__reactHandles$\"+Nf;\nfunction Wc(a){var b=a[Of];if(b)return b;for(var c=a.parentNode;c;){if(b=c[uf]||c[Of]){c=b.alternate;if(null!==b.child||null!==c&&null!==c.child)for(a=Mf(a);null!==a;){if(c=a[Of])return c;a=Mf(a)}return b}a=c;c=a.parentNode}return null}function Cb(a){a=a[Of]||a[uf];return!a||5!==a.tag&&6!==a.tag&&13!==a.tag&&3!==a.tag?null:a}function ue(a){if(5===a.tag||6===a.tag)return a.stateNode;throw Error(p(33));}function Db(a){return a[Pf]||null}var Sf=[],Tf=-1;function Uf(a){return{current:a}}\nfunction E(a){0>Tf||(a.current=Sf[Tf],Sf[Tf]=null,Tf--)}function G(a,b){Tf++;Sf[Tf]=a.current;a.current=b}var Vf={},H=Uf(Vf),Wf=Uf(!1),Xf=Vf;function Yf(a,b){var c=a.type.contextTypes;if(!c)return Vf;var d=a.stateNode;if(d&&d.__reactInternalMemoizedUnmaskedChildContext===b)return d.__reactInternalMemoizedMaskedChildContext;var e={},f;for(f in c)e[f]=b[f];d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=b,a.__reactInternalMemoizedMaskedChildContext=e);return e}\nfunction Zf(a){a=a.childContextTypes;return null!==a&&void 0!==a}function $f(){E(Wf);E(H)}function ag(a,b,c){if(H.current!==Vf)throw Error(p(168));G(H,b);G(Wf,c)}function bg(a,b,c){var d=a.stateNode;b=b.childContextTypes;if(\"function\"!==typeof d.getChildContext)return c;d=d.getChildContext();for(var e in d)if(!(e in b))throw Error(p(108,Ra(a)||\"Unknown\",e));return A({},c,d)}\nfunction cg(a){a=(a=a.stateNode)&&a.__reactInternalMemoizedMergedChildContext||Vf;Xf=H.current;G(H,a);G(Wf,Wf.current);return!0}function dg(a,b,c){var d=a.stateNode;if(!d)throw Error(p(169));c?(a=bg(a,b,Xf),d.__reactInternalMemoizedMergedChildContext=a,E(Wf),E(H),G(H,a)):E(Wf);G(Wf,c)}var eg=null,fg=!1,gg=!1;function hg(a){null===eg?eg=[a]:eg.push(a)}function ig(a){fg=!0;hg(a)}\nfunction jg(){if(!gg&&null!==eg){gg=!0;var a=0,b=C;try{var c=eg;for(C=1;a<c.length;a++){var d=c[a];do d=d(!0);while(null!==d)}eg=null;fg=!1}catch(e){throw null!==eg&&(eg=eg.slice(a+1)),ac(fc,jg),e;}finally{C=b,gg=!1}}return null}var kg=[],lg=0,mg=null,ng=0,og=[],pg=0,qg=null,rg=1,sg=\"\";function tg(a,b){kg[lg++]=ng;kg[lg++]=mg;mg=a;ng=b}\nfunction ug(a,b,c){og[pg++]=rg;og[pg++]=sg;og[pg++]=qg;qg=a;var d=rg;a=sg;var e=32-oc(d)-1;d&=~(1<<e);c+=1;var f=32-oc(b)+e;if(30<f){var g=e-e%5;f=(d&(1<<g)-1).toString(32);d>>=g;e-=g;rg=1<<32-oc(b)+e|c<<e|d;sg=f+a}else rg=1<<f|c<<e|d,sg=a}function vg(a){null!==a.return&&(tg(a,1),ug(a,1,0))}function wg(a){for(;a===mg;)mg=kg[--lg],kg[lg]=null,ng=kg[--lg],kg[lg]=null;for(;a===qg;)qg=og[--pg],og[pg]=null,sg=og[--pg],og[pg]=null,rg=og[--pg],og[pg]=null}var xg=null,yg=null,I=!1,zg=null;\nfunction Ag(a,b){var c=Bg(5,null,null,0);c.elementType=\"DELETED\";c.stateNode=b;c.return=a;b=a.deletions;null===b?(a.deletions=[c],a.flags|=16):b.push(c)}\nfunction Cg(a,b){switch(a.tag){case 5:var c=a.type;b=1!==b.nodeType||c.toLowerCase()!==b.nodeName.toLowerCase()?null:b;return null!==b?(a.stateNode=b,xg=a,yg=Lf(b.firstChild),!0):!1;case 6:return b=\"\"===a.pendingProps||3!==b.nodeType?null:b,null!==b?(a.stateNode=b,xg=a,yg=null,!0):!1;case 13:return b=8!==b.nodeType?null:b,null!==b?(c=null!==qg?{id:rg,overflow:sg}:null,a.memoizedState={dehydrated:b,treeContext:c,retryLane:1073741824},c=Bg(18,null,null,0),c.stateNode=b,c.return=a,a.child=c,xg=a,yg=\nnull,!0):!1;default:return!1}}function Dg(a){return 0!==(a.mode&1)&&0===(a.flags&128)}function Eg(a){if(I){var b=yg;if(b){var c=b;if(!Cg(a,b)){if(Dg(a))throw Error(p(418));b=Lf(c.nextSibling);var d=xg;b&&Cg(a,b)?Ag(d,c):(a.flags=a.flags&-4097|2,I=!1,xg=a)}}else{if(Dg(a))throw Error(p(418));a.flags=a.flags&-4097|2;I=!1;xg=a}}}function Fg(a){for(a=a.return;null!==a&&5!==a.tag&&3!==a.tag&&13!==a.tag;)a=a.return;xg=a}\nfunction Gg(a){if(a!==xg)return!1;if(!I)return Fg(a),I=!0,!1;var b;(b=3!==a.tag)&&!(b=5!==a.tag)&&(b=a.type,b=\"head\"!==b&&\"body\"!==b&&!Ef(a.type,a.memoizedProps));if(b&&(b=yg)){if(Dg(a))throw Hg(),Error(p(418));for(;b;)Ag(a,b),b=Lf(b.nextSibling)}Fg(a);if(13===a.tag){a=a.memoizedState;a=null!==a?a.dehydrated:null;if(!a)throw Error(p(317));a:{a=a.nextSibling;for(b=0;a;){if(8===a.nodeType){var c=a.data;if(\"/$\"===c){if(0===b){yg=Lf(a.nextSibling);break a}b--}else\"$\"!==c&&\"$!\"!==c&&\"$?\"!==c||b++}a=a.nextSibling}yg=\nnull}}else yg=xg?Lf(a.stateNode.nextSibling):null;return!0}function Hg(){for(var a=yg;a;)a=Lf(a.nextSibling)}function Ig(){yg=xg=null;I=!1}function Jg(a){null===zg?zg=[a]:zg.push(a)}var Kg=ua.ReactCurrentBatchConfig;function Lg(a,b){if(a&&a.defaultProps){b=A({},b);a=a.defaultProps;for(var c in a)void 0===b[c]&&(b[c]=a[c]);return b}return b}var Mg=Uf(null),Ng=null,Og=null,Pg=null;function Qg(){Pg=Og=Ng=null}function Rg(a){var b=Mg.current;E(Mg);a._currentValue=b}\nfunction Sg(a,b,c){for(;null!==a;){var d=a.alternate;(a.childLanes&b)!==b?(a.childLanes|=b,null!==d&&(d.childLanes|=b)):null!==d&&(d.childLanes&b)!==b&&(d.childLanes|=b);if(a===c)break;a=a.return}}function Tg(a,b){Ng=a;Pg=Og=null;a=a.dependencies;null!==a&&null!==a.firstContext&&(0!==(a.lanes&b)&&(Ug=!0),a.firstContext=null)}\nfunction Vg(a){var b=a._currentValue;if(Pg!==a)if(a={context:a,memoizedValue:b,next:null},null===Og){if(null===Ng)throw Error(p(308));Og=a;Ng.dependencies={lanes:0,firstContext:a}}else Og=Og.next=a;return b}var Wg=null;function Xg(a){null===Wg?Wg=[a]:Wg.push(a)}function Yg(a,b,c,d){var e=b.interleaved;null===e?(c.next=c,Xg(b)):(c.next=e.next,e.next=c);b.interleaved=c;return Zg(a,d)}\nfunction Zg(a,b){a.lanes|=b;var c=a.alternate;null!==c&&(c.lanes|=b);c=a;for(a=a.return;null!==a;)a.childLanes|=b,c=a.alternate,null!==c&&(c.childLanes|=b),c=a,a=a.return;return 3===c.tag?c.stateNode:null}var $g=!1;function ah(a){a.updateQueue={baseState:a.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}\nfunction bh(a,b){a=a.updateQueue;b.updateQueue===a&&(b.updateQueue={baseState:a.baseState,firstBaseUpdate:a.firstBaseUpdate,lastBaseUpdate:a.lastBaseUpdate,shared:a.shared,effects:a.effects})}function ch(a,b){return{eventTime:a,lane:b,tag:0,payload:null,callback:null,next:null}}\nfunction dh(a,b,c){var d=a.updateQueue;if(null===d)return null;d=d.shared;if(0!==(K&2)){var e=d.pending;null===e?b.next=b:(b.next=e.next,e.next=b);d.pending=b;return Zg(a,c)}e=d.interleaved;null===e?(b.next=b,Xg(d)):(b.next=e.next,e.next=b);d.interleaved=b;return Zg(a,c)}function eh(a,b,c){b=b.updateQueue;if(null!==b&&(b=b.shared,0!==(c&4194240))){var d=b.lanes;d&=a.pendingLanes;c|=d;b.lanes=c;Cc(a,c)}}\nfunction fh(a,b){var c=a.updateQueue,d=a.alternate;if(null!==d&&(d=d.updateQueue,c===d)){var e=null,f=null;c=c.firstBaseUpdate;if(null!==c){do{var g={eventTime:c.eventTime,lane:c.lane,tag:c.tag,payload:c.payload,callback:c.callback,next:null};null===f?e=f=g:f=f.next=g;c=c.next}while(null!==c);null===f?e=f=b:f=f.next=b}else e=f=b;c={baseState:d.baseState,firstBaseUpdate:e,lastBaseUpdate:f,shared:d.shared,effects:d.effects};a.updateQueue=c;return}a=c.lastBaseUpdate;null===a?c.firstBaseUpdate=b:a.next=\nb;c.lastBaseUpdate=b}\nfunction gh(a,b,c,d){var e=a.updateQueue;$g=!1;var f=e.firstBaseUpdate,g=e.lastBaseUpdate,h=e.shared.pending;if(null!==h){e.shared.pending=null;var k=h,l=k.next;k.next=null;null===g?f=l:g.next=l;g=k;var m=a.alternate;null!==m&&(m=m.updateQueue,h=m.lastBaseUpdate,h!==g&&(null===h?m.firstBaseUpdate=l:h.next=l,m.lastBaseUpdate=k))}if(null!==f){var q=e.baseState;g=0;m=l=k=null;h=f;do{var r=h.lane,y=h.eventTime;if((d&r)===r){null!==m&&(m=m.next={eventTime:y,lane:0,tag:h.tag,payload:h.payload,callback:h.callback,\nnext:null});a:{var n=a,t=h;r=b;y=c;switch(t.tag){case 1:n=t.payload;if(\"function\"===typeof n){q=n.call(y,q,r);break a}q=n;break a;case 3:n.flags=n.flags&-65537|128;case 0:n=t.payload;r=\"function\"===typeof n?n.call(y,q,r):n;if(null===r||void 0===r)break a;q=A({},q,r);break a;case 2:$g=!0}}null!==h.callback&&0!==h.lane&&(a.flags|=64,r=e.effects,null===r?e.effects=[h]:r.push(h))}else y={eventTime:y,lane:r,tag:h.tag,payload:h.payload,callback:h.callback,next:null},null===m?(l=m=y,k=q):m=m.next=y,g|=r;\nh=h.next;if(null===h)if(h=e.shared.pending,null===h)break;else r=h,h=r.next,r.next=null,e.lastBaseUpdate=r,e.shared.pending=null}while(1);null===m&&(k=q);e.baseState=k;e.firstBaseUpdate=l;e.lastBaseUpdate=m;b=e.shared.interleaved;if(null!==b){e=b;do g|=e.lane,e=e.next;while(e!==b)}else null===f&&(e.shared.lanes=0);hh|=g;a.lanes=g;a.memoizedState=q}}\nfunction ih(a,b,c){a=b.effects;b.effects=null;if(null!==a)for(b=0;b<a.length;b++){var d=a[b],e=d.callback;if(null!==e){d.callback=null;d=c;if(\"function\"!==typeof e)throw Error(p(191,e));e.call(d)}}}var jh=(new aa.Component).refs;function kh(a,b,c,d){b=a.memoizedState;c=c(d,b);c=null===c||void 0===c?b:A({},b,c);a.memoizedState=c;0===a.lanes&&(a.updateQueue.baseState=c)}\nvar nh={isMounted:function(a){return(a=a._reactInternals)?Vb(a)===a:!1},enqueueSetState:function(a,b,c){a=a._reactInternals;var d=L(),e=lh(a),f=ch(d,e);f.payload=b;void 0!==c&&null!==c&&(f.callback=c);b=dh(a,f,e);null!==b&&(mh(b,a,e,d),eh(b,a,e))},enqueueReplaceState:function(a,b,c){a=a._reactInternals;var d=L(),e=lh(a),f=ch(d,e);f.tag=1;f.payload=b;void 0!==c&&null!==c&&(f.callback=c);b=dh(a,f,e);null!==b&&(mh(b,a,e,d),eh(b,a,e))},enqueueForceUpdate:function(a,b){a=a._reactInternals;var c=L(),d=\nlh(a),e=ch(c,d);e.tag=2;void 0!==b&&null!==b&&(e.callback=b);b=dh(a,e,d);null!==b&&(mh(b,a,d,c),eh(b,a,d))}};function oh(a,b,c,d,e,f,g){a=a.stateNode;return\"function\"===typeof a.shouldComponentUpdate?a.shouldComponentUpdate(d,f,g):b.prototype&&b.prototype.isPureReactComponent?!Ie(c,d)||!Ie(e,f):!0}\nfunction ph(a,b,c){var d=!1,e=Vf;var f=b.contextType;\"object\"===typeof f&&null!==f?f=Vg(f):(e=Zf(b)?Xf:H.current,d=b.contextTypes,f=(d=null!==d&&void 0!==d)?Yf(a,e):Vf);b=new b(c,f);a.memoizedState=null!==b.state&&void 0!==b.state?b.state:null;b.updater=nh;a.stateNode=b;b._reactInternals=a;d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=e,a.__reactInternalMemoizedMaskedChildContext=f);return b}\nfunction qh(a,b,c,d){a=b.state;\"function\"===typeof b.componentWillReceiveProps&&b.componentWillReceiveProps(c,d);\"function\"===typeof b.UNSAFE_componentWillReceiveProps&&b.UNSAFE_componentWillReceiveProps(c,d);b.state!==a&&nh.enqueueReplaceState(b,b.state,null)}\nfunction rh(a,b,c,d){var e=a.stateNode;e.props=c;e.state=a.memoizedState;e.refs=jh;ah(a);var f=b.contextType;\"object\"===typeof f&&null!==f?e.context=Vg(f):(f=Zf(b)?Xf:H.current,e.context=Yf(a,f));e.state=a.memoizedState;f=b.getDerivedStateFromProps;\"function\"===typeof f&&(kh(a,b,f,c),e.state=a.memoizedState);\"function\"===typeof b.getDerivedStateFromProps||\"function\"===typeof e.getSnapshotBeforeUpdate||\"function\"!==typeof e.UNSAFE_componentWillMount&&\"function\"!==typeof e.componentWillMount||(b=e.state,\n\"function\"===typeof e.componentWillMount&&e.componentWillMount(),\"function\"===typeof e.UNSAFE_componentWillMount&&e.UNSAFE_componentWillMount(),b!==e.state&&nh.enqueueReplaceState(e,e.state,null),gh(a,c,e,d),e.state=a.memoizedState);\"function\"===typeof e.componentDidMount&&(a.flags|=4194308)}\nfunction sh(a,b,c){a=c.ref;if(null!==a&&\"function\"!==typeof a&&\"object\"!==typeof a){if(c._owner){c=c._owner;if(c){if(1!==c.tag)throw Error(p(309));var d=c.stateNode}if(!d)throw Error(p(147,a));var e=d,f=\"\"+a;if(null!==b&&null!==b.ref&&\"function\"===typeof b.ref&&b.ref._stringRef===f)return b.ref;b=function(a){var b=e.refs;b===jh&&(b=e.refs={});null===a?delete b[f]:b[f]=a};b._stringRef=f;return b}if(\"string\"!==typeof a)throw Error(p(284));if(!c._owner)throw Error(p(290,a));}return a}\nfunction th(a,b){a=Object.prototype.toString.call(b);throw Error(p(31,\"[object Object]\"===a?\"object with keys {\"+Object.keys(b).join(\", \")+\"}\":a));}function uh(a){var b=a._init;return b(a._payload)}\nfunction vh(a){function b(b,c){if(a){var d=b.deletions;null===d?(b.deletions=[c],b.flags|=16):d.push(c)}}function c(c,d){if(!a)return null;for(;null!==d;)b(c,d),d=d.sibling;return null}function d(a,b){for(a=new Map;null!==b;)null!==b.key?a.set(b.key,b):a.set(b.index,b),b=b.sibling;return a}function e(a,b){a=wh(a,b);a.index=0;a.sibling=null;return a}function f(b,c,d){b.index=d;if(!a)return b.flags|=1048576,c;d=b.alternate;if(null!==d)return d=d.index,d<c?(b.flags|=2,c):d;b.flags|=2;return c}function g(b){a&&\nnull===b.alternate&&(b.flags|=2);return b}function h(a,b,c,d){if(null===b||6!==b.tag)return b=xh(c,a.mode,d),b.return=a,b;b=e(b,c);b.return=a;return b}function k(a,b,c,d){var f=c.type;if(f===ya)return m(a,b,c.props.children,d,c.key);if(null!==b&&(b.elementType===f||\"object\"===typeof f&&null!==f&&f.$$typeof===Ha&&uh(f)===b.type))return d=e(b,c.props),d.ref=sh(a,b,c),d.return=a,d;d=yh(c.type,c.key,c.props,null,a.mode,d);d.ref=sh(a,b,c);d.return=a;return d}function l(a,b,c,d){if(null===b||4!==b.tag||\nb.stateNode.containerInfo!==c.containerInfo||b.stateNode.implementation!==c.implementation)return b=zh(c,a.mode,d),b.return=a,b;b=e(b,c.children||[]);b.return=a;return b}function m(a,b,c,d,f){if(null===b||7!==b.tag)return b=Ah(c,a.mode,d,f),b.return=a,b;b=e(b,c);b.return=a;return b}function q(a,b,c){if(\"string\"===typeof b&&\"\"!==b||\"number\"===typeof b)return b=xh(\"\"+b,a.mode,c),b.return=a,b;if(\"object\"===typeof b&&null!==b){switch(b.$$typeof){case va:return c=yh(b.type,b.key,b.props,null,a.mode,c),\nc.ref=sh(a,null,b),c.return=a,c;case wa:return b=zh(b,a.mode,c),b.return=a,b;case Ha:var d=b._init;return q(a,d(b._payload),c)}if(eb(b)||Ka(b))return b=Ah(b,a.mode,c,null),b.return=a,b;th(a,b)}return null}function r(a,b,c,d){var e=null!==b?b.key:null;if(\"string\"===typeof c&&\"\"!==c||\"number\"===typeof c)return null!==e?null:h(a,b,\"\"+c,d);if(\"object\"===typeof c&&null!==c){switch(c.$$typeof){case va:return c.key===e?k(a,b,c,d):null;case wa:return c.key===e?l(a,b,c,d):null;case Ha:return e=c._init,r(a,\nb,e(c._payload),d)}if(eb(c)||Ka(c))return null!==e?null:m(a,b,c,d,null);th(a,c)}return null}function y(a,b,c,d,e){if(\"string\"===typeof d&&\"\"!==d||\"number\"===typeof d)return a=a.get(c)||null,h(b,a,\"\"+d,e);if(\"object\"===typeof d&&null!==d){switch(d.$$typeof){case va:return a=a.get(null===d.key?c:d.key)||null,k(b,a,d,e);case wa:return a=a.get(null===d.key?c:d.key)||null,l(b,a,d,e);case Ha:var f=d._init;return y(a,b,c,f(d._payload),e)}if(eb(d)||Ka(d))return a=a.get(c)||null,m(b,a,d,e,null);th(b,d)}return null}\nfunction n(e,g,h,k){for(var l=null,m=null,u=g,w=g=0,x=null;null!==u&&w<h.length;w++){u.index>w?(x=u,u=null):x=u.sibling;var n=r(e,u,h[w],k);if(null===n){null===u&&(u=x);break}a&&u&&null===n.alternate&&b(e,u);g=f(n,g,w);null===m?l=n:m.sibling=n;m=n;u=x}if(w===h.length)return c(e,u),I&&tg(e,w),l;if(null===u){for(;w<h.length;w++)u=q(e,h[w],k),null!==u&&(g=f(u,g,w),null===m?l=u:m.sibling=u,m=u);I&&tg(e,w);return l}for(u=d(e,u);w<h.length;w++)x=y(u,e,w,h[w],k),null!==x&&(a&&null!==x.alternate&&u.delete(null===\nx.key?w:x.key),g=f(x,g,w),null===m?l=x:m.sibling=x,m=x);a&&u.forEach(function(a){return b(e,a)});I&&tg(e,w);return l}function t(e,g,h,k){var l=Ka(h);if(\"function\"!==typeof l)throw Error(p(150));h=l.call(h);if(null==h)throw Error(p(151));for(var u=l=null,m=g,w=g=0,x=null,n=h.next();null!==m&&!n.done;w++,n=h.next()){m.index>w?(x=m,m=null):x=m.sibling;var t=r(e,m,n.value,k);if(null===t){null===m&&(m=x);break}a&&m&&null===t.alternate&&b(e,m);g=f(t,g,w);null===u?l=t:u.sibling=t;u=t;m=x}if(n.done)return c(e,\nm),I&&tg(e,w),l;if(null===m){for(;!n.done;w++,n=h.next())n=q(e,n.value,k),null!==n&&(g=f(n,g,w),null===u?l=n:u.sibling=n,u=n);I&&tg(e,w);return l}for(m=d(e,m);!n.done;w++,n=h.next())n=y(m,e,w,n.value,k),null!==n&&(a&&null!==n.alternate&&m.delete(null===n.key?w:n.key),g=f(n,g,w),null===u?l=n:u.sibling=n,u=n);a&&m.forEach(function(a){return b(e,a)});I&&tg(e,w);return l}function J(a,d,f,h){\"object\"===typeof f&&null!==f&&f.type===ya&&null===f.key&&(f=f.props.children);if(\"object\"===typeof f&&null!==f){switch(f.$$typeof){case va:a:{for(var k=\nf.key,l=d;null!==l;){if(l.key===k){k=f.type;if(k===ya){if(7===l.tag){c(a,l.sibling);d=e(l,f.props.children);d.return=a;a=d;break a}}else if(l.elementType===k||\"object\"===typeof k&&null!==k&&k.$$typeof===Ha&&uh(k)===l.type){c(a,l.sibling);d=e(l,f.props);d.ref=sh(a,l,f);d.return=a;a=d;break a}c(a,l);break}else b(a,l);l=l.sibling}f.type===ya?(d=Ah(f.props.children,a.mode,h,f.key),d.return=a,a=d):(h=yh(f.type,f.key,f.props,null,a.mode,h),h.ref=sh(a,d,f),h.return=a,a=h)}return g(a);case wa:a:{for(l=f.key;null!==\nd;){if(d.key===l)if(4===d.tag&&d.stateNode.containerInfo===f.containerInfo&&d.stateNode.implementation===f.implementation){c(a,d.sibling);d=e(d,f.children||[]);d.return=a;a=d;break a}else{c(a,d);break}else b(a,d);d=d.sibling}d=zh(f,a.mode,h);d.return=a;a=d}return g(a);case Ha:return l=f._init,J(a,d,l(f._payload),h)}if(eb(f))return n(a,d,f,h);if(Ka(f))return t(a,d,f,h);th(a,f)}return\"string\"===typeof f&&\"\"!==f||\"number\"===typeof f?(f=\"\"+f,null!==d&&6===d.tag?(c(a,d.sibling),d=e(d,f),d.return=a,a=d):\n(c(a,d),d=xh(f,a.mode,h),d.return=a,a=d),g(a)):c(a,d)}return J}var Bh=vh(!0),Ch=vh(!1),Dh={},Eh=Uf(Dh),Fh=Uf(Dh),Gh=Uf(Dh);function Hh(a){if(a===Dh)throw Error(p(174));return a}function Ih(a,b){G(Gh,b);G(Fh,a);G(Eh,Dh);a=b.nodeType;switch(a){case 9:case 11:b=(b=b.documentElement)?b.namespaceURI:lb(null,\"\");break;default:a=8===a?b.parentNode:b,b=a.namespaceURI||null,a=a.tagName,b=lb(b,a)}E(Eh);G(Eh,b)}function Jh(){E(Eh);E(Fh);E(Gh)}\nfunction Kh(a){Hh(Gh.current);var b=Hh(Eh.current);var c=lb(b,a.type);b!==c&&(G(Fh,a),G(Eh,c))}function Lh(a){Fh.current===a&&(E(Eh),E(Fh))}var M=Uf(0);\nfunction Mh(a){for(var b=a;null!==b;){if(13===b.tag){var c=b.memoizedState;if(null!==c&&(c=c.dehydrated,null===c||\"$?\"===c.data||\"$!\"===c.data))return b}else if(19===b.tag&&void 0!==b.memoizedProps.revealOrder){if(0!==(b.flags&128))return b}else if(null!==b.child){b.child.return=b;b=b.child;continue}if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}return null}var Nh=[];\nfunction Oh(){for(var a=0;a<Nh.length;a++)Nh[a]._workInProgressVersionPrimary=null;Nh.length=0}var Ph=ua.ReactCurrentDispatcher,Qh=ua.ReactCurrentBatchConfig,Rh=0,N=null,O=null,P=null,Sh=!1,Th=!1,Uh=0,Vh=0;function Q(){throw Error(p(321));}function Wh(a,b){if(null===b)return!1;for(var c=0;c<b.length&&c<a.length;c++)if(!He(a[c],b[c]))return!1;return!0}\nfunction Xh(a,b,c,d,e,f){Rh=f;N=b;b.memoizedState=null;b.updateQueue=null;b.lanes=0;Ph.current=null===a||null===a.memoizedState?Yh:Zh;a=c(d,e);if(Th){f=0;do{Th=!1;Uh=0;if(25<=f)throw Error(p(301));f+=1;P=O=null;b.updateQueue=null;Ph.current=$h;a=c(d,e)}while(Th)}Ph.current=ai;b=null!==O&&null!==O.next;Rh=0;P=O=N=null;Sh=!1;if(b)throw Error(p(300));return a}function bi(){var a=0!==Uh;Uh=0;return a}\nfunction ci(){var a={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};null===P?N.memoizedState=P=a:P=P.next=a;return P}function di(){if(null===O){var a=N.alternate;a=null!==a?a.memoizedState:null}else a=O.next;var b=null===P?N.memoizedState:P.next;if(null!==b)P=b,O=a;else{if(null===a)throw Error(p(310));O=a;a={memoizedState:O.memoizedState,baseState:O.baseState,baseQueue:O.baseQueue,queue:O.queue,next:null};null===P?N.memoizedState=P=a:P=P.next=a}return P}\nfunction ei(a,b){return\"function\"===typeof b?b(a):b}\nfunction fi(a){var b=di(),c=b.queue;if(null===c)throw Error(p(311));c.lastRenderedReducer=a;var d=O,e=d.baseQueue,f=c.pending;if(null!==f){if(null!==e){var g=e.next;e.next=f.next;f.next=g}d.baseQueue=e=f;c.pending=null}if(null!==e){f=e.next;d=d.baseState;var h=g=null,k=null,l=f;do{var m=l.lane;if((Rh&m)===m)null!==k&&(k=k.next={lane:0,action:l.action,hasEagerState:l.hasEagerState,eagerState:l.eagerState,next:null}),d=l.hasEagerState?l.eagerState:a(d,l.action);else{var q={lane:m,action:l.action,hasEagerState:l.hasEagerState,\neagerState:l.eagerState,next:null};null===k?(h=k=q,g=d):k=k.next=q;N.lanes|=m;hh|=m}l=l.next}while(null!==l&&l!==f);null===k?g=d:k.next=h;He(d,b.memoizedState)||(Ug=!0);b.memoizedState=d;b.baseState=g;b.baseQueue=k;c.lastRenderedState=d}a=c.interleaved;if(null!==a){e=a;do f=e.lane,N.lanes|=f,hh|=f,e=e.next;while(e!==a)}else null===e&&(c.lanes=0);return[b.memoizedState,c.dispatch]}\nfunction gi(a){var b=di(),c=b.queue;if(null===c)throw Error(p(311));c.lastRenderedReducer=a;var d=c.dispatch,e=c.pending,f=b.memoizedState;if(null!==e){c.pending=null;var g=e=e.next;do f=a(f,g.action),g=g.next;while(g!==e);He(f,b.memoizedState)||(Ug=!0);b.memoizedState=f;null===b.baseQueue&&(b.baseState=f);c.lastRenderedState=f}return[f,d]}function hi(){}\nfunction ii(a,b){var c=N,d=di(),e=b(),f=!He(d.memoizedState,e);f&&(d.memoizedState=e,Ug=!0);d=d.queue;ji(ki.bind(null,c,d,a),[a]);if(d.getSnapshot!==b||f||null!==P&&P.memoizedState.tag&1){c.flags|=2048;li(9,mi.bind(null,c,d,e,b),void 0,null);if(null===R)throw Error(p(349));0!==(Rh&30)||ni(c,b,e)}return e}function ni(a,b,c){a.flags|=16384;a={getSnapshot:b,value:c};b=N.updateQueue;null===b?(b={lastEffect:null,stores:null},N.updateQueue=b,b.stores=[a]):(c=b.stores,null===c?b.stores=[a]:c.push(a))}\nfunction mi(a,b,c,d){b.value=c;b.getSnapshot=d;oi(b)&&pi(a)}function ki(a,b,c){return c(function(){oi(b)&&pi(a)})}function oi(a){var b=a.getSnapshot;a=a.value;try{var c=b();return!He(a,c)}catch(d){return!0}}function pi(a){var b=Zg(a,1);null!==b&&mh(b,a,1,-1)}\nfunction qi(a){var b=ci();\"function\"===typeof a&&(a=a());b.memoizedState=b.baseState=a;a={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:ei,lastRenderedState:a};b.queue=a;a=a.dispatch=ri.bind(null,N,a);return[b.memoizedState,a]}\nfunction li(a,b,c,d){a={tag:a,create:b,destroy:c,deps:d,next:null};b=N.updateQueue;null===b?(b={lastEffect:null,stores:null},N.updateQueue=b,b.lastEffect=a.next=a):(c=b.lastEffect,null===c?b.lastEffect=a.next=a:(d=c.next,c.next=a,a.next=d,b.lastEffect=a));return a}function si(){return di().memoizedState}function ti(a,b,c,d){var e=ci();N.flags|=a;e.memoizedState=li(1|b,c,void 0,void 0===d?null:d)}\nfunction ui(a,b,c,d){var e=di();d=void 0===d?null:d;var f=void 0;if(null!==O){var g=O.memoizedState;f=g.destroy;if(null!==d&&Wh(d,g.deps)){e.memoizedState=li(b,c,f,d);return}}N.flags|=a;e.memoizedState=li(1|b,c,f,d)}function vi(a,b){return ti(8390656,8,a,b)}function ji(a,b){return ui(2048,8,a,b)}function wi(a,b){return ui(4,2,a,b)}function xi(a,b){return ui(4,4,a,b)}\nfunction yi(a,b){if(\"function\"===typeof b)return a=a(),b(a),function(){b(null)};if(null!==b&&void 0!==b)return a=a(),b.current=a,function(){b.current=null}}function zi(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ui(4,4,yi.bind(null,b,a),c)}function Ai(){}function Bi(a,b){var c=di();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&Wh(b,d[1]))return d[0];c.memoizedState=[a,b];return a}\nfunction Ci(a,b){var c=di();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&Wh(b,d[1]))return d[0];a=a();c.memoizedState=[a,b];return a}function Di(a,b,c){if(0===(Rh&21))return a.baseState&&(a.baseState=!1,Ug=!0),a.memoizedState=c;He(c,b)||(c=yc(),N.lanes|=c,hh|=c,a.baseState=!0);return b}function Ei(a,b){var c=C;C=0!==c&&4>c?c:4;a(!0);var d=Qh.transition;Qh.transition={};try{a(!1),b()}finally{C=c,Qh.transition=d}}function Fi(){return di().memoizedState}\nfunction Gi(a,b,c){var d=lh(a);c={lane:d,action:c,hasEagerState:!1,eagerState:null,next:null};if(Hi(a))Ii(b,c);else if(c=Yg(a,b,c,d),null!==c){var e=L();mh(c,a,d,e);Ji(c,b,d)}}\nfunction ri(a,b,c){var d=lh(a),e={lane:d,action:c,hasEagerState:!1,eagerState:null,next:null};if(Hi(a))Ii(b,e);else{var f=a.alternate;if(0===a.lanes&&(null===f||0===f.lanes)&&(f=b.lastRenderedReducer,null!==f))try{var g=b.lastRenderedState,h=f(g,c);e.hasEagerState=!0;e.eagerState=h;if(He(h,g)){var k=b.interleaved;null===k?(e.next=e,Xg(b)):(e.next=k.next,k.next=e);b.interleaved=e;return}}catch(l){}finally{}c=Yg(a,b,e,d);null!==c&&(e=L(),mh(c,a,d,e),Ji(c,b,d))}}\nfunction Hi(a){var b=a.alternate;return a===N||null!==b&&b===N}function Ii(a,b){Th=Sh=!0;var c=a.pending;null===c?b.next=b:(b.next=c.next,c.next=b);a.pending=b}function Ji(a,b,c){if(0!==(c&4194240)){var d=b.lanes;d&=a.pendingLanes;c|=d;b.lanes=c;Cc(a,c)}}\nvar ai={readContext:Vg,useCallback:Q,useContext:Q,useEffect:Q,useImperativeHandle:Q,useInsertionEffect:Q,useLayoutEffect:Q,useMemo:Q,useReducer:Q,useRef:Q,useState:Q,useDebugValue:Q,useDeferredValue:Q,useTransition:Q,useMutableSource:Q,useSyncExternalStore:Q,useId:Q,unstable_isNewReconciler:!1},Yh={readContext:Vg,useCallback:function(a,b){ci().memoizedState=[a,void 0===b?null:b];return a},useContext:Vg,useEffect:vi,useImperativeHandle:function(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ti(4194308,\n4,yi.bind(null,b,a),c)},useLayoutEffect:function(a,b){return ti(4194308,4,a,b)},useInsertionEffect:function(a,b){return ti(4,2,a,b)},useMemo:function(a,b){var c=ci();b=void 0===b?null:b;a=a();c.memoizedState=[a,b];return a},useReducer:function(a,b,c){var d=ci();b=void 0!==c?c(b):b;d.memoizedState=d.baseState=b;a={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:a,lastRenderedState:b};d.queue=a;a=a.dispatch=Gi.bind(null,N,a);return[d.memoizedState,a]},useRef:function(a){var b=\nci();a={current:a};return b.memoizedState=a},useState:qi,useDebugValue:Ai,useDeferredValue:function(a){return ci().memoizedState=a},useTransition:function(){var a=qi(!1),b=a[0];a=Ei.bind(null,a[1]);ci().memoizedState=a;return[b,a]},useMutableSource:function(){},useSyncExternalStore:function(a,b,c){var d=N,e=ci();if(I){if(void 0===c)throw Error(p(407));c=c()}else{c=b();if(null===R)throw Error(p(349));0!==(Rh&30)||ni(d,b,c)}e.memoizedState=c;var f={value:c,getSnapshot:b};e.queue=f;vi(ki.bind(null,d,\nf,a),[a]);d.flags|=2048;li(9,mi.bind(null,d,f,c,b),void 0,null);return c},useId:function(){var a=ci(),b=R.identifierPrefix;if(I){var c=sg;var d=rg;c=(d&~(1<<32-oc(d)-1)).toString(32)+c;b=\":\"+b+\"R\"+c;c=Uh++;0<c&&(b+=\"H\"+c.toString(32));b+=\":\"}else c=Vh++,b=\":\"+b+\"r\"+c.toString(32)+\":\";return a.memoizedState=b},unstable_isNewReconciler:!1},Zh={readContext:Vg,useCallback:Bi,useContext:Vg,useEffect:ji,useImperativeHandle:zi,useInsertionEffect:wi,useLayoutEffect:xi,useMemo:Ci,useReducer:fi,useRef:si,useState:function(){return fi(ei)},\nuseDebugValue:Ai,useDeferredValue:function(a){var b=di();return Di(b,O.memoizedState,a)},useTransition:function(){var a=fi(ei)[0],b=di().memoizedState;return[a,b]},useMutableSource:hi,useSyncExternalStore:ii,useId:Fi,unstable_isNewReconciler:!1},$h={readContext:Vg,useCallback:Bi,useContext:Vg,useEffect:ji,useImperativeHandle:zi,useInsertionEffect:wi,useLayoutEffect:xi,useMemo:Ci,useReducer:gi,useRef:si,useState:function(){return gi(ei)},useDebugValue:Ai,useDeferredValue:function(a){var b=di();return null===\nO?b.memoizedState=a:Di(b,O.memoizedState,a)},useTransition:function(){var a=gi(ei)[0],b=di().memoizedState;return[a,b]},useMutableSource:hi,useSyncExternalStore:ii,useId:Fi,unstable_isNewReconciler:!1};function Ki(a,b){try{var c=\"\",d=b;do c+=Pa(d),d=d.return;while(d);var e=c}catch(f){e=\"\\nError generating stack: \"+f.message+\"\\n\"+f.stack}return{value:a,source:b,stack:e,digest:null}}function Li(a,b,c){return{value:a,source:null,stack:null!=c?c:null,digest:null!=b?b:null}}\nfunction Mi(a,b){try{console.error(b.value)}catch(c){setTimeout(function(){throw c;})}}var Ni=\"function\"===typeof WeakMap?WeakMap:Map;function Oi(a,b,c){c=ch(-1,c);c.tag=3;c.payload={element:null};var d=b.value;c.callback=function(){Pi||(Pi=!0,Qi=d);Mi(a,b)};return c}\nfunction Ri(a,b,c){c=ch(-1,c);c.tag=3;var d=a.type.getDerivedStateFromError;if(\"function\"===typeof d){var e=b.value;c.payload=function(){return d(e)};c.callback=function(){Mi(a,b)}}var f=a.stateNode;null!==f&&\"function\"===typeof f.componentDidCatch&&(c.callback=function(){Mi(a,b);\"function\"!==typeof d&&(null===Si?Si=new Set([this]):Si.add(this));var c=b.stack;this.componentDidCatch(b.value,{componentStack:null!==c?c:\"\"})});return c}\nfunction Ti(a,b,c){var d=a.pingCache;if(null===d){d=a.pingCache=new Ni;var e=new Set;d.set(b,e)}else e=d.get(b),void 0===e&&(e=new Set,d.set(b,e));e.has(c)||(e.add(c),a=Ui.bind(null,a,b,c),b.then(a,a))}function Vi(a){do{var b;if(b=13===a.tag)b=a.memoizedState,b=null!==b?null!==b.dehydrated?!0:!1:!0;if(b)return a;a=a.return}while(null!==a);return null}\nfunction Wi(a,b,c,d,e){if(0===(a.mode&1))return a===b?a.flags|=65536:(a.flags|=128,c.flags|=131072,c.flags&=-52805,1===c.tag&&(null===c.alternate?c.tag=17:(b=ch(-1,1),b.tag=2,dh(c,b,1))),c.lanes|=1),a;a.flags|=65536;a.lanes=e;return a}var Xi=ua.ReactCurrentOwner,Ug=!1;function Yi(a,b,c,d){b.child=null===a?Ch(b,null,c,d):Bh(b,a.child,c,d)}\nfunction Zi(a,b,c,d,e){c=c.render;var f=b.ref;Tg(b,e);d=Xh(a,b,c,d,f,e);c=bi();if(null!==a&&!Ug)return b.updateQueue=a.updateQueue,b.flags&=-2053,a.lanes&=~e,$i(a,b,e);I&&c&&vg(b);b.flags|=1;Yi(a,b,d,e);return b.child}\nfunction aj(a,b,c,d,e){if(null===a){var f=c.type;if(\"function\"===typeof f&&!bj(f)&&void 0===f.defaultProps&&null===c.compare&&void 0===c.defaultProps)return b.tag=15,b.type=f,cj(a,b,f,d,e);a=yh(c.type,null,d,b,b.mode,e);a.ref=b.ref;a.return=b;return b.child=a}f=a.child;if(0===(a.lanes&e)){var g=f.memoizedProps;c=c.compare;c=null!==c?c:Ie;if(c(g,d)&&a.ref===b.ref)return $i(a,b,e)}b.flags|=1;a=wh(f,d);a.ref=b.ref;a.return=b;return b.child=a}\nfunction cj(a,b,c,d,e){if(null!==a){var f=a.memoizedProps;if(Ie(f,d)&&a.ref===b.ref)if(Ug=!1,b.pendingProps=d=f,0!==(a.lanes&e))0!==(a.flags&131072)&&(Ug=!0);else return b.lanes=a.lanes,$i(a,b,e)}return dj(a,b,c,d,e)}\nfunction ej(a,b,c){var d=b.pendingProps,e=d.children,f=null!==a?a.memoizedState:null;if(\"hidden\"===d.mode)if(0===(b.mode&1))b.memoizedState={baseLanes:0,cachePool:null,transitions:null},G(fj,gj),gj|=c;else{if(0===(c&1073741824))return a=null!==f?f.baseLanes|c:c,b.lanes=b.childLanes=1073741824,b.memoizedState={baseLanes:a,cachePool:null,transitions:null},b.updateQueue=null,G(fj,gj),gj|=a,null;b.memoizedState={baseLanes:0,cachePool:null,transitions:null};d=null!==f?f.baseLanes:c;G(fj,gj);gj|=d}else null!==\nf?(d=f.baseLanes|c,b.memoizedState=null):d=c,G(fj,gj),gj|=d;Yi(a,b,e,c);return b.child}function hj(a,b){var c=b.ref;if(null===a&&null!==c||null!==a&&a.ref!==c)b.flags|=512,b.flags|=2097152}function dj(a,b,c,d,e){var f=Zf(c)?Xf:H.current;f=Yf(b,f);Tg(b,e);c=Xh(a,b,c,d,f,e);d=bi();if(null!==a&&!Ug)return b.updateQueue=a.updateQueue,b.flags&=-2053,a.lanes&=~e,$i(a,b,e);I&&d&&vg(b);b.flags|=1;Yi(a,b,c,e);return b.child}\nfunction ij(a,b,c,d,e){if(Zf(c)){var f=!0;cg(b)}else f=!1;Tg(b,e);if(null===b.stateNode)jj(a,b),ph(b,c,d),rh(b,c,d,e),d=!0;else if(null===a){var g=b.stateNode,h=b.memoizedProps;g.props=h;var k=g.context,l=c.contextType;\"object\"===typeof l&&null!==l?l=Vg(l):(l=Zf(c)?Xf:H.current,l=Yf(b,l));var m=c.getDerivedStateFromProps,q=\"function\"===typeof m||\"function\"===typeof g.getSnapshotBeforeUpdate;q||\"function\"!==typeof g.UNSAFE_componentWillReceiveProps&&\"function\"!==typeof g.componentWillReceiveProps||\n(h!==d||k!==l)&&qh(b,g,d,l);$g=!1;var r=b.memoizedState;g.state=r;gh(b,d,g,e);k=b.memoizedState;h!==d||r!==k||Wf.current||$g?(\"function\"===typeof m&&(kh(b,c,m,d),k=b.memoizedState),(h=$g||oh(b,c,h,d,r,k,l))?(q||\"function\"!==typeof g.UNSAFE_componentWillMount&&\"function\"!==typeof g.componentWillMount||(\"function\"===typeof g.componentWillMount&&g.componentWillMount(),\"function\"===typeof g.UNSAFE_componentWillMount&&g.UNSAFE_componentWillMount()),\"function\"===typeof g.componentDidMount&&(b.flags|=4194308)):\n(\"function\"===typeof g.componentDidMount&&(b.flags|=4194308),b.memoizedProps=d,b.memoizedState=k),g.props=d,g.state=k,g.context=l,d=h):(\"function\"===typeof g.componentDidMount&&(b.flags|=4194308),d=!1)}else{g=b.stateNode;bh(a,b);h=b.memoizedProps;l=b.type===b.elementType?h:Lg(b.type,h);g.props=l;q=b.pendingProps;r=g.context;k=c.contextType;\"object\"===typeof k&&null!==k?k=Vg(k):(k=Zf(c)?Xf:H.current,k=Yf(b,k));var y=c.getDerivedStateFromProps;(m=\"function\"===typeof y||\"function\"===typeof g.getSnapshotBeforeUpdate)||\n\"function\"!==typeof g.UNSAFE_componentWillReceiveProps&&\"function\"!==typeof g.componentWillReceiveProps||(h!==q||r!==k)&&qh(b,g,d,k);$g=!1;r=b.memoizedState;g.state=r;gh(b,d,g,e);var n=b.memoizedState;h!==q||r!==n||Wf.current||$g?(\"function\"===typeof y&&(kh(b,c,y,d),n=b.memoizedState),(l=$g||oh(b,c,l,d,r,n,k)||!1)?(m||\"function\"!==typeof g.UNSAFE_componentWillUpdate&&\"function\"!==typeof g.componentWillUpdate||(\"function\"===typeof g.componentWillUpdate&&g.componentWillUpdate(d,n,k),\"function\"===typeof g.UNSAFE_componentWillUpdate&&\ng.UNSAFE_componentWillUpdate(d,n,k)),\"function\"===typeof g.componentDidUpdate&&(b.flags|=4),\"function\"===typeof g.getSnapshotBeforeUpdate&&(b.flags|=1024)):(\"function\"!==typeof g.componentDidUpdate||h===a.memoizedProps&&r===a.memoizedState||(b.flags|=4),\"function\"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&r===a.memoizedState||(b.flags|=1024),b.memoizedProps=d,b.memoizedState=n),g.props=d,g.state=n,g.context=k,d=l):(\"function\"!==typeof g.componentDidUpdate||h===a.memoizedProps&&r===\na.memoizedState||(b.flags|=4),\"function\"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&r===a.memoizedState||(b.flags|=1024),d=!1)}return kj(a,b,c,d,f,e)}\nfunction kj(a,b,c,d,e,f){hj(a,b);var g=0!==(b.flags&128);if(!d&&!g)return e&&dg(b,c,!1),$i(a,b,f);d=b.stateNode;Xi.current=b;var h=g&&\"function\"!==typeof c.getDerivedStateFromError?null:d.render();b.flags|=1;null!==a&&g?(b.child=Bh(b,a.child,null,f),b.child=Bh(b,null,h,f)):Yi(a,b,h,f);b.memoizedState=d.state;e&&dg(b,c,!0);return b.child}function lj(a){var b=a.stateNode;b.pendingContext?ag(a,b.pendingContext,b.pendingContext!==b.context):b.context&&ag(a,b.context,!1);Ih(a,b.containerInfo)}\nfunction mj(a,b,c,d,e){Ig();Jg(e);b.flags|=256;Yi(a,b,c,d);return b.child}var nj={dehydrated:null,treeContext:null,retryLane:0};function oj(a){return{baseLanes:a,cachePool:null,transitions:null}}\nfunction pj(a,b,c){var d=b.pendingProps,e=M.current,f=!1,g=0!==(b.flags&128),h;(h=g)||(h=null!==a&&null===a.memoizedState?!1:0!==(e&2));if(h)f=!0,b.flags&=-129;else if(null===a||null!==a.memoizedState)e|=1;G(M,e&1);if(null===a){Eg(b);a=b.memoizedState;if(null!==a&&(a=a.dehydrated,null!==a))return 0===(b.mode&1)?b.lanes=1:\"$!\"===a.data?b.lanes=8:b.lanes=1073741824,null;g=d.children;a=d.fallback;return f?(d=b.mode,f=b.child,g={mode:\"hidden\",children:g},0===(d&1)&&null!==f?(f.childLanes=0,f.pendingProps=\ng):f=qj(g,d,0,null),a=Ah(a,d,c,null),f.return=b,a.return=b,f.sibling=a,b.child=f,b.child.memoizedState=oj(c),b.memoizedState=nj,a):rj(b,g)}e=a.memoizedState;if(null!==e&&(h=e.dehydrated,null!==h))return sj(a,b,g,d,h,e,c);if(f){f=d.fallback;g=b.mode;e=a.child;h=e.sibling;var k={mode:\"hidden\",children:d.children};0===(g&1)&&b.child!==e?(d=b.child,d.childLanes=0,d.pendingProps=k,b.deletions=null):(d=wh(e,k),d.subtreeFlags=e.subtreeFlags&14680064);null!==h?f=wh(h,f):(f=Ah(f,g,c,null),f.flags|=2);f.return=\nb;d.return=b;d.sibling=f;b.child=d;d=f;f=b.child;g=a.child.memoizedState;g=null===g?oj(c):{baseLanes:g.baseLanes|c,cachePool:null,transitions:g.transitions};f.memoizedState=g;f.childLanes=a.childLanes&~c;b.memoizedState=nj;return d}f=a.child;a=f.sibling;d=wh(f,{mode:\"visible\",children:d.children});0===(b.mode&1)&&(d.lanes=c);d.return=b;d.sibling=null;null!==a&&(c=b.deletions,null===c?(b.deletions=[a],b.flags|=16):c.push(a));b.child=d;b.memoizedState=null;return d}\nfunction rj(a,b){b=qj({mode:\"visible\",children:b},a.mode,0,null);b.return=a;return a.child=b}function tj(a,b,c,d){null!==d&&Jg(d);Bh(b,a.child,null,c);a=rj(b,b.pendingProps.children);a.flags|=2;b.memoizedState=null;return a}\nfunction sj(a,b,c,d,e,f,g){if(c){if(b.flags&256)return b.flags&=-257,d=Li(Error(p(422))),tj(a,b,g,d);if(null!==b.memoizedState)return b.child=a.child,b.flags|=128,null;f=d.fallback;e=b.mode;d=qj({mode:\"visible\",children:d.children},e,0,null);f=Ah(f,e,g,null);f.flags|=2;d.return=b;f.return=b;d.sibling=f;b.child=d;0!==(b.mode&1)&&Bh(b,a.child,null,g);b.child.memoizedState=oj(g);b.memoizedState=nj;return f}if(0===(b.mode&1))return tj(a,b,g,null);if(\"$!\"===e.data){d=e.nextSibling&&e.nextSibling.dataset;\nif(d)var h=d.dgst;d=h;f=Error(p(419));d=Li(f,d,void 0);return tj(a,b,g,d)}h=0!==(g&a.childLanes);if(Ug||h){d=R;if(null!==d){switch(g&-g){case 4:e=2;break;case 16:e=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:e=32;break;case 536870912:e=268435456;break;default:e=0}e=0!==(e&(d.suspendedLanes|g))?0:e;\n0!==e&&e!==f.retryLane&&(f.retryLane=e,Zg(a,e),mh(d,a,e,-1))}uj();d=Li(Error(p(421)));return tj(a,b,g,d)}if(\"$?\"===e.data)return b.flags|=128,b.child=a.child,b=vj.bind(null,a),e._reactRetry=b,null;a=f.treeContext;yg=Lf(e.nextSibling);xg=b;I=!0;zg=null;null!==a&&(og[pg++]=rg,og[pg++]=sg,og[pg++]=qg,rg=a.id,sg=a.overflow,qg=b);b=rj(b,d.children);b.flags|=4096;return b}function wj(a,b,c){a.lanes|=b;var d=a.alternate;null!==d&&(d.lanes|=b);Sg(a.return,b,c)}\nfunction xj(a,b,c,d,e){var f=a.memoizedState;null===f?a.memoizedState={isBackwards:b,rendering:null,renderingStartTime:0,last:d,tail:c,tailMode:e}:(f.isBackwards=b,f.rendering=null,f.renderingStartTime=0,f.last=d,f.tail=c,f.tailMode=e)}\nfunction yj(a,b,c){var d=b.pendingProps,e=d.revealOrder,f=d.tail;Yi(a,b,d.children,c);d=M.current;if(0!==(d&2))d=d&1|2,b.flags|=128;else{if(null!==a&&0!==(a.flags&128))a:for(a=b.child;null!==a;){if(13===a.tag)null!==a.memoizedState&&wj(a,c,b);else if(19===a.tag)wj(a,c,b);else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===b)break a;for(;null===a.sibling;){if(null===a.return||a.return===b)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}d&=1}G(M,d);if(0===(b.mode&1))b.memoizedState=\nnull;else switch(e){case \"forwards\":c=b.child;for(e=null;null!==c;)a=c.alternate,null!==a&&null===Mh(a)&&(e=c),c=c.sibling;c=e;null===c?(e=b.child,b.child=null):(e=c.sibling,c.sibling=null);xj(b,!1,e,c,f);break;case \"backwards\":c=null;e=b.child;for(b.child=null;null!==e;){a=e.alternate;if(null!==a&&null===Mh(a)){b.child=e;break}a=e.sibling;e.sibling=c;c=e;e=a}xj(b,!0,c,null,f);break;case \"together\":xj(b,!1,null,null,void 0);break;default:b.memoizedState=null}return b.child}\nfunction jj(a,b){0===(b.mode&1)&&null!==a&&(a.alternate=null,b.alternate=null,b.flags|=2)}function $i(a,b,c){null!==a&&(b.dependencies=a.dependencies);hh|=b.lanes;if(0===(c&b.childLanes))return null;if(null!==a&&b.child!==a.child)throw Error(p(153));if(null!==b.child){a=b.child;c=wh(a,a.pendingProps);b.child=c;for(c.return=b;null!==a.sibling;)a=a.sibling,c=c.sibling=wh(a,a.pendingProps),c.return=b;c.sibling=null}return b.child}\nfunction zj(a,b,c){switch(b.tag){case 3:lj(b);Ig();break;case 5:Kh(b);break;case 1:Zf(b.type)&&cg(b);break;case 4:Ih(b,b.stateNode.containerInfo);break;case 10:var d=b.type._context,e=b.memoizedProps.value;G(Mg,d._currentValue);d._currentValue=e;break;case 13:d=b.memoizedState;if(null!==d){if(null!==d.dehydrated)return G(M,M.current&1),b.flags|=128,null;if(0!==(c&b.child.childLanes))return pj(a,b,c);G(M,M.current&1);a=$i(a,b,c);return null!==a?a.sibling:null}G(M,M.current&1);break;case 19:d=0!==(c&\nb.childLanes);if(0!==(a.flags&128)){if(d)return yj(a,b,c);b.flags|=128}e=b.memoizedState;null!==e&&(e.rendering=null,e.tail=null,e.lastEffect=null);G(M,M.current);if(d)break;else return null;case 22:case 23:return b.lanes=0,ej(a,b,c)}return $i(a,b,c)}var Aj,Bj,Cj,Dj;\nAj=function(a,b){for(var c=b.child;null!==c;){if(5===c.tag||6===c.tag)a.appendChild(c.stateNode);else if(4!==c.tag&&null!==c.child){c.child.return=c;c=c.child;continue}if(c===b)break;for(;null===c.sibling;){if(null===c.return||c.return===b)return;c=c.return}c.sibling.return=c.return;c=c.sibling}};Bj=function(){};\nCj=function(a,b,c,d){var e=a.memoizedProps;if(e!==d){a=b.stateNode;Hh(Eh.current);var f=null;switch(c){case \"input\":e=Ya(a,e);d=Ya(a,d);f=[];break;case \"select\":e=A({},e,{value:void 0});d=A({},d,{value:void 0});f=[];break;case \"textarea\":e=gb(a,e);d=gb(a,d);f=[];break;default:\"function\"!==typeof e.onClick&&\"function\"===typeof d.onClick&&(a.onclick=Bf)}ub(c,d);var g;c=null;for(l in e)if(!d.hasOwnProperty(l)&&e.hasOwnProperty(l)&&null!=e[l])if(\"style\"===l){var h=e[l];for(g in h)h.hasOwnProperty(g)&&\n(c||(c={}),c[g]=\"\")}else\"dangerouslySetInnerHTML\"!==l&&\"children\"!==l&&\"suppressContentEditableWarning\"!==l&&\"suppressHydrationWarning\"!==l&&\"autoFocus\"!==l&&(ea.hasOwnProperty(l)?f||(f=[]):(f=f||[]).push(l,null));for(l in d){var k=d[l];h=null!=e?e[l]:void 0;if(d.hasOwnProperty(l)&&k!==h&&(null!=k||null!=h))if(\"style\"===l)if(h){for(g in h)!h.hasOwnProperty(g)||k&&k.hasOwnProperty(g)||(c||(c={}),c[g]=\"\");for(g in k)k.hasOwnProperty(g)&&h[g]!==k[g]&&(c||(c={}),c[g]=k[g])}else c||(f||(f=[]),f.push(l,\nc)),c=k;else\"dangerouslySetInnerHTML\"===l?(k=k?k.__html:void 0,h=h?h.__html:void 0,null!=k&&h!==k&&(f=f||[]).push(l,k)):\"children\"===l?\"string\"!==typeof k&&\"number\"!==typeof k||(f=f||[]).push(l,\"\"+k):\"suppressContentEditableWarning\"!==l&&\"suppressHydrationWarning\"!==l&&(ea.hasOwnProperty(l)?(null!=k&&\"onScroll\"===l&&D(\"scroll\",a),f||h===k||(f=[])):(f=f||[]).push(l,k))}c&&(f=f||[]).push(\"style\",c);var l=f;if(b.updateQueue=l)b.flags|=4}};Dj=function(a,b,c,d){c!==d&&(b.flags|=4)};\nfunction Ej(a,b){if(!I)switch(a.tailMode){case \"hidden\":b=a.tail;for(var c=null;null!==b;)null!==b.alternate&&(c=b),b=b.sibling;null===c?a.tail=null:c.sibling=null;break;case \"collapsed\":c=a.tail;for(var d=null;null!==c;)null!==c.alternate&&(d=c),c=c.sibling;null===d?b||null===a.tail?a.tail=null:a.tail.sibling=null:d.sibling=null}}\nfunction S(a){var b=null!==a.alternate&&a.alternate.child===a.child,c=0,d=0;if(b)for(var e=a.child;null!==e;)c|=e.lanes|e.childLanes,d|=e.subtreeFlags&14680064,d|=e.flags&14680064,e.return=a,e=e.sibling;else for(e=a.child;null!==e;)c|=e.lanes|e.childLanes,d|=e.subtreeFlags,d|=e.flags,e.return=a,e=e.sibling;a.subtreeFlags|=d;a.childLanes=c;return b}\nfunction Fj(a,b,c){var d=b.pendingProps;wg(b);switch(b.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return S(b),null;case 1:return Zf(b.type)&&$f(),S(b),null;case 3:d=b.stateNode;Jh();E(Wf);E(H);Oh();d.pendingContext&&(d.context=d.pendingContext,d.pendingContext=null);if(null===a||null===a.child)Gg(b)?b.flags|=4:null===a||a.memoizedState.isDehydrated&&0===(b.flags&256)||(b.flags|=1024,null!==zg&&(Gj(zg),zg=null));Bj(a,b);S(b);return null;case 5:Lh(b);var e=Hh(Gh.current);\nc=b.type;if(null!==a&&null!=b.stateNode)Cj(a,b,c,d,e),a.ref!==b.ref&&(b.flags|=512,b.flags|=2097152);else{if(!d){if(null===b.stateNode)throw Error(p(166));S(b);return null}a=Hh(Eh.current);if(Gg(b)){d=b.stateNode;c=b.type;var f=b.memoizedProps;d[Of]=b;d[Pf]=f;a=0!==(b.mode&1);switch(c){case \"dialog\":D(\"cancel\",d);D(\"close\",d);break;case \"iframe\":case \"object\":case \"embed\":D(\"load\",d);break;case \"video\":case \"audio\":for(e=0;e<lf.length;e++)D(lf[e],d);break;case \"source\":D(\"error\",d);break;case \"img\":case \"image\":case \"link\":D(\"error\",\nd);D(\"load\",d);break;case \"details\":D(\"toggle\",d);break;case \"input\":Za(d,f);D(\"invalid\",d);break;case \"select\":d._wrapperState={wasMultiple:!!f.multiple};D(\"invalid\",d);break;case \"textarea\":hb(d,f),D(\"invalid\",d)}ub(c,f);e=null;for(var g in f)if(f.hasOwnProperty(g)){var h=f[g];\"children\"===g?\"string\"===typeof h?d.textContent!==h&&(!0!==f.suppressHydrationWarning&&Af(d.textContent,h,a),e=[\"children\",h]):\"number\"===typeof h&&d.textContent!==\"\"+h&&(!0!==f.suppressHydrationWarning&&Af(d.textContent,\nh,a),e=[\"children\",\"\"+h]):ea.hasOwnProperty(g)&&null!=h&&\"onScroll\"===g&&D(\"scroll\",d)}switch(c){case \"input\":Va(d);db(d,f,!0);break;case \"textarea\":Va(d);jb(d);break;case \"select\":case \"option\":break;default:\"function\"===typeof f.onClick&&(d.onclick=Bf)}d=e;b.updateQueue=d;null!==d&&(b.flags|=4)}else{g=9===e.nodeType?e:e.ownerDocument;\"http://www.w3.org/1999/xhtml\"===a&&(a=kb(c));\"http://www.w3.org/1999/xhtml\"===a?\"script\"===c?(a=g.createElement(\"div\"),a.innerHTML=\"<script>\\x3c/script>\",a=a.removeChild(a.firstChild)):\n\"string\"===typeof d.is?a=g.createElement(c,{is:d.is}):(a=g.createElement(c),\"select\"===c&&(g=a,d.multiple?g.multiple=!0:d.size&&(g.size=d.size))):a=g.createElementNS(a,c);a[Of]=b;a[Pf]=d;Aj(a,b,!1,!1);b.stateNode=a;a:{g=vb(c,d);switch(c){case \"dialog\":D(\"cancel\",a);D(\"close\",a);e=d;break;case \"iframe\":case \"object\":case \"embed\":D(\"load\",a);e=d;break;case \"video\":case \"audio\":for(e=0;e<lf.length;e++)D(lf[e],a);e=d;break;case \"source\":D(\"error\",a);e=d;break;case \"img\":case \"image\":case \"link\":D(\"error\",\na);D(\"load\",a);e=d;break;case \"details\":D(\"toggle\",a);e=d;break;case \"input\":Za(a,d);e=Ya(a,d);D(\"invalid\",a);break;case \"option\":e=d;break;case \"select\":a._wrapperState={wasMultiple:!!d.multiple};e=A({},d,{value:void 0});D(\"invalid\",a);break;case \"textarea\":hb(a,d);e=gb(a,d);D(\"invalid\",a);break;default:e=d}ub(c,e);h=e;for(f in h)if(h.hasOwnProperty(f)){var k=h[f];\"style\"===f?sb(a,k):\"dangerouslySetInnerHTML\"===f?(k=k?k.__html:void 0,null!=k&&nb(a,k)):\"children\"===f?\"string\"===typeof k?(\"textarea\"!==\nc||\"\"!==k)&&ob(a,k):\"number\"===typeof k&&ob(a,\"\"+k):\"suppressContentEditableWarning\"!==f&&\"suppressHydrationWarning\"!==f&&\"autoFocus\"!==f&&(ea.hasOwnProperty(f)?null!=k&&\"onScroll\"===f&&D(\"scroll\",a):null!=k&&ta(a,f,k,g))}switch(c){case \"input\":Va(a);db(a,d,!1);break;case \"textarea\":Va(a);jb(a);break;case \"option\":null!=d.value&&a.setAttribute(\"value\",\"\"+Sa(d.value));break;case \"select\":a.multiple=!!d.multiple;f=d.value;null!=f?fb(a,!!d.multiple,f,!1):null!=d.defaultValue&&fb(a,!!d.multiple,d.defaultValue,\n!0);break;default:\"function\"===typeof e.onClick&&(a.onclick=Bf)}switch(c){case \"button\":case \"input\":case \"select\":case \"textarea\":d=!!d.autoFocus;break a;case \"img\":d=!0;break a;default:d=!1}}d&&(b.flags|=4)}null!==b.ref&&(b.flags|=512,b.flags|=2097152)}S(b);return null;case 6:if(a&&null!=b.stateNode)Dj(a,b,a.memoizedProps,d);else{if(\"string\"!==typeof d&&null===b.stateNode)throw Error(p(166));c=Hh(Gh.current);Hh(Eh.current);if(Gg(b)){d=b.stateNode;c=b.memoizedProps;d[Of]=b;if(f=d.nodeValue!==c)if(a=\nxg,null!==a)switch(a.tag){case 3:Af(d.nodeValue,c,0!==(a.mode&1));break;case 5:!0!==a.memoizedProps.suppressHydrationWarning&&Af(d.nodeValue,c,0!==(a.mode&1))}f&&(b.flags|=4)}else d=(9===c.nodeType?c:c.ownerDocument).createTextNode(d),d[Of]=b,b.stateNode=d}S(b);return null;case 13:E(M);d=b.memoizedState;if(null===a||null!==a.memoizedState&&null!==a.memoizedState.dehydrated){if(I&&null!==yg&&0!==(b.mode&1)&&0===(b.flags&128))Hg(),Ig(),b.flags|=98560,f=!1;else if(f=Gg(b),null!==d&&null!==d.dehydrated){if(null===\na){if(!f)throw Error(p(318));f=b.memoizedState;f=null!==f?f.dehydrated:null;if(!f)throw Error(p(317));f[Of]=b}else Ig(),0===(b.flags&128)&&(b.memoizedState=null),b.flags|=4;S(b);f=!1}else null!==zg&&(Gj(zg),zg=null),f=!0;if(!f)return b.flags&65536?b:null}if(0!==(b.flags&128))return b.lanes=c,b;d=null!==d;d!==(null!==a&&null!==a.memoizedState)&&d&&(b.child.flags|=8192,0!==(b.mode&1)&&(null===a||0!==(M.current&1)?0===T&&(T=3):uj()));null!==b.updateQueue&&(b.flags|=4);S(b);return null;case 4:return Jh(),\nBj(a,b),null===a&&sf(b.stateNode.containerInfo),S(b),null;case 10:return Rg(b.type._context),S(b),null;case 17:return Zf(b.type)&&$f(),S(b),null;case 19:E(M);f=b.memoizedState;if(null===f)return S(b),null;d=0!==(b.flags&128);g=f.rendering;if(null===g)if(d)Ej(f,!1);else{if(0!==T||null!==a&&0!==(a.flags&128))for(a=b.child;null!==a;){g=Mh(a);if(null!==g){b.flags|=128;Ej(f,!1);d=g.updateQueue;null!==d&&(b.updateQueue=d,b.flags|=4);b.subtreeFlags=0;d=c;for(c=b.child;null!==c;)f=c,a=d,f.flags&=14680066,\ng=f.alternate,null===g?(f.childLanes=0,f.lanes=a,f.child=null,f.subtreeFlags=0,f.memoizedProps=null,f.memoizedState=null,f.updateQueue=null,f.dependencies=null,f.stateNode=null):(f.childLanes=g.childLanes,f.lanes=g.lanes,f.child=g.child,f.subtreeFlags=0,f.deletions=null,f.memoizedProps=g.memoizedProps,f.memoizedState=g.memoizedState,f.updateQueue=g.updateQueue,f.type=g.type,a=g.dependencies,f.dependencies=null===a?null:{lanes:a.lanes,firstContext:a.firstContext}),c=c.sibling;G(M,M.current&1|2);return b.child}a=\na.sibling}null!==f.tail&&B()>Hj&&(b.flags|=128,d=!0,Ej(f,!1),b.lanes=4194304)}else{if(!d)if(a=Mh(g),null!==a){if(b.flags|=128,d=!0,c=a.updateQueue,null!==c&&(b.updateQueue=c,b.flags|=4),Ej(f,!0),null===f.tail&&\"hidden\"===f.tailMode&&!g.alternate&&!I)return S(b),null}else 2*B()-f.renderingStartTime>Hj&&1073741824!==c&&(b.flags|=128,d=!0,Ej(f,!1),b.lanes=4194304);f.isBackwards?(g.sibling=b.child,b.child=g):(c=f.last,null!==c?c.sibling=g:b.child=g,f.last=g)}if(null!==f.tail)return b=f.tail,f.rendering=\nb,f.tail=b.sibling,f.renderingStartTime=B(),b.sibling=null,c=M.current,G(M,d?c&1|2:c&1),b;S(b);return null;case 22:case 23:return Ij(),d=null!==b.memoizedState,null!==a&&null!==a.memoizedState!==d&&(b.flags|=8192),d&&0!==(b.mode&1)?0!==(gj&1073741824)&&(S(b),b.subtreeFlags&6&&(b.flags|=8192)):S(b),null;case 24:return null;case 25:return null}throw Error(p(156,b.tag));}\nfunction Jj(a,b){wg(b);switch(b.tag){case 1:return Zf(b.type)&&$f(),a=b.flags,a&65536?(b.flags=a&-65537|128,b):null;case 3:return Jh(),E(Wf),E(H),Oh(),a=b.flags,0!==(a&65536)&&0===(a&128)?(b.flags=a&-65537|128,b):null;case 5:return Lh(b),null;case 13:E(M);a=b.memoizedState;if(null!==a&&null!==a.dehydrated){if(null===b.alternate)throw Error(p(340));Ig()}a=b.flags;return a&65536?(b.flags=a&-65537|128,b):null;case 19:return E(M),null;case 4:return Jh(),null;case 10:return Rg(b.type._context),null;case 22:case 23:return Ij(),\nnull;case 24:return null;default:return null}}var Kj=!1,U=!1,Lj=\"function\"===typeof WeakSet?WeakSet:Set,V=null;function Mj(a,b){var c=a.ref;if(null!==c)if(\"function\"===typeof c)try{c(null)}catch(d){W(a,b,d)}else c.current=null}function Nj(a,b,c){try{c()}catch(d){W(a,b,d)}}var Oj=!1;\nfunction Pj(a,b){Cf=dd;a=Me();if(Ne(a)){if(\"selectionStart\"in a)var c={start:a.selectionStart,end:a.selectionEnd};else a:{c=(c=a.ownerDocument)&&c.defaultView||window;var d=c.getSelection&&c.getSelection();if(d&&0!==d.rangeCount){c=d.anchorNode;var e=d.anchorOffset,f=d.focusNode;d=d.focusOffset;try{c.nodeType,f.nodeType}catch(F){c=null;break a}var g=0,h=-1,k=-1,l=0,m=0,q=a,r=null;b:for(;;){for(var y;;){q!==c||0!==e&&3!==q.nodeType||(h=g+e);q!==f||0!==d&&3!==q.nodeType||(k=g+d);3===q.nodeType&&(g+=\nq.nodeValue.length);if(null===(y=q.firstChild))break;r=q;q=y}for(;;){if(q===a)break b;r===c&&++l===e&&(h=g);r===f&&++m===d&&(k=g);if(null!==(y=q.nextSibling))break;q=r;r=q.parentNode}q=y}c=-1===h||-1===k?null:{start:h,end:k}}else c=null}c=c||{start:0,end:0}}else c=null;Df={focusedElem:a,selectionRange:c};dd=!1;for(V=b;null!==V;)if(b=V,a=b.child,0!==(b.subtreeFlags&1028)&&null!==a)a.return=b,V=a;else for(;null!==V;){b=V;try{var n=b.alternate;if(0!==(b.flags&1024))switch(b.tag){case 0:case 11:case 15:break;\ncase 1:if(null!==n){var t=n.memoizedProps,J=n.memoizedState,x=b.stateNode,w=x.getSnapshotBeforeUpdate(b.elementType===b.type?t:Lg(b.type,t),J);x.__reactInternalSnapshotBeforeUpdate=w}break;case 3:var u=b.stateNode.containerInfo;1===u.nodeType?u.textContent=\"\":9===u.nodeType&&u.documentElement&&u.removeChild(u.documentElement);break;case 5:case 6:case 4:case 17:break;default:throw Error(p(163));}}catch(F){W(b,b.return,F)}a=b.sibling;if(null!==a){a.return=b.return;V=a;break}V=b.return}n=Oj;Oj=!1;return n}\nfunction Qj(a,b,c){var d=b.updateQueue;d=null!==d?d.lastEffect:null;if(null!==d){var e=d=d.next;do{if((e.tag&a)===a){var f=e.destroy;e.destroy=void 0;void 0!==f&&Nj(b,c,f)}e=e.next}while(e!==d)}}function Rj(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.create;c.destroy=d()}c=c.next}while(c!==b)}}function Sj(a){var b=a.ref;if(null!==b){var c=a.stateNode;switch(a.tag){case 5:a=c;break;default:a=c}\"function\"===typeof b?b(a):b.current=a}}\nfunction Tj(a){var b=a.alternate;null!==b&&(a.alternate=null,Tj(b));a.child=null;a.deletions=null;a.sibling=null;5===a.tag&&(b=a.stateNode,null!==b&&(delete b[Of],delete b[Pf],delete b[of],delete b[Qf],delete b[Rf]));a.stateNode=null;a.return=null;a.dependencies=null;a.memoizedProps=null;a.memoizedState=null;a.pendingProps=null;a.stateNode=null;a.updateQueue=null}function Uj(a){return 5===a.tag||3===a.tag||4===a.tag}\nfunction Vj(a){a:for(;;){for(;null===a.sibling;){if(null===a.return||Uj(a.return))return null;a=a.return}a.sibling.return=a.return;for(a=a.sibling;5!==a.tag&&6!==a.tag&&18!==a.tag;){if(a.flags&2)continue a;if(null===a.child||4===a.tag)continue a;else a.child.return=a,a=a.child}if(!(a.flags&2))return a.stateNode}}\nfunction Wj(a,b,c){var d=a.tag;if(5===d||6===d)a=a.stateNode,b?8===c.nodeType?c.parentNode.insertBefore(a,b):c.insertBefore(a,b):(8===c.nodeType?(b=c.parentNode,b.insertBefore(a,c)):(b=c,b.appendChild(a)),c=c._reactRootContainer,null!==c&&void 0!==c||null!==b.onclick||(b.onclick=Bf));else if(4!==d&&(a=a.child,null!==a))for(Wj(a,b,c),a=a.sibling;null!==a;)Wj(a,b,c),a=a.sibling}\nfunction Xj(a,b,c){var d=a.tag;if(5===d||6===d)a=a.stateNode,b?c.insertBefore(a,b):c.appendChild(a);else if(4!==d&&(a=a.child,null!==a))for(Xj(a,b,c),a=a.sibling;null!==a;)Xj(a,b,c),a=a.sibling}var X=null,Yj=!1;function Zj(a,b,c){for(c=c.child;null!==c;)ak(a,b,c),c=c.sibling}\nfunction ak(a,b,c){if(lc&&\"function\"===typeof lc.onCommitFiberUnmount)try{lc.onCommitFiberUnmount(kc,c)}catch(h){}switch(c.tag){case 5:U||Mj(c,b);case 6:var d=X,e=Yj;X=null;Zj(a,b,c);X=d;Yj=e;null!==X&&(Yj?(a=X,c=c.stateNode,8===a.nodeType?a.parentNode.removeChild(c):a.removeChild(c)):X.removeChild(c.stateNode));break;case 18:null!==X&&(Yj?(a=X,c=c.stateNode,8===a.nodeType?Kf(a.parentNode,c):1===a.nodeType&&Kf(a,c),bd(a)):Kf(X,c.stateNode));break;case 4:d=X;e=Yj;X=c.stateNode.containerInfo;Yj=!0;\nZj(a,b,c);X=d;Yj=e;break;case 0:case 11:case 14:case 15:if(!U&&(d=c.updateQueue,null!==d&&(d=d.lastEffect,null!==d))){e=d=d.next;do{var f=e,g=f.destroy;f=f.tag;void 0!==g&&(0!==(f&2)?Nj(c,b,g):0!==(f&4)&&Nj(c,b,g));e=e.next}while(e!==d)}Zj(a,b,c);break;case 1:if(!U&&(Mj(c,b),d=c.stateNode,\"function\"===typeof d.componentWillUnmount))try{d.props=c.memoizedProps,d.state=c.memoizedState,d.componentWillUnmount()}catch(h){W(c,b,h)}Zj(a,b,c);break;case 21:Zj(a,b,c);break;case 22:c.mode&1?(U=(d=U)||null!==\nc.memoizedState,Zj(a,b,c),U=d):Zj(a,b,c);break;default:Zj(a,b,c)}}function bk(a){var b=a.updateQueue;if(null!==b){a.updateQueue=null;var c=a.stateNode;null===c&&(c=a.stateNode=new Lj);b.forEach(function(b){var d=ck.bind(null,a,b);c.has(b)||(c.add(b),b.then(d,d))})}}\nfunction dk(a,b){var c=b.deletions;if(null!==c)for(var d=0;d<c.length;d++){var e=c[d];try{var f=a,g=b,h=g;a:for(;null!==h;){switch(h.tag){case 5:X=h.stateNode;Yj=!1;break a;case 3:X=h.stateNode.containerInfo;Yj=!0;break a;case 4:X=h.stateNode.containerInfo;Yj=!0;break a}h=h.return}if(null===X)throw Error(p(160));ak(f,g,e);X=null;Yj=!1;var k=e.alternate;null!==k&&(k.return=null);e.return=null}catch(l){W(e,b,l)}}if(b.subtreeFlags&12854)for(b=b.child;null!==b;)ek(b,a),b=b.sibling}\nfunction ek(a,b){var c=a.alternate,d=a.flags;switch(a.tag){case 0:case 11:case 14:case 15:dk(b,a);fk(a);if(d&4){try{Qj(3,a,a.return),Rj(3,a)}catch(t){W(a,a.return,t)}try{Qj(5,a,a.return)}catch(t){W(a,a.return,t)}}break;case 1:dk(b,a);fk(a);d&512&&null!==c&&Mj(c,c.return);break;case 5:dk(b,a);fk(a);d&512&&null!==c&&Mj(c,c.return);if(a.flags&32){var e=a.stateNode;try{ob(e,\"\")}catch(t){W(a,a.return,t)}}if(d&4&&(e=a.stateNode,null!=e)){var f=a.memoizedProps,g=null!==c?c.memoizedProps:f,h=a.type,k=a.updateQueue;\na.updateQueue=null;if(null!==k)try{\"input\"===h&&\"radio\"===f.type&&null!=f.name&&ab(e,f);vb(h,g);var l=vb(h,f);for(g=0;g<k.length;g+=2){var m=k[g],q=k[g+1];\"style\"===m?sb(e,q):\"dangerouslySetInnerHTML\"===m?nb(e,q):\"children\"===m?ob(e,q):ta(e,m,q,l)}switch(h){case \"input\":bb(e,f);break;case \"textarea\":ib(e,f);break;case \"select\":var r=e._wrapperState.wasMultiple;e._wrapperState.wasMultiple=!!f.multiple;var y=f.value;null!=y?fb(e,!!f.multiple,y,!1):r!==!!f.multiple&&(null!=f.defaultValue?fb(e,!!f.multiple,\nf.defaultValue,!0):fb(e,!!f.multiple,f.multiple?[]:\"\",!1))}e[Pf]=f}catch(t){W(a,a.return,t)}}break;case 6:dk(b,a);fk(a);if(d&4){if(null===a.stateNode)throw Error(p(162));e=a.stateNode;f=a.memoizedProps;try{e.nodeValue=f}catch(t){W(a,a.return,t)}}break;case 3:dk(b,a);fk(a);if(d&4&&null!==c&&c.memoizedState.isDehydrated)try{bd(b.containerInfo)}catch(t){W(a,a.return,t)}break;case 4:dk(b,a);fk(a);break;case 13:dk(b,a);fk(a);e=a.child;e.flags&8192&&(f=null!==e.memoizedState,e.stateNode.isHidden=f,!f||\nnull!==e.alternate&&null!==e.alternate.memoizedState||(gk=B()));d&4&&bk(a);break;case 22:m=null!==c&&null!==c.memoizedState;a.mode&1?(U=(l=U)||m,dk(b,a),U=l):dk(b,a);fk(a);if(d&8192){l=null!==a.memoizedState;if((a.stateNode.isHidden=l)&&!m&&0!==(a.mode&1))for(V=a,m=a.child;null!==m;){for(q=V=m;null!==V;){r=V;y=r.child;switch(r.tag){case 0:case 11:case 14:case 15:Qj(4,r,r.return);break;case 1:Mj(r,r.return);var n=r.stateNode;if(\"function\"===typeof n.componentWillUnmount){d=r;c=r.return;try{b=d,n.props=\nb.memoizedProps,n.state=b.memoizedState,n.componentWillUnmount()}catch(t){W(d,c,t)}}break;case 5:Mj(r,r.return);break;case 22:if(null!==r.memoizedState){hk(q);continue}}null!==y?(y.return=r,V=y):hk(q)}m=m.sibling}a:for(m=null,q=a;;){if(5===q.tag){if(null===m){m=q;try{e=q.stateNode,l?(f=e.style,\"function\"===typeof f.setProperty?f.setProperty(\"display\",\"none\",\"important\"):f.display=\"none\"):(h=q.stateNode,k=q.memoizedProps.style,g=void 0!==k&&null!==k&&k.hasOwnProperty(\"display\")?k.display:null,h.style.display=\nrb(\"display\",g))}catch(t){W(a,a.return,t)}}}else if(6===q.tag){if(null===m)try{q.stateNode.nodeValue=l?\"\":q.memoizedProps}catch(t){W(a,a.return,t)}}else if((22!==q.tag&&23!==q.tag||null===q.memoizedState||q===a)&&null!==q.child){q.child.return=q;q=q.child;continue}if(q===a)break a;for(;null===q.sibling;){if(null===q.return||q.return===a)break a;m===q&&(m=null);q=q.return}m===q&&(m=null);q.sibling.return=q.return;q=q.sibling}}break;case 19:dk(b,a);fk(a);d&4&&bk(a);break;case 21:break;default:dk(b,\na),fk(a)}}function fk(a){var b=a.flags;if(b&2){try{a:{for(var c=a.return;null!==c;){if(Uj(c)){var d=c;break a}c=c.return}throw Error(p(160));}switch(d.tag){case 5:var e=d.stateNode;d.flags&32&&(ob(e,\"\"),d.flags&=-33);var f=Vj(a);Xj(a,f,e);break;case 3:case 4:var g=d.stateNode.containerInfo,h=Vj(a);Wj(a,h,g);break;default:throw Error(p(161));}}catch(k){W(a,a.return,k)}a.flags&=-3}b&4096&&(a.flags&=-4097)}function ik(a,b,c){V=a;jk(a,b,c)}\nfunction jk(a,b,c){for(var d=0!==(a.mode&1);null!==V;){var e=V,f=e.child;if(22===e.tag&&d){var g=null!==e.memoizedState||Kj;if(!g){var h=e.alternate,k=null!==h&&null!==h.memoizedState||U;h=Kj;var l=U;Kj=g;if((U=k)&&!l)for(V=e;null!==V;)g=V,k=g.child,22===g.tag&&null!==g.memoizedState?kk(e):null!==k?(k.return=g,V=k):kk(e);for(;null!==f;)V=f,jk(f,b,c),f=f.sibling;V=e;Kj=h;U=l}lk(a,b,c)}else 0!==(e.subtreeFlags&8772)&&null!==f?(f.return=e,V=f):lk(a,b,c)}}\nfunction lk(a){for(;null!==V;){var b=V;if(0!==(b.flags&8772)){var c=b.alternate;try{if(0!==(b.flags&8772))switch(b.tag){case 0:case 11:case 15:U||Rj(5,b);break;case 1:var d=b.stateNode;if(b.flags&4&&!U)if(null===c)d.componentDidMount();else{var e=b.elementType===b.type?c.memoizedProps:Lg(b.type,c.memoizedProps);d.componentDidUpdate(e,c.memoizedState,d.__reactInternalSnapshotBeforeUpdate)}var f=b.updateQueue;null!==f&&ih(b,f,d);break;case 3:var g=b.updateQueue;if(null!==g){c=null;if(null!==b.child)switch(b.child.tag){case 5:c=\nb.child.stateNode;break;case 1:c=b.child.stateNode}ih(b,g,c)}break;case 5:var h=b.stateNode;if(null===c&&b.flags&4){c=h;var k=b.memoizedProps;switch(b.type){case \"button\":case \"input\":case \"select\":case \"textarea\":k.autoFocus&&c.focus();break;case \"img\":k.src&&(c.src=k.src)}}break;case 6:break;case 4:break;case 12:break;case 13:if(null===b.memoizedState){var l=b.alternate;if(null!==l){var m=l.memoizedState;if(null!==m){var q=m.dehydrated;null!==q&&bd(q)}}}break;case 19:case 17:case 21:case 22:case 23:case 25:break;\ndefault:throw Error(p(163));}U||b.flags&512&&Sj(b)}catch(r){W(b,b.return,r)}}if(b===a){V=null;break}c=b.sibling;if(null!==c){c.return=b.return;V=c;break}V=b.return}}function hk(a){for(;null!==V;){var b=V;if(b===a){V=null;break}var c=b.sibling;if(null!==c){c.return=b.return;V=c;break}V=b.return}}\nfunction kk(a){for(;null!==V;){var b=V;try{switch(b.tag){case 0:case 11:case 15:var c=b.return;try{Rj(4,b)}catch(k){W(b,c,k)}break;case 1:var d=b.stateNode;if(\"function\"===typeof d.componentDidMount){var e=b.return;try{d.componentDidMount()}catch(k){W(b,e,k)}}var f=b.return;try{Sj(b)}catch(k){W(b,f,k)}break;case 5:var g=b.return;try{Sj(b)}catch(k){W(b,g,k)}}}catch(k){W(b,b.return,k)}if(b===a){V=null;break}var h=b.sibling;if(null!==h){h.return=b.return;V=h;break}V=b.return}}\nvar mk=Math.ceil,nk=ua.ReactCurrentDispatcher,ok=ua.ReactCurrentOwner,pk=ua.ReactCurrentBatchConfig,K=0,R=null,Y=null,Z=0,gj=0,fj=Uf(0),T=0,qk=null,hh=0,rk=0,sk=0,tk=null,uk=null,gk=0,Hj=Infinity,vk=null,Pi=!1,Qi=null,Si=null,wk=!1,xk=null,yk=0,zk=0,Ak=null,Bk=-1,Ck=0;function L(){return 0!==(K&6)?B():-1!==Bk?Bk:Bk=B()}\nfunction lh(a){if(0===(a.mode&1))return 1;if(0!==(K&2)&&0!==Z)return Z&-Z;if(null!==Kg.transition)return 0===Ck&&(Ck=yc()),Ck;a=C;if(0!==a)return a;a=window.event;a=void 0===a?16:jd(a.type);return a}function mh(a,b,c,d){if(50<zk)throw zk=0,Ak=null,Error(p(185));Ac(a,c,d);if(0===(K&2)||a!==R)a===R&&(0===(K&2)&&(rk|=c),4===T&&Dk(a,Z)),Ek(a,d),1===c&&0===K&&0===(b.mode&1)&&(Hj=B()+500,fg&&jg())}\nfunction Ek(a,b){var c=a.callbackNode;wc(a,b);var d=uc(a,a===R?Z:0);if(0===d)null!==c&&bc(c),a.callbackNode=null,a.callbackPriority=0;else if(b=d&-d,a.callbackPriority!==b){null!=c&&bc(c);if(1===b)0===a.tag?ig(Fk.bind(null,a)):hg(Fk.bind(null,a)),Jf(function(){0===(K&6)&&jg()}),c=null;else{switch(Dc(d)){case 1:c=fc;break;case 4:c=gc;break;case 16:c=hc;break;case 536870912:c=jc;break;default:c=hc}c=Gk(c,Hk.bind(null,a))}a.callbackPriority=b;a.callbackNode=c}}\nfunction Hk(a,b){Bk=-1;Ck=0;if(0!==(K&6))throw Error(p(327));var c=a.callbackNode;if(Ik()&&a.callbackNode!==c)return null;var d=uc(a,a===R?Z:0);if(0===d)return null;if(0!==(d&30)||0!==(d&a.expiredLanes)||b)b=Jk(a,d);else{b=d;var e=K;K|=2;var f=Kk();if(R!==a||Z!==b)vk=null,Hj=B()+500,Lk(a,b);do try{Mk();break}catch(h){Nk(a,h)}while(1);Qg();nk.current=f;K=e;null!==Y?b=0:(R=null,Z=0,b=T)}if(0!==b){2===b&&(e=xc(a),0!==e&&(d=e,b=Ok(a,e)));if(1===b)throw c=qk,Lk(a,0),Dk(a,d),Ek(a,B()),c;if(6===b)Dk(a,d);\nelse{e=a.current.alternate;if(0===(d&30)&&!Pk(e)&&(b=Jk(a,d),2===b&&(f=xc(a),0!==f&&(d=f,b=Ok(a,f))),1===b))throw c=qk,Lk(a,0),Dk(a,d),Ek(a,B()),c;a.finishedWork=e;a.finishedLanes=d;switch(b){case 0:case 1:throw Error(p(345));case 2:Qk(a,uk,vk);break;case 3:Dk(a,d);if((d&130023424)===d&&(b=gk+500-B(),10<b)){if(0!==uc(a,0))break;e=a.suspendedLanes;if((e&d)!==d){L();a.pingedLanes|=a.suspendedLanes&e;break}a.timeoutHandle=Ff(Qk.bind(null,a,uk,vk),b);break}Qk(a,uk,vk);break;case 4:Dk(a,d);if((d&4194240)===\nd)break;b=a.eventTimes;for(e=-1;0<d;){var g=31-oc(d);f=1<<g;g=b[g];g>e&&(e=g);d&=~f}d=e;d=B()-d;d=(120>d?120:480>d?480:1080>d?1080:1920>d?1920:3E3>d?3E3:4320>d?4320:1960*mk(d/1960))-d;if(10<d){a.timeoutHandle=Ff(Qk.bind(null,a,uk,vk),d);break}Qk(a,uk,vk);break;case 5:Qk(a,uk,vk);break;default:throw Error(p(329));}}}Ek(a,B());return a.callbackNode===c?Hk.bind(null,a):null}\nfunction Ok(a,b){var c=tk;a.current.memoizedState.isDehydrated&&(Lk(a,b).flags|=256);a=Jk(a,b);2!==a&&(b=uk,uk=c,null!==b&&Gj(b));return a}function Gj(a){null===uk?uk=a:uk.push.apply(uk,a)}\nfunction Pk(a){for(var b=a;;){if(b.flags&16384){var c=b.updateQueue;if(null!==c&&(c=c.stores,null!==c))for(var d=0;d<c.length;d++){var e=c[d],f=e.getSnapshot;e=e.value;try{if(!He(f(),e))return!1}catch(g){return!1}}}c=b.child;if(b.subtreeFlags&16384&&null!==c)c.return=b,b=c;else{if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return!0;b=b.return}b.sibling.return=b.return;b=b.sibling}}return!0}\nfunction Dk(a,b){b&=~sk;b&=~rk;a.suspendedLanes|=b;a.pingedLanes&=~b;for(a=a.expirationTimes;0<b;){var c=31-oc(b),d=1<<c;a[c]=-1;b&=~d}}function Fk(a){if(0!==(K&6))throw Error(p(327));Ik();var b=uc(a,0);if(0===(b&1))return Ek(a,B()),null;var c=Jk(a,b);if(0!==a.tag&&2===c){var d=xc(a);0!==d&&(b=d,c=Ok(a,d))}if(1===c)throw c=qk,Lk(a,0),Dk(a,b),Ek(a,B()),c;if(6===c)throw Error(p(345));a.finishedWork=a.current.alternate;a.finishedLanes=b;Qk(a,uk,vk);Ek(a,B());return null}\nfunction Rk(a,b){var c=K;K|=1;try{return a(b)}finally{K=c,0===K&&(Hj=B()+500,fg&&jg())}}function Sk(a){null!==xk&&0===xk.tag&&0===(K&6)&&Ik();var b=K;K|=1;var c=pk.transition,d=C;try{if(pk.transition=null,C=1,a)return a()}finally{C=d,pk.transition=c,K=b,0===(K&6)&&jg()}}function Ij(){gj=fj.current;E(fj)}\nfunction Lk(a,b){a.finishedWork=null;a.finishedLanes=0;var c=a.timeoutHandle;-1!==c&&(a.timeoutHandle=-1,Gf(c));if(null!==Y)for(c=Y.return;null!==c;){var d=c;wg(d);switch(d.tag){case 1:d=d.type.childContextTypes;null!==d&&void 0!==d&&$f();break;case 3:Jh();E(Wf);E(H);Oh();break;case 5:Lh(d);break;case 4:Jh();break;case 13:E(M);break;case 19:E(M);break;case 10:Rg(d.type._context);break;case 22:case 23:Ij()}c=c.return}R=a;Y=a=wh(a.current,null);Z=gj=b;T=0;qk=null;sk=rk=hh=0;uk=tk=null;if(null!==Wg){for(b=\n0;b<Wg.length;b++)if(c=Wg[b],d=c.interleaved,null!==d){c.interleaved=null;var e=d.next,f=c.pending;if(null!==f){var g=f.next;f.next=e;d.next=g}c.pending=d}Wg=null}return a}\nfunction Nk(a,b){do{var c=Y;try{Qg();Ph.current=ai;if(Sh){for(var d=N.memoizedState;null!==d;){var e=d.queue;null!==e&&(e.pending=null);d=d.next}Sh=!1}Rh=0;P=O=N=null;Th=!1;Uh=0;ok.current=null;if(null===c||null===c.return){T=1;qk=b;Y=null;break}a:{var f=a,g=c.return,h=c,k=b;b=Z;h.flags|=32768;if(null!==k&&\"object\"===typeof k&&\"function\"===typeof k.then){var l=k,m=h,q=m.tag;if(0===(m.mode&1)&&(0===q||11===q||15===q)){var r=m.alternate;r?(m.updateQueue=r.updateQueue,m.memoizedState=r.memoizedState,\nm.lanes=r.lanes):(m.updateQueue=null,m.memoizedState=null)}var y=Vi(g);if(null!==y){y.flags&=-257;Wi(y,g,h,f,b);y.mode&1&&Ti(f,l,b);b=y;k=l;var n=b.updateQueue;if(null===n){var t=new Set;t.add(k);b.updateQueue=t}else n.add(k);break a}else{if(0===(b&1)){Ti(f,l,b);uj();break a}k=Error(p(426))}}else if(I&&h.mode&1){var J=Vi(g);if(null!==J){0===(J.flags&65536)&&(J.flags|=256);Wi(J,g,h,f,b);Jg(Ki(k,h));break a}}f=k=Ki(k,h);4!==T&&(T=2);null===tk?tk=[f]:tk.push(f);f=g;do{switch(f.tag){case 3:f.flags|=65536;\nb&=-b;f.lanes|=b;var x=Oi(f,k,b);fh(f,x);break a;case 1:h=k;var w=f.type,u=f.stateNode;if(0===(f.flags&128)&&(\"function\"===typeof w.getDerivedStateFromError||null!==u&&\"function\"===typeof u.componentDidCatch&&(null===Si||!Si.has(u)))){f.flags|=65536;b&=-b;f.lanes|=b;var F=Ri(f,h,b);fh(f,F);break a}}f=f.return}while(null!==f)}Tk(c)}catch(na){b=na;Y===c&&null!==c&&(Y=c=c.return);continue}break}while(1)}function Kk(){var a=nk.current;nk.current=ai;return null===a?ai:a}\nfunction uj(){if(0===T||3===T||2===T)T=4;null===R||0===(hh&268435455)&&0===(rk&268435455)||Dk(R,Z)}function Jk(a,b){var c=K;K|=2;var d=Kk();if(R!==a||Z!==b)vk=null,Lk(a,b);do try{Uk();break}catch(e){Nk(a,e)}while(1);Qg();K=c;nk.current=d;if(null!==Y)throw Error(p(261));R=null;Z=0;return T}function Uk(){for(;null!==Y;)Vk(Y)}function Mk(){for(;null!==Y&&!cc();)Vk(Y)}function Vk(a){var b=Wk(a.alternate,a,gj);a.memoizedProps=a.pendingProps;null===b?Tk(a):Y=b;ok.current=null}\nfunction Tk(a){var b=a;do{var c=b.alternate;a=b.return;if(0===(b.flags&32768)){if(c=Fj(c,b,gj),null!==c){Y=c;return}}else{c=Jj(c,b);if(null!==c){c.flags&=32767;Y=c;return}if(null!==a)a.flags|=32768,a.subtreeFlags=0,a.deletions=null;else{T=6;Y=null;return}}b=b.sibling;if(null!==b){Y=b;return}Y=b=a}while(null!==b);0===T&&(T=5)}function Qk(a,b,c){var d=C,e=pk.transition;try{pk.transition=null,C=1,Xk(a,b,c,d)}finally{pk.transition=e,C=d}return null}\nfunction Xk(a,b,c,d){do Ik();while(null!==xk);if(0!==(K&6))throw Error(p(327));c=a.finishedWork;var e=a.finishedLanes;if(null===c)return null;a.finishedWork=null;a.finishedLanes=0;if(c===a.current)throw Error(p(177));a.callbackNode=null;a.callbackPriority=0;var f=c.lanes|c.childLanes;Bc(a,f);a===R&&(Y=R=null,Z=0);0===(c.subtreeFlags&2064)&&0===(c.flags&2064)||wk||(wk=!0,Gk(hc,function(){Ik();return null}));f=0!==(c.flags&15990);if(0!==(c.subtreeFlags&15990)||f){f=pk.transition;pk.transition=null;\nvar g=C;C=1;var h=K;K|=4;ok.current=null;Pj(a,c);ek(c,a);Oe(Df);dd=!!Cf;Df=Cf=null;a.current=c;ik(c,a,e);dc();K=h;C=g;pk.transition=f}else a.current=c;wk&&(wk=!1,xk=a,yk=e);f=a.pendingLanes;0===f&&(Si=null);mc(c.stateNode,d);Ek(a,B());if(null!==b)for(d=a.onRecoverableError,c=0;c<b.length;c++)e=b[c],d(e.value,{componentStack:e.stack,digest:e.digest});if(Pi)throw Pi=!1,a=Qi,Qi=null,a;0!==(yk&1)&&0!==a.tag&&Ik();f=a.pendingLanes;0!==(f&1)?a===Ak?zk++:(zk=0,Ak=a):zk=0;jg();return null}\nfunction Ik(){if(null!==xk){var a=Dc(yk),b=pk.transition,c=C;try{pk.transition=null;C=16>a?16:a;if(null===xk)var d=!1;else{a=xk;xk=null;yk=0;if(0!==(K&6))throw Error(p(331));var e=K;K|=4;for(V=a.current;null!==V;){var f=V,g=f.child;if(0!==(V.flags&16)){var h=f.deletions;if(null!==h){for(var k=0;k<h.length;k++){var l=h[k];for(V=l;null!==V;){var m=V;switch(m.tag){case 0:case 11:case 15:Qj(8,m,f)}var q=m.child;if(null!==q)q.return=m,V=q;else for(;null!==V;){m=V;var r=m.sibling,y=m.return;Tj(m);if(m===\nl){V=null;break}if(null!==r){r.return=y;V=r;break}V=y}}}var n=f.alternate;if(null!==n){var t=n.child;if(null!==t){n.child=null;do{var J=t.sibling;t.sibling=null;t=J}while(null!==t)}}V=f}}if(0!==(f.subtreeFlags&2064)&&null!==g)g.return=f,V=g;else b:for(;null!==V;){f=V;if(0!==(f.flags&2048))switch(f.tag){case 0:case 11:case 15:Qj(9,f,f.return)}var x=f.sibling;if(null!==x){x.return=f.return;V=x;break b}V=f.return}}var w=a.current;for(V=w;null!==V;){g=V;var u=g.child;if(0!==(g.subtreeFlags&2064)&&null!==\nu)u.return=g,V=u;else b:for(g=w;null!==V;){h=V;if(0!==(h.flags&2048))try{switch(h.tag){case 0:case 11:case 15:Rj(9,h)}}catch(na){W(h,h.return,na)}if(h===g){V=null;break b}var F=h.sibling;if(null!==F){F.return=h.return;V=F;break b}V=h.return}}K=e;jg();if(lc&&\"function\"===typeof lc.onPostCommitFiberRoot)try{lc.onPostCommitFiberRoot(kc,a)}catch(na){}d=!0}return d}finally{C=c,pk.transition=b}}return!1}function Yk(a,b,c){b=Ki(c,b);b=Oi(a,b,1);a=dh(a,b,1);b=L();null!==a&&(Ac(a,1,b),Ek(a,b))}\nfunction W(a,b,c){if(3===a.tag)Yk(a,a,c);else for(;null!==b;){if(3===b.tag){Yk(b,a,c);break}else if(1===b.tag){var d=b.stateNode;if(\"function\"===typeof b.type.getDerivedStateFromError||\"function\"===typeof d.componentDidCatch&&(null===Si||!Si.has(d))){a=Ki(c,a);a=Ri(b,a,1);b=dh(b,a,1);a=L();null!==b&&(Ac(b,1,a),Ek(b,a));break}}b=b.return}}\nfunction Ui(a,b,c){var d=a.pingCache;null!==d&&d.delete(b);b=L();a.pingedLanes|=a.suspendedLanes&c;R===a&&(Z&c)===c&&(4===T||3===T&&(Z&130023424)===Z&&500>B()-gk?Lk(a,0):sk|=c);Ek(a,b)}function Zk(a,b){0===b&&(0===(a.mode&1)?b=1:(b=sc,sc<<=1,0===(sc&130023424)&&(sc=4194304)));var c=L();a=Zg(a,b);null!==a&&(Ac(a,b,c),Ek(a,c))}function vj(a){var b=a.memoizedState,c=0;null!==b&&(c=b.retryLane);Zk(a,c)}\nfunction ck(a,b){var c=0;switch(a.tag){case 13:var d=a.stateNode;var e=a.memoizedState;null!==e&&(c=e.retryLane);break;case 19:d=a.stateNode;break;default:throw Error(p(314));}null!==d&&d.delete(b);Zk(a,c)}var Wk;\nWk=function(a,b,c){if(null!==a)if(a.memoizedProps!==b.pendingProps||Wf.current)Ug=!0;else{if(0===(a.lanes&c)&&0===(b.flags&128))return Ug=!1,zj(a,b,c);Ug=0!==(a.flags&131072)?!0:!1}else Ug=!1,I&&0!==(b.flags&1048576)&&ug(b,ng,b.index);b.lanes=0;switch(b.tag){case 2:var d=b.type;jj(a,b);a=b.pendingProps;var e=Yf(b,H.current);Tg(b,c);e=Xh(null,b,d,a,e,c);var f=bi();b.flags|=1;\"object\"===typeof e&&null!==e&&\"function\"===typeof e.render&&void 0===e.$$typeof?(b.tag=1,b.memoizedState=null,b.updateQueue=\nnull,Zf(d)?(f=!0,cg(b)):f=!1,b.memoizedState=null!==e.state&&void 0!==e.state?e.state:null,ah(b),e.updater=nh,b.stateNode=e,e._reactInternals=b,rh(b,d,a,c),b=kj(null,b,d,!0,f,c)):(b.tag=0,I&&f&&vg(b),Yi(null,b,e,c),b=b.child);return b;case 16:d=b.elementType;a:{jj(a,b);a=b.pendingProps;e=d._init;d=e(d._payload);b.type=d;e=b.tag=$k(d);a=Lg(d,a);switch(e){case 0:b=dj(null,b,d,a,c);break a;case 1:b=ij(null,b,d,a,c);break a;case 11:b=Zi(null,b,d,a,c);break a;case 14:b=aj(null,b,d,Lg(d.type,a),c);break a}throw Error(p(306,\nd,\"\"));}return b;case 0:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:Lg(d,e),dj(a,b,d,e,c);case 1:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:Lg(d,e),ij(a,b,d,e,c);case 3:a:{lj(b);if(null===a)throw Error(p(387));d=b.pendingProps;f=b.memoizedState;e=f.element;bh(a,b);gh(b,d,null,c);var g=b.memoizedState;d=g.element;if(f.isDehydrated)if(f={element:d,isDehydrated:!1,cache:g.cache,pendingSuspenseBoundaries:g.pendingSuspenseBoundaries,transitions:g.transitions},b.updateQueue.baseState=\nf,b.memoizedState=f,b.flags&256){e=Ki(Error(p(423)),b);b=mj(a,b,d,c,e);break a}else if(d!==e){e=Ki(Error(p(424)),b);b=mj(a,b,d,c,e);break a}else for(yg=Lf(b.stateNode.containerInfo.firstChild),xg=b,I=!0,zg=null,c=Ch(b,null,d,c),b.child=c;c;)c.flags=c.flags&-3|4096,c=c.sibling;else{Ig();if(d===e){b=$i(a,b,c);break a}Yi(a,b,d,c)}b=b.child}return b;case 5:return Kh(b),null===a&&Eg(b),d=b.type,e=b.pendingProps,f=null!==a?a.memoizedProps:null,g=e.children,Ef(d,e)?g=null:null!==f&&Ef(d,f)&&(b.flags|=32),\nhj(a,b),Yi(a,b,g,c),b.child;case 6:return null===a&&Eg(b),null;case 13:return pj(a,b,c);case 4:return Ih(b,b.stateNode.containerInfo),d=b.pendingProps,null===a?b.child=Bh(b,null,d,c):Yi(a,b,d,c),b.child;case 11:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:Lg(d,e),Zi(a,b,d,e,c);case 7:return Yi(a,b,b.pendingProps,c),b.child;case 8:return Yi(a,b,b.pendingProps.children,c),b.child;case 12:return Yi(a,b,b.pendingProps.children,c),b.child;case 10:a:{d=b.type._context;e=b.pendingProps;f=b.memoizedProps;\ng=e.value;G(Mg,d._currentValue);d._currentValue=g;if(null!==f)if(He(f.value,g)){if(f.children===e.children&&!Wf.current){b=$i(a,b,c);break a}}else for(f=b.child,null!==f&&(f.return=b);null!==f;){var h=f.dependencies;if(null!==h){g=f.child;for(var k=h.firstContext;null!==k;){if(k.context===d){if(1===f.tag){k=ch(-1,c&-c);k.tag=2;var l=f.updateQueue;if(null!==l){l=l.shared;var m=l.pending;null===m?k.next=k:(k.next=m.next,m.next=k);l.pending=k}}f.lanes|=c;k=f.alternate;null!==k&&(k.lanes|=c);Sg(f.return,\nc,b);h.lanes|=c;break}k=k.next}}else if(10===f.tag)g=f.type===b.type?null:f.child;else if(18===f.tag){g=f.return;if(null===g)throw Error(p(341));g.lanes|=c;h=g.alternate;null!==h&&(h.lanes|=c);Sg(g,c,b);g=f.sibling}else g=f.child;if(null!==g)g.return=f;else for(g=f;null!==g;){if(g===b){g=null;break}f=g.sibling;if(null!==f){f.return=g.return;g=f;break}g=g.return}f=g}Yi(a,b,e.children,c);b=b.child}return b;case 9:return e=b.type,d=b.pendingProps.children,Tg(b,c),e=Vg(e),d=d(e),b.flags|=1,Yi(a,b,d,c),\nb.child;case 14:return d=b.type,e=Lg(d,b.pendingProps),e=Lg(d.type,e),aj(a,b,d,e,c);case 15:return cj(a,b,b.type,b.pendingProps,c);case 17:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:Lg(d,e),jj(a,b),b.tag=1,Zf(d)?(a=!0,cg(b)):a=!1,Tg(b,c),ph(b,d,e),rh(b,d,e,c),kj(null,b,d,!0,a,c);case 19:return yj(a,b,c);case 22:return ej(a,b,c)}throw Error(p(156,b.tag));};function Gk(a,b){return ac(a,b)}\nfunction al(a,b,c,d){this.tag=a;this.key=c;this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null;this.index=0;this.ref=null;this.pendingProps=b;this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null;this.mode=d;this.subtreeFlags=this.flags=0;this.deletions=null;this.childLanes=this.lanes=0;this.alternate=null}function Bg(a,b,c,d){return new al(a,b,c,d)}function bj(a){a=a.prototype;return!(!a||!a.isReactComponent)}\nfunction $k(a){if(\"function\"===typeof a)return bj(a)?1:0;if(void 0!==a&&null!==a){a=a.$$typeof;if(a===Da)return 11;if(a===Ga)return 14}return 2}\nfunction wh(a,b){var c=a.alternate;null===c?(c=Bg(a.tag,b,a.key,a.mode),c.elementType=a.elementType,c.type=a.type,c.stateNode=a.stateNode,c.alternate=a,a.alternate=c):(c.pendingProps=b,c.type=a.type,c.flags=0,c.subtreeFlags=0,c.deletions=null);c.flags=a.flags&14680064;c.childLanes=a.childLanes;c.lanes=a.lanes;c.child=a.child;c.memoizedProps=a.memoizedProps;c.memoizedState=a.memoizedState;c.updateQueue=a.updateQueue;b=a.dependencies;c.dependencies=null===b?null:{lanes:b.lanes,firstContext:b.firstContext};\nc.sibling=a.sibling;c.index=a.index;c.ref=a.ref;return c}\nfunction yh(a,b,c,d,e,f){var g=2;d=a;if(\"function\"===typeof a)bj(a)&&(g=1);else if(\"string\"===typeof a)g=5;else a:switch(a){case ya:return Ah(c.children,e,f,b);case za:g=8;e|=8;break;case Aa:return a=Bg(12,c,b,e|2),a.elementType=Aa,a.lanes=f,a;case Ea:return a=Bg(13,c,b,e),a.elementType=Ea,a.lanes=f,a;case Fa:return a=Bg(19,c,b,e),a.elementType=Fa,a.lanes=f,a;case Ia:return qj(c,e,f,b);default:if(\"object\"===typeof a&&null!==a)switch(a.$$typeof){case Ba:g=10;break a;case Ca:g=9;break a;case Da:g=11;\nbreak a;case Ga:g=14;break a;case Ha:g=16;d=null;break a}throw Error(p(130,null==a?a:typeof a,\"\"));}b=Bg(g,c,b,e);b.elementType=a;b.type=d;b.lanes=f;return b}function Ah(a,b,c,d){a=Bg(7,a,d,b);a.lanes=c;return a}function qj(a,b,c,d){a=Bg(22,a,d,b);a.elementType=Ia;a.lanes=c;a.stateNode={isHidden:!1};return a}function xh(a,b,c){a=Bg(6,a,null,b);a.lanes=c;return a}\nfunction zh(a,b,c){b=Bg(4,null!==a.children?a.children:[],a.key,b);b.lanes=c;b.stateNode={containerInfo:a.containerInfo,pendingChildren:null,implementation:a.implementation};return b}\nfunction bl(a,b,c,d,e){this.tag=b;this.containerInfo=a;this.finishedWork=this.pingCache=this.current=this.pendingChildren=null;this.timeoutHandle=-1;this.callbackNode=this.pendingContext=this.context=null;this.callbackPriority=0;this.eventTimes=zc(0);this.expirationTimes=zc(-1);this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0;this.entanglements=zc(0);this.identifierPrefix=d;this.onRecoverableError=e;this.mutableSourceEagerHydrationData=\nnull}function cl(a,b,c,d,e,f,g,h,k){a=new bl(a,b,c,h,k);1===b?(b=1,!0===f&&(b|=8)):b=0;f=Bg(3,null,null,b);a.current=f;f.stateNode=a;f.memoizedState={element:d,isDehydrated:c,cache:null,transitions:null,pendingSuspenseBoundaries:null};ah(f);return a}function dl(a,b,c){var d=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:wa,key:null==d?null:\"\"+d,children:a,containerInfo:b,implementation:c}}\nfunction el(a){if(!a)return Vf;a=a._reactInternals;a:{if(Vb(a)!==a||1!==a.tag)throw Error(p(170));var b=a;do{switch(b.tag){case 3:b=b.stateNode.context;break a;case 1:if(Zf(b.type)){b=b.stateNode.__reactInternalMemoizedMergedChildContext;break a}}b=b.return}while(null!==b);throw Error(p(171));}if(1===a.tag){var c=a.type;if(Zf(c))return bg(a,c,b)}return b}\nfunction fl(a,b,c,d,e,f,g,h,k){a=cl(c,d,!0,a,e,f,g,h,k);a.context=el(null);c=a.current;d=L();e=lh(c);f=ch(d,e);f.callback=void 0!==b&&null!==b?b:null;dh(c,f,e);a.current.lanes=e;Ac(a,e,d);Ek(a,d);return a}function gl(a,b,c,d){var e=b.current,f=L(),g=lh(e);c=el(c);null===b.context?b.context=c:b.pendingContext=c;b=ch(f,g);b.payload={element:a};d=void 0===d?null:d;null!==d&&(b.callback=d);a=dh(e,b,g);null!==a&&(mh(a,e,g,f),eh(a,e,g));return g}\nfunction hl(a){a=a.current;if(!a.child)return null;switch(a.child.tag){case 5:return a.child.stateNode;default:return a.child.stateNode}}function il(a,b){a=a.memoizedState;if(null!==a&&null!==a.dehydrated){var c=a.retryLane;a.retryLane=0!==c&&c<b?c:b}}function jl(a,b){il(a,b);(a=a.alternate)&&il(a,b)}function kl(){return null}var ll=\"function\"===typeof reportError?reportError:function(a){console.error(a)};function ml(a){this._internalRoot=a}\nnl.prototype.render=ml.prototype.render=function(a){var b=this._internalRoot;if(null===b)throw Error(p(409));gl(a,b,null,null)};nl.prototype.unmount=ml.prototype.unmount=function(){var a=this._internalRoot;if(null!==a){this._internalRoot=null;var b=a.containerInfo;Sk(function(){gl(null,a,null,null)});b[uf]=null}};function nl(a){this._internalRoot=a}\nnl.prototype.unstable_scheduleHydration=function(a){if(a){var b=Hc();a={blockedOn:null,target:a,priority:b};for(var c=0;c<Qc.length&&0!==b&&b<Qc[c].priority;c++);Qc.splice(c,0,a);0===c&&Vc(a)}};function ol(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType)}function pl(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType&&(8!==a.nodeType||\" react-mount-point-unstable \"!==a.nodeValue))}function ql(){}\nfunction rl(a,b,c,d,e){if(e){if(\"function\"===typeof d){var f=d;d=function(){var a=hl(g);f.call(a)}}var g=fl(b,d,a,0,null,!1,!1,\"\",ql);a._reactRootContainer=g;a[uf]=g.current;sf(8===a.nodeType?a.parentNode:a);Sk();return g}for(;e=a.lastChild;)a.removeChild(e);if(\"function\"===typeof d){var h=d;d=function(){var a=hl(k);h.call(a)}}var k=cl(a,0,!1,null,null,!1,!1,\"\",ql);a._reactRootContainer=k;a[uf]=k.current;sf(8===a.nodeType?a.parentNode:a);Sk(function(){gl(b,k,c,d)});return k}\nfunction sl(a,b,c,d,e){var f=c._reactRootContainer;if(f){var g=f;if(\"function\"===typeof e){var h=e;e=function(){var a=hl(g);h.call(a)}}gl(b,g,a,e)}else g=rl(c,b,a,e,d);return hl(g)}Ec=function(a){switch(a.tag){case 3:var b=a.stateNode;if(b.current.memoizedState.isDehydrated){var c=tc(b.pendingLanes);0!==c&&(Cc(b,c|1),Ek(b,B()),0===(K&6)&&(Hj=B()+500,jg()))}break;case 13:Sk(function(){var b=Zg(a,1);if(null!==b){var c=L();mh(b,a,1,c)}}),jl(a,1)}};\nFc=function(a){if(13===a.tag){var b=Zg(a,134217728);if(null!==b){var c=L();mh(b,a,134217728,c)}jl(a,134217728)}};Gc=function(a){if(13===a.tag){var b=lh(a),c=Zg(a,b);if(null!==c){var d=L();mh(c,a,b,d)}jl(a,b)}};Hc=function(){return C};Ic=function(a,b){var c=C;try{return C=a,b()}finally{C=c}};\nyb=function(a,b,c){switch(b){case \"input\":bb(a,c);b=c.name;if(\"radio\"===c.type&&null!=b){for(c=a;c.parentNode;)c=c.parentNode;c=c.querySelectorAll(\"input[name=\"+JSON.stringify(\"\"+b)+'][type=\"radio\"]');for(b=0;b<c.length;b++){var d=c[b];if(d!==a&&d.form===a.form){var e=Db(d);if(!e)throw Error(p(90));Wa(d);bb(d,e)}}}break;case \"textarea\":ib(a,c);break;case \"select\":b=c.value,null!=b&&fb(a,!!c.multiple,b,!1)}};Gb=Rk;Hb=Sk;\nvar tl={usingClientEntryPoint:!1,Events:[Cb,ue,Db,Eb,Fb,Rk]},ul={findFiberByHostInstance:Wc,bundleType:0,version:\"18.2.0\",rendererPackageName:\"react-dom\"};\nvar vl={bundleType:ul.bundleType,version:ul.version,rendererPackageName:ul.rendererPackageName,rendererConfig:ul.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:ua.ReactCurrentDispatcher,findHostInstanceByFiber:function(a){a=Zb(a);return null===a?null:a.stateNode},findFiberByHostInstance:ul.findFiberByHostInstance||\nkl,findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:\"18.2.0-next-9e3b772b8-20220608\"};if(\"undefined\"!==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__){var wl=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!wl.isDisabled&&wl.supportsFiber)try{kc=wl.inject(vl),lc=wl}catch(a){}}exports.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=tl;\nexports.createPortal=function(a,b){var c=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;if(!ol(b))throw Error(p(200));return dl(a,b,null,c)};exports.createRoot=function(a,b){if(!ol(a))throw Error(p(299));var c=!1,d=\"\",e=ll;null!==b&&void 0!==b&&(!0===b.unstable_strictMode&&(c=!0),void 0!==b.identifierPrefix&&(d=b.identifierPrefix),void 0!==b.onRecoverableError&&(e=b.onRecoverableError));b=cl(a,1,!1,null,null,c,!1,d,e);a[uf]=b.current;sf(8===a.nodeType?a.parentNode:a);return new ml(b)};\nexports.findDOMNode=function(a){if(null==a)return null;if(1===a.nodeType)return a;var b=a._reactInternals;if(void 0===b){if(\"function\"===typeof a.render)throw Error(p(188));a=Object.keys(a).join(\",\");throw Error(p(268,a));}a=Zb(b);a=null===a?null:a.stateNode;return a};exports.flushSync=function(a){return Sk(a)};exports.hydrate=function(a,b,c){if(!pl(b))throw Error(p(200));return sl(null,a,b,!0,c)};\nexports.hydrateRoot=function(a,b,c){if(!ol(a))throw Error(p(405));var d=null!=c&&c.hydratedSources||null,e=!1,f=\"\",g=ll;null!==c&&void 0!==c&&(!0===c.unstable_strictMode&&(e=!0),void 0!==c.identifierPrefix&&(f=c.identifierPrefix),void 0!==c.onRecoverableError&&(g=c.onRecoverableError));b=fl(b,null,a,1,null!=c?c:null,e,!1,f,g);a[uf]=b.current;sf(a);if(d)for(a=0;a<d.length;a++)c=d[a],e=c._getVersion,e=e(c._source),null==b.mutableSourceEagerHydrationData?b.mutableSourceEagerHydrationData=[c,e]:b.mutableSourceEagerHydrationData.push(c,\ne);return new nl(b)};exports.render=function(a,b,c){if(!pl(b))throw Error(p(200));return sl(null,a,b,!1,c)};exports.unmountComponentAtNode=function(a){if(!pl(a))throw Error(p(40));return a._reactRootContainer?(Sk(function(){sl(null,null,a,!1,function(){a._reactRootContainer=null;a[uf]=null})}),!0):!1};exports.unstable_batchedUpdates=Rk;\nexports.unstable_renderSubtreeIntoContainer=function(a,b,c,d){if(!pl(c))throw Error(p(200));if(null==a||void 0===a._reactInternals)throw Error(p(38));return sl(a,b,c,!1,d)};exports.version=\"18.2.0-next-9e3b772b8-20220608\";\n","'use strict';\n\nvar m = require('react-dom');\nif (process.env.NODE_ENV === 'production') {\n  exports.createRoot = m.createRoot;\n  exports.hydrateRoot = m.hydrateRoot;\n} else {\n  var i = m.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;\n  exports.createRoot = function(c, o) {\n    i.usingClientEntryPoint = true;\n    try {\n      return m.createRoot(c, o);\n    } finally {\n      i.usingClientEntryPoint = false;\n    }\n  };\n  exports.hydrateRoot = function(c, h, o) {\n    i.usingClientEntryPoint = true;\n    try {\n      return m.hydrateRoot(c, h, o);\n    } finally {\n      i.usingClientEntryPoint = false;\n    }\n  };\n}\n","'use strict';\n\nfunction checkDCE() {\n  /* global __REACT_DEVTOOLS_GLOBAL_HOOK__ */\n  if (\n    typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ === 'undefined' ||\n    typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE !== 'function'\n  ) {\n    return;\n  }\n  if (process.env.NODE_ENV !== 'production') {\n    // This branch is unreachable because this function is only called\n    // in production, but the condition is true only in development.\n    // Therefore if the branch is still here, dead code elimination wasn't\n    // properly applied.\n    // Don't change the message. React DevTools relies on it. Also make sure\n    // this message doesn't occur elsewhere in this function, or it will cause\n    // a false positive.\n    throw new Error('^_^');\n  }\n  try {\n    // Verify that the code above has been dead code eliminated (DCE'd).\n    __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(checkDCE);\n  } catch (err) {\n    // DevTools shouldn't crash React, no matter what.\n    // We should still report in case we break this code.\n    console.error(err);\n  }\n}\n\nif (process.env.NODE_ENV === 'production') {\n  // DCE check should happen before ReactDOM bundle executes so that\n  // DevTools can report bad minification during injection.\n  checkDCE();\n  module.exports = require('./cjs/react-dom.production.min.js');\n} else {\n  module.exports = require('./cjs/react-dom.development.js');\n}\n","// TYPES\n// FUNCTIONS\nvar logger = console;\nexport function getLogger() {\n  return logger;\n}\nexport function setLogger(newLogger) {\n  logger = newLogger;\n}","import { scheduleMicrotask } from './utils'; // TYPES\n\n// CLASS\nexport var NotifyManager = /*#__PURE__*/function () {\n  function NotifyManager() {\n    this.queue = [];\n    this.transactions = 0;\n\n    this.notifyFn = function (callback) {\n      callback();\n    };\n\n    this.batchNotifyFn = function (callback) {\n      callback();\n    };\n  }\n\n  var _proto = NotifyManager.prototype;\n\n  _proto.batch = function batch(callback) {\n    var result;\n    this.transactions++;\n\n    try {\n      result = callback();\n    } finally {\n      this.transactions--;\n\n      if (!this.transactions) {\n        this.flush();\n      }\n    }\n\n    return result;\n  };\n\n  _proto.schedule = function schedule(callback) {\n    var _this = this;\n\n    if (this.transactions) {\n      this.queue.push(callback);\n    } else {\n      scheduleMicrotask(function () {\n        _this.notifyFn(callback);\n      });\n    }\n  }\n  /**\n   * All calls to the wrapped function will be batched.\n   */\n  ;\n\n  _proto.batchCalls = function batchCalls(callback) {\n    var _this2 = this;\n\n    return function () {\n      for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n        args[_key] = arguments[_key];\n      }\n\n      _this2.schedule(function () {\n        callback.apply(void 0, args);\n      });\n    };\n  };\n\n  _proto.flush = function flush() {\n    var _this3 = this;\n\n    var queue = this.queue;\n    this.queue = [];\n\n    if (queue.length) {\n      scheduleMicrotask(function () {\n        _this3.batchNotifyFn(function () {\n          queue.forEach(function (callback) {\n            _this3.notifyFn(callback);\n          });\n        });\n      });\n    }\n  }\n  /**\n   * Use this method to set a custom notify function.\n   * This can be used to for example wrap notifications with `React.act` while running tests.\n   */\n  ;\n\n  _proto.setNotifyFunction = function setNotifyFunction(fn) {\n    this.notifyFn = fn;\n  }\n  /**\n   * Use this method to set a custom function to batch notifications together into a single tick.\n   * By default React Query will use the batch function provided by ReactDOM or React Native.\n   */\n  ;\n\n  _proto.setBatchNotifyFunction = function setBatchNotifyFunction(fn) {\n    this.batchNotifyFn = fn;\n  };\n\n  return NotifyManager;\n}(); // SINGLETON\n\nexport var notifyManager = new NotifyManager();","export default function _setPrototypeOf(o, p) {\n  _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function _setPrototypeOf(o, p) {\n    o.__proto__ = p;\n    return o;\n  };\n  return _setPrototypeOf(o, p);\n}","import setPrototypeOf from \"./setPrototypeOf.js\";\nexport default function _inheritsLoose(subClass, superClass) {\n  subClass.prototype = Object.create(superClass.prototype);\n  subClass.prototype.constructor = subClass;\n  setPrototypeOf(subClass, superClass);\n}","export var Subscribable = /*#__PURE__*/function () {\n  function Subscribable() {\n    this.listeners = [];\n  }\n\n  var _proto = Subscribable.prototype;\n\n  _proto.subscribe = function subscribe(listener) {\n    var _this = this;\n\n    var callback = listener || function () {\n      return undefined;\n    };\n\n    this.listeners.push(callback);\n    this.onSubscribe();\n    return function () {\n      _this.listeners = _this.listeners.filter(function (x) {\n        return x !== callback;\n      });\n\n      _this.onUnsubscribe();\n    };\n  };\n\n  _proto.hasListeners = function hasListeners() {\n    return this.listeners.length > 0;\n  };\n\n  _proto.onSubscribe = function onSubscribe() {// Do nothing\n  };\n\n  _proto.onUnsubscribe = function onUnsubscribe() {// Do nothing\n  };\n\n  return Subscribable;\n}();","import _inheritsLoose from \"@babel/runtime/helpers/esm/inheritsLoose\";\nimport { Subscribable } from './subscribable';\nimport { isServer } from './utils';\nexport var FocusManager = /*#__PURE__*/function (_Subscribable) {\n  _inheritsLoose(FocusManager, _Subscribable);\n\n  function FocusManager() {\n    var _this;\n\n    _this = _Subscribable.call(this) || this;\n\n    _this.setup = function (onFocus) {\n      var _window;\n\n      if (!isServer && ((_window = window) == null ? void 0 : _window.addEventListener)) {\n        var listener = function listener() {\n          return onFocus();\n        }; // Listen to visibillitychange and focus\n\n\n        window.addEventListener('visibilitychange', listener, false);\n        window.addEventListener('focus', listener, false);\n        return function () {\n          // Be sure to unsubscribe if a new handler is set\n          window.removeEventListener('visibilitychange', listener);\n          window.removeEventListener('focus', listener);\n        };\n      }\n    };\n\n    return _this;\n  }\n\n  var _proto = FocusManager.prototype;\n\n  _proto.onSubscribe = function onSubscribe() {\n    if (!this.cleanup) {\n      this.setEventListener(this.setup);\n    }\n  };\n\n  _proto.onUnsubscribe = function onUnsubscribe() {\n    if (!this.hasListeners()) {\n      var _this$cleanup;\n\n      (_this$cleanup = this.cleanup) == null ? void 0 : _this$cleanup.call(this);\n      this.cleanup = undefined;\n    }\n  };\n\n  _proto.setEventListener = function setEventListener(setup) {\n    var _this$cleanup2,\n        _this2 = this;\n\n    this.setup = setup;\n    (_this$cleanup2 = this.cleanup) == null ? void 0 : _this$cleanup2.call(this);\n    this.cleanup = setup(function (focused) {\n      if (typeof focused === 'boolean') {\n        _this2.setFocused(focused);\n      } else {\n        _this2.onFocus();\n      }\n    });\n  };\n\n  _proto.setFocused = function setFocused(focused) {\n    this.focused = focused;\n\n    if (focused) {\n      this.onFocus();\n    }\n  };\n\n  _proto.onFocus = function onFocus() {\n    this.listeners.forEach(function (listener) {\n      listener();\n    });\n  };\n\n  _proto.isFocused = function isFocused() {\n    if (typeof this.focused === 'boolean') {\n      return this.focused;\n    } // document global can be unavailable in react native\n\n\n    if (typeof document === 'undefined') {\n      return true;\n    }\n\n    return [undefined, 'visible', 'prerender'].includes(document.visibilityState);\n  };\n\n  return FocusManager;\n}(Subscribable);\nexport var focusManager = new FocusManager();","import _inheritsLoose from \"@babel/runtime/helpers/esm/inheritsLoose\";\nimport { Subscribable } from './subscribable';\nimport { isServer } from './utils';\nexport var OnlineManager = /*#__PURE__*/function (_Subscribable) {\n  _inheritsLoose(OnlineManager, _Subscribable);\n\n  function OnlineManager() {\n    var _this;\n\n    _this = _Subscribable.call(this) || this;\n\n    _this.setup = function (onOnline) {\n      var _window;\n\n      if (!isServer && ((_window = window) == null ? void 0 : _window.addEventListener)) {\n        var listener = function listener() {\n          return onOnline();\n        }; // Listen to online\n\n\n        window.addEventListener('online', listener, false);\n        window.addEventListener('offline', listener, false);\n        return function () {\n          // Be sure to unsubscribe if a new handler is set\n          window.removeEventListener('online', listener);\n          window.removeEventListener('offline', listener);\n        };\n      }\n    };\n\n    return _this;\n  }\n\n  var _proto = OnlineManager.prototype;\n\n  _proto.onSubscribe = function onSubscribe() {\n    if (!this.cleanup) {\n      this.setEventListener(this.setup);\n    }\n  };\n\n  _proto.onUnsubscribe = function onUnsubscribe() {\n    if (!this.hasListeners()) {\n      var _this$cleanup;\n\n      (_this$cleanup = this.cleanup) == null ? void 0 : _this$cleanup.call(this);\n      this.cleanup = undefined;\n    }\n  };\n\n  _proto.setEventListener = function setEventListener(setup) {\n    var _this$cleanup2,\n        _this2 = this;\n\n    this.setup = setup;\n    (_this$cleanup2 = this.cleanup) == null ? void 0 : _this$cleanup2.call(this);\n    this.cleanup = setup(function (online) {\n      if (typeof online === 'boolean') {\n        _this2.setOnline(online);\n      } else {\n        _this2.onOnline();\n      }\n    });\n  };\n\n  _proto.setOnline = function setOnline(online) {\n    this.online = online;\n\n    if (online) {\n      this.onOnline();\n    }\n  };\n\n  _proto.onOnline = function onOnline() {\n    this.listeners.forEach(function (listener) {\n      listener();\n    });\n  };\n\n  _proto.isOnline = function isOnline() {\n    if (typeof this.online === 'boolean') {\n      return this.online;\n    }\n\n    if (typeof navigator === 'undefined' || typeof navigator.onLine === 'undefined') {\n      return true;\n    }\n\n    return navigator.onLine;\n  };\n\n  return OnlineManager;\n}(Subscribable);\nexport var onlineManager = new OnlineManager();","import { focusManager } from './focusManager';\nimport { onlineManager } from './onlineManager';\nimport { sleep } from './utils';\n\nfunction defaultRetryDelay(failureCount) {\n  return Math.min(1000 * Math.pow(2, failureCount), 30000);\n}\n\nexport function isCancelable(value) {\n  return typeof (value == null ? void 0 : value.cancel) === 'function';\n}\nexport var CancelledError = function CancelledError(options) {\n  this.revert = options == null ? void 0 : options.revert;\n  this.silent = options == null ? void 0 : options.silent;\n};\nexport function isCancelledError(value) {\n  return value instanceof CancelledError;\n} // CLASS\n\nexport var Retryer = function Retryer(config) {\n  var _this = this;\n\n  var cancelRetry = false;\n  var cancelFn;\n  var continueFn;\n  var promiseResolve;\n  var promiseReject;\n  this.abort = config.abort;\n\n  this.cancel = function (cancelOptions) {\n    return cancelFn == null ? void 0 : cancelFn(cancelOptions);\n  };\n\n  this.cancelRetry = function () {\n    cancelRetry = true;\n  };\n\n  this.continueRetry = function () {\n    cancelRetry = false;\n  };\n\n  this.continue = function () {\n    return continueFn == null ? void 0 : continueFn();\n  };\n\n  this.failureCount = 0;\n  this.isPaused = false;\n  this.isResolved = false;\n  this.isTransportCancelable = false;\n  this.promise = new Promise(function (outerResolve, outerReject) {\n    promiseResolve = outerResolve;\n    promiseReject = outerReject;\n  });\n\n  var resolve = function resolve(value) {\n    if (!_this.isResolved) {\n      _this.isResolved = true;\n      config.onSuccess == null ? void 0 : config.onSuccess(value);\n      continueFn == null ? void 0 : continueFn();\n      promiseResolve(value);\n    }\n  };\n\n  var reject = function reject(value) {\n    if (!_this.isResolved) {\n      _this.isResolved = true;\n      config.onError == null ? void 0 : config.onError(value);\n      continueFn == null ? void 0 : continueFn();\n      promiseReject(value);\n    }\n  };\n\n  var pause = function pause() {\n    return new Promise(function (continueResolve) {\n      continueFn = continueResolve;\n      _this.isPaused = true;\n      config.onPause == null ? void 0 : config.onPause();\n    }).then(function () {\n      continueFn = undefined;\n      _this.isPaused = false;\n      config.onContinue == null ? void 0 : config.onContinue();\n    });\n  }; // Create loop function\n\n\n  var run = function run() {\n    // Do nothing if already resolved\n    if (_this.isResolved) {\n      return;\n    }\n\n    var promiseOrValue; // Execute query\n\n    try {\n      promiseOrValue = config.fn();\n    } catch (error) {\n      promiseOrValue = Promise.reject(error);\n    } // Create callback to cancel this fetch\n\n\n    cancelFn = function cancelFn(cancelOptions) {\n      if (!_this.isResolved) {\n        reject(new CancelledError(cancelOptions));\n        _this.abort == null ? void 0 : _this.abort(); // Cancel transport if supported\n\n        if (isCancelable(promiseOrValue)) {\n          try {\n            promiseOrValue.cancel();\n          } catch (_unused) {}\n        }\n      }\n    }; // Check if the transport layer support cancellation\n\n\n    _this.isTransportCancelable = isCancelable(promiseOrValue);\n    Promise.resolve(promiseOrValue).then(resolve).catch(function (error) {\n      var _config$retry, _config$retryDelay;\n\n      // Stop if the fetch is already resolved\n      if (_this.isResolved) {\n        return;\n      } // Do we need to retry the request?\n\n\n      var retry = (_config$retry = config.retry) != null ? _config$retry : 3;\n      var retryDelay = (_config$retryDelay = config.retryDelay) != null ? _config$retryDelay : defaultRetryDelay;\n      var delay = typeof retryDelay === 'function' ? retryDelay(_this.failureCount, error) : retryDelay;\n      var shouldRetry = retry === true || typeof retry === 'number' && _this.failureCount < retry || typeof retry === 'function' && retry(_this.failureCount, error);\n\n      if (cancelRetry || !shouldRetry) {\n        // We are done if the query does not need to be retried\n        reject(error);\n        return;\n      }\n\n      _this.failureCount++; // Notify on fail\n\n      config.onFail == null ? void 0 : config.onFail(_this.failureCount, error); // Delay\n\n      sleep(delay) // Pause if the document is not visible or when the device is offline\n      .then(function () {\n        if (!focusManager.isFocused() || !onlineManager.isOnline()) {\n          return pause();\n        }\n      }).then(function () {\n        if (cancelRetry) {\n          reject(error);\n        } else {\n          run();\n        }\n      });\n    });\n  }; // Start loop\n\n\n  run();\n};","import _extends from \"@babel/runtime/helpers/esm/extends\";\nimport { getAbortController, functionalUpdate, isValidTimeout, noop, replaceEqualDeep, timeUntilStale, ensureQueryKeyArray } from './utils';\nimport { notifyManager } from './notifyManager';\nimport { getLogger } from './logger';\nimport { Retryer, isCancelledError } from './retryer'; // TYPES\n\n// CLASS\nexport var Query = /*#__PURE__*/function () {\n  function Query(config) {\n    this.abortSignalConsumed = false;\n    this.hadObservers = false;\n    this.defaultOptions = config.defaultOptions;\n    this.setOptions(config.options);\n    this.observers = [];\n    this.cache = config.cache;\n    this.queryKey = config.queryKey;\n    this.queryHash = config.queryHash;\n    this.initialState = config.state || this.getDefaultState(this.options);\n    this.state = this.initialState;\n    this.meta = config.meta;\n    this.scheduleGc();\n  }\n\n  var _proto = Query.prototype;\n\n  _proto.setOptions = function setOptions(options) {\n    var _this$options$cacheTi;\n\n    this.options = _extends({}, this.defaultOptions, options);\n    this.meta = options == null ? void 0 : options.meta; // Default to 5 minutes if not cache time is set\n\n    this.cacheTime = Math.max(this.cacheTime || 0, (_this$options$cacheTi = this.options.cacheTime) != null ? _this$options$cacheTi : 5 * 60 * 1000);\n  };\n\n  _proto.setDefaultOptions = function setDefaultOptions(options) {\n    this.defaultOptions = options;\n  };\n\n  _proto.scheduleGc = function scheduleGc() {\n    var _this = this;\n\n    this.clearGcTimeout();\n\n    if (isValidTimeout(this.cacheTime)) {\n      this.gcTimeout = setTimeout(function () {\n        _this.optionalRemove();\n      }, this.cacheTime);\n    }\n  };\n\n  _proto.clearGcTimeout = function clearGcTimeout() {\n    clearTimeout(this.gcTimeout);\n    this.gcTimeout = undefined;\n  };\n\n  _proto.optionalRemove = function optionalRemove() {\n    if (!this.observers.length) {\n      if (this.state.isFetching) {\n        if (this.hadObservers) {\n          this.scheduleGc();\n        }\n      } else {\n        this.cache.remove(this);\n      }\n    }\n  };\n\n  _proto.setData = function setData(updater, options) {\n    var _this$options$isDataE, _this$options;\n\n    var prevData = this.state.data; // Get the new data\n\n    var data = functionalUpdate(updater, prevData); // Use prev data if an isDataEqual function is defined and returns `true`\n\n    if ((_this$options$isDataE = (_this$options = this.options).isDataEqual) == null ? void 0 : _this$options$isDataE.call(_this$options, prevData, data)) {\n      data = prevData;\n    } else if (this.options.structuralSharing !== false) {\n      // Structurally share data between prev and new data if needed\n      data = replaceEqualDeep(prevData, data);\n    } // Set data and mark it as cached\n\n\n    this.dispatch({\n      data: data,\n      type: 'success',\n      dataUpdatedAt: options == null ? void 0 : options.updatedAt\n    });\n    return data;\n  };\n\n  _proto.setState = function setState(state, setStateOptions) {\n    this.dispatch({\n      type: 'setState',\n      state: state,\n      setStateOptions: setStateOptions\n    });\n  };\n\n  _proto.cancel = function cancel(options) {\n    var _this$retryer;\n\n    var promise = this.promise;\n    (_this$retryer = this.retryer) == null ? void 0 : _this$retryer.cancel(options);\n    return promise ? promise.then(noop).catch(noop) : Promise.resolve();\n  };\n\n  _proto.destroy = function destroy() {\n    this.clearGcTimeout();\n    this.cancel({\n      silent: true\n    });\n  };\n\n  _proto.reset = function reset() {\n    this.destroy();\n    this.setState(this.initialState);\n  };\n\n  _proto.isActive = function isActive() {\n    return this.observers.some(function (observer) {\n      return observer.options.enabled !== false;\n    });\n  };\n\n  _proto.isFetching = function isFetching() {\n    return this.state.isFetching;\n  };\n\n  _proto.isStale = function isStale() {\n    return this.state.isInvalidated || !this.state.dataUpdatedAt || this.observers.some(function (observer) {\n      return observer.getCurrentResult().isStale;\n    });\n  };\n\n  _proto.isStaleByTime = function isStaleByTime(staleTime) {\n    if (staleTime === void 0) {\n      staleTime = 0;\n    }\n\n    return this.state.isInvalidated || !this.state.dataUpdatedAt || !timeUntilStale(this.state.dataUpdatedAt, staleTime);\n  };\n\n  _proto.onFocus = function onFocus() {\n    var _this$retryer2;\n\n    var observer = this.observers.find(function (x) {\n      return x.shouldFetchOnWindowFocus();\n    });\n\n    if (observer) {\n      observer.refetch();\n    } // Continue fetch if currently paused\n\n\n    (_this$retryer2 = this.retryer) == null ? void 0 : _this$retryer2.continue();\n  };\n\n  _proto.onOnline = function onOnline() {\n    var _this$retryer3;\n\n    var observer = this.observers.find(function (x) {\n      return x.shouldFetchOnReconnect();\n    });\n\n    if (observer) {\n      observer.refetch();\n    } // Continue fetch if currently paused\n\n\n    (_this$retryer3 = this.retryer) == null ? void 0 : _this$retryer3.continue();\n  };\n\n  _proto.addObserver = function addObserver(observer) {\n    if (this.observers.indexOf(observer) === -1) {\n      this.observers.push(observer);\n      this.hadObservers = true; // Stop the query from being garbage collected\n\n      this.clearGcTimeout();\n      this.cache.notify({\n        type: 'observerAdded',\n        query: this,\n        observer: observer\n      });\n    }\n  };\n\n  _proto.removeObserver = function removeObserver(observer) {\n    if (this.observers.indexOf(observer) !== -1) {\n      this.observers = this.observers.filter(function (x) {\n        return x !== observer;\n      });\n\n      if (!this.observers.length) {\n        // If the transport layer does not support cancellation\n        // we'll let the query continue so the result can be cached\n        if (this.retryer) {\n          if (this.retryer.isTransportCancelable || this.abortSignalConsumed) {\n            this.retryer.cancel({\n              revert: true\n            });\n          } else {\n            this.retryer.cancelRetry();\n          }\n        }\n\n        if (this.cacheTime) {\n          this.scheduleGc();\n        } else {\n          this.cache.remove(this);\n        }\n      }\n\n      this.cache.notify({\n        type: 'observerRemoved',\n        query: this,\n        observer: observer\n      });\n    }\n  };\n\n  _proto.getObserversCount = function getObserversCount() {\n    return this.observers.length;\n  };\n\n  _proto.invalidate = function invalidate() {\n    if (!this.state.isInvalidated) {\n      this.dispatch({\n        type: 'invalidate'\n      });\n    }\n  };\n\n  _proto.fetch = function fetch(options, fetchOptions) {\n    var _this2 = this,\n        _this$options$behavio,\n        _context$fetchOptions,\n        _abortController$abor;\n\n    if (this.state.isFetching) {\n      if (this.state.dataUpdatedAt && (fetchOptions == null ? void 0 : fetchOptions.cancelRefetch)) {\n        // Silently cancel current fetch if the user wants to cancel refetches\n        this.cancel({\n          silent: true\n        });\n      } else if (this.promise) {\n        var _this$retryer4;\n\n        // make sure that retries that were potentially cancelled due to unmounts can continue\n        (_this$retryer4 = this.retryer) == null ? void 0 : _this$retryer4.continueRetry(); // Return current promise if we are already fetching\n\n        return this.promise;\n      }\n    } // Update config if passed, otherwise the config from the last execution is used\n\n\n    if (options) {\n      this.setOptions(options);\n    } // Use the options from the first observer with a query function if no function is found.\n    // This can happen when the query is hydrated or created with setQueryData.\n\n\n    if (!this.options.queryFn) {\n      var observer = this.observers.find(function (x) {\n        return x.options.queryFn;\n      });\n\n      if (observer) {\n        this.setOptions(observer.options);\n      }\n    }\n\n    var queryKey = ensureQueryKeyArray(this.queryKey);\n    var abortController = getAbortController(); // Create query function context\n\n    var queryFnContext = {\n      queryKey: queryKey,\n      pageParam: undefined,\n      meta: this.meta\n    };\n    Object.defineProperty(queryFnContext, 'signal', {\n      enumerable: true,\n      get: function get() {\n        if (abortController) {\n          _this2.abortSignalConsumed = true;\n          return abortController.signal;\n        }\n\n        return undefined;\n      }\n    }); // Create fetch function\n\n    var fetchFn = function fetchFn() {\n      if (!_this2.options.queryFn) {\n        return Promise.reject('Missing queryFn');\n      }\n\n      _this2.abortSignalConsumed = false;\n      return _this2.options.queryFn(queryFnContext);\n    }; // Trigger behavior hook\n\n\n    var context = {\n      fetchOptions: fetchOptions,\n      options: this.options,\n      queryKey: queryKey,\n      state: this.state,\n      fetchFn: fetchFn,\n      meta: this.meta\n    };\n\n    if ((_this$options$behavio = this.options.behavior) == null ? void 0 : _this$options$behavio.onFetch) {\n      var _this$options$behavio2;\n\n      (_this$options$behavio2 = this.options.behavior) == null ? void 0 : _this$options$behavio2.onFetch(context);\n    } // Store state in case the current fetch needs to be reverted\n\n\n    this.revertState = this.state; // Set to fetching state if not already in it\n\n    if (!this.state.isFetching || this.state.fetchMeta !== ((_context$fetchOptions = context.fetchOptions) == null ? void 0 : _context$fetchOptions.meta)) {\n      var _context$fetchOptions2;\n\n      this.dispatch({\n        type: 'fetch',\n        meta: (_context$fetchOptions2 = context.fetchOptions) == null ? void 0 : _context$fetchOptions2.meta\n      });\n    } // Try to fetch the data\n\n\n    this.retryer = new Retryer({\n      fn: context.fetchFn,\n      abort: abortController == null ? void 0 : (_abortController$abor = abortController.abort) == null ? void 0 : _abortController$abor.bind(abortController),\n      onSuccess: function onSuccess(data) {\n        _this2.setData(data); // Notify cache callback\n\n\n        _this2.cache.config.onSuccess == null ? void 0 : _this2.cache.config.onSuccess(data, _this2); // Remove query after fetching if cache time is 0\n\n        if (_this2.cacheTime === 0) {\n          _this2.optionalRemove();\n        }\n      },\n      onError: function onError(error) {\n        // Optimistically update state if needed\n        if (!(isCancelledError(error) && error.silent)) {\n          _this2.dispatch({\n            type: 'error',\n            error: error\n          });\n        }\n\n        if (!isCancelledError(error)) {\n          // Notify cache callback\n          _this2.cache.config.onError == null ? void 0 : _this2.cache.config.onError(error, _this2); // Log error\n\n          getLogger().error(error);\n        } // Remove query after fetching if cache time is 0\n\n\n        if (_this2.cacheTime === 0) {\n          _this2.optionalRemove();\n        }\n      },\n      onFail: function onFail() {\n        _this2.dispatch({\n          type: 'failed'\n        });\n      },\n      onPause: function onPause() {\n        _this2.dispatch({\n          type: 'pause'\n        });\n      },\n      onContinue: function onContinue() {\n        _this2.dispatch({\n          type: 'continue'\n        });\n      },\n      retry: context.options.retry,\n      retryDelay: context.options.retryDelay\n    });\n    this.promise = this.retryer.promise;\n    return this.promise;\n  };\n\n  _proto.dispatch = function dispatch(action) {\n    var _this3 = this;\n\n    this.state = this.reducer(this.state, action);\n    notifyManager.batch(function () {\n      _this3.observers.forEach(function (observer) {\n        observer.onQueryUpdate(action);\n      });\n\n      _this3.cache.notify({\n        query: _this3,\n        type: 'queryUpdated',\n        action: action\n      });\n    });\n  };\n\n  _proto.getDefaultState = function getDefaultState(options) {\n    var data = typeof options.initialData === 'function' ? options.initialData() : options.initialData;\n    var hasInitialData = typeof options.initialData !== 'undefined';\n    var initialDataUpdatedAt = hasInitialData ? typeof options.initialDataUpdatedAt === 'function' ? options.initialDataUpdatedAt() : options.initialDataUpdatedAt : 0;\n    var hasData = typeof data !== 'undefined';\n    return {\n      data: data,\n      dataUpdateCount: 0,\n      dataUpdatedAt: hasData ? initialDataUpdatedAt != null ? initialDataUpdatedAt : Date.now() : 0,\n      error: null,\n      errorUpdateCount: 0,\n      errorUpdatedAt: 0,\n      fetchFailureCount: 0,\n      fetchMeta: null,\n      isFetching: false,\n      isInvalidated: false,\n      isPaused: false,\n      status: hasData ? 'success' : 'idle'\n    };\n  };\n\n  _proto.reducer = function reducer(state, action) {\n    var _action$meta, _action$dataUpdatedAt;\n\n    switch (action.type) {\n      case 'failed':\n        return _extends({}, state, {\n          fetchFailureCount: state.fetchFailureCount + 1\n        });\n\n      case 'pause':\n        return _extends({}, state, {\n          isPaused: true\n        });\n\n      case 'continue':\n        return _extends({}, state, {\n          isPaused: false\n        });\n\n      case 'fetch':\n        return _extends({}, state, {\n          fetchFailureCount: 0,\n          fetchMeta: (_action$meta = action.meta) != null ? _action$meta : null,\n          isFetching: true,\n          isPaused: false\n        }, !state.dataUpdatedAt && {\n          error: null,\n          status: 'loading'\n        });\n\n      case 'success':\n        return _extends({}, state, {\n          data: action.data,\n          dataUpdateCount: state.dataUpdateCount + 1,\n          dataUpdatedAt: (_action$dataUpdatedAt = action.dataUpdatedAt) != null ? _action$dataUpdatedAt : Date.now(),\n          error: null,\n          fetchFailureCount: 0,\n          isFetching: false,\n          isInvalidated: false,\n          isPaused: false,\n          status: 'success'\n        });\n\n      case 'error':\n        var error = action.error;\n\n        if (isCancelledError(error) && error.revert && this.revertState) {\n          return _extends({}, this.revertState);\n        }\n\n        return _extends({}, state, {\n          error: error,\n          errorUpdateCount: state.errorUpdateCount + 1,\n          errorUpdatedAt: Date.now(),\n          fetchFailureCount: state.fetchFailureCount + 1,\n          isFetching: false,\n          isPaused: false,\n          status: 'error'\n        });\n\n      case 'invalidate':\n        return _extends({}, state, {\n          isInvalidated: true\n        });\n\n      case 'setState':\n        return _extends({}, state, action.state);\n\n      default:\n        return state;\n    }\n  };\n\n  return Query;\n}();","import _inheritsLoose from \"@babel/runtime/helpers/esm/inheritsLoose\";\nimport { hashQueryKeyByOptions, matchQuery, parseFilterArgs } from './utils';\nimport { Query } from './query';\nimport { notifyManager } from './notifyManager';\nimport { Subscribable } from './subscribable';\n// CLASS\nexport var QueryCache = /*#__PURE__*/function (_Subscribable) {\n  _inheritsLoose(QueryCache, _Subscribable);\n\n  function QueryCache(config) {\n    var _this;\n\n    _this = _Subscribable.call(this) || this;\n    _this.config = config || {};\n    _this.queries = [];\n    _this.queriesMap = {};\n    return _this;\n  }\n\n  var _proto = QueryCache.prototype;\n\n  _proto.build = function build(client, options, state) {\n    var _options$queryHash;\n\n    var queryKey = options.queryKey;\n    var queryHash = (_options$queryHash = options.queryHash) != null ? _options$queryHash : hashQueryKeyByOptions(queryKey, options);\n    var query = this.get(queryHash);\n\n    if (!query) {\n      query = new Query({\n        cache: this,\n        queryKey: queryKey,\n        queryHash: queryHash,\n        options: client.defaultQueryOptions(options),\n        state: state,\n        defaultOptions: client.getQueryDefaults(queryKey),\n        meta: options.meta\n      });\n      this.add(query);\n    }\n\n    return query;\n  };\n\n  _proto.add = function add(query) {\n    if (!this.queriesMap[query.queryHash]) {\n      this.queriesMap[query.queryHash] = query;\n      this.queries.push(query);\n      this.notify({\n        type: 'queryAdded',\n        query: query\n      });\n    }\n  };\n\n  _proto.remove = function remove(query) {\n    var queryInMap = this.queriesMap[query.queryHash];\n\n    if (queryInMap) {\n      query.destroy();\n      this.queries = this.queries.filter(function (x) {\n        return x !== query;\n      });\n\n      if (queryInMap === query) {\n        delete this.queriesMap[query.queryHash];\n      }\n\n      this.notify({\n        type: 'queryRemoved',\n        query: query\n      });\n    }\n  };\n\n  _proto.clear = function clear() {\n    var _this2 = this;\n\n    notifyManager.batch(function () {\n      _this2.queries.forEach(function (query) {\n        _this2.remove(query);\n      });\n    });\n  };\n\n  _proto.get = function get(queryHash) {\n    return this.queriesMap[queryHash];\n  };\n\n  _proto.getAll = function getAll() {\n    return this.queries;\n  };\n\n  _proto.find = function find(arg1, arg2) {\n    var _parseFilterArgs = parseFilterArgs(arg1, arg2),\n        filters = _parseFilterArgs[0];\n\n    if (typeof filters.exact === 'undefined') {\n      filters.exact = true;\n    }\n\n    return this.queries.find(function (query) {\n      return matchQuery(filters, query);\n    });\n  };\n\n  _proto.findAll = function findAll(arg1, arg2) {\n    var _parseFilterArgs2 = parseFilterArgs(arg1, arg2),\n        filters = _parseFilterArgs2[0];\n\n    return Object.keys(filters).length > 0 ? this.queries.filter(function (query) {\n      return matchQuery(filters, query);\n    }) : this.queries;\n  };\n\n  _proto.notify = function notify(event) {\n    var _this3 = this;\n\n    notifyManager.batch(function () {\n      _this3.listeners.forEach(function (listener) {\n        listener(event);\n      });\n    });\n  };\n\n  _proto.onFocus = function onFocus() {\n    var _this4 = this;\n\n    notifyManager.batch(function () {\n      _this4.queries.forEach(function (query) {\n        query.onFocus();\n      });\n    });\n  };\n\n  _proto.onOnline = function onOnline() {\n    var _this5 = this;\n\n    notifyManager.batch(function () {\n      _this5.queries.forEach(function (query) {\n        query.onOnline();\n      });\n    });\n  };\n\n  return QueryCache;\n}(Subscribable);","import _extends from \"@babel/runtime/helpers/esm/extends\";\nimport { getLogger } from './logger';\nimport { notifyManager } from './notifyManager';\nimport { Retryer } from './retryer';\nimport { noop } from './utils'; // TYPES\n\n// CLASS\nexport var Mutation = /*#__PURE__*/function () {\n  function Mutation(config) {\n    this.options = _extends({}, config.defaultOptions, config.options);\n    this.mutationId = config.mutationId;\n    this.mutationCache = config.mutationCache;\n    this.observers = [];\n    this.state = config.state || getDefaultState();\n    this.meta = config.meta;\n  }\n\n  var _proto = Mutation.prototype;\n\n  _proto.setState = function setState(state) {\n    this.dispatch({\n      type: 'setState',\n      state: state\n    });\n  };\n\n  _proto.addObserver = function addObserver(observer) {\n    if (this.observers.indexOf(observer) === -1) {\n      this.observers.push(observer);\n    }\n  };\n\n  _proto.removeObserver = function removeObserver(observer) {\n    this.observers = this.observers.filter(function (x) {\n      return x !== observer;\n    });\n  };\n\n  _proto.cancel = function cancel() {\n    if (this.retryer) {\n      this.retryer.cancel();\n      return this.retryer.promise.then(noop).catch(noop);\n    }\n\n    return Promise.resolve();\n  };\n\n  _proto.continue = function _continue() {\n    if (this.retryer) {\n      this.retryer.continue();\n      return this.retryer.promise;\n    }\n\n    return this.execute();\n  };\n\n  _proto.execute = function execute() {\n    var _this = this;\n\n    var data;\n    var restored = this.state.status === 'loading';\n    var promise = Promise.resolve();\n\n    if (!restored) {\n      this.dispatch({\n        type: 'loading',\n        variables: this.options.variables\n      });\n      promise = promise.then(function () {\n        // Notify cache callback\n        _this.mutationCache.config.onMutate == null ? void 0 : _this.mutationCache.config.onMutate(_this.state.variables, _this);\n      }).then(function () {\n        return _this.options.onMutate == null ? void 0 : _this.options.onMutate(_this.state.variables);\n      }).then(function (context) {\n        if (context !== _this.state.context) {\n          _this.dispatch({\n            type: 'loading',\n            context: context,\n            variables: _this.state.variables\n          });\n        }\n      });\n    }\n\n    return promise.then(function () {\n      return _this.executeMutation();\n    }).then(function (result) {\n      data = result; // Notify cache callback\n\n      _this.mutationCache.config.onSuccess == null ? void 0 : _this.mutationCache.config.onSuccess(data, _this.state.variables, _this.state.context, _this);\n    }).then(function () {\n      return _this.options.onSuccess == null ? void 0 : _this.options.onSuccess(data, _this.state.variables, _this.state.context);\n    }).then(function () {\n      return _this.options.onSettled == null ? void 0 : _this.options.onSettled(data, null, _this.state.variables, _this.state.context);\n    }).then(function () {\n      _this.dispatch({\n        type: 'success',\n        data: data\n      });\n\n      return data;\n    }).catch(function (error) {\n      // Notify cache callback\n      _this.mutationCache.config.onError == null ? void 0 : _this.mutationCache.config.onError(error, _this.state.variables, _this.state.context, _this); // Log error\n\n      getLogger().error(error);\n      return Promise.resolve().then(function () {\n        return _this.options.onError == null ? void 0 : _this.options.onError(error, _this.state.variables, _this.state.context);\n      }).then(function () {\n        return _this.options.onSettled == null ? void 0 : _this.options.onSettled(undefined, error, _this.state.variables, _this.state.context);\n      }).then(function () {\n        _this.dispatch({\n          type: 'error',\n          error: error\n        });\n\n        throw error;\n      });\n    });\n  };\n\n  _proto.executeMutation = function executeMutation() {\n    var _this2 = this,\n        _this$options$retry;\n\n    this.retryer = new Retryer({\n      fn: function fn() {\n        if (!_this2.options.mutationFn) {\n          return Promise.reject('No mutationFn found');\n        }\n\n        return _this2.options.mutationFn(_this2.state.variables);\n      },\n      onFail: function onFail() {\n        _this2.dispatch({\n          type: 'failed'\n        });\n      },\n      onPause: function onPause() {\n        _this2.dispatch({\n          type: 'pause'\n        });\n      },\n      onContinue: function onContinue() {\n        _this2.dispatch({\n          type: 'continue'\n        });\n      },\n      retry: (_this$options$retry = this.options.retry) != null ? _this$options$retry : 0,\n      retryDelay: this.options.retryDelay\n    });\n    return this.retryer.promise;\n  };\n\n  _proto.dispatch = function dispatch(action) {\n    var _this3 = this;\n\n    this.state = reducer(this.state, action);\n    notifyManager.batch(function () {\n      _this3.observers.forEach(function (observer) {\n        observer.onMutationUpdate(action);\n      });\n\n      _this3.mutationCache.notify(_this3);\n    });\n  };\n\n  return Mutation;\n}();\nexport function getDefaultState() {\n  return {\n    context: undefined,\n    data: undefined,\n    error: null,\n    failureCount: 0,\n    isPaused: false,\n    status: 'idle',\n    variables: undefined\n  };\n}\n\nfunction reducer(state, action) {\n  switch (action.type) {\n    case 'failed':\n      return _extends({}, state, {\n        failureCount: state.failureCount + 1\n      });\n\n    case 'pause':\n      return _extends({}, state, {\n        isPaused: true\n      });\n\n    case 'continue':\n      return _extends({}, state, {\n        isPaused: false\n      });\n\n    case 'loading':\n      return _extends({}, state, {\n        context: action.context,\n        data: undefined,\n        error: null,\n        isPaused: false,\n        status: 'loading',\n        variables: action.variables\n      });\n\n    case 'success':\n      return _extends({}, state, {\n        data: action.data,\n        error: null,\n        status: 'success',\n        isPaused: false\n      });\n\n    case 'error':\n      return _extends({}, state, {\n        data: undefined,\n        error: action.error,\n        failureCount: state.failureCount + 1,\n        isPaused: false,\n        status: 'error'\n      });\n\n    case 'setState':\n      return _extends({}, state, action.state);\n\n    default:\n      return state;\n  }\n}","import _inheritsLoose from \"@babel/runtime/helpers/esm/inheritsLoose\";\nimport { notifyManager } from './notifyManager';\nimport { Mutation } from './mutation';\nimport { matchMutation, noop } from './utils';\nimport { Subscribable } from './subscribable'; // TYPES\n\n// CLASS\nexport var MutationCache = /*#__PURE__*/function (_Subscribable) {\n  _inheritsLoose(MutationCache, _Subscribable);\n\n  function MutationCache(config) {\n    var _this;\n\n    _this = _Subscribable.call(this) || this;\n    _this.config = config || {};\n    _this.mutations = [];\n    _this.mutationId = 0;\n    return _this;\n  }\n\n  var _proto = MutationCache.prototype;\n\n  _proto.build = function build(client, options, state) {\n    var mutation = new Mutation({\n      mutationCache: this,\n      mutationId: ++this.mutationId,\n      options: client.defaultMutationOptions(options),\n      state: state,\n      defaultOptions: options.mutationKey ? client.getMutationDefaults(options.mutationKey) : undefined,\n      meta: options.meta\n    });\n    this.add(mutation);\n    return mutation;\n  };\n\n  _proto.add = function add(mutation) {\n    this.mutations.push(mutation);\n    this.notify(mutation);\n  };\n\n  _proto.remove = function remove(mutation) {\n    this.mutations = this.mutations.filter(function (x) {\n      return x !== mutation;\n    });\n    mutation.cancel();\n    this.notify(mutation);\n  };\n\n  _proto.clear = function clear() {\n    var _this2 = this;\n\n    notifyManager.batch(function () {\n      _this2.mutations.forEach(function (mutation) {\n        _this2.remove(mutation);\n      });\n    });\n  };\n\n  _proto.getAll = function getAll() {\n    return this.mutations;\n  };\n\n  _proto.find = function find(filters) {\n    if (typeof filters.exact === 'undefined') {\n      filters.exact = true;\n    }\n\n    return this.mutations.find(function (mutation) {\n      return matchMutation(filters, mutation);\n    });\n  };\n\n  _proto.findAll = function findAll(filters) {\n    return this.mutations.filter(function (mutation) {\n      return matchMutation(filters, mutation);\n    });\n  };\n\n  _proto.notify = function notify(mutation) {\n    var _this3 = this;\n\n    notifyManager.batch(function () {\n      _this3.listeners.forEach(function (listener) {\n        listener(mutation);\n      });\n    });\n  };\n\n  _proto.onFocus = function onFocus() {\n    this.resumePausedMutations();\n  };\n\n  _proto.onOnline = function onOnline() {\n    this.resumePausedMutations();\n  };\n\n  _proto.resumePausedMutations = function resumePausedMutations() {\n    var pausedMutations = this.mutations.filter(function (x) {\n      return x.state.isPaused;\n    });\n    return notifyManager.batch(function () {\n      return pausedMutations.reduce(function (promise, mutation) {\n        return promise.then(function () {\n          return mutation.continue().catch(noop);\n        });\n      }, Promise.resolve());\n    });\n  };\n\n  return MutationCache;\n}(Subscribable);","import { isCancelable } from './retryer';\nimport { getAbortController } from './utils';\nexport function infiniteQueryBehavior() {\n  return {\n    onFetch: function onFetch(context) {\n      context.fetchFn = function () {\n        var _context$fetchOptions, _context$fetchOptions2, _context$fetchOptions3, _context$fetchOptions4, _context$state$data, _context$state$data2;\n\n        var refetchPage = (_context$fetchOptions = context.fetchOptions) == null ? void 0 : (_context$fetchOptions2 = _context$fetchOptions.meta) == null ? void 0 : _context$fetchOptions2.refetchPage;\n        var fetchMore = (_context$fetchOptions3 = context.fetchOptions) == null ? void 0 : (_context$fetchOptions4 = _context$fetchOptions3.meta) == null ? void 0 : _context$fetchOptions4.fetchMore;\n        var pageParam = fetchMore == null ? void 0 : fetchMore.pageParam;\n        var isFetchingNextPage = (fetchMore == null ? void 0 : fetchMore.direction) === 'forward';\n        var isFetchingPreviousPage = (fetchMore == null ? void 0 : fetchMore.direction) === 'backward';\n        var oldPages = ((_context$state$data = context.state.data) == null ? void 0 : _context$state$data.pages) || [];\n        var oldPageParams = ((_context$state$data2 = context.state.data) == null ? void 0 : _context$state$data2.pageParams) || [];\n        var abortController = getAbortController();\n        var abortSignal = abortController == null ? void 0 : abortController.signal;\n        var newPageParams = oldPageParams;\n        var cancelled = false; // Get query function\n\n        var queryFn = context.options.queryFn || function () {\n          return Promise.reject('Missing queryFn');\n        };\n\n        var buildNewPages = function buildNewPages(pages, param, page, previous) {\n          newPageParams = previous ? [param].concat(newPageParams) : [].concat(newPageParams, [param]);\n          return previous ? [page].concat(pages) : [].concat(pages, [page]);\n        }; // Create function to fetch a page\n\n\n        var fetchPage = function fetchPage(pages, manual, param, previous) {\n          if (cancelled) {\n            return Promise.reject('Cancelled');\n          }\n\n          if (typeof param === 'undefined' && !manual && pages.length) {\n            return Promise.resolve(pages);\n          }\n\n          var queryFnContext = {\n            queryKey: context.queryKey,\n            signal: abortSignal,\n            pageParam: param,\n            meta: context.meta\n          };\n          var queryFnResult = queryFn(queryFnContext);\n          var promise = Promise.resolve(queryFnResult).then(function (page) {\n            return buildNewPages(pages, param, page, previous);\n          });\n\n          if (isCancelable(queryFnResult)) {\n            var promiseAsAny = promise;\n            promiseAsAny.cancel = queryFnResult.cancel;\n          }\n\n          return promise;\n        };\n\n        var promise; // Fetch first page?\n\n        if (!oldPages.length) {\n          promise = fetchPage([]);\n        } // Fetch next page?\n        else if (isFetchingNextPage) {\n            var manual = typeof pageParam !== 'undefined';\n            var param = manual ? pageParam : getNextPageParam(context.options, oldPages);\n            promise = fetchPage(oldPages, manual, param);\n          } // Fetch previous page?\n          else if (isFetchingPreviousPage) {\n              var _manual = typeof pageParam !== 'undefined';\n\n              var _param = _manual ? pageParam : getPreviousPageParam(context.options, oldPages);\n\n              promise = fetchPage(oldPages, _manual, _param, true);\n            } // Refetch pages\n            else {\n                (function () {\n                  newPageParams = [];\n                  var manual = typeof context.options.getNextPageParam === 'undefined';\n                  var shouldFetchFirstPage = refetchPage && oldPages[0] ? refetchPage(oldPages[0], 0, oldPages) : true; // Fetch first page\n\n                  promise = shouldFetchFirstPage ? fetchPage([], manual, oldPageParams[0]) : Promise.resolve(buildNewPages([], oldPageParams[0], oldPages[0])); // Fetch remaining pages\n\n                  var _loop = function _loop(i) {\n                    promise = promise.then(function (pages) {\n                      var shouldFetchNextPage = refetchPage && oldPages[i] ? refetchPage(oldPages[i], i, oldPages) : true;\n\n                      if (shouldFetchNextPage) {\n                        var _param2 = manual ? oldPageParams[i] : getNextPageParam(context.options, pages);\n\n                        return fetchPage(pages, manual, _param2);\n                      }\n\n                      return Promise.resolve(buildNewPages(pages, oldPageParams[i], oldPages[i]));\n                    });\n                  };\n\n                  for (var i = 1; i < oldPages.length; i++) {\n                    _loop(i);\n                  }\n                })();\n              }\n\n        var finalPromise = promise.then(function (pages) {\n          return {\n            pages: pages,\n            pageParams: newPageParams\n          };\n        });\n        var finalPromiseAsAny = finalPromise;\n\n        finalPromiseAsAny.cancel = function () {\n          cancelled = true;\n          abortController == null ? void 0 : abortController.abort();\n\n          if (isCancelable(promise)) {\n            promise.cancel();\n          }\n        };\n\n        return finalPromise;\n      };\n    }\n  };\n}\nexport function getNextPageParam(options, pages) {\n  return options.getNextPageParam == null ? void 0 : options.getNextPageParam(pages[pages.length - 1], pages);\n}\nexport function getPreviousPageParam(options, pages) {\n  return options.getPreviousPageParam == null ? void 0 : options.getPreviousPageParam(pages[0], pages);\n}\n/**\n * Checks if there is a next page.\n * Returns `undefined` if it cannot be determined.\n */\n\nexport function hasNextPage(options, pages) {\n  if (options.getNextPageParam && Array.isArray(pages)) {\n    var nextPageParam = getNextPageParam(options, pages);\n    return typeof nextPageParam !== 'undefined' && nextPageParam !== null && nextPageParam !== false;\n  }\n}\n/**\n * Checks if there is a previous page.\n * Returns `undefined` if it cannot be determined.\n */\n\nexport function hasPreviousPage(options, pages) {\n  if (options.getPreviousPageParam && Array.isArray(pages)) {\n    var previousPageParam = getPreviousPageParam(options, pages);\n    return typeof previousPageParam !== 'undefined' && previousPageParam !== null && previousPageParam !== false;\n  }\n}","import _extends from \"@babel/runtime/helpers/esm/extends\";\nimport { hashQueryKey, noop, parseFilterArgs, parseQueryArgs, partialMatchKey, hashQueryKeyByOptions } from './utils';\nimport { QueryCache } from './queryCache';\nimport { MutationCache } from './mutationCache';\nimport { focusManager } from './focusManager';\nimport { onlineManager } from './onlineManager';\nimport { notifyManager } from './notifyManager';\nimport { infiniteQueryBehavior } from './infiniteQueryBehavior';\n// CLASS\nexport var QueryClient = /*#__PURE__*/function () {\n  function QueryClient(config) {\n    if (config === void 0) {\n      config = {};\n    }\n\n    this.queryCache = config.queryCache || new QueryCache();\n    this.mutationCache = config.mutationCache || new MutationCache();\n    this.defaultOptions = config.defaultOptions || {};\n    this.queryDefaults = [];\n    this.mutationDefaults = [];\n  }\n\n  var _proto = QueryClient.prototype;\n\n  _proto.mount = function mount() {\n    var _this = this;\n\n    this.unsubscribeFocus = focusManager.subscribe(function () {\n      if (focusManager.isFocused() && onlineManager.isOnline()) {\n        _this.mutationCache.onFocus();\n\n        _this.queryCache.onFocus();\n      }\n    });\n    this.unsubscribeOnline = onlineManager.subscribe(function () {\n      if (focusManager.isFocused() && onlineManager.isOnline()) {\n        _this.mutationCache.onOnline();\n\n        _this.queryCache.onOnline();\n      }\n    });\n  };\n\n  _proto.unmount = function unmount() {\n    var _this$unsubscribeFocu, _this$unsubscribeOnli;\n\n    (_this$unsubscribeFocu = this.unsubscribeFocus) == null ? void 0 : _this$unsubscribeFocu.call(this);\n    (_this$unsubscribeOnli = this.unsubscribeOnline) == null ? void 0 : _this$unsubscribeOnli.call(this);\n  };\n\n  _proto.isFetching = function isFetching(arg1, arg2) {\n    var _parseFilterArgs = parseFilterArgs(arg1, arg2),\n        filters = _parseFilterArgs[0];\n\n    filters.fetching = true;\n    return this.queryCache.findAll(filters).length;\n  };\n\n  _proto.isMutating = function isMutating(filters) {\n    return this.mutationCache.findAll(_extends({}, filters, {\n      fetching: true\n    })).length;\n  };\n\n  _proto.getQueryData = function getQueryData(queryKey, filters) {\n    var _this$queryCache$find;\n\n    return (_this$queryCache$find = this.queryCache.find(queryKey, filters)) == null ? void 0 : _this$queryCache$find.state.data;\n  };\n\n  _proto.getQueriesData = function getQueriesData(queryKeyOrFilters) {\n    return this.getQueryCache().findAll(queryKeyOrFilters).map(function (_ref) {\n      var queryKey = _ref.queryKey,\n          state = _ref.state;\n      var data = state.data;\n      return [queryKey, data];\n    });\n  };\n\n  _proto.setQueryData = function setQueryData(queryKey, updater, options) {\n    var parsedOptions = parseQueryArgs(queryKey);\n    var defaultedOptions = this.defaultQueryOptions(parsedOptions);\n    return this.queryCache.build(this, defaultedOptions).setData(updater, options);\n  };\n\n  _proto.setQueriesData = function setQueriesData(queryKeyOrFilters, updater, options) {\n    var _this2 = this;\n\n    return notifyManager.batch(function () {\n      return _this2.getQueryCache().findAll(queryKeyOrFilters).map(function (_ref2) {\n        var queryKey = _ref2.queryKey;\n        return [queryKey, _this2.setQueryData(queryKey, updater, options)];\n      });\n    });\n  };\n\n  _proto.getQueryState = function getQueryState(queryKey, filters) {\n    var _this$queryCache$find2;\n\n    return (_this$queryCache$find2 = this.queryCache.find(queryKey, filters)) == null ? void 0 : _this$queryCache$find2.state;\n  };\n\n  _proto.removeQueries = function removeQueries(arg1, arg2) {\n    var _parseFilterArgs2 = parseFilterArgs(arg1, arg2),\n        filters = _parseFilterArgs2[0];\n\n    var queryCache = this.queryCache;\n    notifyManager.batch(function () {\n      queryCache.findAll(filters).forEach(function (query) {\n        queryCache.remove(query);\n      });\n    });\n  };\n\n  _proto.resetQueries = function resetQueries(arg1, arg2, arg3) {\n    var _this3 = this;\n\n    var _parseFilterArgs3 = parseFilterArgs(arg1, arg2, arg3),\n        filters = _parseFilterArgs3[0],\n        options = _parseFilterArgs3[1];\n\n    var queryCache = this.queryCache;\n\n    var refetchFilters = _extends({}, filters, {\n      active: true\n    });\n\n    return notifyManager.batch(function () {\n      queryCache.findAll(filters).forEach(function (query) {\n        query.reset();\n      });\n      return _this3.refetchQueries(refetchFilters, options);\n    });\n  };\n\n  _proto.cancelQueries = function cancelQueries(arg1, arg2, arg3) {\n    var _this4 = this;\n\n    var _parseFilterArgs4 = parseFilterArgs(arg1, arg2, arg3),\n        filters = _parseFilterArgs4[0],\n        _parseFilterArgs4$ = _parseFilterArgs4[1],\n        cancelOptions = _parseFilterArgs4$ === void 0 ? {} : _parseFilterArgs4$;\n\n    if (typeof cancelOptions.revert === 'undefined') {\n      cancelOptions.revert = true;\n    }\n\n    var promises = notifyManager.batch(function () {\n      return _this4.queryCache.findAll(filters).map(function (query) {\n        return query.cancel(cancelOptions);\n      });\n    });\n    return Promise.all(promises).then(noop).catch(noop);\n  };\n\n  _proto.invalidateQueries = function invalidateQueries(arg1, arg2, arg3) {\n    var _ref3,\n        _filters$refetchActiv,\n        _filters$refetchInact,\n        _this5 = this;\n\n    var _parseFilterArgs5 = parseFilterArgs(arg1, arg2, arg3),\n        filters = _parseFilterArgs5[0],\n        options = _parseFilterArgs5[1];\n\n    var refetchFilters = _extends({}, filters, {\n      // if filters.refetchActive is not provided and filters.active is explicitly false,\n      // e.g. invalidateQueries({ active: false }), we don't want to refetch active queries\n      active: (_ref3 = (_filters$refetchActiv = filters.refetchActive) != null ? _filters$refetchActiv : filters.active) != null ? _ref3 : true,\n      inactive: (_filters$refetchInact = filters.refetchInactive) != null ? _filters$refetchInact : false\n    });\n\n    return notifyManager.batch(function () {\n      _this5.queryCache.findAll(filters).forEach(function (query) {\n        query.invalidate();\n      });\n\n      return _this5.refetchQueries(refetchFilters, options);\n    });\n  };\n\n  _proto.refetchQueries = function refetchQueries(arg1, arg2, arg3) {\n    var _this6 = this;\n\n    var _parseFilterArgs6 = parseFilterArgs(arg1, arg2, arg3),\n        filters = _parseFilterArgs6[0],\n        options = _parseFilterArgs6[1];\n\n    var promises = notifyManager.batch(function () {\n      return _this6.queryCache.findAll(filters).map(function (query) {\n        return query.fetch(undefined, _extends({}, options, {\n          meta: {\n            refetchPage: filters == null ? void 0 : filters.refetchPage\n          }\n        }));\n      });\n    });\n    var promise = Promise.all(promises).then(noop);\n\n    if (!(options == null ? void 0 : options.throwOnError)) {\n      promise = promise.catch(noop);\n    }\n\n    return promise;\n  };\n\n  _proto.fetchQuery = function fetchQuery(arg1, arg2, arg3) {\n    var parsedOptions = parseQueryArgs(arg1, arg2, arg3);\n    var defaultedOptions = this.defaultQueryOptions(parsedOptions); // https://github.com/tannerlinsley/react-query/issues/652\n\n    if (typeof defaultedOptions.retry === 'undefined') {\n      defaultedOptions.retry = false;\n    }\n\n    var query = this.queryCache.build(this, defaultedOptions);\n    return query.isStaleByTime(defaultedOptions.staleTime) ? query.fetch(defaultedOptions) : Promise.resolve(query.state.data);\n  };\n\n  _proto.prefetchQuery = function prefetchQuery(arg1, arg2, arg3) {\n    return this.fetchQuery(arg1, arg2, arg3).then(noop).catch(noop);\n  };\n\n  _proto.fetchInfiniteQuery = function fetchInfiniteQuery(arg1, arg2, arg3) {\n    var parsedOptions = parseQueryArgs(arg1, arg2, arg3);\n    parsedOptions.behavior = infiniteQueryBehavior();\n    return this.fetchQuery(parsedOptions);\n  };\n\n  _proto.prefetchInfiniteQuery = function prefetchInfiniteQuery(arg1, arg2, arg3) {\n    return this.fetchInfiniteQuery(arg1, arg2, arg3).then(noop).catch(noop);\n  };\n\n  _proto.cancelMutations = function cancelMutations() {\n    var _this7 = this;\n\n    var promises = notifyManager.batch(function () {\n      return _this7.mutationCache.getAll().map(function (mutation) {\n        return mutation.cancel();\n      });\n    });\n    return Promise.all(promises).then(noop).catch(noop);\n  };\n\n  _proto.resumePausedMutations = function resumePausedMutations() {\n    return this.getMutationCache().resumePausedMutations();\n  };\n\n  _proto.executeMutation = function executeMutation(options) {\n    return this.mutationCache.build(this, options).execute();\n  };\n\n  _proto.getQueryCache = function getQueryCache() {\n    return this.queryCache;\n  };\n\n  _proto.getMutationCache = function getMutationCache() {\n    return this.mutationCache;\n  };\n\n  _proto.getDefaultOptions = function getDefaultOptions() {\n    return this.defaultOptions;\n  };\n\n  _proto.setDefaultOptions = function setDefaultOptions(options) {\n    this.defaultOptions = options;\n  };\n\n  _proto.setQueryDefaults = function setQueryDefaults(queryKey, options) {\n    var result = this.queryDefaults.find(function (x) {\n      return hashQueryKey(queryKey) === hashQueryKey(x.queryKey);\n    });\n\n    if (result) {\n      result.defaultOptions = options;\n    } else {\n      this.queryDefaults.push({\n        queryKey: queryKey,\n        defaultOptions: options\n      });\n    }\n  };\n\n  _proto.getQueryDefaults = function getQueryDefaults(queryKey) {\n    var _this$queryDefaults$f;\n\n    return queryKey ? (_this$queryDefaults$f = this.queryDefaults.find(function (x) {\n      return partialMatchKey(queryKey, x.queryKey);\n    })) == null ? void 0 : _this$queryDefaults$f.defaultOptions : undefined;\n  };\n\n  _proto.setMutationDefaults = function setMutationDefaults(mutationKey, options) {\n    var result = this.mutationDefaults.find(function (x) {\n      return hashQueryKey(mutationKey) === hashQueryKey(x.mutationKey);\n    });\n\n    if (result) {\n      result.defaultOptions = options;\n    } else {\n      this.mutationDefaults.push({\n        mutationKey: mutationKey,\n        defaultOptions: options\n      });\n    }\n  };\n\n  _proto.getMutationDefaults = function getMutationDefaults(mutationKey) {\n    var _this$mutationDefault;\n\n    return mutationKey ? (_this$mutationDefault = this.mutationDefaults.find(function (x) {\n      return partialMatchKey(mutationKey, x.mutationKey);\n    })) == null ? void 0 : _this$mutationDefault.defaultOptions : undefined;\n  };\n\n  _proto.defaultQueryOptions = function defaultQueryOptions(options) {\n    if (options == null ? void 0 : options._defaulted) {\n      return options;\n    }\n\n    var defaultedOptions = _extends({}, this.defaultOptions.queries, this.getQueryDefaults(options == null ? void 0 : options.queryKey), options, {\n      _defaulted: true\n    });\n\n    if (!defaultedOptions.queryHash && defaultedOptions.queryKey) {\n      defaultedOptions.queryHash = hashQueryKeyByOptions(defaultedOptions.queryKey, defaultedOptions);\n    }\n\n    return defaultedOptions;\n  };\n\n  _proto.defaultQueryObserverOptions = function defaultQueryObserverOptions(options) {\n    return this.defaultQueryOptions(options);\n  };\n\n  _proto.defaultMutationOptions = function defaultMutationOptions(options) {\n    if (options == null ? void 0 : options._defaulted) {\n      return options;\n    }\n\n    return _extends({}, this.defaultOptions.mutations, this.getMutationDefaults(options == null ? void 0 : options.mutationKey), options, {\n      _defaulted: true\n    });\n  };\n\n  _proto.clear = function clear() {\n    this.queryCache.clear();\n    this.mutationCache.clear();\n  };\n\n  return QueryClient;\n}();","import _extends from \"@babel/runtime/helpers/esm/extends\";\n// TYPES\n// UTILS\nexport var isServer = typeof window === 'undefined';\nexport function noop() {\n  return undefined;\n}\nexport function functionalUpdate(updater, input) {\n  return typeof updater === 'function' ? updater(input) : updater;\n}\nexport function isValidTimeout(value) {\n  return typeof value === 'number' && value >= 0 && value !== Infinity;\n}\nexport function ensureQueryKeyArray(value) {\n  return Array.isArray(value) ? value : [value];\n}\nexport function difference(array1, array2) {\n  return array1.filter(function (x) {\n    return array2.indexOf(x) === -1;\n  });\n}\nexport function replaceAt(array, index, value) {\n  var copy = array.slice(0);\n  copy[index] = value;\n  return copy;\n}\nexport function timeUntilStale(updatedAt, staleTime) {\n  return Math.max(updatedAt + (staleTime || 0) - Date.now(), 0);\n}\nexport function parseQueryArgs(arg1, arg2, arg3) {\n  if (!isQueryKey(arg1)) {\n    return arg1;\n  }\n\n  if (typeof arg2 === 'function') {\n    return _extends({}, arg3, {\n      queryKey: arg1,\n      queryFn: arg2\n    });\n  }\n\n  return _extends({}, arg2, {\n    queryKey: arg1\n  });\n}\nexport function parseMutationArgs(arg1, arg2, arg3) {\n  if (isQueryKey(arg1)) {\n    if (typeof arg2 === 'function') {\n      return _extends({}, arg3, {\n        mutationKey: arg1,\n        mutationFn: arg2\n      });\n    }\n\n    return _extends({}, arg2, {\n      mutationKey: arg1\n    });\n  }\n\n  if (typeof arg1 === 'function') {\n    return _extends({}, arg2, {\n      mutationFn: arg1\n    });\n  }\n\n  return _extends({}, arg1);\n}\nexport function parseFilterArgs(arg1, arg2, arg3) {\n  return isQueryKey(arg1) ? [_extends({}, arg2, {\n    queryKey: arg1\n  }), arg3] : [arg1 || {}, arg2];\n}\nexport function parseMutationFilterArgs(arg1, arg2) {\n  return isQueryKey(arg1) ? _extends({}, arg2, {\n    mutationKey: arg1\n  }) : arg1;\n}\nexport function mapQueryStatusFilter(active, inactive) {\n  if (active === true && inactive === true || active == null && inactive == null) {\n    return 'all';\n  } else if (active === false && inactive === false) {\n    return 'none';\n  } else {\n    // At this point, active|inactive can only be true|false or false|true\n    // so, when only one value is provided, the missing one has to be the negated value\n    var isActive = active != null ? active : !inactive;\n    return isActive ? 'active' : 'inactive';\n  }\n}\nexport function matchQuery(filters, query) {\n  var active = filters.active,\n      exact = filters.exact,\n      fetching = filters.fetching,\n      inactive = filters.inactive,\n      predicate = filters.predicate,\n      queryKey = filters.queryKey,\n      stale = filters.stale;\n\n  if (isQueryKey(queryKey)) {\n    if (exact) {\n      if (query.queryHash !== hashQueryKeyByOptions(queryKey, query.options)) {\n        return false;\n      }\n    } else if (!partialMatchKey(query.queryKey, queryKey)) {\n      return false;\n    }\n  }\n\n  var queryStatusFilter = mapQueryStatusFilter(active, inactive);\n\n  if (queryStatusFilter === 'none') {\n    return false;\n  } else if (queryStatusFilter !== 'all') {\n    var isActive = query.isActive();\n\n    if (queryStatusFilter === 'active' && !isActive) {\n      return false;\n    }\n\n    if (queryStatusFilter === 'inactive' && isActive) {\n      return false;\n    }\n  }\n\n  if (typeof stale === 'boolean' && query.isStale() !== stale) {\n    return false;\n  }\n\n  if (typeof fetching === 'boolean' && query.isFetching() !== fetching) {\n    return false;\n  }\n\n  if (predicate && !predicate(query)) {\n    return false;\n  }\n\n  return true;\n}\nexport function matchMutation(filters, mutation) {\n  var exact = filters.exact,\n      fetching = filters.fetching,\n      predicate = filters.predicate,\n      mutationKey = filters.mutationKey;\n\n  if (isQueryKey(mutationKey)) {\n    if (!mutation.options.mutationKey) {\n      return false;\n    }\n\n    if (exact) {\n      if (hashQueryKey(mutation.options.mutationKey) !== hashQueryKey(mutationKey)) {\n        return false;\n      }\n    } else if (!partialMatchKey(mutation.options.mutationKey, mutationKey)) {\n      return false;\n    }\n  }\n\n  if (typeof fetching === 'boolean' && mutation.state.status === 'loading' !== fetching) {\n    return false;\n  }\n\n  if (predicate && !predicate(mutation)) {\n    return false;\n  }\n\n  return true;\n}\nexport function hashQueryKeyByOptions(queryKey, options) {\n  var hashFn = (options == null ? void 0 : options.queryKeyHashFn) || hashQueryKey;\n  return hashFn(queryKey);\n}\n/**\n * Default query keys hash function.\n */\n\nexport function hashQueryKey(queryKey) {\n  var asArray = ensureQueryKeyArray(queryKey);\n  return stableValueHash(asArray);\n}\n/**\n * Hashes the value into a stable hash.\n */\n\nexport function stableValueHash(value) {\n  return JSON.stringify(value, function (_, val) {\n    return isPlainObject(val) ? Object.keys(val).sort().reduce(function (result, key) {\n      result[key] = val[key];\n      return result;\n    }, {}) : val;\n  });\n}\n/**\n * Checks if key `b` partially matches with key `a`.\n */\n\nexport function partialMatchKey(a, b) {\n  return partialDeepEqual(ensureQueryKeyArray(a), ensureQueryKeyArray(b));\n}\n/**\n * Checks if `b` partially matches with `a`.\n */\n\nexport function partialDeepEqual(a, b) {\n  if (a === b) {\n    return true;\n  }\n\n  if (typeof a !== typeof b) {\n    return false;\n  }\n\n  if (a && b && typeof a === 'object' && typeof b === 'object') {\n    return !Object.keys(b).some(function (key) {\n      return !partialDeepEqual(a[key], b[key]);\n    });\n  }\n\n  return false;\n}\n/**\n * This function returns `a` if `b` is deeply equal.\n * If not, it will replace any deeply equal children of `b` with those of `a`.\n * This can be used for structural sharing between JSON values for example.\n */\n\nexport function replaceEqualDeep(a, b) {\n  if (a === b) {\n    return a;\n  }\n\n  var array = Array.isArray(a) && Array.isArray(b);\n\n  if (array || isPlainObject(a) && isPlainObject(b)) {\n    var aSize = array ? a.length : Object.keys(a).length;\n    var bItems = array ? b : Object.keys(b);\n    var bSize = bItems.length;\n    var copy = array ? [] : {};\n    var equalItems = 0;\n\n    for (var i = 0; i < bSize; i++) {\n      var key = array ? i : bItems[i];\n      copy[key] = replaceEqualDeep(a[key], b[key]);\n\n      if (copy[key] === a[key]) {\n        equalItems++;\n      }\n    }\n\n    return aSize === bSize && equalItems === aSize ? a : copy;\n  }\n\n  return b;\n}\n/**\n * Shallow compare objects. Only works with objects that always have the same properties.\n */\n\nexport function shallowEqualObjects(a, b) {\n  if (a && !b || b && !a) {\n    return false;\n  }\n\n  for (var key in a) {\n    if (a[key] !== b[key]) {\n      return false;\n    }\n  }\n\n  return true;\n} // Copied from: https://github.com/jonschlinkert/is-plain-object\n\nexport function isPlainObject(o) {\n  if (!hasObjectPrototype(o)) {\n    return false;\n  } // If has modified constructor\n\n\n  var ctor = o.constructor;\n\n  if (typeof ctor === 'undefined') {\n    return true;\n  } // If has modified prototype\n\n\n  var prot = ctor.prototype;\n\n  if (!hasObjectPrototype(prot)) {\n    return false;\n  } // If constructor does not have an Object-specific method\n\n\n  if (!prot.hasOwnProperty('isPrototypeOf')) {\n    return false;\n  } // Most likely a plain Object\n\n\n  return true;\n}\n\nfunction hasObjectPrototype(o) {\n  return Object.prototype.toString.call(o) === '[object Object]';\n}\n\nexport function isQueryKey(value) {\n  return typeof value === 'string' || Array.isArray(value);\n}\nexport function isError(value) {\n  return value instanceof Error;\n}\nexport function sleep(timeout) {\n  return new Promise(function (resolve) {\n    setTimeout(resolve, timeout);\n  });\n}\n/**\n * Schedules a microtask.\n * This can be useful to schedule state updates after rendering.\n */\n\nexport function scheduleMicrotask(callback) {\n  Promise.resolve().then(callback).catch(function (error) {\n    return setTimeout(function () {\n      throw error;\n    });\n  });\n}\nexport function getAbortController() {\n  if (typeof AbortController === 'function') {\n    return new AbortController();\n  }\n}","import ReactDOM from 'react-dom';\nexport var unstable_batchedUpdates = ReactDOM.unstable_batchedUpdates;","import { notifyManager } from '../core';\nimport { unstable_batchedUpdates } from './reactBatchedUpdates';\nnotifyManager.setBatchNotifyFunction(unstable_batchedUpdates);","export var logger = console;","import { setLogger } from '../core';\nimport { logger } from './logger';\nsetLogger(logger);","import React from 'react';\nvar defaultContext = /*#__PURE__*/React.createContext(undefined);\nvar QueryClientSharingContext = /*#__PURE__*/React.createContext(false); // if contextSharing is on, we share the first and at least one\n// instance of the context across the window\n// to ensure that if React Query is used across\n// different bundles or microfrontends they will\n// all use the same **instance** of context, regardless\n// of module scoping.\n\nfunction getQueryClientContext(contextSharing) {\n  if (contextSharing && typeof window !== 'undefined') {\n    if (!window.ReactQueryClientContext) {\n      window.ReactQueryClientContext = defaultContext;\n    }\n\n    return window.ReactQueryClientContext;\n  }\n\n  return defaultContext;\n}\n\nexport var useQueryClient = function useQueryClient() {\n  var queryClient = React.useContext(getQueryClientContext(React.useContext(QueryClientSharingContext)));\n\n  if (!queryClient) {\n    throw new Error('No QueryClient set, use QueryClientProvider to set one');\n  }\n\n  return queryClient;\n};\nexport var QueryClientProvider = function QueryClientProvider(_ref) {\n  var client = _ref.client,\n      _ref$contextSharing = _ref.contextSharing,\n      contextSharing = _ref$contextSharing === void 0 ? false : _ref$contextSharing,\n      children = _ref.children;\n  React.useEffect(function () {\n    client.mount();\n    return function () {\n      client.unmount();\n    };\n  }, [client]);\n  var Context = getQueryClientContext(contextSharing);\n  return /*#__PURE__*/React.createElement(QueryClientSharingContext.Provider, {\n    value: contextSharing\n  }, /*#__PURE__*/React.createElement(Context.Provider, {\n    value: client\n  }, children));\n};","/**\n * @license React\n * react-jsx-runtime.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n'use strict';var f=require(\"react\"),k=Symbol.for(\"react.element\"),l=Symbol.for(\"react.fragment\"),m=Object.prototype.hasOwnProperty,n=f.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,p={key:!0,ref:!0,__self:!0,__source:!0};\nfunction q(c,a,g){var b,d={},e=null,h=null;void 0!==g&&(e=\"\"+g);void 0!==a.key&&(e=\"\"+a.key);void 0!==a.ref&&(h=a.ref);for(b in a)m.call(a,b)&&!p.hasOwnProperty(b)&&(d[b]=a[b]);if(c&&c.defaultProps)for(b in a=c.defaultProps,a)void 0===d[b]&&(d[b]=a[b]);return{$$typeof:k,type:c,key:e,ref:h,props:d,_owner:n.current}}exports.Fragment=l;exports.jsx=q;exports.jsxs=q;\n","/**\n * @license React\n * react.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n'use strict';var l=Symbol.for(\"react.element\"),n=Symbol.for(\"react.portal\"),p=Symbol.for(\"react.fragment\"),q=Symbol.for(\"react.strict_mode\"),r=Symbol.for(\"react.profiler\"),t=Symbol.for(\"react.provider\"),u=Symbol.for(\"react.context\"),v=Symbol.for(\"react.forward_ref\"),w=Symbol.for(\"react.suspense\"),x=Symbol.for(\"react.memo\"),y=Symbol.for(\"react.lazy\"),z=Symbol.iterator;function A(a){if(null===a||\"object\"!==typeof a)return null;a=z&&a[z]||a[\"@@iterator\"];return\"function\"===typeof a?a:null}\nvar B={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},C=Object.assign,D={};function E(a,b,e){this.props=a;this.context=b;this.refs=D;this.updater=e||B}E.prototype.isReactComponent={};\nE.prototype.setState=function(a,b){if(\"object\"!==typeof a&&\"function\"!==typeof a&&null!=a)throw Error(\"setState(...): takes an object of state variables to update or a function which returns an object of state variables.\");this.updater.enqueueSetState(this,a,b,\"setState\")};E.prototype.forceUpdate=function(a){this.updater.enqueueForceUpdate(this,a,\"forceUpdate\")};function F(){}F.prototype=E.prototype;function G(a,b,e){this.props=a;this.context=b;this.refs=D;this.updater=e||B}var H=G.prototype=new F;\nH.constructor=G;C(H,E.prototype);H.isPureReactComponent=!0;var I=Array.isArray,J=Object.prototype.hasOwnProperty,K={current:null},L={key:!0,ref:!0,__self:!0,__source:!0};\nfunction M(a,b,e){var d,c={},k=null,h=null;if(null!=b)for(d in void 0!==b.ref&&(h=b.ref),void 0!==b.key&&(k=\"\"+b.key),b)J.call(b,d)&&!L.hasOwnProperty(d)&&(c[d]=b[d]);var g=arguments.length-2;if(1===g)c.children=e;else if(1<g){for(var f=Array(g),m=0;m<g;m++)f[m]=arguments[m+2];c.children=f}if(a&&a.defaultProps)for(d in g=a.defaultProps,g)void 0===c[d]&&(c[d]=g[d]);return{$$typeof:l,type:a,key:k,ref:h,props:c,_owner:K.current}}\nfunction N(a,b){return{$$typeof:l,type:a.type,key:b,ref:a.ref,props:a.props,_owner:a._owner}}function O(a){return\"object\"===typeof a&&null!==a&&a.$$typeof===l}function escape(a){var b={\"=\":\"=0\",\":\":\"=2\"};return\"$\"+a.replace(/[=:]/g,function(a){return b[a]})}var P=/\\/+/g;function Q(a,b){return\"object\"===typeof a&&null!==a&&null!=a.key?escape(\"\"+a.key):b.toString(36)}\nfunction R(a,b,e,d,c){var k=typeof a;if(\"undefined\"===k||\"boolean\"===k)a=null;var h=!1;if(null===a)h=!0;else switch(k){case \"string\":case \"number\":h=!0;break;case \"object\":switch(a.$$typeof){case l:case n:h=!0}}if(h)return h=a,c=c(h),a=\"\"===d?\".\"+Q(h,0):d,I(c)?(e=\"\",null!=a&&(e=a.replace(P,\"$&/\")+\"/\"),R(c,b,e,\"\",function(a){return a})):null!=c&&(O(c)&&(c=N(c,e+(!c.key||h&&h.key===c.key?\"\":(\"\"+c.key).replace(P,\"$&/\")+\"/\")+a)),b.push(c)),1;h=0;d=\"\"===d?\".\":d+\":\";if(I(a))for(var g=0;g<a.length;g++){k=\na[g];var f=d+Q(k,g);h+=R(k,b,e,f,c)}else if(f=A(a),\"function\"===typeof f)for(a=f.call(a),g=0;!(k=a.next()).done;)k=k.value,f=d+Q(k,g++),h+=R(k,b,e,f,c);else if(\"object\"===k)throw b=String(a),Error(\"Objects are not valid as a React child (found: \"+(\"[object Object]\"===b?\"object with keys {\"+Object.keys(a).join(\", \")+\"}\":b)+\"). If you meant to render a collection of children, use an array instead.\");return h}\nfunction S(a,b,e){if(null==a)return a;var d=[],c=0;R(a,d,\"\",\"\",function(a){return b.call(e,a,c++)});return d}function T(a){if(-1===a._status){var b=a._result;b=b();b.then(function(b){if(0===a._status||-1===a._status)a._status=1,a._result=b},function(b){if(0===a._status||-1===a._status)a._status=2,a._result=b});-1===a._status&&(a._status=0,a._result=b)}if(1===a._status)return a._result.default;throw a._result;}\nvar U={current:null},V={transition:null},W={ReactCurrentDispatcher:U,ReactCurrentBatchConfig:V,ReactCurrentOwner:K};exports.Children={map:S,forEach:function(a,b,e){S(a,function(){b.apply(this,arguments)},e)},count:function(a){var b=0;S(a,function(){b++});return b},toArray:function(a){return S(a,function(a){return a})||[]},only:function(a){if(!O(a))throw Error(\"React.Children.only expected to receive a single React element child.\");return a}};exports.Component=E;exports.Fragment=p;\nexports.Profiler=r;exports.PureComponent=G;exports.StrictMode=q;exports.Suspense=w;exports.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=W;\nexports.cloneElement=function(a,b,e){if(null===a||void 0===a)throw Error(\"React.cloneElement(...): The argument must be a React element, but you passed \"+a+\".\");var d=C({},a.props),c=a.key,k=a.ref,h=a._owner;if(null!=b){void 0!==b.ref&&(k=b.ref,h=K.current);void 0!==b.key&&(c=\"\"+b.key);if(a.type&&a.type.defaultProps)var g=a.type.defaultProps;for(f in b)J.call(b,f)&&!L.hasOwnProperty(f)&&(d[f]=void 0===b[f]&&void 0!==g?g[f]:b[f])}var f=arguments.length-2;if(1===f)d.children=e;else if(1<f){g=Array(f);\nfor(var m=0;m<f;m++)g[m]=arguments[m+2];d.children=g}return{$$typeof:l,type:a.type,key:c,ref:k,props:d,_owner:h}};exports.createContext=function(a){a={$$typeof:u,_currentValue:a,_currentValue2:a,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null};a.Provider={$$typeof:t,_context:a};return a.Consumer=a};exports.createElement=M;exports.createFactory=function(a){var b=M.bind(null,a);b.type=a;return b};exports.createRef=function(){return{current:null}};\nexports.forwardRef=function(a){return{$$typeof:v,render:a}};exports.isValidElement=O;exports.lazy=function(a){return{$$typeof:y,_payload:{_status:-1,_result:a},_init:T}};exports.memo=function(a,b){return{$$typeof:x,type:a,compare:void 0===b?null:b}};exports.startTransition=function(a){var b=V.transition;V.transition={};try{a()}finally{V.transition=b}};exports.unstable_act=function(){throw Error(\"act(...) is not supported in production builds of React.\");};\nexports.useCallback=function(a,b){return U.current.useCallback(a,b)};exports.useContext=function(a){return U.current.useContext(a)};exports.useDebugValue=function(){};exports.useDeferredValue=function(a){return U.current.useDeferredValue(a)};exports.useEffect=function(a,b){return U.current.useEffect(a,b)};exports.useId=function(){return U.current.useId()};exports.useImperativeHandle=function(a,b,e){return U.current.useImperativeHandle(a,b,e)};\nexports.useInsertionEffect=function(a,b){return U.current.useInsertionEffect(a,b)};exports.useLayoutEffect=function(a,b){return U.current.useLayoutEffect(a,b)};exports.useMemo=function(a,b){return U.current.useMemo(a,b)};exports.useReducer=function(a,b,e){return U.current.useReducer(a,b,e)};exports.useRef=function(a){return U.current.useRef(a)};exports.useState=function(a){return U.current.useState(a)};exports.useSyncExternalStore=function(a,b,e){return U.current.useSyncExternalStore(a,b,e)};\nexports.useTransition=function(){return U.current.useTransition()};exports.version=\"18.2.0\";\n","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('./cjs/react.production.min.js');\n} else {\n  module.exports = require('./cjs/react.development.js');\n}\n","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('./cjs/react-jsx-runtime.production.min.js');\n} else {\n  module.exports = require('./cjs/react-jsx-runtime.development.js');\n}\n","/**\n * @license React\n * scheduler.production.min.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n'use strict';function f(a,b){var c=a.length;a.push(b);a:for(;0<c;){var d=c-1>>>1,e=a[d];if(0<g(e,b))a[d]=b,a[c]=e,c=d;else break a}}function h(a){return 0===a.length?null:a[0]}function k(a){if(0===a.length)return null;var b=a[0],c=a.pop();if(c!==b){a[0]=c;a:for(var d=0,e=a.length,w=e>>>1;d<w;){var m=2*(d+1)-1,C=a[m],n=m+1,x=a[n];if(0>g(C,c))n<e&&0>g(x,C)?(a[d]=x,a[n]=c,d=n):(a[d]=C,a[m]=c,d=m);else if(n<e&&0>g(x,c))a[d]=x,a[n]=c,d=n;else break a}}return b}\nfunction g(a,b){var c=a.sortIndex-b.sortIndex;return 0!==c?c:a.id-b.id}if(\"object\"===typeof performance&&\"function\"===typeof performance.now){var l=performance;exports.unstable_now=function(){return l.now()}}else{var p=Date,q=p.now();exports.unstable_now=function(){return p.now()-q}}var r=[],t=[],u=1,v=null,y=3,z=!1,A=!1,B=!1,D=\"function\"===typeof setTimeout?setTimeout:null,E=\"function\"===typeof clearTimeout?clearTimeout:null,F=\"undefined\"!==typeof setImmediate?setImmediate:null;\n\"undefined\"!==typeof navigator&&void 0!==navigator.scheduling&&void 0!==navigator.scheduling.isInputPending&&navigator.scheduling.isInputPending.bind(navigator.scheduling);function G(a){for(var b=h(t);null!==b;){if(null===b.callback)k(t);else if(b.startTime<=a)k(t),b.sortIndex=b.expirationTime,f(r,b);else break;b=h(t)}}function H(a){B=!1;G(a);if(!A)if(null!==h(r))A=!0,I(J);else{var b=h(t);null!==b&&K(H,b.startTime-a)}}\nfunction J(a,b){A=!1;B&&(B=!1,E(L),L=-1);z=!0;var c=y;try{G(b);for(v=h(r);null!==v&&(!(v.expirationTime>b)||a&&!M());){var d=v.callback;if(\"function\"===typeof d){v.callback=null;y=v.priorityLevel;var e=d(v.expirationTime<=b);b=exports.unstable_now();\"function\"===typeof e?v.callback=e:v===h(r)&&k(r);G(b)}else k(r);v=h(r)}if(null!==v)var w=!0;else{var m=h(t);null!==m&&K(H,m.startTime-b);w=!1}return w}finally{v=null,y=c,z=!1}}var N=!1,O=null,L=-1,P=5,Q=-1;\nfunction M(){return exports.unstable_now()-Q<P?!1:!0}function R(){if(null!==O){var a=exports.unstable_now();Q=a;var b=!0;try{b=O(!0,a)}finally{b?S():(N=!1,O=null)}}else N=!1}var S;if(\"function\"===typeof F)S=function(){F(R)};else if(\"undefined\"!==typeof MessageChannel){var T=new MessageChannel,U=T.port2;T.port1.onmessage=R;S=function(){U.postMessage(null)}}else S=function(){D(R,0)};function I(a){O=a;N||(N=!0,S())}function K(a,b){L=D(function(){a(exports.unstable_now())},b)}\nexports.unstable_IdlePriority=5;exports.unstable_ImmediatePriority=1;exports.unstable_LowPriority=4;exports.unstable_NormalPriority=3;exports.unstable_Profiling=null;exports.unstable_UserBlockingPriority=2;exports.unstable_cancelCallback=function(a){a.callback=null};exports.unstable_continueExecution=function(){A||z||(A=!0,I(J))};\nexports.unstable_forceFrameRate=function(a){0>a||125<a?console.error(\"forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported\"):P=0<a?Math.floor(1E3/a):5};exports.unstable_getCurrentPriorityLevel=function(){return y};exports.unstable_getFirstCallbackNode=function(){return h(r)};exports.unstable_next=function(a){switch(y){case 1:case 2:case 3:var b=3;break;default:b=y}var c=y;y=b;try{return a()}finally{y=c}};exports.unstable_pauseExecution=function(){};\nexports.unstable_requestPaint=function(){};exports.unstable_runWithPriority=function(a,b){switch(a){case 1:case 2:case 3:case 4:case 5:break;default:a=3}var c=y;y=a;try{return b()}finally{y=c}};\nexports.unstable_scheduleCallback=function(a,b,c){var d=exports.unstable_now();\"object\"===typeof c&&null!==c?(c=c.delay,c=\"number\"===typeof c&&0<c?d+c:d):c=d;switch(a){case 1:var e=-1;break;case 2:e=250;break;case 5:e=1073741823;break;case 4:e=1E4;break;default:e=5E3}e=c+e;a={id:u++,callback:b,priorityLevel:a,startTime:c,expirationTime:e,sortIndex:-1};c>d?(a.sortIndex=c,f(t,a),null===h(r)&&a===h(t)&&(B?(E(L),L=-1):B=!0,K(H,c-d))):(a.sortIndex=e,f(r,a),A||z||(A=!0,I(J)));return a};\nexports.unstable_shouldYield=M;exports.unstable_wrapCallback=function(a){var b=y;return function(){var c=y;y=b;try{return a.apply(this,arguments)}finally{y=c}}};\n","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('./cjs/scheduler.production.min.js');\n} else {\n  module.exports = require('./cjs/scheduler.development.js');\n}\n","export default function _extends() {\n  _extends = Object.assign ? Object.assign.bind() : function (target) {\n    for (var i = 1; i < arguments.length; i++) {\n      var source = arguments[i];\n\n      for (var key in source) {\n        if (Object.prototype.hasOwnProperty.call(source, key)) {\n          target[key] = source[key];\n        }\n      }\n    }\n\n    return target;\n  };\n  return _extends.apply(this, arguments);\n}","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = function(chunkId) {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce(function(promises, key) {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks\n__webpack_require__.u = function(chunkId) {\n\t// return url for filenames based on template\n\treturn \"static/js/\" + chunkId + \".\" + \"f72b89af\" + \".chunk.js\";\n};","// This function allow to reference async chunks\n__webpack_require__.miniCssF = function(chunkId) {\n\t// return url for filenames based on template\n\treturn undefined;\n};","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","var inProgress = {};\nvar dataWebpackPrefix = \"aws-solv:\";\n// loadScript function to load a script via script tag\n__webpack_require__.l = function(url, done, key, chunkId) {\n\tif(inProgress[url]) { inProgress[url].push(done); return; }\n\tvar script, needAttach;\n\tif(key !== undefined) {\n\t\tvar scripts = document.getElementsByTagName(\"script\");\n\t\tfor(var i = 0; i < scripts.length; i++) {\n\t\t\tvar s = scripts[i];\n\t\t\tif(s.getAttribute(\"src\") == url || s.getAttribute(\"data-webpack\") == dataWebpackPrefix + key) { script = s; break; }\n\t\t}\n\t}\n\tif(!script) {\n\t\tneedAttach = true;\n\t\tscript = document.createElement('script');\n\n\t\tscript.charset = 'utf-8';\n\t\tscript.timeout = 120;\n\t\tif (__webpack_require__.nc) {\n\t\t\tscript.setAttribute(\"nonce\", __webpack_require__.nc);\n\t\t}\n\t\tscript.setAttribute(\"data-webpack\", dataWebpackPrefix + key);\n\t\tscript.src = url;\n\t}\n\tinProgress[url] = [done];\n\tvar onScriptComplete = function(prev, event) {\n\t\t// avoid mem leaks in IE.\n\t\tscript.onerror = script.onload = null;\n\t\tclearTimeout(timeout);\n\t\tvar doneFns = inProgress[url];\n\t\tdelete inProgress[url];\n\t\tscript.parentNode && script.parentNode.removeChild(script);\n\t\tdoneFns && doneFns.forEach(function(fn) { return fn(event); });\n\t\tif(prev) return prev(event);\n\t}\n\t;\n\tvar timeout = setTimeout(onScriptComplete.bind(null, undefined, { type: 'timeout', target: script }), 120000);\n\tscript.onerror = onScriptComplete.bind(null, script.onerror);\n\tscript.onload = onScriptComplete.bind(null, script.onload);\n\tneedAttach && document.head.appendChild(script);\n};","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.p = \"/aws/\";","// no baseURI\n\n// object to store loaded and loading chunks\n// undefined = chunk not loaded, null = chunk preloaded/prefetched\n// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded\nvar installedChunks = {\n\t179: 0\n};\n\n__webpack_require__.f.j = function(chunkId, promises) {\n\t\t// JSONP chunk loading for javascript\n\t\tvar installedChunkData = __webpack_require__.o(installedChunks, chunkId) ? installedChunks[chunkId] : undefined;\n\t\tif(installedChunkData !== 0) { // 0 means \"already installed\".\n\n\t\t\t// a Promise means \"currently loading\".\n\t\t\tif(installedChunkData) {\n\t\t\t\tpromises.push(installedChunkData[2]);\n\t\t\t} else {\n\t\t\t\tif(true) { // all chunks have JS\n\t\t\t\t\t// setup Promise in chunk cache\n\t\t\t\t\tvar promise = new Promise(function(resolve, reject) { installedChunkData = installedChunks[chunkId] = [resolve, reject]; });\n\t\t\t\t\tpromises.push(installedChunkData[2] = promise);\n\n\t\t\t\t\t// start chunk loading\n\t\t\t\t\tvar url = __webpack_require__.p + __webpack_require__.u(chunkId);\n\t\t\t\t\t// create error before stack unwound to get useful stacktrace later\n\t\t\t\t\tvar error = new Error();\n\t\t\t\t\tvar loadingEnded = function(event) {\n\t\t\t\t\t\tif(__webpack_require__.o(installedChunks, chunkId)) {\n\t\t\t\t\t\t\tinstalledChunkData = installedChunks[chunkId];\n\t\t\t\t\t\t\tif(installedChunkData !== 0) installedChunks[chunkId] = undefined;\n\t\t\t\t\t\t\tif(installedChunkData) {\n\t\t\t\t\t\t\t\tvar errorType = event && (event.type === 'load' ? 'missing' : event.type);\n\t\t\t\t\t\t\t\tvar realSrc = event && event.target && event.target.src;\n\t\t\t\t\t\t\t\terror.message = 'Loading chunk ' + chunkId + ' failed.\\n(' + errorType + ': ' + realSrc + ')';\n\t\t\t\t\t\t\t\terror.name = 'ChunkLoadError';\n\t\t\t\t\t\t\t\terror.type = errorType;\n\t\t\t\t\t\t\t\terror.request = realSrc;\n\t\t\t\t\t\t\t\tinstalledChunkData[1](error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t};\n\t\t\t\t\t__webpack_require__.l(url, loadingEnded, \"chunk-\" + chunkId, chunkId);\n\t\t\t\t} else installedChunks[chunkId] = 0;\n\t\t\t}\n\t\t}\n};\n\n// no prefetching\n\n// no preloaded\n\n// no HMR\n\n// no HMR manifest\n\n// no on chunks loaded\n\n// install a JSONP callback for chunk loading\nvar webpackJsonpCallback = function(parentChunkLoadingFunction, data) {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\t// add \"moreModules\" to the modules object,\n\t// then flag all \"chunkIds\" as loaded and fire callback\n\tvar moduleId, chunkId, i = 0;\n\tif(chunkIds.some(function(id) { return installedChunks[id] !== 0; })) {\n\t\tfor(moduleId in moreModules) {\n\t\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t\t}\n\t\t}\n\t\tif(runtime) var result = runtime(__webpack_require__);\n\t}\n\tif(parentChunkLoadingFunction) parentChunkLoadingFunction(data);\n\tfor(;i < chunkIds.length; i++) {\n\t\tchunkId = chunkIds[i];\n\t\tif(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {\n\t\t\tinstalledChunks[chunkId][0]();\n\t\t}\n\t\tinstalledChunks[chunkId] = 0;\n\t}\n\n}\n\nvar chunkLoadingGlobal = self[\"webpackChunkaws_solv\"] = self[\"webpackChunkaws_solv\"] || [];\nchunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));\nchunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));","export default function _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n\n  return arr2;\n}","import arrayWithHoles from \"./arrayWithHoles.js\";\nimport iterableToArrayLimit from \"./iterableToArrayLimit.js\";\nimport unsupportedIterableToArray from \"./unsupportedIterableToArray.js\";\nimport nonIterableRest from \"./nonIterableRest.js\";\nexport default function _slicedToArray(arr, i) {\n  return arrayWithHoles(arr) || iterableToArrayLimit(arr, i) || unsupportedIterableToArray(arr, i) || nonIterableRest();\n}","export default function _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}","export default function _iterableToArrayLimit(arr, i) {\n  var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"];\n\n  if (_i == null) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n\n  var _s, _e;\n\n  try {\n    for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n\n  return _arr;\n}","import arrayLikeToArray from \"./arrayLikeToArray.js\";\nexport default function _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return arrayLikeToArray(o, minLen);\n}","export default function _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}","import * as React from \"react\";\nimport type { History, Location } from \"history\";\nimport { Action as NavigationType } from \"history\";\n\nimport type { RouteMatch } from \"./router\";\n\n/**\n * A Navigator is a \"location changer\"; it's how you get to different locations.\n *\n * Every history instance conforms to the Navigator interface, but the\n * distinction is useful primarily when it comes to the low-level <Router> API\n * where both the location and a navigator must be provided separately in order\n * to avoid \"tearing\" that may occur in a suspense-enabled app if the action\n * and/or location were to be read directly from the history instance.\n */\nexport type Navigator = Pick<History, \"go\" | \"push\" | \"replace\" | \"createHref\">;\n\ninterface NavigationContextObject {\n  basename: string;\n  navigator: Navigator;\n  static: boolean;\n}\n\nexport const NavigationContext = React.createContext<NavigationContextObject>(\n  null!\n);\n\nif (__DEV__) {\n  NavigationContext.displayName = \"Navigation\";\n}\n\ninterface LocationContextObject {\n  location: Location;\n  navigationType: NavigationType;\n}\n\nexport const LocationContext = React.createContext<LocationContextObject>(\n  null!\n);\n\nif (__DEV__) {\n  LocationContext.displayName = \"Location\";\n}\n\ninterface RouteContextObject {\n  outlet: React.ReactElement | null;\n  matches: RouteMatch[];\n}\n\nexport const RouteContext = React.createContext<RouteContextObject>({\n  outlet: null,\n  matches: [],\n});\n\nif (__DEV__) {\n  RouteContext.displayName = \"Route\";\n}\n","import type { Location, Path, To } from \"history\";\nimport { parsePath } from \"history\";\n\nexport function invariant(cond: any, message: string): asserts cond {\n  if (!cond) throw new Error(message);\n}\n\nexport function warning(cond: any, message: string): void {\n  if (!cond) {\n    // eslint-disable-next-line no-console\n    if (typeof console !== \"undefined\") console.warn(message);\n\n    try {\n      // Welcome to debugging React Router!\n      //\n      // This error is thrown as a convenience so you can more easily\n      // find the source for a warning that appears in the console by\n      // enabling \"pause on exceptions\" in your JavaScript debugger.\n      throw new Error(message);\n      // eslint-disable-next-line no-empty\n    } catch (e) {}\n  }\n}\n\nconst alreadyWarned: Record<string, boolean> = {};\nexport function warningOnce(key: string, cond: boolean, message: string) {\n  if (!cond && !alreadyWarned[key]) {\n    alreadyWarned[key] = true;\n    warning(false, message);\n  }\n}\n\ntype ParamParseFailed = { failed: true };\n\ntype ParamParseSegment<Segment extends string> =\n  // Check here if there exists a forward slash in the string.\n  Segment extends `${infer LeftSegment}/${infer RightSegment}`\n    ? // If there is a forward slash, then attempt to parse each side of the\n      // forward slash.\n      ParamParseSegment<LeftSegment> extends infer LeftResult\n      ? ParamParseSegment<RightSegment> extends infer RightResult\n        ? LeftResult extends string\n          ? // If the left side is successfully parsed as a param, then check if\n            // the right side can be successfully parsed as well. If both sides\n            // can be parsed, then the result is a union of the two sides\n            // (read: \"foo\" | \"bar\").\n            RightResult extends string\n            ? LeftResult | RightResult\n            : LeftResult\n          : // If the left side is not successfully parsed as a param, then check\n          // if only the right side can be successfully parse as a param. If it\n          // can, then the result is just right, else it's a failure.\n          RightResult extends string\n          ? RightResult\n          : ParamParseFailed\n        : ParamParseFailed\n      : // If the left side didn't parse into a param, then just check the right\n      // side.\n      ParamParseSegment<RightSegment> extends infer RightResult\n      ? RightResult extends string\n        ? RightResult\n        : ParamParseFailed\n      : ParamParseFailed\n    : // If there's no forward slash, then check if this segment starts with a\n    // colon. If it does, then this is a dynamic segment, so the result is\n    // just the remainder of the string. Otherwise, it's a failure.\n    Segment extends `:${infer Remaining}`\n    ? Remaining\n    : ParamParseFailed;\n\n// Attempt to parse the given string segment. If it fails, then just return the\n// plain string type as a default fallback. Otherwise return the union of the\n// parsed string literals that were referenced as dynamic segments in the route.\nexport type ParamParseKey<Segment extends string> =\n  ParamParseSegment<Segment> extends string\n    ? ParamParseSegment<Segment>\n    : string;\n\n/**\n * The parameters that were parsed from the URL path.\n */\nexport type Params<Key extends string = string> = {\n  readonly [key in Key]: string | undefined;\n};\n\n/**\n * A route object represents a logical route, with (optionally) its child\n * routes organized in a tree-like structure.\n */\nexport interface RouteObject {\n  caseSensitive?: boolean;\n  children?: RouteObject[];\n  element?: React.ReactNode;\n  index?: boolean;\n  path?: string;\n}\n\n/**\n * Returns a path with params interpolated.\n *\n * @see https://reactrouter.com/docs/en/v6/api#generatepath\n */\nexport function generatePath(path: string, params: Params = {}): string {\n  return path\n    .replace(/:(\\w+)/g, (_, key) => {\n      invariant(params[key] != null, `Missing \":${key}\" param`);\n      return params[key]!;\n    })\n    .replace(/\\/*\\*$/, (_) =>\n      params[\"*\"] == null ? \"\" : params[\"*\"].replace(/^\\/*/, \"/\")\n    );\n}\n\n/**\n * A RouteMatch contains info about how a route matched a URL.\n */\nexport interface RouteMatch<ParamKey extends string = string> {\n  /**\n   * The names and values of dynamic parameters in the URL.\n   */\n  params: Params<ParamKey>;\n  /**\n   * The portion of the URL pathname that was matched.\n   */\n  pathname: string;\n  /**\n   * The portion of the URL pathname that was matched before child routes.\n   */\n  pathnameBase: string;\n  /**\n   * The route object that was used to match.\n   */\n  route: RouteObject;\n}\n\n/**\n * Matches the given routes to a location and returns the match data.\n *\n * @see https://reactrouter.com/docs/en/v6/api#matchroutes\n */\nexport function matchRoutes(\n  routes: RouteObject[],\n  locationArg: Partial<Location> | string,\n  basename = \"/\"\n): RouteMatch[] | null {\n  let location =\n    typeof locationArg === \"string\" ? parsePath(locationArg) : locationArg;\n\n  let pathname = stripBasename(location.pathname || \"/\", basename);\n\n  if (pathname == null) {\n    return null;\n  }\n\n  let branches = flattenRoutes(routes);\n  rankRouteBranches(branches);\n\n  let matches = null;\n  for (let i = 0; matches == null && i < branches.length; ++i) {\n    matches = matchRouteBranch(branches[i], pathname);\n  }\n\n  return matches;\n}\n\ninterface RouteMeta {\n  relativePath: string;\n  caseSensitive: boolean;\n  childrenIndex: number;\n  route: RouteObject;\n}\n\ninterface RouteBranch {\n  path: string;\n  score: number;\n  routesMeta: RouteMeta[];\n}\n\nfunction flattenRoutes(\n  routes: RouteObject[],\n  branches: RouteBranch[] = [],\n  parentsMeta: RouteMeta[] = [],\n  parentPath = \"\"\n): RouteBranch[] {\n  routes.forEach((route, index) => {\n    let meta: RouteMeta = {\n      relativePath: route.path || \"\",\n      caseSensitive: route.caseSensitive === true,\n      childrenIndex: index,\n      route,\n    };\n\n    if (meta.relativePath.startsWith(\"/\")) {\n      invariant(\n        meta.relativePath.startsWith(parentPath),\n        `Absolute route path \"${meta.relativePath}\" nested under path ` +\n          `\"${parentPath}\" is not valid. An absolute child route path ` +\n          `must start with the combined path of all its parent routes.`\n      );\n\n      meta.relativePath = meta.relativePath.slice(parentPath.length);\n    }\n\n    let path = joinPaths([parentPath, meta.relativePath]);\n    let routesMeta = parentsMeta.concat(meta);\n\n    // Add the children before adding this route to the array so we traverse the\n    // route tree depth-first and child routes appear before their parents in\n    // the \"flattened\" version.\n    if (route.children && route.children.length > 0) {\n      invariant(\n        route.index !== true,\n        `Index routes must not have child routes. Please remove ` +\n          `all child routes from route path \"${path}\".`\n      );\n\n      flattenRoutes(route.children, branches, routesMeta, path);\n    }\n\n    // Routes without a path shouldn't ever match by themselves unless they are\n    // index routes, so don't add them to the list of possible branches.\n    if (route.path == null && !route.index) {\n      return;\n    }\n\n    branches.push({ path, score: computeScore(path, route.index), routesMeta });\n  });\n\n  return branches;\n}\n\nfunction rankRouteBranches(branches: RouteBranch[]): void {\n  branches.sort((a, b) =>\n    a.score !== b.score\n      ? b.score - a.score // Higher score first\n      : compareIndexes(\n          a.routesMeta.map((meta) => meta.childrenIndex),\n          b.routesMeta.map((meta) => meta.childrenIndex)\n        )\n  );\n}\n\nconst paramRe = /^:\\w+$/;\nconst dynamicSegmentValue = 3;\nconst indexRouteValue = 2;\nconst emptySegmentValue = 1;\nconst staticSegmentValue = 10;\nconst splatPenalty = -2;\nconst isSplat = (s: string) => s === \"*\";\n\nfunction computeScore(path: string, index: boolean | undefined): number {\n  let segments = path.split(\"/\");\n  let initialScore = segments.length;\n  if (segments.some(isSplat)) {\n    initialScore += splatPenalty;\n  }\n\n  if (index) {\n    initialScore += indexRouteValue;\n  }\n\n  return segments\n    .filter((s) => !isSplat(s))\n    .reduce(\n      (score, segment) =>\n        score +\n        (paramRe.test(segment)\n          ? dynamicSegmentValue\n          : segment === \"\"\n          ? emptySegmentValue\n          : staticSegmentValue),\n      initialScore\n    );\n}\n\nfunction compareIndexes(a: number[], b: number[]): number {\n  let siblings =\n    a.length === b.length && a.slice(0, -1).every((n, i) => n === b[i]);\n\n  return siblings\n    ? // If two routes are siblings, we should try to match the earlier sibling\n      // first. This allows people to have fine-grained control over the matching\n      // behavior by simply putting routes with identical paths in the order they\n      // want them tried.\n      a[a.length - 1] - b[b.length - 1]\n    : // Otherwise, it doesn't really make sense to rank non-siblings by index,\n      // so they sort equally.\n      0;\n}\n\nfunction matchRouteBranch<ParamKey extends string = string>(\n  branch: RouteBranch,\n  pathname: string\n): RouteMatch<ParamKey>[] | null {\n  let { routesMeta } = branch;\n\n  let matchedParams = {};\n  let matchedPathname = \"/\";\n  let matches: RouteMatch[] = [];\n  for (let i = 0; i < routesMeta.length; ++i) {\n    let meta = routesMeta[i];\n    let end = i === routesMeta.length - 1;\n    let remainingPathname =\n      matchedPathname === \"/\"\n        ? pathname\n        : pathname.slice(matchedPathname.length) || \"/\";\n    let match = matchPath(\n      { path: meta.relativePath, caseSensitive: meta.caseSensitive, end },\n      remainingPathname\n    );\n\n    if (!match) return null;\n\n    Object.assign(matchedParams, match.params);\n\n    let route = meta.route;\n\n    matches.push({\n      params: matchedParams,\n      pathname: joinPaths([matchedPathname, match.pathname]),\n      pathnameBase: normalizePathname(\n        joinPaths([matchedPathname, match.pathnameBase])\n      ),\n      route,\n    });\n\n    if (match.pathnameBase !== \"/\") {\n      matchedPathname = joinPaths([matchedPathname, match.pathnameBase]);\n    }\n  }\n\n  return matches;\n}\n\n/**\n * A PathPattern is used to match on some portion of a URL pathname.\n */\nexport interface PathPattern<Path extends string = string> {\n  /**\n   * A string to match against a URL pathname. May contain `:id`-style segments\n   * to indicate placeholders for dynamic parameters. May also end with `/*` to\n   * indicate matching the rest of the URL pathname.\n   */\n  path: Path;\n  /**\n   * Should be `true` if the static portions of the `path` should be matched in\n   * the same case.\n   */\n  caseSensitive?: boolean;\n  /**\n   * Should be `true` if this pattern should match the entire URL pathname.\n   */\n  end?: boolean;\n}\n\n/**\n * A PathMatch contains info about how a PathPattern matched on a URL pathname.\n */\nexport interface PathMatch<ParamKey extends string = string> {\n  /**\n   * The names and values of dynamic parameters in the URL.\n   */\n  params: Params<ParamKey>;\n  /**\n   * The portion of the URL pathname that was matched.\n   */\n  pathname: string;\n  /**\n   * The portion of the URL pathname that was matched before child routes.\n   */\n  pathnameBase: string;\n  /**\n   * The pattern that was used to match.\n   */\n  pattern: PathPattern;\n}\n\ntype Mutable<T> = {\n  -readonly [P in keyof T]: T[P];\n};\n\n/**\n * Performs pattern matching on a URL pathname and returns information about\n * the match.\n *\n * @see https://reactrouter.com/docs/en/v6/api#matchpath\n */\nexport function matchPath<\n  ParamKey extends ParamParseKey<Path>,\n  Path extends string\n>(\n  pattern: PathPattern<Path> | Path,\n  pathname: string\n): PathMatch<ParamKey> | null {\n  if (typeof pattern === \"string\") {\n    pattern = { path: pattern, caseSensitive: false, end: true };\n  }\n\n  let [matcher, paramNames] = compilePath(\n    pattern.path,\n    pattern.caseSensitive,\n    pattern.end\n  );\n\n  let match = pathname.match(matcher);\n  if (!match) return null;\n\n  let matchedPathname = match[0];\n  let pathnameBase = matchedPathname.replace(/(.)\\/+$/, \"$1\");\n  let captureGroups = match.slice(1);\n  let params: Params = paramNames.reduce<Mutable<Params>>(\n    (memo, paramName, index) => {\n      // We need to compute the pathnameBase here using the raw splat value\n      // instead of using params[\"*\"] later because it will be decoded then\n      if (paramName === \"*\") {\n        let splatValue = captureGroups[index] || \"\";\n        pathnameBase = matchedPathname\n          .slice(0, matchedPathname.length - splatValue.length)\n          .replace(/(.)\\/+$/, \"$1\");\n      }\n\n      memo[paramName] = safelyDecodeURIComponent(\n        captureGroups[index] || \"\",\n        paramName\n      );\n      return memo;\n    },\n    {}\n  );\n\n  return {\n    params,\n    pathname: matchedPathname,\n    pathnameBase,\n    pattern,\n  };\n}\n\nfunction compilePath(\n  path: string,\n  caseSensitive = false,\n  end = true\n): [RegExp, string[]] {\n  warning(\n    path === \"*\" || !path.endsWith(\"*\") || path.endsWith(\"/*\"),\n    `Route path \"${path}\" will be treated as if it were ` +\n      `\"${path.replace(/\\*$/, \"/*\")}\" because the \\`*\\` character must ` +\n      `always follow a \\`/\\` in the pattern. To get rid of this warning, ` +\n      `please change the route path to \"${path.replace(/\\*$/, \"/*\")}\".`\n  );\n\n  let paramNames: string[] = [];\n  let regexpSource =\n    \"^\" +\n    path\n      .replace(/\\/*\\*?$/, \"\") // Ignore trailing / and /*, we'll handle it below\n      .replace(/^\\/*/, \"/\") // Make sure it has a leading /\n      .replace(/[\\\\.*+^$?{}|()[\\]]/g, \"\\\\$&\") // Escape special regex chars\n      .replace(/:(\\w+)/g, (_: string, paramName: string) => {\n        paramNames.push(paramName);\n        return \"([^\\\\/]+)\";\n      });\n\n  if (path.endsWith(\"*\")) {\n    paramNames.push(\"*\");\n    regexpSource +=\n      path === \"*\" || path === \"/*\"\n        ? \"(.*)$\" // Already matched the initial /, just match the rest\n        : \"(?:\\\\/(.+)|\\\\/*)$\"; // Don't include the / in params[\"*\"]\n  } else {\n    regexpSource += end\n      ? \"\\\\/*$\" // When matching to the end, ignore trailing slashes\n      : // Otherwise, match a word boundary or a proceeding /. The word boundary restricts\n        // parent routes to matching only their own words and nothing more, e.g. parent\n        // route \"/home\" should not match \"/home2\".\n        // Additionally, allow paths starting with `.`, `-`, `~`, and url-encoded entities,\n        // but do not consume the character in the matched path so they can match against\n        // nested paths.\n        \"(?:(?=[.~-]|%[0-9A-F]{2})|\\\\b|\\\\/|$)\";\n  }\n\n  let matcher = new RegExp(regexpSource, caseSensitive ? undefined : \"i\");\n\n  return [matcher, paramNames];\n}\n\nfunction safelyDecodeURIComponent(value: string, paramName: string) {\n  try {\n    return decodeURIComponent(value);\n  } catch (error) {\n    warning(\n      false,\n      `The value for the URL param \"${paramName}\" will not be decoded because` +\n        ` the string \"${value}\" is a malformed URL segment. This is probably` +\n        ` due to a bad percent encoding (${error}).`\n    );\n\n    return value;\n  }\n}\n\n/**\n * Returns a resolved path object relative to the given pathname.\n *\n * @see https://reactrouter.com/docs/en/v6/api#resolvepath\n */\nexport function resolvePath(to: To, fromPathname = \"/\"): Path {\n  let {\n    pathname: toPathname,\n    search = \"\",\n    hash = \"\",\n  } = typeof to === \"string\" ? parsePath(to) : to;\n\n  let pathname = toPathname\n    ? toPathname.startsWith(\"/\")\n      ? toPathname\n      : resolvePathname(toPathname, fromPathname)\n    : fromPathname;\n\n  return {\n    pathname,\n    search: normalizeSearch(search),\n    hash: normalizeHash(hash),\n  };\n}\n\nfunction resolvePathname(relativePath: string, fromPathname: string): string {\n  let segments = fromPathname.replace(/\\/+$/, \"\").split(\"/\");\n  let relativeSegments = relativePath.split(\"/\");\n\n  relativeSegments.forEach((segment) => {\n    if (segment === \"..\") {\n      // Keep the root \"\" segment so the pathname starts at /\n      if (segments.length > 1) segments.pop();\n    } else if (segment !== \".\") {\n      segments.push(segment);\n    }\n  });\n\n  return segments.length > 1 ? segments.join(\"/\") : \"/\";\n}\n\nexport function resolveTo(\n  toArg: To,\n  routePathnames: string[],\n  locationPathname: string\n): Path {\n  let to = typeof toArg === \"string\" ? parsePath(toArg) : toArg;\n  let toPathname = toArg === \"\" || to.pathname === \"\" ? \"/\" : to.pathname;\n\n  // If a pathname is explicitly provided in `to`, it should be relative to the\n  // route context. This is explained in `Note on `<Link to>` values` in our\n  // migration guide from v5 as a means of disambiguation between `to` values\n  // that begin with `/` and those that do not. However, this is problematic for\n  // `to` values that do not provide a pathname. `to` can simply be a search or\n  // hash string, in which case we should assume that the navigation is relative\n  // to the current location's pathname and *not* the route pathname.\n  let from: string;\n  if (toPathname == null) {\n    from = locationPathname;\n  } else {\n    let routePathnameIndex = routePathnames.length - 1;\n\n    if (toPathname.startsWith(\"..\")) {\n      let toSegments = toPathname.split(\"/\");\n\n      // Each leading .. segment means \"go up one route\" instead of \"go up one\n      // URL segment\".  This is a key difference from how <a href> works and a\n      // major reason we call this a \"to\" value instead of a \"href\".\n      while (toSegments[0] === \"..\") {\n        toSegments.shift();\n        routePathnameIndex -= 1;\n      }\n\n      to.pathname = toSegments.join(\"/\");\n    }\n\n    // If there are more \"..\" segments than parent routes, resolve relative to\n    // the root / URL.\n    from = routePathnameIndex >= 0 ? routePathnames[routePathnameIndex] : \"/\";\n  }\n\n  let path = resolvePath(to, from);\n\n  // Ensure the pathname has a trailing slash if the original to value had one.\n  if (\n    toPathname &&\n    toPathname !== \"/\" &&\n    toPathname.endsWith(\"/\") &&\n    !path.pathname.endsWith(\"/\")\n  ) {\n    path.pathname += \"/\";\n  }\n\n  return path;\n}\n\nexport function getToPathname(to: To): string | undefined {\n  // Empty strings should be treated the same as / paths\n  return to === \"\" || (to as Path).pathname === \"\"\n    ? \"/\"\n    : typeof to === \"string\"\n    ? parsePath(to).pathname\n    : to.pathname;\n}\n\nexport function stripBasename(\n  pathname: string,\n  basename: string\n): string | null {\n  if (basename === \"/\") return pathname;\n\n  if (!pathname.toLowerCase().startsWith(basename.toLowerCase())) {\n    return null;\n  }\n\n  let nextChar = pathname.charAt(basename.length);\n  if (nextChar && nextChar !== \"/\") {\n    // pathname does not start with basename/\n    return null;\n  }\n\n  return pathname.slice(basename.length) || \"/\";\n}\n\nexport const joinPaths = (paths: string[]): string =>\n  paths.join(\"/\").replace(/\\/\\/+/g, \"/\");\n\nexport const normalizePathname = (pathname: string): string =>\n  pathname.replace(/\\/+$/, \"\").replace(/^\\/*/, \"/\");\n\nconst normalizeSearch = (search: string): string =>\n  !search || search === \"?\"\n    ? \"\"\n    : search.startsWith(\"?\")\n    ? search\n    : \"?\" + search;\n\nconst normalizeHash = (hash: string): string =>\n  !hash || hash === \"#\" ? \"\" : hash.startsWith(\"#\") ? hash : \"#\" + hash;\n","import * as React from \"react\";\nimport type { Location, Path, To } from \"history\";\nimport { Action as NavigationType, parsePath } from \"history\";\n\nimport { LocationContext, NavigationContext, RouteContext } from \"./context\";\nimport type {\n  ParamParseKey,\n  Params,\n  PathMatch,\n  PathPattern,\n  RouteMatch,\n  RouteObject,\n} from \"./router\";\nimport {\n  getToPathname,\n  invariant,\n  joinPaths,\n  matchPath,\n  matchRoutes,\n  resolveTo,\n  warning,\n  warningOnce,\n} from \"./router\";\n\n/**\n * Returns the full href for the given \"to\" value. This is useful for building\n * custom links that are also accessible and preserve right-click behavior.\n *\n * @see https://reactrouter.com/docs/en/v6/api#usehref\n */\nexport function useHref(to: To): string {\n  invariant(\n    useInRouterContext(),\n    // TODO: This error is probably because they somehow have 2 versions of the\n    // router loaded. We can help them understand how to avoid that.\n    `useHref() may be used only in the context of a <Router> component.`\n  );\n\n  let { basename, navigator } = React.useContext(NavigationContext);\n  let { hash, pathname, search } = useResolvedPath(to);\n\n  let joinedPathname = pathname;\n  if (basename !== \"/\") {\n    let toPathname = getToPathname(to);\n    let endsWithSlash = toPathname != null && toPathname.endsWith(\"/\");\n    joinedPathname =\n      pathname === \"/\"\n        ? basename + (endsWithSlash ? \"/\" : \"\")\n        : joinPaths([basename, pathname]);\n  }\n\n  return navigator.createHref({ pathname: joinedPathname, search, hash });\n}\n\n/**\n * Returns true if this component is a descendant of a <Router>.\n *\n * @see https://reactrouter.com/docs/en/v6/api#useinroutercontext\n */\nexport function useInRouterContext(): boolean {\n  return React.useContext(LocationContext) != null;\n}\n\n/**\n * Returns the current location object, which represents the current URL in web\n * browsers.\n *\n * Note: If you're using this it may mean you're doing some of your own\n * \"routing\" in your app, and we'd like to know what your use case is. We may\n * be able to provide something higher-level to better suit your needs.\n *\n * @see https://reactrouter.com/docs/en/v6/api#uselocation\n */\nexport function useLocation(): Location {\n  invariant(\n    useInRouterContext(),\n    // TODO: This error is probably because they somehow have 2 versions of the\n    // router loaded. We can help them understand how to avoid that.\n    `useLocation() may be used only in the context of a <Router> component.`\n  );\n\n  return React.useContext(LocationContext).location;\n}\n\n/**\n * Returns the current navigation action which describes how the router came to\n * the current location, either by a pop, push, or replace on the history stack.\n *\n * @see https://reactrouter.com/docs/en/v6/api#usenavigationtype\n */\nexport function useNavigationType(): NavigationType {\n  return React.useContext(LocationContext).navigationType;\n}\n\n/**\n * Returns true if the URL for the given \"to\" value matches the current URL.\n * This is useful for components that need to know \"active\" state, e.g.\n * <NavLink>.\n *\n * @see https://reactrouter.com/docs/en/v6/api#usematch\n */\nexport function useMatch<\n  ParamKey extends ParamParseKey<Path>,\n  Path extends string\n>(pattern: PathPattern<Path> | Path): PathMatch<ParamKey> | null {\n  invariant(\n    useInRouterContext(),\n    // TODO: This error is probably because they somehow have 2 versions of the\n    // router loaded. We can help them understand how to avoid that.\n    `useMatch() may be used only in the context of a <Router> component.`\n  );\n\n  let { pathname } = useLocation();\n  return React.useMemo(\n    () => matchPath<ParamKey, Path>(pattern, pathname),\n    [pathname, pattern]\n  );\n}\n\n/**\n * The interface for the navigate() function returned from useNavigate().\n */\nexport interface NavigateFunction {\n  (to: To, options?: NavigateOptions): void;\n  (delta: number): void;\n}\n\nexport interface NavigateOptions {\n  replace?: boolean;\n  state?: any;\n}\n\n/**\n * Returns an imperative method for changing the location. Used by <Link>s, but\n * may also be used by other elements to change the location.\n *\n * @see https://reactrouter.com/docs/en/v6/api#usenavigate\n */\nexport function useNavigate(): NavigateFunction {\n  invariant(\n    useInRouterContext(),\n    // TODO: This error is probably because they somehow have 2 versions of the\n    // router loaded. We can help them understand how to avoid that.\n    `useNavigate() may be used only in the context of a <Router> component.`\n  );\n\n  let { basename, navigator } = React.useContext(NavigationContext);\n  let { matches } = React.useContext(RouteContext);\n  let { pathname: locationPathname } = useLocation();\n\n  let routePathnamesJson = JSON.stringify(\n    matches.map((match) => match.pathnameBase)\n  );\n\n  let activeRef = React.useRef(false);\n  React.useEffect(() => {\n    activeRef.current = true;\n  });\n\n  let navigate: NavigateFunction = React.useCallback(\n    (to: To | number, options: NavigateOptions = {}) => {\n      warning(\n        activeRef.current,\n        `You should call navigate() in a React.useEffect(), not when ` +\n          `your component is first rendered.`\n      );\n\n      if (!activeRef.current) return;\n\n      if (typeof to === \"number\") {\n        navigator.go(to);\n        return;\n      }\n\n      let path = resolveTo(\n        to,\n        JSON.parse(routePathnamesJson),\n        locationPathname\n      );\n\n      if (basename !== \"/\") {\n        path.pathname = joinPaths([basename, path.pathname]);\n      }\n\n      (!!options.replace ? navigator.replace : navigator.push)(\n        path,\n        options.state\n      );\n    },\n    [basename, navigator, routePathnamesJson, locationPathname]\n  );\n\n  return navigate;\n}\n\nconst OutletContext = React.createContext<unknown>(null);\n\n/**\n * Returns the context (if provided) for the child route at this level of the route\n * hierarchy.\n * @see https://reactrouter.com/docs/en/v6/api#useoutletcontext\n */\nexport function useOutletContext<Context = unknown>(): Context {\n  return React.useContext(OutletContext) as Context;\n}\n\n/**\n * Returns the element for the child route at this level of the route\n * hierarchy. Used internally by <Outlet> to render child routes.\n *\n * @see https://reactrouter.com/docs/en/v6/api#useoutlet\n */\nexport function useOutlet(context?: unknown): React.ReactElement | null {\n  let outlet = React.useContext(RouteContext).outlet;\n  if (outlet) {\n    return (\n      <OutletContext.Provider value={context}>{outlet}</OutletContext.Provider>\n    );\n  }\n  return outlet;\n}\n\n/**\n * Returns an object of key/value pairs of the dynamic params from the current\n * URL that were matched by the route path.\n *\n * @see https://reactrouter.com/docs/en/v6/api#useparams\n */\nexport function useParams<\n  ParamsOrKey extends string | Record<string, string | undefined> = string\n>(): Readonly<\n  [ParamsOrKey] extends [string] ? Params<ParamsOrKey> : Partial<ParamsOrKey>\n> {\n  let { matches } = React.useContext(RouteContext);\n  let routeMatch = matches[matches.length - 1];\n  return routeMatch ? (routeMatch.params as any) : {};\n}\n\n/**\n * Resolves the pathname of the given `to` value against the current location.\n *\n * @see https://reactrouter.com/docs/en/v6/api#useresolvedpath\n */\nexport function useResolvedPath(to: To): Path {\n  let { matches } = React.useContext(RouteContext);\n  let { pathname: locationPathname } = useLocation();\n\n  let routePathnamesJson = JSON.stringify(\n    matches.map((match) => match.pathnameBase)\n  );\n\n  return React.useMemo(\n    () => resolveTo(to, JSON.parse(routePathnamesJson), locationPathname),\n    [to, routePathnamesJson, locationPathname]\n  );\n}\n\n/**\n * Returns the element of the route that matched the current location, prepared\n * with the correct context to render the remainder of the route tree. Route\n * elements in the tree must render an <Outlet> to render their child route's\n * element.\n *\n * @see https://reactrouter.com/docs/en/v6/api#useroutes\n */\nexport function useRoutes(\n  routes: RouteObject[],\n  locationArg?: Partial<Location> | string\n): React.ReactElement | null {\n  invariant(\n    useInRouterContext(),\n    // TODO: This error is probably because they somehow have 2 versions of the\n    // router loaded. We can help them understand how to avoid that.\n    `useRoutes() may be used only in the context of a <Router> component.`\n  );\n\n  let { matches: parentMatches } = React.useContext(RouteContext);\n  let routeMatch = parentMatches[parentMatches.length - 1];\n  let parentParams = routeMatch ? routeMatch.params : {};\n  let parentPathname = routeMatch ? routeMatch.pathname : \"/\";\n  let parentPathnameBase = routeMatch ? routeMatch.pathnameBase : \"/\";\n  let parentRoute = routeMatch && routeMatch.route;\n\n  if (__DEV__) {\n    // You won't get a warning about 2 different <Routes> under a <Route>\n    // without a trailing *, but this is a best-effort warning anyway since we\n    // cannot even give the warning unless they land at the parent route.\n    //\n    // Example:\n    //\n    // <Routes>\n    //   {/* This route path MUST end with /* because otherwise\n    //       it will never match /blog/post/123 */}\n    //   <Route path=\"blog\" element={<Blog />} />\n    //   <Route path=\"blog/feed\" element={<BlogFeed />} />\n    // </Routes>\n    //\n    // function Blog() {\n    //   return (\n    //     <Routes>\n    //       <Route path=\"post/:id\" element={<Post />} />\n    //     </Routes>\n    //   );\n    // }\n    let parentPath = (parentRoute && parentRoute.path) || \"\";\n    warningOnce(\n      parentPathname,\n      !parentRoute || parentPath.endsWith(\"*\"),\n      `You rendered descendant <Routes> (or called \\`useRoutes()\\`) at ` +\n        `\"${parentPathname}\" (under <Route path=\"${parentPath}\">) but the ` +\n        `parent route path has no trailing \"*\". This means if you navigate ` +\n        `deeper, the parent won't match anymore and therefore the child ` +\n        `routes will never render.\\n\\n` +\n        `Please change the parent <Route path=\"${parentPath}\"> to <Route ` +\n        `path=\"${parentPath === \"/\" ? \"*\" : `${parentPath}/*`}\">.`\n    );\n  }\n\n  let locationFromContext = useLocation();\n\n  let location;\n  if (locationArg) {\n    let parsedLocationArg =\n      typeof locationArg === \"string\" ? parsePath(locationArg) : locationArg;\n\n    invariant(\n      parentPathnameBase === \"/\" ||\n        parsedLocationArg.pathname?.startsWith(parentPathnameBase),\n      `When overriding the location using \\`<Routes location>\\` or \\`useRoutes(routes, location)\\`, ` +\n        `the location pathname must begin with the portion of the URL pathname that was ` +\n        `matched by all parent routes. The current pathname base is \"${parentPathnameBase}\" ` +\n        `but pathname \"${parsedLocationArg.pathname}\" was given in the \\`location\\` prop.`\n    );\n\n    location = parsedLocationArg;\n  } else {\n    location = locationFromContext;\n  }\n\n  let pathname = location.pathname || \"/\";\n  let remainingPathname =\n    parentPathnameBase === \"/\"\n      ? pathname\n      : pathname.slice(parentPathnameBase.length) || \"/\";\n  let matches = matchRoutes(routes, { pathname: remainingPathname });\n\n  if (__DEV__) {\n    warning(\n      parentRoute || matches != null,\n      `No routes matched location \"${location.pathname}${location.search}${location.hash}\" `\n    );\n\n    warning(\n      matches == null ||\n        matches[matches.length - 1].route.element !== undefined,\n      `Matched leaf route at location \"${location.pathname}${location.search}${location.hash}\" does not have an element. ` +\n        `This means it will render an <Outlet /> with a null value by default resulting in an \"empty\" page.`\n    );\n  }\n\n  return _renderMatches(\n    matches &&\n      matches.map((match) =>\n        Object.assign({}, match, {\n          params: Object.assign({}, parentParams, match.params),\n          pathname: joinPaths([parentPathnameBase, match.pathname]),\n          pathnameBase:\n            match.pathnameBase === \"/\"\n              ? parentPathnameBase\n              : joinPaths([parentPathnameBase, match.pathnameBase]),\n        })\n      ),\n    parentMatches\n  );\n}\n\nexport function _renderMatches(\n  matches: RouteMatch[] | null,\n  parentMatches: RouteMatch[] = []\n): React.ReactElement | null {\n  if (matches == null) return null;\n\n  return matches.reduceRight((outlet, match, index) => {\n    return (\n      <RouteContext.Provider\n        children={\n          match.route.element !== undefined ? match.route.element : outlet\n        }\n        value={{\n          outlet,\n          matches: parentMatches.concat(matches.slice(0, index + 1)),\n        }}\n      />\n    );\n  }, null as React.ReactElement | null);\n}\n","import * as React from \"react\";\nimport type { InitialEntry, Location, MemoryHistory, To } from \"history\";\nimport {\n  Action as NavigationType,\n  createMemoryHistory,\n  parsePath,\n} from \"history\";\n\nimport { LocationContext, NavigationContext, Navigator } from \"./context\";\nimport {\n  useInRouterContext,\n  useNavigate,\n  useOutlet,\n  useRoutes,\n  _renderMatches,\n} from \"./hooks\";\nimport type { RouteMatch, RouteObject } from \"./router\";\nimport { invariant, normalizePathname, stripBasename, warning } from \"./router\";\n\nexport interface MemoryRouterProps {\n  basename?: string;\n  children?: React.ReactNode;\n  initialEntries?: InitialEntry[];\n  initialIndex?: number;\n}\n\n/**\n * A <Router> that stores all entries in memory.\n *\n * @see https://reactrouter.com/docs/en/v6/api#memoryrouter\n */\nexport function MemoryRouter({\n  basename,\n  children,\n  initialEntries,\n  initialIndex,\n}: MemoryRouterProps): React.ReactElement {\n  let historyRef = React.useRef<MemoryHistory>();\n  if (historyRef.current == null) {\n    historyRef.current = createMemoryHistory({ initialEntries, initialIndex });\n  }\n\n  let history = historyRef.current;\n  let [state, setState] = React.useState({\n    action: history.action,\n    location: history.location,\n  });\n\n  React.useLayoutEffect(() => history.listen(setState), [history]);\n\n  return (\n    <Router\n      basename={basename}\n      children={children}\n      location={state.location}\n      navigationType={state.action}\n      navigator={history}\n    />\n  );\n}\n\nexport interface NavigateProps {\n  to: To;\n  replace?: boolean;\n  state?: any;\n}\n\n/**\n * Changes the current location.\n *\n * Note: This API is mostly useful in React.Component subclasses that are not\n * able to use hooks. In functional components, we recommend you use the\n * `useNavigate` hook instead.\n *\n * @see https://reactrouter.com/docs/en/v6/api#navigate\n */\nexport function Navigate({ to, replace, state }: NavigateProps): null {\n  invariant(\n    useInRouterContext(),\n    // TODO: This error is probably because they somehow have 2 versions of\n    // the router loaded. We can help them understand how to avoid that.\n    `<Navigate> may be used only in the context of a <Router> component.`\n  );\n\n  warning(\n    !React.useContext(NavigationContext).static,\n    `<Navigate> must not be used on the initial render in a <StaticRouter>. ` +\n      `This is a no-op, but you should modify your code so the <Navigate> is ` +\n      `only ever rendered in response to some user interaction or state change.`\n  );\n\n  let navigate = useNavigate();\n  React.useEffect(() => {\n    navigate(to, { replace, state });\n  });\n\n  return null;\n}\n\nexport interface OutletProps {\n  context?: unknown;\n}\n\n/**\n * Renders the child route's element, if there is one.\n *\n * @see https://reactrouter.com/docs/en/v6/api#outlet\n */\nexport function Outlet(props: OutletProps): React.ReactElement | null {\n  return useOutlet(props.context);\n}\n\nexport interface RouteProps {\n  caseSensitive?: boolean;\n  children?: React.ReactNode;\n  element?: React.ReactNode | null;\n  index?: boolean;\n  path?: string;\n}\n\nexport interface PathRouteProps {\n  caseSensitive?: boolean;\n  children?: React.ReactNode;\n  element?: React.ReactNode | null;\n  index?: false;\n  path: string;\n}\n\nexport interface LayoutRouteProps {\n  children?: React.ReactNode;\n  element?: React.ReactNode | null;\n}\n\nexport interface IndexRouteProps {\n  element?: React.ReactNode | null;\n  index: true;\n}\n\n/**\n * Declares an element that should be rendered at a certain URL path.\n *\n * @see https://reactrouter.com/docs/en/v6/api#route\n */\nexport function Route(\n  _props: PathRouteProps | LayoutRouteProps | IndexRouteProps\n): React.ReactElement | null {\n  invariant(\n    false,\n    `A <Route> is only ever to be used as the child of <Routes> element, ` +\n      `never rendered directly. Please wrap your <Route> in a <Routes>.`\n  );\n}\n\nexport interface RouterProps {\n  basename?: string;\n  children?: React.ReactNode;\n  location: Partial<Location> | string;\n  navigationType?: NavigationType;\n  navigator: Navigator;\n  static?: boolean;\n}\n\n/**\n * Provides location context for the rest of the app.\n *\n * Note: You usually won't render a <Router> directly. Instead, you'll render a\n * router that is more specific to your environment such as a <BrowserRouter>\n * in web browsers or a <StaticRouter> for server rendering.\n *\n * @see https://reactrouter.com/docs/en/v6/api#router\n */\nexport function Router({\n  basename: basenameProp = \"/\",\n  children = null,\n  location: locationProp,\n  navigationType = NavigationType.Pop,\n  navigator,\n  static: staticProp = false,\n}: RouterProps): React.ReactElement | null {\n  invariant(\n    !useInRouterContext(),\n    `You cannot render a <Router> inside another <Router>.` +\n      ` You should never have more than one in your app.`\n  );\n\n  let basename = normalizePathname(basenameProp);\n  let navigationContext = React.useMemo(\n    () => ({ basename, navigator, static: staticProp }),\n    [basename, navigator, staticProp]\n  );\n\n  if (typeof locationProp === \"string\") {\n    locationProp = parsePath(locationProp);\n  }\n\n  let {\n    pathname = \"/\",\n    search = \"\",\n    hash = \"\",\n    state = null,\n    key = \"default\",\n  } = locationProp;\n\n  let location = React.useMemo(() => {\n    let trailingPathname = stripBasename(pathname, basename);\n\n    if (trailingPathname == null) {\n      return null;\n    }\n\n    return {\n      pathname: trailingPathname,\n      search,\n      hash,\n      state,\n      key,\n    };\n  }, [basename, pathname, search, hash, state, key]);\n\n  warning(\n    location != null,\n    `<Router basename=\"${basename}\"> is not able to match the URL ` +\n      `\"${pathname}${search}${hash}\" because it does not start with the ` +\n      `basename, so the <Router> won't render anything.`\n  );\n\n  if (location == null) {\n    return null;\n  }\n\n  return (\n    <NavigationContext.Provider value={navigationContext}>\n      <LocationContext.Provider\n        children={children}\n        value={{ location, navigationType }}\n      />\n    </NavigationContext.Provider>\n  );\n}\n\nexport interface RoutesProps {\n  children?: React.ReactNode;\n  location?: Partial<Location> | string;\n}\n\n/**\n * A container for a nested tree of <Route> elements that renders the branch\n * that best matches the current location.\n *\n * @see https://reactrouter.com/docs/en/v6/api#routes\n */\nexport function Routes({\n  children,\n  location,\n}: RoutesProps): React.ReactElement | null {\n  return useRoutes(createRoutesFromChildren(children), location);\n}\n\n///////////////////////////////////////////////////////////////////////////////\n// UTILS\n///////////////////////////////////////////////////////////////////////////////\n\n/**\n * Creates a route config from a React \"children\" object, which is usually\n * either a `<Route>` element or an array of them. Used internally by\n * `<Routes>` to create a route config from its children.\n *\n * @see https://reactrouter.com/docs/en/v6/api#createroutesfromchildren\n */\nexport function createRoutesFromChildren(\n  children: React.ReactNode\n): RouteObject[] {\n  let routes: RouteObject[] = [];\n\n  React.Children.forEach(children, (element) => {\n    if (!React.isValidElement(element)) {\n      // Ignore non-elements. This allows people to more easily inline\n      // conditionals in their route config.\n      return;\n    }\n\n    if (element.type === React.Fragment) {\n      // Transparently support React.Fragment and its children.\n      routes.push.apply(\n        routes,\n        createRoutesFromChildren(element.props.children)\n      );\n      return;\n    }\n\n    invariant(\n      element.type === Route,\n      `[${\n        typeof element.type === \"string\" ? element.type : element.type.name\n      }] is not a <Route> component. All component children of <Routes> must be a <Route> or <React.Fragment>`\n    );\n\n    let route: RouteObject = {\n      caseSensitive: element.props.caseSensitive,\n      element: element.props.element,\n      index: element.props.index,\n      path: element.props.path,\n    };\n\n    if (element.props.children) {\n      route.children = createRoutesFromChildren(element.props.children);\n    }\n\n    routes.push(route);\n  });\n\n  return routes;\n}\n\n/**\n * Renders the result of `matchRoutes()` into a React element.\n */\nexport function renderMatches(\n  matches: RouteMatch[] | null\n): React.ReactElement | null {\n  return _renderMatches(matches);\n}\n","/**\n * NOTE: If you refactor this to split up the modules into separate files,\n * you'll need to update the rollup config for react-router-dom-v5-compat.\n */\nimport * as React from \"react\";\nimport type { BrowserHistory, HashHistory, History } from \"history\";\nimport { createBrowserHistory, createHashHistory } from \"history\";\nimport {\n  MemoryRouter,\n  Navigate,\n  Outlet,\n  Route,\n  Router,\n  Routes,\n  createRoutesFromChildren,\n  generatePath,\n  matchRoutes,\n  matchPath,\n  createPath,\n  parsePath,\n  resolvePath,\n  renderMatches,\n  useHref,\n  useInRouterContext,\n  useLocation,\n  useMatch,\n  useNavigate,\n  useNavigationType,\n  useOutlet,\n  useParams,\n  useResolvedPath,\n  useRoutes,\n  useOutletContext,\n} from \"react-router\";\nimport type { To } from \"react-router\";\n\nfunction warning(cond: boolean, message: string): void {\n  if (!cond) {\n    // eslint-disable-next-line no-console\n    if (typeof console !== \"undefined\") console.warn(message);\n\n    try {\n      // Welcome to debugging React Router!\n      //\n      // This error is thrown as a convenience so you can more easily\n      // find the source for a warning that appears in the console by\n      // enabling \"pause on exceptions\" in your JavaScript debugger.\n      throw new Error(message);\n      // eslint-disable-next-line no-empty\n    } catch (e) {}\n  }\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// RE-EXPORTS\n////////////////////////////////////////////////////////////////////////////////\n\n// Note: Keep in sync with react-router exports!\nexport {\n  MemoryRouter,\n  Navigate,\n  Outlet,\n  Route,\n  Router,\n  Routes,\n  createRoutesFromChildren,\n  generatePath,\n  matchRoutes,\n  matchPath,\n  createPath,\n  parsePath,\n  renderMatches,\n  resolvePath,\n  useHref,\n  useInRouterContext,\n  useLocation,\n  useMatch,\n  useNavigate,\n  useNavigationType,\n  useOutlet,\n  useParams,\n  useResolvedPath,\n  useRoutes,\n  useOutletContext,\n};\n\nexport { NavigationType } from \"react-router\";\nexport type {\n  Hash,\n  Location,\n  Path,\n  To,\n  MemoryRouterProps,\n  NavigateFunction,\n  NavigateOptions,\n  NavigateProps,\n  Navigator,\n  OutletProps,\n  Params,\n  PathMatch,\n  RouteMatch,\n  RouteObject,\n  RouteProps,\n  PathRouteProps,\n  LayoutRouteProps,\n  IndexRouteProps,\n  RouterProps,\n  Pathname,\n  Search,\n  RoutesProps,\n} from \"react-router\";\n\n///////////////////////////////////////////////////////////////////////////////\n// DANGER! PLEASE READ ME!\n// We provide these exports as an escape hatch in the event that you need any\n// routing data that we don't provide an explicit API for. With that said, we\n// want to cover your use case if we can, so if you feel the need to use these\n// we want to hear from you. Let us know what you're building and we'll do our\n// best to make sure we can support you!\n//\n// We consider these exports an implementation detail and do not guarantee\n// against any breaking changes, regardless of the semver release. Use with\n// extreme caution and only if you understand the consequences. Godspeed.\n///////////////////////////////////////////////////////////////////////////////\n\n/** @internal */\nexport {\n  UNSAFE_NavigationContext,\n  UNSAFE_LocationContext,\n  UNSAFE_RouteContext,\n} from \"react-router\";\n\n////////////////////////////////////////////////////////////////////////////////\n// COMPONENTS\n////////////////////////////////////////////////////////////////////////////////\n\nexport interface BrowserRouterProps {\n  basename?: string;\n  children?: React.ReactNode;\n  window?: Window;\n}\n\n/**\n * A `<Router>` for use in web browsers. Provides the cleanest URLs.\n */\nexport function BrowserRouter({\n  basename,\n  children,\n  window,\n}: BrowserRouterProps) {\n  let historyRef = React.useRef<BrowserHistory>();\n  if (historyRef.current == null) {\n    historyRef.current = createBrowserHistory({ window });\n  }\n\n  let history = historyRef.current;\n  let [state, setState] = React.useState({\n    action: history.action,\n    location: history.location,\n  });\n\n  React.useLayoutEffect(() => history.listen(setState), [history]);\n\n  return (\n    <Router\n      basename={basename}\n      children={children}\n      location={state.location}\n      navigationType={state.action}\n      navigator={history}\n    />\n  );\n}\n\nexport interface HashRouterProps {\n  basename?: string;\n  children?: React.ReactNode;\n  window?: Window;\n}\n\n/**\n * A `<Router>` for use in web browsers. Stores the location in the hash\n * portion of the URL so it is not sent to the server.\n */\nexport function HashRouter({ basename, children, window }: HashRouterProps) {\n  let historyRef = React.useRef<HashHistory>();\n  if (historyRef.current == null) {\n    historyRef.current = createHashHistory({ window });\n  }\n\n  let history = historyRef.current;\n  let [state, setState] = React.useState({\n    action: history.action,\n    location: history.location,\n  });\n\n  React.useLayoutEffect(() => history.listen(setState), [history]);\n\n  return (\n    <Router\n      basename={basename}\n      children={children}\n      location={state.location}\n      navigationType={state.action}\n      navigator={history}\n    />\n  );\n}\n\nexport interface HistoryRouterProps {\n  basename?: string;\n  children?: React.ReactNode;\n  history: History;\n}\n\n/**\n * A `<Router>` that accepts a pre-instantiated history object. It's important\n * to note that using your own history object is highly discouraged and may add\n * two versions of the history library to your bundles unless you use the same\n * version of the history library that React Router uses internally.\n */\nfunction HistoryRouter({ basename, children, history }: HistoryRouterProps) {\n  const [state, setState] = React.useState({\n    action: history.action,\n    location: history.location,\n  });\n\n  React.useLayoutEffect(() => history.listen(setState), [history]);\n\n  return (\n    <Router\n      basename={basename}\n      children={children}\n      location={state.location}\n      navigationType={state.action}\n      navigator={history}\n    />\n  );\n}\n\nif (__DEV__) {\n  HistoryRouter.displayName = \"unstable_HistoryRouter\";\n}\n\nexport { HistoryRouter as unstable_HistoryRouter };\n\nfunction isModifiedEvent(event: React.MouseEvent) {\n  return !!(event.metaKey || event.altKey || event.ctrlKey || event.shiftKey);\n}\n\nexport interface LinkProps\n  extends Omit<React.AnchorHTMLAttributes<HTMLAnchorElement>, \"href\"> {\n  reloadDocument?: boolean;\n  replace?: boolean;\n  state?: any;\n  to: To;\n}\n\n/**\n * The public API for rendering a history-aware <a>.\n */\nexport const Link = React.forwardRef<HTMLAnchorElement, LinkProps>(\n  function LinkWithRef(\n    { onClick, reloadDocument, replace = false, state, target, to, ...rest },\n    ref\n  ) {\n    let href = useHref(to);\n    let internalOnClick = useLinkClickHandler(to, { replace, state, target });\n    function handleClick(\n      event: React.MouseEvent<HTMLAnchorElement, MouseEvent>\n    ) {\n      if (onClick) onClick(event);\n      if (!event.defaultPrevented && !reloadDocument) {\n        internalOnClick(event);\n      }\n    }\n\n    return (\n      // eslint-disable-next-line jsx-a11y/anchor-has-content\n      <a\n        {...rest}\n        href={href}\n        onClick={handleClick}\n        ref={ref}\n        target={target}\n      />\n    );\n  }\n);\n\nif (__DEV__) {\n  Link.displayName = \"Link\";\n}\n\nexport interface NavLinkProps\n  extends Omit<LinkProps, \"className\" | \"style\" | \"children\"> {\n  children?:\n    | React.ReactNode\n    | ((props: { isActive: boolean }) => React.ReactNode);\n  caseSensitive?: boolean;\n  className?: string | ((props: { isActive: boolean }) => string | undefined);\n  end?: boolean;\n  style?:\n    | React.CSSProperties\n    | ((props: { isActive: boolean }) => React.CSSProperties);\n}\n\n/**\n * A <Link> wrapper that knows if it's \"active\" or not.\n */\nexport const NavLink = React.forwardRef<HTMLAnchorElement, NavLinkProps>(\n  function NavLinkWithRef(\n    {\n      \"aria-current\": ariaCurrentProp = \"page\",\n      caseSensitive = false,\n      className: classNameProp = \"\",\n      end = false,\n      style: styleProp,\n      to,\n      children,\n      ...rest\n    },\n    ref\n  ) {\n    let location = useLocation();\n    let path = useResolvedPath(to);\n\n    let locationPathname = location.pathname;\n    let toPathname = path.pathname;\n    if (!caseSensitive) {\n      locationPathname = locationPathname.toLowerCase();\n      toPathname = toPathname.toLowerCase();\n    }\n\n    let isActive =\n      locationPathname === toPathname ||\n      (!end &&\n        locationPathname.startsWith(toPathname) &&\n        locationPathname.charAt(toPathname.length) === \"/\");\n\n    let ariaCurrent = isActive ? ariaCurrentProp : undefined;\n\n    let className: string | undefined;\n    if (typeof classNameProp === \"function\") {\n      className = classNameProp({ isActive });\n    } else {\n      // If the className prop is not a function, we use a default `active`\n      // class for <NavLink />s that are active. In v5 `active` was the default\n      // value for `activeClassName`, but we are removing that API and can still\n      // use the old default behavior for a cleaner upgrade path and keep the\n      // simple styling rules working as they currently do.\n      className = [classNameProp, isActive ? \"active\" : null]\n        .filter(Boolean)\n        .join(\" \");\n    }\n\n    let style =\n      typeof styleProp === \"function\" ? styleProp({ isActive }) : styleProp;\n\n    return (\n      <Link\n        {...rest}\n        aria-current={ariaCurrent}\n        className={className}\n        ref={ref}\n        style={style}\n        to={to}\n      >\n        {typeof children === \"function\" ? children({ isActive }) : children}\n      </Link>\n    );\n  }\n);\n\nif (__DEV__) {\n  NavLink.displayName = \"NavLink\";\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// HOOKS\n////////////////////////////////////////////////////////////////////////////////\n\n/**\n * Handles the click behavior for router `<Link>` components. This is useful if\n * you need to create custom `<Link>` components with the same click behavior we\n * use in our exported `<Link>`.\n */\nexport function useLinkClickHandler<E extends Element = HTMLAnchorElement>(\n  to: To,\n  {\n    target,\n    replace: replaceProp,\n    state,\n  }: {\n    target?: React.HTMLAttributeAnchorTarget;\n    replace?: boolean;\n    state?: any;\n  } = {}\n): (event: React.MouseEvent<E, MouseEvent>) => void {\n  let navigate = useNavigate();\n  let location = useLocation();\n  let path = useResolvedPath(to);\n\n  return React.useCallback(\n    (event: React.MouseEvent<E, MouseEvent>) => {\n      if (\n        event.button === 0 && // Ignore everything but left clicks\n        (!target || target === \"_self\") && // Let browser handle \"target=_blank\" etc.\n        !isModifiedEvent(event) // Ignore clicks with modifier keys\n      ) {\n        event.preventDefault();\n\n        // If the URL hasn't changed, a regular <a> will do a replace instead of\n        // a push, so do the same here.\n        let replace =\n          !!replaceProp || createPath(location) === createPath(path);\n\n        navigate(to, { replace, state });\n      }\n    },\n    [location, navigate, path, replaceProp, state, target, to]\n  );\n}\n\n/**\n * A convenient wrapper for reading and writing search parameters via the\n * URLSearchParams interface.\n */\nexport function useSearchParams(defaultInit?: URLSearchParamsInit) {\n  warning(\n    typeof URLSearchParams !== \"undefined\",\n    `You cannot use the \\`useSearchParams\\` hook in a browser that does not ` +\n      `support the URLSearchParams API. If you need to support Internet ` +\n      `Explorer 11, we recommend you load a polyfill such as ` +\n      `https://github.com/ungap/url-search-params\\n\\n` +\n      `If you're unsure how to load polyfills, we recommend you check out ` +\n      `https://polyfill.io/v3/ which provides some recommendations about how ` +\n      `to load polyfills only for users that need them, instead of for every ` +\n      `user.`\n  );\n\n  let defaultSearchParamsRef = React.useRef(createSearchParams(defaultInit));\n\n  let location = useLocation();\n  let searchParams = React.useMemo(() => {\n    let searchParams = createSearchParams(location.search);\n\n    for (let key of defaultSearchParamsRef.current.keys()) {\n      if (!searchParams.has(key)) {\n        defaultSearchParamsRef.current.getAll(key).forEach((value) => {\n          searchParams.append(key, value);\n        });\n      }\n    }\n\n    return searchParams;\n  }, [location.search]);\n\n  let navigate = useNavigate();\n  let setSearchParams = React.useCallback(\n    (\n      nextInit: URLSearchParamsInit,\n      navigateOptions?: { replace?: boolean; state?: any }\n    ) => {\n      navigate(\"?\" + createSearchParams(nextInit), navigateOptions);\n    },\n    [navigate]\n  );\n\n  return [searchParams, setSearchParams] as const;\n}\n\nexport type ParamKeyValuePair = [string, string];\n\nexport type URLSearchParamsInit =\n  | string\n  | ParamKeyValuePair[]\n  | Record<string, string | string[]>\n  | URLSearchParams;\n\n/**\n * Creates a URLSearchParams object using the given initializer.\n *\n * This is identical to `new URLSearchParams(init)` except it also\n * supports arrays as values in the object form of the initializer\n * instead of just strings. This is convenient when you need multiple\n * values for a given key, but don't want to use an array initializer.\n *\n * For example, instead of:\n *\n *   let searchParams = new URLSearchParams([\n *     ['sort', 'name'],\n *     ['sort', 'price']\n *   ]);\n *\n * you can do:\n *\n *   let searchParams = createSearchParams({\n *     sort: ['name', 'price']\n *   });\n */\nexport function createSearchParams(\n  init: URLSearchParamsInit = \"\"\n): URLSearchParams {\n  return new URLSearchParams(\n    typeof init === \"string\" ||\n    Array.isArray(init) ||\n    init instanceof URLSearchParams\n      ? init\n      : Object.keys(init).reduce((memo, key) => {\n          let value = init[key];\n          return memo.concat(\n            Array.isArray(value) ? value.map((v) => [key, v]) : [[key, value]]\n          );\n        }, [] as ParamKeyValuePair[])\n  );\n}\n","export const data =[[\"회사에서 새로운 서버리스 워크로드를 배포할 준비를 하고 있습니다. 솔루션 설계자는 AWS Lambda 함수를 호출하기 위한 권한을 구성해야 합니다. 이 함수는 Amazon EventBridge(Amazon CloudWatch Events) 규칙에 의해 트리거됩니다. 최소 권한 원칙을 사용하여 권한을 구성해야 합니다.\\n어떤 솔루션이 이러한 요구 사항을 충족합니까?\\n\\nA.lambda:InvokeFunction을 작업으로 사용하고 *를 보안 주체로 사용하여 함수에 실행 역할을 추가합니다.\\nB. Lambda:InvokeFunction을 작업으로, Service:amazonaws.com을 보안 주체로 사용하여 함수에 실행 역할을 추가합니다.\\nC. lambda:'*를 작업으로, Service:events.amazonaws.com을 보안 주체로 사용하여 리소스 기반 정책을 함수에 추가합니다.\\nD. Lambda:InvokeFunction을 작업으로, Service:events.amazonaws.com을 보안 주체로 사용하여 리소스 기반 정책을 함수에 추가합니다.\", \"A company is preparing to deploy a new serverless workload. A solutions architect needs to configure permissions for invoking an AWS Lambda function. The function will be triggered by an Amazon EventBridge (Amazon CloudWatch Events) rule. Permissions should be configured using the principle of least privilege.\\nWhich solution will meet these requirements?\\n\\nA.Add an execution role to the function with lambda:InvokeFunction as the action and * as the principal.\\nB. Add an execution role to the function with lambda:InvokeFunction as the action and Service:amazonaws.com as the principal.\\nC. Add a resource-based policy to the function with lambda:'* as the action and Service:events.amazonaws.com as the principal.\\nD. Add a resource-based policy to the function with lambda:InvokeFunction as the action and Service:events.amazonaws.com as the principal.\", \"D. EventBridge가 lambda를 호출하기 위해서는 lambda:InvokeFunction에 대한 권한이 events.amazonaws.com에게 부여되어야 함. 따라서 C, D가 가능하지만, least privilege를 요구하였으므로 D가 정답.\"],\n[\"회사는 Amazon Elastic Block Store(Amazon EBS)를 사용해 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 인스턴스는 매일 12시간 동안 사용할 수 있어야 합니다. 회사는 애플리케이션에 필요한 창 밖에 인스턴스를 만들어 비용을 절감하고자 합니다. 그러나 인스턴스를 사용할 수 없을 때마다 메모리 내용을 보존해야 합니다.\\n솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?\\n\\nA.애플리케이션의 가용성 창 밖에서 인스턴스를 중지(stop)합니다. 필요할 때 인스턴스를 다시 시작하십시오.\\nB. 애플리케이션의 가용성 창 밖에서 인스턴스를 최대절전모드(hibernate)합니다. 필요할 때 인스턴스를 다시 시작하십시오.\\nC. Auto Scaling을 사용하여 애플리케이션의 가용성 창 밖에서 인스턴스를 축소합니다. 필요한 경우 인스턴스를 확장합니다.\\nD. 애플리케이션의 가용성 창 밖에서 인스턴스를 종료합니다. 필요한 경우 사전 구성된 Amazon 머신 이미지(AMI)를 사용하여 인스턴스를 시작합니다.\", \"A company runs an application on an Amazon EC2 instances backed by Amazon Elastic Block Store (Amazon EBS). The instances need to be available for 12 hours daily. The company wants to save costs by making the instance outside the window required for the application. However, the contents of the memory must be preserved whenever the instance is unavailable.\\nWhat should a solutions architect do to meet this requirement?\\n\\nA.Stop the instance outside the application's availability window. Start up the instance again when required.\\nB. Hibernate the instance outside the application's availability window. Start up the instance again when required.\\nC. Use Auto Scaling to scale down the instance outside the application's availability window. Scale up the instance when required.\\nD. Terminate the instance outside the application's availability window. Launch the instance by using a preconfigured Amazon Machine Image (AMI) when required.\", \"B. 메모리를 보존하면서 비용을 절감하기 위해 최대절전모드 사용.\"],\n[\"회사는 회계 시스템을 온프레미스 데이터 센터에서 Amazon Web Services(AWS) 리전으로 마이그레이션하려고 합니다. 데이터 보안과 변경 불가능한 감사 로그가 우선되어야 합니다. 모든 AWS 활동은 규정 준수 감사를 받아야 합니다. 비즈니스에서 AWS CloudTrail을 활성화했음에도 불구하고 이러한 요구 사항을 충족하는지 확인하려고 합니다.\\nCloudTrail을 보호하고 보호하기 위해 솔루션 설계자가 포함해야 하는 예방 조치 및 보안 절차는 무엇입니까? (2개를 선택하세요.)\\n\\nA.CloudTrail 로그 파일 유효성 검사를 활성화해야 합니다.\\nB. CloudTrail 처리 라이브러리를 설치합니다.\\nC. CloudTrail에서 Insights 이벤트 로깅을 활성화합니다.\\nD. 온프레미스 리소스에서 사용자 지정 로깅을 활성화합니다.\\nE. CloudTrail이 AWS KMS 관리형 암호화 키(SSE-KMS)와 함께 서버 측 암호화를 사용하도록 구성되었는지 여부를 모니터링하는 AWS Config 규칙을 생성합니다\", \"A firm seeks to migrate its accounting system from an on-premises data center to an Amazon Web Services (AWS) Region. Data security and an unalterable audit log should be prioritized. All AWS activities must be subjected to compliance audits. Despite the fact that the business has enabled AWS CloudTrail, it want to guarantee that it meets these requirements.\\nWhat precautions and security procedures should a solutions architect include to protect and secure CloudTrail? (Choose two.)\\n\\nA.Enable CloudTrail log file validation.\\nB. Install the CloudTrail Processing Library.\\nC. Enable logging of Insights events in CloudTrail.\\nD. Enable custom logging from the on-premises resources.\\nE. Create an AWS Config rule to monitor whether CloudTrail is configured to use server-side encryption with AWS KMS managed encryption keys (SSE-KMS).\", \"A, E\"],\n[\"웹사이트에서 기업은 검색 가능한 물건을 보관합니다. 데이터는 Amazon RDS for MySQL 데이터베이스의 천만 개 이상의 행이 있는 테이블에 저장됩니다. 데이터베이스는 2TB 범용 SSD(gp2) 어레이에 저장됩니다. 매일 회사 웹 사이트는 수백만 건의 이 데이터 변경 사항을 수신합니다. 조직은 특정 작업에 10초 이상이 소요된다는 사실을 발견하고 병목 현상이 데이터베이스 스토리지 성능이라는 결론을 내렸습니다.\\n성능 요구 사항을 충족하는 옵션은 무엇입니까?\\n\\nA.스토리지 유형을 프로비저닝된 IOPS SSD(io1)로 변경합니다.\\nB. 인스턴스를 메모리 최적화 인스턴스 클래스로 변경합니다.\\nC. 인스턴스를 버스트 가능한 성능 DB 인스턴스 클래스로 변경합니다.\\nD. MySQL 기본 비동기 복제로 다중 AZ RDS 읽기 전용 복제본을 활성화합니다.\", \"On its website, a business keeps a searchable store of things. The data is stored in a table with over ten million rows in an Amazon RDS for MySQL database. The database is stored on a 2 TB General Purpose SSD (gp2) array. Every day, the company's website receives millions of changes to this data. The organization found that certain activities were taking ten seconds or more and concluded that the bottleneck was the database storage performance.\\nWhich option satisfies the performance requirement?\\n\\nA.Change the storage type to Provisioned IOPS SSD (io1).\\nB. Change the instance to a memory-optimized instance class.\\nC. Change the instance to a burstable performance DB instance class.\\nD. Enable Multi-AZ RDS read replicas with MySQL native asynchronous replication.\", \"A. 스토리지 성능에 문제가 있다고 하였으므로 스토리지 유형을 업그레이드 한다.\"],\n[\"현재 온프레미스에서 웹 애플리케이션을 호스팅하고 있는 비즈니스는 AWS로 전환하고 애플리케이션의 새 버전을 출시할 준비가 되어 있습니다. 조직은 URL 쿼리 문자열을 기반으로 AWS 또는 온프레미스 애플리케이션으로 요청을 라우팅해야 합니다. 온프레미스 애플리케이션은 인터넷을 통해 연결할 수 없도록 렌더링되고 Amazon VPC와 비즈니스 데이터 센터 간에 VPN 연결이 설정됩니다. 회사는 로드 밸런서(ALB)를 사용하여 이 애플리케이션을 배포하려고 합니다.\\n다음 중 이러한 기준을 충족하는 솔루션은 무엇입니까?\\n\\nA.두 개의 ALB를 사용하십시오. 하나는 온프레미스용이고 다른 하나는 AWS 리소스용입니다. 각 ALB의 각 대상 그룹에 호스트를 추가하십시오. URL 쿼리 문자열을 기반으로 Amazon Route 53으로 라우팅합니다.\\nB. 두 개의 ALB를 사용합니다. 하나는 온프레미스용이고 다른 하나는 AWS 리소스용입니다. 각 ALB의 대상 그룹에 호스트를 추가하십시오. URL 쿼리 문자열을 기반으로 EC2 인스턴스에 소프트웨어 라우터를 생성합니다.\\nC. 하나의 ALB를 두 개의 대상 그룹으로 사용합니다. 하나는 AWS 리소스용이고 다른 하나는 온프레미스용입니다. ALB의 각 대상 그룹에 호스트를 추가합니다. URL 쿼리 문자열을 기반으로 리스너 규칙을 구성합니다.\\nD. 2개의 AWS Auto Scaling 그룹과 함께 하나의 ALB를 사용합니다. 하나는 AWS 리소스용이고 다른 하나는 온프레미스용입니다. 각 Auto Scaling 그룹에 호스트를 추가합니다. URL 쿼리 문자열을 기반으로 Amazon Route 53으로 라우팅합니다.\", \"A firm that now hosts a web application on-premises is ready to migrate to AWS and launch a newer version of the program. The organization must route requests depending on the URL query string to either the AWS- or on-premises-hosted application. The on-premises application is inaccessible over the internet, and a VPN connection between Amazon VPC and the company's data center is formed. The firm intends to deploy this application using an Application Load Balancer (ALB).\\nWhich solution satisfies these criteria?\\n\\nA.Use two ALBs: one for on-premises and one for the AWS resource. Add hosts to each target group of each ALB. Route with Amazon Route 53 based on the URL query string.\\nB. Use two ALBs: one for on-premises and one for the AWS resource. Add hosts to the target group of each ALB. Create a software router on an EC2 instance based on the URL query string.\\nC. Use one ALB with two target groups: one for the AWS resource and one for on premises. Add hosts to each target group of the ALB. Configure listener rules based on the URL query string.\\nD. Use one ALB with two AWS Auto Scaling groups: one for the AWS resource and one for on premises. Add hosts to each Auto Scaling group. Route with Amazon Route 53 based on the URL query string.\", \"C\"],\n[\"회사에서 데이터 저장을 위해 Amazon DynamoDB 테이블을 사용할 계획입니다. 회사는 비용 최적화에 대해 우려하고 있습니다. 이 테이블은 대부분의 아침 저녁에 사용되지 않습니다. 읽기 및 쓰기 트래픽은 종종 예측할 수 없습니다. 트래픽 스파이크가 발생하면 매우 빠르게 발생합니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\\n\\nA.온디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다.\\nB. 글로벌 보조 인덱스가 있는 DynamoDB 테이블을 생성합니다.\\nC. 프로비저닝된 용량 및 Auto Scaling으로 DynamoDB 테이블을 생성합니다.\\nD. 프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 전역 테이블로 구성합니다.\", \"A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings in the evenings, the read and write traffic will often be unpredictable When traffic spikes occur they will happen very quickly.\\nWhat should a solutions architect recommend?\\n\\nA.Create a DynamoDB table in on-demand capacity mode.\\nB. Create a DynamoDB table with a global secondary Index.\\nC. Create a DynamoDB table with provisioned capacity and auto scaling.\\nD. Create a DynamoDB table in provisioned capacity mode, and configure it as a global table.\", \"A\"],\n[\"기업은 AWS 애플리케이션을 사용하여 전 세계 구독자에게 콘텐츠를 제공합니다. 수많은 Amazon EC2 인스턴스가 애플리케이션(ALB)용 Application Load Balancer 뒤의 프라이빗 서브넷에 배포됩니다. CIO(최고 정보 책임자)는 최근 저작권 규정 변경으로 인해 일부 국가에 대한 액세스를 제한하고자 합니다.\\n이러한 기준을 충족하는 조치는 무엇입니까?\\n\\nA.차단된 국가에서 들어오는 트래픽을 거부하도록 ALB 보안 그룹을 수정합니다.\\nB. 차단된 국가에서 들어오는 트래픽을 거부하도록 EC2 인스턴스에 대한 보안 그룹을 수정합니다.\\nC. Amazon CloudFront를 사용하여 애플리케이션을 제공하고 차단된 국가에 대한 액세스를 거부합니다.\\nD. ALB 수신기 규칙을 사용하여 차단된 국가에서 들어오는 트래픽에 대한 액세스 거부 응답을 반환합니다.\", \"A corporation uses an AWS application to offer content to its subscribers worldwide. Numerous Amazon EC2 instances are deployed on a private subnet behind an Application Load Balancer for the application (ALB). The chief information officer (CIO) wishes to limit access to some nations due to a recent change in copyright regulations.\\nWhich course of action will satisfy these criteria?\\n\\nA.Modify the ALB security group to deny incoming traffic from blocked countries.\\nB. Modify the security group for EC2 instances to deny incoming traffic from blocked countries.\\nC. Use Amazon CloudFront to serve the application and deny access to blocked countries.\\nD. Use ALB listener rules to return access denied responses to incoming traffic from blocked countries.\", \"C. 지역별 차단 기능은 CloudFront가 제공\"],\n[\"7개의 Amazon EC2 인스턴스를 사용하여 기업은 AWS에서 웹 애플리케이션을 실행합니다. 조직은 DNS 쿼리가 모든 정상 EC2 인스턴스의 IP 주소를 제공해야 합니다.\\n이 규정을 준수하려면 어떤 정책을 사용해야 합니까?\\n\\nA.단순 라우팅 정책\\nB. 지연 라우팅 정책\\nC. 다중값 라우팅 정책\\nD. 지리적 위치 라우팅 정책\", \"Using seven Amazon EC2 instances, a business runs its web application on AWS. The organization needs that DNS queries provide the IP addresses of all healthy EC2 instances.\\nWhich policy should be employed to comply with this stipulation?\\n\\nA.Simple routing policy\\nB. Latency routing policy\\nC. Multi-value routing policy\\nD. Geolocation routing policy\", \"C.\"],\n[\"매일 기업은 수백만 명의 소비자로부터 약 1'에 달하는 데이터를 수집합니다. 회사는 고객에게 지난 12개월 동안의 사용 기록을 제공합니다. 규제 및 감사 표준을 충족하려면 모든 사용 데이터를 최소 5년 동안 보관해야 합니다.\\n가장 저렴한 스토리지 옵션은 무엇입니까?\\n\\nA.Amazon S3 Standard에 데이터를 저장합니다. 수명 주기 규칙을 설정하여 1년 후에 데이터를 S3 Glacier Deep Archive로 전환합니다. 5년 후 데이터를 삭제하는 수명 주기 규칙을 설정합니다.\\nB. Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)에 데이터를 저장합니다. 수명 주기 규칙을 설정하여 1년 후에 데이터를 S3 Glacier로 전환합니다. 5년 후에 데이터를 삭제하도록 수명 주기 규칙을 설정합니다.\\nC. Amazon S3 Standard에 데이터를 저장합니다. 수명 주기 규칙을 설정하여 1년 후에 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다. 5년 후 데이터를 삭제하는 수명 주기 규칙을 설정합니다.\\nD. Amazon S3 Standard에 데이터를 저장합니다. 1년 후에 데이터를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하는 수명 주기 규칙을 설정합니다. 5년 후 데이터를 삭제하는 수명 주기 규칙을 설정합니다.\", \"Each day, a corporation collects data from millions of consumers totalling around 1'. The firm delivers use records for the last 12 months to its customers. To meet with regulatory and auditing standards, all use data must be retained for at least five years.\\nWhich storage option is the MOST CHEAPEST?\\n\\nA.Store the data in Amazon S3 Standard. Set a lifecycle rule to transition the data to S3 Glacier Deep Archive after 1 year. Set a lifecycle rule to delete the data after 5 years.\\nB. Store the data in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). Set a lifecycle rule to transition the data to S3 Glacier after 1 year. Set the lifecycle rule to delete the data after 5 years.\\nC. Store the data in Amazon S3 Standard. Set a lifecycle rule to transition the data to S3 Standard-Infrequent Access (S3 Standard-IA) after 1 year. Set a lifecycle rule to delete the data after 5 years.\\nD. Store the data in Amazon S3 Standard. Set a lifecycle rule to transition the data to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 1 year. Set a lifecycle rule to delete the data after 5 years.\", \"A. 초기 1년동안은 데이터에 자주 access하므로 S3 Standard 사용. (Infrequent Access 사용불가.) 이후 S3 IA나 Glacier로 전환 가능하지만 Glacier가 더 저렴하므로 A.\"],\n[\"기업은 Amazon RDS for PostgreSQL 데이터베이스 인스턴스를 사용하여 웹 서버 집합을 관리합니다. 정상적인 규정 준수 검토 후 회사는 모든 프로덕션 데이터베이스에 1초 미만의 RPO(복구 시점 목표)를 갖도록 요구하는 표준을 설정합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.DB 인스턴스에 대한 다중 AZ 배포를 활성화합니다.\\nB. 하나의 가용 영역에서 DB 인스턴스에 대한 Auto Scaling을 활성화합니다.\\nC. 하나의 가용 영역에 DB 인스턴스를 구성하고 별도의 가용 영역에 여러 개의 읽기 전용 복제본을 생성합니다.\\nD. 하나의 가용 영역에서 DB 인스턴스를 구성하고 AWS DMS(AWS Database Migration Service) 변경 데이터 캡처(CDC) 작업을 구성합니다.\", \"A business uses an Amazon RDS for PostgreSQL database instance to manage a fleet of web servers. Following a normal compliance review, the corporation establishes a standard requiring all production databases to have a recovery point objective (RPO) of less than one second.\\nWhich solution satisfies these criteria?\\n\\nA.Enable a Multi-AZ deployment for the DB instance.\\nB. Enable auto scaling for the DB instance in one Availability Zone.\\nC. Configure the DB instance in one Availability Zone, and create multiple read replicas in a separate Availability Zone.\\nD. Configure the DB instance in one Availability Zone, and configure AWS Database Migration Service (AWS DMS) change data capture (CDC) tasks.\", \"A.\"],\n[\"Amazon EC2 인스턴스에서 기업은 일시적인 트랜잭션 데이터를 생성하는 애플리케이션을 개발하고 있습니다. 애플리케이션에는 조정 가능하고 일관된 IOPS를 제공할 수 있는 데이터 스토리지에 대한 액세스가 필요합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.처리량 최적화 HDD(st1) 루트 볼륨 및 Cold HDD(sc1) 데이터 볼륨으로 EC2 인스턴스를 프로비저닝합니다.\\nB. 루트 및 데이터 볼륨 역할을 할 처리량 최적화 HDD(st1) 볼륨으로 EC2 인스턴스를 프로비저닝합니다.\\nC. 범용 SSD(gp2) 루트 볼륨 및 프로비저닝된 IOPS SSD(io1) 데이터 볼륨으로 EC2 인스턴스를 프로비저닝합니다.\\nD. 범용 SSD(gp2) 루트 볼륨으로 EC2 인스턴스를 프로비저닝합니다. Amazon S3 버킷에 데이터를 저장하도록 애플리케이션을 구성합니다.\", \"On Amazon EC2 instances, a business is developing an application that creates transitory transactional data. Access to data storage that can deliver adjustable and consistent IOPS is required by the application.\\nWhat recommendations should a solutions architect make?\\n\\nA.Provision an EC2 instance with a Throughput Optimized HDD (st1) root volume and a Cold HDD (sc1) data volume.\\nB. Provision an EC2 instance with a Throughput Optimized HDD (st1) volume that will serve as the root and data volume.\\nC. Provision an EC2 instance with a General Purpose SSD (gp2) root volume and Provisioned IOPS SSD (io1) data volume.\\nD. Provision an EC2 instance with a General Purpose SSD (gp2) root volume. Configure the application to store its data in an Amazon S3 bucket.\", \"C. 일관된 IOPS를 위해서는 SSD 필요\"],\n[\"새 워크로드를 구현하기 전에 솔루션 설계자는 회사의 현재 IAM 규칙을 검사하고 업데이트해야 합니다. 다음 정책은 솔루션 설계자가 작성했습니다.\\n정책의 순 효과는 무엇입니까?\\n\\nA.다중 요소 인증(MFA)이 활성화된 경우 사용자는 s3:PutObject를 제외한 모든 작업이 허용됩니다.\\nB. 다중 요소 인증(MFA)이 활성화되지 않은 경우 사용자는 s3:PutObject를 제외한 모든 작업이 허용됩니다.\\nC. 다중 요소 인증(MFA)이 활성화된 경우 사용자는 s3:PutObject를 제외한 모든 작업이 거부됩니다.\\nD. 다중 요소 인증(MFA)이 활성화되지 않은 경우 사용자는 s3:PutObject를 제외한 모든 작업이 거부됩니다.\", \"Prior to implementing a new workload, a solutions architect must examine and update the company's current IAM rules. The following policy was written by the solutions architect:\\nWhat is the policy's net effect?\\n\\nA.Users will be allowed all actions except s3:PutObject if multi-factor authentication (MFA) is enabled.\\nB. Users will be allowed all actions except s3:PutObject if multi-factor authentication (MFA) is not enabled.\\nC. Users will be denied all actions except s3:PutObject if multi-factor authentication (MFA) is enabled.\\nD. Users will be denied all actions except s3:PutObject if multi-factor authentication (MFA) is not enabled.\", \"D. Condition을 보면, MFA가 false일 때 적용됨을 알 수 있고, 모든 것을 Deny하지만, put object만 제외함\"],\n[\"실시간 처리를 허용하려면 웹 애플리케이션이 Amazon S3에 주문 데이터를 유지해야 합니다. 솔루션 설계자는 확장 가능하고 내결함성이 있는 아키텍처를 설계해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까? (2개를 선택하세요.)\\n\\nA.Amazon DynamoDB 테이블에 주문 이벤트를 씁니다. DynamoDB 스트림을 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다.\\nB. Amazon Simple Queue Service(Amazon SQS) 대기열에 주문 이벤트를 씁니다. 대기열을 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWSLambda 함수를 트리거합니다.\\nC. Amazon Simple Notification Service(Amazon SNS) 주제에 주문 이벤트를 씁니다. SNS 주제를 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다.\\nD. Amazon Simple Queue Service(Amazon SQS) 대기열에 주문 이벤트를 씁니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다.\\nE. Amazon Simple Notification Service(Amazon SNS) 주제에 주문 이벤트를 씁니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다.\", \"To allow neat-real-time processing, a web application must persist order data to Amazon S3. A solutions architect must design a scalable and fault-tolerant architecture.\\nWhich solutions satisfy these criteria? (Select two.)\\n\\nA.Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.\\nB. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWSLambda function that parsers the payload and writes the data to Amazon S3.\\nC. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use the SNS topic to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.\\nD. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3.\\nE. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload andwrites the data to Amazon S3.\", \"A,C. 논란이 되고 있는 문제로, 실시간 처리에 SQS가 적합하지 않다는 의견이 많음.\"],\n[\"us-east-1 지역의 비즈니스에서 사진 호스팅 서비스를 제공합니다. 많은 국가의 사용자가 프로그램을 사용하여 이미지를 업로드하고 탐색할 수 있습니다. 일부 사진은 몇 달 동안 조회수가 많은 반면 다른 사진은 일주일 미만 동안 조회수가 적습니다. 이 프로그램은 최대 20MB 크기의 사진 업로드를 지원합니다. 서비스는 사진 정보를 기반으로 각 사용자에게 어떤 사진을 보여줄지 결정합니다.\\n적합한 사용자에게 가장 비용 효율적인 액세스를 제공하는 옵션은 무엇입니까?\\n\\nA.Amazon DynamoDB에 사진을 저장합니다. 자주 보는 항목을 캐시하려면 DynamoDB Accelerator(DAX)를 켜십시오.\\nB. Amazon S3 Intelligent-Tiering 스토리지 클래스에 사진을 저장합니다. 사진 메타데이터와 해당 S3 위치를 DynamoDB에 저장합니다.\\nC. Amazon S3 Standard 스토리지 클래스에 사진을 저장합니다. S3 수명 주기 정책을 설정하여 30일이 지난 사진을 S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스로 이동합니다. 객체 태그를 사용하여 메타데이터를 추적합니다.\\nD. Amazon S3 Glacier 스토리지 클래스에 사진을 저장합니다. S3 수명 주기 정책을 설정하여 30일이 지난 사진을 S3 Glacier Deep Archive 스토리지 클래스로 이동합니다. 사진 메타데이터와 해당 S3 위치를 Amazon Elasticsearch Service(Amazon ES)에 저장합니다.\", \"A business in the us-east-1 region offers a picture hosting service. Users from many countries may upload and browse images using the program. Some photographs get a high volume of views over months, while others receive a low volume of views for less than a week. The program supports picture uploads of up to 20 MB in size. The service determines which photographs to show to each user based on the photo information.\\nWhich option delivers the most cost-effective access to the suitable users?\\n\\nA.Store the photos in Amazon DynamoDB. Turn on DynamoDB Accelerator (DAX) to cache frequently viewed items.\\nB. Store the photos in the Amazon S3 Intelligent-Tiering storage class. Store the photo metadata and its S3 location in DynamoDB.\\nC. Store the photos in the Amazon S3 Standard storage class. Set up an S3 Lifecycle policy to move photos older than 30 days to the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Use the object tags to keep track of metadata.\\nD. Store the photos in the Amazon S3 Glacier storage class. Set up an S3 Lifecycle policy to move photos older than 30 days to the S3 Glacier Deep Archive storage class. Store the photo metadata and its S3 location in Amazon Elasticsearch Service (Amazon ES).\", \"B. 정확히 30일 뒤 조회수가 줄어드는 것이 아니므로 Intelligent-tiering이 적합.\"],\n[\"한 비즈니스에서 Amazon S3 버킷에 정적 사진을 저장할 웹 사이트를 만들고 있습니다. 회사의 목표는 모든 향후 요청에 대한 대기 시간과 비용을 줄이는 것입니다.\\n솔루션 설계자는 서비스 구성을 어떻게 제안해야 합니까?\\n\\nA.Amazon S3 앞에 NAT 서버를 배포합니다.\\nB. Amazon S3 앞에 Amazon CloudFront를 배포합니다.\\nC. Amazon S3 앞에 Network Load Balancer를 배포합니다.\\nD. Auto Scaling을 구성하여 웹사이트의 용량을 자동으로 조정합니다.\", \"A business is creating a website that will store static photos in an Amazon S3 bucket. The company's goal is to reduce both latency and cost for all future requests.\\nHow should a solutions architect propose a service configuration?\\n\\nA.Deploy a NAT server in front of Amazon S3.\\nB. Deploy Amazon CloudFront in front of Amazon S3.\\nC. Deploy a Network Load Balancer in front of Amazon S3.\\nD. Configure Auto Scaling to automatically adjust the capacity of the website.\", \"B\"],\n[\"전자 상거래 웹 사이트의 데이터베이스 계층의 경우 회사는 처리량이 제공되는 Amazon DynamoDB를 사용합니다. 플래시 판매 기간 동안 데이터베이스가 트랜잭션 볼륨을 관리할 수 없을 때 클라이언트는 지연 기간에 직면할 수 있습니다. 결과적으로 비즈니스는 거래를 잃게 됩니다. 데이터베이스는 정규 시간 동안 정상적으로 작동합니다.\\n어떤 접근 방식이 회사의 성과 문제를 해결합니까?\\n\\nA.플래시 판매 기간 동안 DynamoDB를 온디맨드 모드로 전환합니다.\\nB. 빠른 메모리 성능을 위해 DynamoDB Accelerator를 구현합니다.\\nC. Amazon Kinesis를 사용하여 DynamoDB에 대한 처리를 위해 트랜잭션을 대기열에 넣습니다.\\nD. Amazon Simple Queue Service(Amazon SQS)를 사용하여 DynamoDB에 대한 트랜잭션을 대기열에 넣습니다.\", \"For the database layer of its ecommerce website, a firm uses Amazon DynamoDB with provided throughput. During flash sales, clients may encounter periods of delay when the database is unable to manage the volume of transactions. As a result, the business loses transactions. The database operates normally during regular times.\\nWhich approach resolves the company's performance issue?\\n\\nA.Switch DynamoDB to on-demand mode during flash sales.\\nB. Implement DynamoDB Accelerator for fast in memory performance.\\nC. Use Amazon Kinesis to queue transactions for processing to DynamoDB.\\nD. Use Amazon Simple Queue Service (Amazon SQS) to queue transactions to DynamoDB.\", \"A. 플래시 판매 기간은 예측 가능하므로 온디맨드 모드 가능\"],\n[\"중요한 미디어 회사는 AWS를 사용하여 웹 애플리케이션을 호스팅합니다. 회사는 전 세계 소비자에게 신뢰할 수 있는 액세스를 제공하기 위해 비밀 미디어 파일 캐싱을 시작할 계획입니다. Amazon S3 버킷은 자료를 저장하는 데 사용됩니다. 조직은 요청의 출처에 관계없이 신속하게 자재를 공급해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.AWS DataSync를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다.\\nB. AWS Global Accelerator를 배포하여 S3 버킷을 웹 애플리케이션에 연결합니다.\\nC. Amazon CloudFront를 배포하여 S3 버킷을 CloudFront 엣지 서버에 연결합니다.\\nD. Amazon Simple Queue Service(Amazon SQS)를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다.\", \"A significant media corporation uses AWS to host a web application. The corporation intends to begin caching secret media files in order to provide dependable access to them to consumers worldwide. Amazon S3 buckets are used to store the material. The organization must supply material rapidly, regardless of the origin of the requests.\\nWhich solution will satisfy these criteria?\\n\\nA.Use AWS DataSync to connect the S3 buckets to the web application.\\nB. Deploy AWS Global Accelerator to connect the S3 buckets to the web application.\\nC. Deploy Amazon CloudFront to connect the S3 buckets to CloudFront edge servers.\\nD. Use Amazon Simple Queue Service (Amazon SQS) to connect the S3 buckets to the web application.\", \"C. B의 경우 네트워크 지연 시간을 줄이기 위해 사용(캐싱 X)\"],\n[\"AWS 클라우드에는 웹 애플리케이션이 배포됩니다. 웹 및 데이터베이스 계층으로 구성된 2계층 설계입니다. 웹 서버에서 XSS(교차 사이트 스크립팅) 공격이 가능합니다.\\n솔루션 설계자가 취약점을 해결하기 위해 취해야 하는 최선의 조치는 무엇입니까?\\n\\nA.클래식 로드 밸런서를 생성합니다. 로드 밸런서 뒤에 웹 계층을 배치하고 AWS WAF를 활성화합니다.\\nB. 네트워크 로드 밸런서를 생성합니다. 로드 밸런서 뒤에 웹 계층을 배치하고 AWS WAF를 활성화합니다.\\nC. 애플리케이션 로드 밸런서를 생성합니다. 로드 밸런서 뒤에 웹 계층을 배치하고 AWS WAF를 활성화합니다.\\nD. 애플리케이션 로드 밸런서를 생성합니다. 로드 밸런서 뒤에 웹 계층을 놓고 AWS Shield Standard를 사용합니다.\", \"In the AWS Cloud, a web application is deployed. It is a two-tier design comprised of a web and database layer. Cross-site scripting (XSS) attacks are possible on the web server.\\nWhat is the best course of action for a solutions architect to take to address the vulnerability?\\n\\nA.Create a Classic Load Balancer. Put the web layer behind the load balancer and enable AWS WAF.\\nB. Create a Network Load Balancer. Put the web layer behind the load balancer and enable AWS WAF.\\nC. Create an Application Load Balancer. Put the web layer behind the load balancer and enable AWS WAF.\\nD. Create an Application Load Balancer. Put the web layer behind the load balancer and use AWS Shield Standard.\", \"C. Application layer에 대한 공격이므로 ALB를 사용해야하고, Shield Advanced는 L3/L4 공격 방어\"],\n[\"기업은 Amazon S3를 사용하여 민감한 데이터를 저장할 준비가 되어 있습니다. 규정 준수를 위해 데이터를 암호화해야 합니다. 암호화 키 사용에 대한 감사가 필요합니다. 매년 키를 교체해야 합니다.\\n어떤 솔루션이 이러한 매개변수를 충족하고 운영 효율성 측면에서 가장 최적입니까?\\n\\nA.고객 제공 키를 사용한 서버 측 암호화(SSE-C)\\nB. Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3)\\nC. 수동 교체가 있는 AWS KMS(SSE-KMS) 고객 마스터 키(CMK)를 사용한 서버 측 암호화\\nD. 자동 교체 기능이 있는 AWS KMS(SSE-KMS) 고객 마스터 키(CMK)를 사용한 서버 측 암호화\", \"A business is prepared to use Amazon S3 to store sensitive data. Data must be encrypted at rest for compliance purposes. Auditing of encryption key use is required. Each year, keys must be rotated.\\nWhich solution satisfies these parameters and is the MOST OPTIMAL in terms of operational efficiency?\\n\\nA.Server-side encryption with customer-provided keys (SSE-C)\\nB. Server-side encryption with Amazon S3 managed keys (SSE-S3)\\nC. Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with manual rotation\\nD. Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with automatic rotation\", \"D\"],\n[\"관리는 예산 계획 프로세스의 일부로 사용자별로 분류된 AWS 청구 항목 요약이 필요합니다. 부서에 대한 예산은 데이터를 사용하여 생성됩니다. 솔루션 설계자는 이 보고서 데이터를 얻는 가장 효과적인 방법을 확인해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon Athena로 쿼리를 실행하여 보고서를 생성합니다.\\nB. 비용 탐색기에서 보고서를 생성하고 보고서를 다운로드합니다.\\nC. 청구 대시보드에서 청구 내역에 액세스하여 청구서를 다운로드합니다.\\nD. AWS 예산에서 비용 예산을 수정하여 Amazon Simple Email Service(Amazon SES)에 알림을 보냅니다.\", \"Management need a summary of AWS billed items broken down by user as part of their budget planning process. Budgets for departments will be created using the data. A solutions architect must ascertain the most effective method of obtaining this report data.\\nWhich solution satisfies these criteria?\\n\\nA.Run a query with Amazon Athena to generate the report.\\nB. Create a report in Cost Explorer and download the report.\\nC. Access the bill details from the billing dashboard and download the bill.\\nD. Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES).\", \"B\"],\n[\"솔루션 설계자는 클라이언트 사례 파일을 보관하기 위한 시스템을 만들어야 합니다. 파일은 중요한 기업 자산입니다. 파일 수는 시간이 지남에 따라 증가합니다.\\nAmazon EC2 인스턴스에서 실행되는 여러 애플리케이션 서버는 파일에 동시에 액세스할 수 있어야 합니다. 솔루션에는 기본 제공 중복성이 있어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon Elastic File System(Amazon EFS)\\nB. Amazon Elastic Block Store(Amazon EBS)\\nC. Amazon S3 Glacier 딥 아카이브\\nD. AWS 백업\", \"A solutions architect must create a system for archiving client case files. The files are critical corporate assets. The file count will increase over time.\\nMultiple application servers running on Amazon EC2 instances must be able to access the files concurrently. There must be built-in redundancy in the solution.\\nWhich solution satisfies these criteria?\\n\\nA.Amazon Elastic File System (Amazon EFS)\\nB. Amazon Elastic Block Store (Amazon EBS)\\nC. Amazon S3 Glacier Deep Archive\\nD. AWS Backup\", \"A. EFS를 통해 여러 EC2에 마운트 가능. 그런데, EBS Multi-Attach 출시로 인해 더 이상 출제되지 않을 듯.\"],\n[\"기업은 직원에게 기밀 및 민감한 데이터에 대한 보안 액세스를 제공해야 합니다. 회사는 승인된 개인만 데이터에 액세스할 수 있도록 보장하기를 원합니다. 데이터는 작업자의 장치에 안전하게 다운로드되어야 합니다.\\n파일은 온프레미스 Windows 파일 서버에 보관됩니다. 그러나 원격 트래픽이 증가함에 따라 파일 서버의 용량이 고갈되고 있습니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.파일 서버를 퍼블릭 서브넷의 Amazon EC2 인스턴스로 마이그레이션합니다. 직원의 IP 주소에 대한 인바운드 트래픽을 제한하도록 보안 그룹을 구성합니다.\\nB. 파일을 Windows 파일 서버용 Amazon FSx 파일 시스템으로 마이그레이션합니다. Amazon FSx 파일 시스템을 온프레미스 Active Directory와 통합합니다. AWS 클라이언트 VPN을 구성합니다.\\nC. 파일을 Amazon S3로 마이그레이션하고 프라이빗 VPC 엔드포인트를 생성합니다. 다운로드를 허용하려면 서명된 URL을 만듭니다.\\nD. 파일을 Amazon S3로 마이그레이션하고 퍼블릭 VPC 엔드포인트를 생성합니다. 직원이 AWS Single Sign-On으로 로그인하도록 허용합니다.\", \"A business must give secure access to secret and sensitive data to its workers. The firm want to guarantee that only authorized individuals have access to the data. The data must be safely downloaded to the workers' devices.\\nThe files are kept on a Windows file server on-premises. However, as remote traffic increases, the file server's capacity is being depleted.\\nWhich solution will satisfy these criteria?\\n\\nA.Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees' IP addresses.\\nB. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on-premises Active Directory. Configure AWS Client VPN.\\nC. Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.\\nD. Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS Single Sign-On.\", \"B\"],\n[\"법률 회사는 대중과 소통해야 합니다. 수백 개의 파일에 공개적으로 액세스할 수 있어야 합니다. 누구든지 지정된 미래 날짜 이전에 파일을 수정하거나 삭제할 수 없습니다.\\n가능한 가장 안전한 방법으로 이러한 기준을 충족하는 솔루션은 무엇입니까?\\n\\nA.모든 파일을 정적 웹 사이트 호스팅용으로 구성된 Amazon S3 버킷에 업로드합니다. 지정된 날짜까지 S3 버킷에 액세스하는 모든 AWS 보안 주체에게 읽기 전용 IAM 권한을 부여합니다.\\nB. S3 버전 관리가 활성화된 새 Amazon S3 버킷을 생성합니다. 지정된 날짜에 따라 보존 기간이 있는 S3 Object Lock을 사용합니다. 정적 웹 사이트 호스팅을 위해 S3 버킷을 구성합니다. 객체에 대한 읽기 전용 액세스를 허용하도록 S3 버킷 정책을 설정합니다.\\nC. S3 버전 관리가 활성화된 새 Amazon S3 버킷을 생성합니다. 객체 수정 또는 삭제 시 AWS Lambda 함수를 실행하도록 이벤트 트리거를 구성합니다. 객체를 프라이빗 S3 버킷의 원래 버전으로 교체하도록 Lambda 함수를 구성합니다.\\nD. 정적 웹 사이트 호스팅용으로 구성된 Amazon S3 버킷에 모든 파일을 업로드합니다. 파일이 포함된 폴더를 선택합니다. 지정된 날짜에 따라 보존 기간이 있는 S3 Object Lock을 사용합니다. S3 버킷에 액세스하는 모든 AWS 보안 주체에게 읽기 전용 IAM 권한을 부여합니다.\", \"A legal company must communicate with the public. Hundreds of files must be publicly accessible. Anyone is banned from modifying or deleting the files before to a specified future date.\\nWhich solution satisfies these criteria the SAFEST way possible?\\n\\nA.Upload all flies to an Amazon S3 bucket that is configured for static website hosting. Grant read-only IAM permissions to any AWS principals that access the S3 bucket until the designated date.\\nB. Create a new Amazon S3 bucket with S3 Versioning enabled. Use S3 Object Lock with a retention period in accordance with the designated date. Configure the S3 bucket for static website hosting. Set an S3 bucket policy to allow read-only access to the objects.\\nC. Create a new Amazon S3 bucket with S3 Versioning enabled. Configure an event trigger to run an AWS Lambda function in case of object modification or deletion. Configure the Lambda function to replace the objects with the original versions from a private S3 bucket.\\nD. Upload all files to an Amazon S3 bucket that is configured for static website hosting. Select the folder that contains the files. Use S3 Object Lock with a retention period in accordance with the designated date. Grant read-only IAM permissions to any AWS principals that access the S3 bucket.\", \"B\"],\n[\"기업은 10Gbps AWS Direct Connect 연결을 통해 온프레미스 서버를 AWS에 연결합니다. 연결의 작업 부하가 중요합니다. 조직에는 기존 연결 대역폭을 최소화하면서 최대한 탄력적인 재해 복구 접근 방식이 필요합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.다른 AWS 리전에서 새 Direct Connect 연결을 설정합니다.\\nB. 다른 AWS 리전에서 새 AWS 관리형 VPN 연결을 설정합니다.\\nC. 현재 AWS 리전과 다른 리전에 각각 하나씩 두 개의 새로운 Direct Connect 연결을 설정합니다.\\nD. 두 개의 새로운 AWS 관리형 VPN 연결을 설정합니다. 하나는 현재 AWS 리전에, 다른 하나는 다른 리전에 있습니다.\", \"A corporation connects its on-premises servers to AWS through a 10 Gbps AWS Direct Connect connection. The connection's workloads are crucial. The organization needs a catastrophe recovery approach that is as resilient as possible while minimizing the existing connection bandwidth.\\nWhat recommendations should a solutions architect make?\\n\\nA.Set up a new Direct Connect connection in another AWS Region.\\nB. Set up a new AWS managed VPN connection in another AWS Region.\\nC. Set up two new Direct Connect connections: one in the current AWS Region and one in another Region.\\nD. Set up two new AWS managed VPN connections: one in the current AWS Region and one in another Region.\", \"C A 둘다 답이 된다는 의견이 많음\"],\n[\"기업에는 관리 및 생산이라는 레이블이 붙은 두 개의 가상 사설 클라우드(VPC)가 있습니다. 관리 VPC는 ​​고객 게이트웨이를 통해 VPN을 사용하여 데이터 센터의 단일 장치에 연결합니다. 프로덕션 VPC는 ​​가상 프라이빗 게이트웨이를 통해 두 개의 AWS Direct Connect 연결을 통해 AWS에 연결됩니다. 관리 및 프로덕션 VPC는 ​​모두 단일 VPC 피어링 연결을 통해 서로 통신합니다.\\n아키텍처의 단일 실패 지점을 최소화하기 위해 솔루션 설계자는 무엇을 해야 합니까?\\n\\nA.관리 VPC와 프로덕션 VPC 간에 VPN 세트를 추가합니다.\\nB. 두 번째 가상 프라이빗 게이트웨이를 추가하고 관리 VPC에 연결합니다.\\nC. 두 번째 고객 게이트웨이 장치에서 관리 VPC로 두 번째 VPN 세트를 추가합니다.\\nD. 관리 VPC와 프로덕션 VPC 간에 두 번째 VPC 피어링 연결을 추가합니다.\", \"A business has two virtual private clouds (VPCs) labeled Management and Production. The Management VPC connects to a single device in the data center using VPNs via a customer gateway. The Production VPC is connected to AWS through two AWS Direct Connect connections via a virtual private gateway. Both the Management and Production VPCs communicate with one another through a single VPC peering connection.\\nWhat should a solutions architect do to minimize the architecture's single point of failure?\\n\\nA.Add a set of VPNs between the Management and Production VPCs.\\nB. Add a second virtual private gateway and attach it to the Management VPC.\\nC. Add a second set of VPNs to the Management VPC from a second customer gateway device.\\nD. Add a second VPC peering connection between the Management VPC and the Production VPC.\", \"C\"],\n[\"AWS는 회사의 거의 실시간 스트리밍 애플리케이션을 호스팅합니다. 데이터가 수집되는 동안 완료하는 데 30분이 걸리는 작업이 수행됩니다. 방대한 양의 수신 데이터로 인해 워크로드는 정기적으로 상당한 대기 시간에 직면합니다. 성능을 최적화하기 위해 솔루션 설계자는 확장 가능한 서버리스 시스템을 구축해야 합니다.\\n솔루션 아키텍트는 어떤 조치를 취해야 합니까? (2개를 선택하세요.)\\n\\nA.Amazon Kinesis Data Firehose를 사용하여 데이터를 수집합니다.\\nB. AWS Step Functions와 함께 AWS Lambda를 사용하여 데이터를 처리합니다.\\nC. AWS Database Migration Service(AWS DMS)를 사용하여 데이터를 수집합니다.\\nD. Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용하여 데이터를 처리합니다.\\nE. Amazon Elastic Container Service(Amazon ECS)와 함께 AWS Fargate를 사용하여 데이터를 처리합니다.\", \"AWS hosts a company's near-real-time streaming application. While the data is being ingested, a job is being performed on it that takes 30 minutes to finish. Due to the massive volume of incoming data, the workload regularly faces significant latency. To optimize performance, a solutions architect must build a scalable and serverless system.\\nWhich actions should the solutions architect do in combination? (Select two.)\\n\\nA.Use Amazon Kinesis Data Firehose to ingest the data.\\nB. Use AWS Lambda with AWS Step Functions to process the data.\\nC. Use AWS Database Migration Service (AWS DMS) to ingest the data.\\nD. Use Amazon EC2 instances in an Auto Scaling group to process the data.\\nE. Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.\", \"A, E\"],\n[\"Amazon Elastic Block Store(Amazon EBS) 볼륨은 미디어 조직에서 비디오 자료를 저장하는 데 사용합니다. 특정 비디오 파일이 인기를 얻었고 현재 전 세계에서 많은 사람들이 이 파일을 보고 있습니다. 결과적으로 비용이 증가했습니다.\\n사용자 접근성을 위태롭게 하지 않으면서 비용을 절감할 수 있는 단계는 무엇입니까?\\n\\nA.EBS 볼륨을 프로비저닝된 IOPS(PIOPS)로 변경합니다.\\nB. 비디오를 Amazon S3 버킷에 저장하고 Amazon CloudFront 배포를 생성합니다.\\nC. 비디오를 여러 개의 작은 세그먼트로 분할하여 사용자가 요청된 비디오 세그먼트로만 라우팅되도록 합니다.\\nD. 각 리전에서 Amazon S3 버킷을 지우고 사용자가 가장 가까운 S3 버킷으로 라우팅되도록 동영상을 업로드합니다.\", \"Amazon Elastic Block Store (Amazon EBS) volumes are used by a media organization to store video material. A certain video file has gained popularity, and a significant number of individuals from all over the globe are now viewing it. As a consequence, costs have increased.\\nWhich step will result in a cost reduction without jeopardizing user accessibility?\\n\\nA.Change the EBS volume to Provisioned IOPS (PIOPS).\\nB. Store the video in an Amazon S3 bucket and create an Amazon CloudFront distribution.\\nC. Split the video into multiple, smaller segments so users are routed to the requested video segments only.\\nD. Clear an Amazon S3 bucket in each Region and upload the videos so users are routed to the nearest S3 bucket.\", \"B\"],\n[\"Amazon S3 버킷은 이미지 호스팅 회사에서 객체를 저장하는 데 사용합니다. 회사는 S3 버킷에 포함된 항목이 의도하지 않게 공개되는 것을 방지하고자 합니다. AWS 계정의 모든 S3 항목은 전체적으로 비공개로 유지되어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Amazon GuardDuty를 사용하여 S3 버킷 정책을 모니터링합니다. AWS Lambda 함수를 사용하여 객체를 공개하는 모든 변경 사항을 수정하는 자동 수정 작업 규칙을 생성합니다.\\nB. AWS Trusted Advisor를 사용하여 공개적으로 액세스 가능한 S3 버킷을 찾습니다. 변경 사항이 감지되면 Trusted Advisor에서 이메일 알림을 구성합니다. 공개 액세스를 허용하는 경우 S3 버킷 정책을 수동으로 변경합니다.\\nC. AWS Resource Access Manager를 사용하여 공개적으로 액세스 가능한 S3 버킷을 찾습니다. 변경이 감지되면 Amazon Simple Notification Service(Amazon SNS)를 사용하여 AWS Lambda 함수를 호출합니다. 프로그래밍 방식으로 변경 사항을 수정하는 Lambda 함수를 배포합니다.\\nD. 계정 수준에서 S3 공개 액세스 차단 기능을 사용합니다. AWS Organizations를 사용하여 IAM 사용자가 설정을 변경하지 못하도록 하는 SCP(서비스 제어 정책)를 생성합니다. SCP를 계정에 적용합니다.\", \"Amazon S3 buckets are used by an image hosting firm to store its objects. The firm wishes to prevent unintentional public disclosure of the items contained in the S3 buckets. All S3 items in the AWS account as a whole must remain private.\\nWhich solution will satisfy these criteria?\\n\\nA.Use Amazon GuardDuty to monitor S3 bucket policies. Create an automatic remediation action rule that uses an AWS Lambda function to remediate any change that makes the objects public.\\nB. Use AWS Trusted Advisor to find publicly accessible S3 buckets. Configure email notifications in Trusted Advisor when a change is detected. Manually change the S3 bucket policy if it allows public access.\\nC. Use AWS Resource Access Manager to find publicly accessible S3 buckets. Use Amazon Simple Notification Service (Amazon SNS) to invoke an AWS Lambda function when a change is detected. Deploy a Lambda function that programmatically remediates the change.\\nD. Use the S3 Block Public Access feature on the account level. Use AWS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. Apply the SCP to the account.\", \"D.\"],\n[\"회사 웹 사이트는 Amazon RDS MySQL 다중 AZ DB 인스턴스에 트랜잭션 데이터를 저장합니다. 다른 내부 시스템은 이 데이터베이스 인스턴스를 쿼리하여 일괄 처리를 위한 데이터를 가져옵니다. 내부 시스템이 RDS DB 인스턴스에서 데이터를 요청하면 RDS DB 인스턴스가 급격히 느려집니다. 이는 웹사이트의 읽기 및 쓰기 성능에 영향을 미치므로 사용자의 응답 시간이 느려집니다.\\n어떤 접근 방식이 웹사이트 성능을 향상시킬까요?\\n\\nA.MySQL 데이터베이스 대신 RDS PostgreSQL DB 인스턴스를 사용합니다.\\nB. Amazon ElastiCache를 사용하여 웹 사이트에 대한 쿼리 응답을 캐시합니다.\\nC. 현재 RDS MySQL 다중 AZ DB 인스턴스에 가용 영역을 추가합니다.\\nD. RDS DB 인스턴스에 읽기 전용 복제본을 추가하고 읽기 전용 복제본을 쿼리하도록 내부 시스템을 구성합니다.\", \"A company's website stores transactional data on an Amazon RDS MySQL Multi-AZ DB instance. Other internal systems query this database instance to get data for batch processing. When internal systems request data from the RDS DB instance, the RDS DB instance drastically slows down. This has an effect on the website's read and write performance, resulting in poor response times for users.\\nWhich approach will result in an increase in website performance?\\n\\nA.Use an RDS PostgreSQL DB instance instead of a MySQL database.\\nB. Use Amazon ElastiCache to cache the query responses for the website.\\nC. Add an additional Availability Zone to the current RDS MySQL Multi-AZ DB instance.\\nD. Add a read replica to the RDS DB instance and configure the internal systems to query the read replica.\", \"D\"],\n[\"현재 회사의 레거시 애플리케이션은 단일 인스턴스가 있는 암호화되지 않은 Amazon RDS MySQL 데이터베이스에 의존합니다. 이 데이터베이스의 모든 현재 및 새 데이터는 새로운 규정 준수 표준을 준수하도록 암호화되어야 합니다.\\n이것은 어떻게 달성될 수 있습니까?\\n\\nA.서버 측 암호화가 활성화된 Amazon S3 버킷을 생성합니다. 모든 데이터를 Amazon S3로 이동합니다. RDS 인스턴스를 삭제합니다.\\nB. 미사용 데이터 암호화가 활성화된 RDS 다중 AZ 모드를 활성화합니다. 대기 인스턴스로 장애 조치를 수행하여 원본 인스턴스를 삭제합니다.\\nC. RDS 인스턴스의 스냅샷을 만듭니다. 스냅샷의 암호화된 복사본을 만듭니다. 암호화된 스냅샷에서 RDS 인스턴스를 복원합니다.\\nD. 미사용 데이터 암호화가 활성화된 RDS 읽기 전용 복제본을 생성합니다. 읽기 전용 복제본을 마스터로 승격하고 애플리케이션을 새 마스터로 전환합니다. 이전 RDS 인스턴스를 삭제합니다.\", \"Currently, a company's legacy application relies on an unencrypted Amazon RDS MySQL database with a single instance. All current and new data in this database must be encrypted to comply with new compliance standards.\\nHow is this to be achieved?\\n\\nA.Create an Amazon S3 bucket with server-side encryption enabled. Move all the data to Amazon S3. Delete the RDS instance.\\nB. Enable RDS Multi-AZ mode with encryption at rest enabled. Perform a failover to the standby instance to delete the original instance.\\nC. Take a Snapshot of the RDS instance. Create an encrypted copy of the snapshot. Restore the RDS instance from the encrypted snapshot.\\nD. Create an RDS read replica with encryption at rest enabled. Promote the read replica to master and switch the application over to the new master. Delete the old RDS instance.\", \"C. RDS 가동중에는 암호화 불가능하므로, 스냅샷 생성해서 스냅샷을 암호화하고 스냅샷을 기반으로 한 인스턴스 만들어야 함.\"],\n[\"마케팅 회사는 Amazon S3 버킷을 사용하여 통계 연구를 위한 CSV 데이터를 저장합니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션이 S3 버킷에 저장된 CSV 데이터를 올바르게 처리하려면 권한이 필요합니다.\\nEC2 인스턴스의 S3 버킷에 대한 가장 안전한 액세스를 제공하는 단계는 무엇입니까?\\n\\nA.리소스 기반 정책을 S3 버킷에 연결합니다.\\nB. S3 버킷에 대한 특정 권한이 있는 애플리케이션의 IAM 사용자를 생성합니다.\\nC. IAM 역할을 EC2 인스턴스 프로파일에 대한 최소 권한 권한과 연결합니다.\\nD. API 호출에 사용할 인스턴스의 애플리케이션을 위해 EC2 인스턴스에 AWS 자격 증명을 직접 저장합니다.\", \"A marketing firm uses an Amazon S3 bucket to store CSV data for statistical research. Permission is required for an application running on an Amazon EC2 instance to properly handle the CSV data stored in the S3 bucket.\\nWhich step will provide the MOST SECURE access to the S3 bucket for the EC2 instance?\\n\\nA.Attach a resource-based policy to the S3 bucket.\\nB. Create an IAM user for the application with specific permissions to the S3 bucket.\\nC. Associate an IAM role with least privilege permissions to the EC2 instance profile.\\nD. Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls.\\n \", \"C.\"],\n[\"Amazon Linux EC2 인스턴스 클러스터에서 기업은 애플리케이션을 실행합니다. 조직은 규정 준수를 위해 모든 애플리케이션 로그 파일을 7년 동안 저장해야 합니다.\\n로그 파일은 모든 파일에 대한 동시 액세스가 필요한 보고 프로그램에 의해 평가됩니다.\\n비용 효율성 측면에서 이러한 기준을 가장 잘 충족하는 스토리지 시스템은 무엇입니까?\\n\\nA.Amazon Elastic Block Store(Amazon EBS)\\nB. Amazon Elastic File System(Amazon EFS)\\nC. Amazon EC2 인스턴스 스토어\\nD. 아마존 S3\", \"On a cluster of Amazon Linux EC2 instances, a business runs an application. The organization is required to store all application log files for seven years for compliance purposes.\\nThe log files will be evaluated by a reporting program, which will need concurrent access to all files.\\nWhich storage system best satisfies these criteria in terms of cost-effectiveness?\\n\\nA.Amazon Elastic Block Store (Amazon EBS)\\nB. Amazon Elastic File System (Amazon EFS)\\nC. Amazon EC2 instance store\\nD. Amazon S3\", \"D. 동시 쓰기가 필요하면 EFS를 사용해야하지만, 동시 읽기만 되면 되기 때문에 S3이 더 저렴함\"],\n[\"Amazon EC2 인스턴스 집합에서 기업은 교육 사이트를 제공합니다. 이 회사는 웹에서 수백 개의 교육 비디오를 포함하는 새로운 과정이 일주일 안에 제공되면 엄청난 인기를 얻을 것으로 예측합니다.\\n솔루션 설계자는 예측된 서버 로드를 최소로 유지하기 위해 무엇을 해야 합니까?\\n\\nA.Redis용 Amazon ElastiCache에 비디오를 저장합니다. ElastiCache API를 사용하여 비디오를 제공하도록 웹 서버를 업데이트하십시오.\\nB. 비디오를 Amazon Elastic File System(Amazon EFS)에 저장합니다. 웹 서버가 EFS 볼륨을 탑재할 사용자 데이터 스크립트를 생성합니다.\\nC. 비디오를 Amazon S3 버킷에 저장합니다. 해당 S3 버킷의 원본 액세스 ID(OAI)를 사용하여 Amazon CloudFront 배포를 생성합니다. OAI에 대한 Amazon S3 액세스를 제한합니다.\\nD. 비디오를 Amazon S3 버킷에 저장합니다. S3 버킷에 액세스할 AWS Storage Gateway 파일 게이트웨이를 생성합니다. 파일 게이트웨이를 탑재할 웹 서버용 사용자 데이터 스크립트를 생성합니다.\", \"On a fleet of Amazon EC2 instances, a business provides a training site. The business predicts that when its new course, which includes hundreds of training videos on the web, is available in one week, it will be tremendously popular.\\nWhat should a solutions architect do to ensure that the predicted server load is kept to a minimum?\\n\\nA.Store the videos in Amazon ElastiCache for Redis. Update the web servers to serve the videos using the ElastiCache API.\\nB. Store the videos in Amazon Elastic File System (Amazon EFS). Create a user data script for the web servers to mount the EFS volume.\\nC. Store the videos in an Amazon S3 bucket. Create an Amazon CloudFront distribution with an origin access identity (OAI) of that S3 bucket. Restrict Amazon S3 access to the OAI.\\nD. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket. Create a user data script for the web servers to mount the file gateway.\", \"C\"],\n[\"기업은 3계층 웹 애플리케이션을 온프레미스에서 AWS 클라우드로 전환하기로 선택합니다. 새 데이터베이스는 저장 용량을 동적으로 확장하고 테이블 조인을 수행할 수 있어야 합니다.\\n이 기준을 충족하는 AWS 서비스는 무엇입니까?\\n\\nA.아마존 오로라\\nB. SqlServer용 Amazon RDS\\nC. Amazon DynamoDB 스트림\\nD. Amazon DynamoDB 온디맨드\", \"A business chooses to transition from on-premises to the AWS Cloud its three-tier web application. The new database must be able to scale storage capacity dynamically and conduct table joins.\\nWhich AWS service satisfies these criteria?\\n\\nA.Amazon Aurora\\nB. Amazon RDS for SqlServer\\nC. Amazon DynamoDB Streams\\nD. Amazon DynamoDB on-demand\", \"A. DynamoDB는 테이블 조인을 지원하지 않음. SqlServer RDS는 저장 용량을 동적으로 확장 불가(그런데 이제 가능해졌으므로, 출제되지 않을 것)\"],\n[\"Amazon EC2 인스턴스 집합에서 기업은 프로덕션 애플리케이션을 실행합니다. 이 프로그램은 Amazon SQS 대기열에서 데이터를 가져와 동시에 메시지를 처리합니다. 메시지 볼륨은 가변적이며 트래픽이 자주 중단됩니다. 이 프로그램은 중단 없이 지속적으로 메시지를 처리해야 합니다.\\n비용 효율성 측면에서 이러한 기준에 가장 적합한 옵션은 무엇입니까?\\n\\nA.스팟 인스턴스만 사용하여 필요한 최대 용량을 처리하십시오.\\nB. 필요한 최대 용량을 처리하기 위해 독점적으로 예약 인스턴스를 사용합니다.\\nC. 기준 용량으로 예약 인스턴스를 사용하고 추가 용량을 처리하기 위해 스팟 인스턴스를 사용합니다.\\nD. 기준 용량으로 예약 인스턴스를 사용하고 추가 용량을 처리하기 위해 온디맨드 인스턴스를 사용합니다.\", \"On a fleet of Amazon EC2 instances, a business runs a production application. The program takes data from an Amazon SQS queue and concurrently processes the messages. The message volume is variable, and traffic is often interrupted. This program should handle messages continuously and without interruption.\\nWhich option best fits these criteria in terms of cost-effectiveness?\\n\\nA.Use Spot Instances exclusively to handle the maximum capacity required.\\nB. Use Reserved Instances exclusively to handle the maximum capacity required.\\nC. Use Reserved Instances for the baseline capacity and use Spot Instances to handle additional capacity.\\nD. Use Reserved Instances for the baseline capacity and use On-Demand Instances to handle additional capacity.\", \"C or D(논란). 중단 없이 처리해야하므로 예약 인스턴스로 베이스를 깔아놓고, 트래픽이 몰리면 추가로 증설해야하는데, 스팟을 사용하면 비용적으로 저렴하지만 스팟 재고가 없을 경우 불가능해서 D가 답이라는 의견과, 이론적으로만 따지면 C가 답이라는 의견 존재\"],\n[\"한 스타트업이 자동차에 설치된 사물인터넷(IoT) 센서에서 데이터를 수집하는 애플리케이션을 개발했습니다. Amazon Kinesis Data Firehose를 통해 데이터가 Amazon S3로 전송되고 저장됩니다. 매년 데이터는 수십억 개의 S3 객체를 생성합니다. 매일 아침 비즈니스는 이전 30일 동안의 데이터를 사용하여 일련의 기계 학습(ML) 모델을 재교육합니다.\\n회사는 1년에 4번 이전 12개월의 데이터를 사용하여 다른 기계 학습 모델을 분석하고 교육합니다. 데이터는 최대 1년 동안 최소한의 지연으로 액세스할 수 있어야 합니다. 데이터는 1년 후에 아카이브를 위해 보존해야 합니다.\\n비용 효율성 측면에서 이러한 기준을 가장 잘 충족하는 스토리지 시스템은 무엇입니까?\\n\\nA.S3 Intelligent-Tiering 스토리지 클래스를 사용하십시오. S3 수명 주기 정책을 생성하여 1년 후 객체를 S3 Glacier Deep Archive로 전환합니다.\\nB. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1년 후에 객체를 자동으로 S3 Glacier Deep Archive로 이동하도록 S3 Intelligent-Tiering을 구성합니다.\\nC. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용합니다. S3 수명 주기 정책을 생성하여 1년 후 객체를 S3 Glacier Deep Archive로 전환합니다.\\nD. S3 Standard 스토리지 클래스를 사용합니다. S3 수명 주기 정책을 생성하여 30일 후에 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하고 1년 후에 S3 Glacier Deep Archive로 전환합니다.\", \"A startup has developed an application that gathers data from Internet of Things (IoT) sensors installed on autos. Through Amazon Kinesis Data Firehose, the data is transmitted to and stored in Amazon S3. Each year, data generates billions of S3 objects. Each morning, the business retrains a set of machine learning (ML) models using data from the preceding 30 days.\\nFour times a year, the corporation analyzes and trains other machine learning models using data from the preceding 12 months. The data must be accessible with a minimum of delay for a period of up to one year. Data must be preserved for archive reasons after one year.\\nWhich storage system best satisfies these criteria in terms of cost-effectiveness?\\n\\nA.Use the S3 Intelligent-Tiering storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.\\nB. Use the S3 Intelligent-Tiering storage class. Configure S3 Intelligent-Tiering to automativally move objects to S3 Glacier Deep Archive after 1 year.\\nC. Use the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.\\nD. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year.\", \"D\"],\n[\"비즈니스에는 Amazon S3에 데이터 스토리지가 필요합니다. 규정 준수 요구 사항은 개체가 수정될 때 원래 상태를 유지해야 한다고 규정합니다. 또한 5년 이상 된 데이터는 감사 목적으로 보관해야 합니다.\\n솔루션 아키텍트가 가장 노력하기 위해 추천해야 하는 것은 무엇입니까?\\n\\nA.거버넌스 모드에서 객체 수준 버전 관리 및 S3 객체 잠금 활성화\\nB. 규정 준수 모드에서 객체 수준 버전 관리 및 S3 객체 잠금 활성화\\nC. 개체 수준 버전 관리를 활성화합니다. 수명 주기 정책을 활성화하여 5년 이상 된 데이터를 S3 Glacier Deep Archive로 이동\\nD. 개체 수준 버전 관리를 활성화합니다. 수명 주기 정책을 활성화하여 5년 이상 된 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다.\", \"A business requires data storage on Amazon S3. A compliance requirement stipulates that when objects are modified, their original state must be retained. Additionally, data older than five years should be kept for auditing purposes.\\nWhat SHOULD A SOLUTIONS ARCHITECT RECOMMEND AS THE MOST EFFORTABLE?\\n\\nA.Enable object-level versioning and S3 Object Lock in governance mode\\nB. Enable object-level versioning and S3 Object Lock in compliance mode\\nC. Enable object-level versioning. Enable a lifecycle policy to move data older than 5 years to S3 Glacier Deep Archive\\nD. Enable object-level versioning. Enable a lifecycle policy to move data older than 5 years to S3 Standard-Infrequent Access (S3 Standard-IA)\", \"C\"],\n[\"여러 Amazon EC2 인스턴스는 애플리케이션을 호스팅하는 데 사용됩니다. 이 프로그램은 Amazon SQS 대기열에서 메시지를 읽고 Amazon RDS 데이터베이스에 쓴 다음 대기열에서 제거합니다. RDS 테이블에 중복 항목이 포함되는 경우가 있습니다. SQS 대기열에는 중복 메시지가 없습니다.\\n솔루션 설계자는 메시지가 한 번만 처리되도록 어떻게 보장할 수 있습니까?\\n\\nA.CreateQueue API 호출을 사용하여 새 대기열을 만듭니다.\\nB. AddPermission API 호출을 사용하여 적절한 권한을 추가합니다.\\nC. ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다.\\nD. ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과를 늘립니다.\", \"Multiple Amazon EC2 instances are used to host an application. The program reads messages from an Amazon SQS queue, writes them to an Amazon RDS database, and then removes them from the queue. The RDS table sometimes contains duplicate entries. There are no duplicate messages in the SQS queue.\\nHow can a solutions architect guarantee that messages are handled just once?\\n\\nA.Use the CreateQueue API call to create a new queue.\\nB. Use the AddPermission API call to add appropriate permissions.\\nC. Use the ReceiveMessage API call to set an appropriate wait time.\\nD. Use the ChangeMessageVisibility API call to increase the visibility timeout.\", \"D. 메시지를 처리하는데 오랜 시간이 걸리면, 한 인스턴스가 작업을 처리하는 동안 SQS는 해당 인스턴스가 작업을 처리하다가 죽었다고 판단해서 메시지를 다시 살림. 이 인터벌을 조절하는게 가시성 시간 초과 이므로 늘려야 함.\"],\n[\"한 기업이 소매 웹사이트의 전 세계 출시를 발표했습니다. 웹사이트는 Elastic Load Balancer를 통해 라우팅되는 수많은 Amazon EC2 인스턴스에서 호스팅됩니다. 인스턴스는 Auto Scaling 그룹의 여러 가용 영역에 분산됩니다.\\n회사는 고객이 웹사이트를 보는 장치에 따라 맞춤형 자료를 제공하기를 원합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계를 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.여러 버전의 콘텐츠를 캐시하도록 Amazon CloudFront를 구성합니다.\\nB. 네트워크 로드 밸런서에서 호스트 헤더를 구성하여 트래픽을 다른 인스턴스로 전달합니다.\\nC. User-Agent 헤더를 기반으로 특정 객체를 사용자에게 보내도록 Lambda@Edge 함수를 구성합니다 .\\nD. AWS Global Accelerator를 구성합니다. NLB(Network Load Balancer)로 요청을 전달합니다. 다른 EC2 인스턴스에 대한 호스트 기반 라우팅을 설정하도록 NLB를 구성합니다.\\nE. AWS Global Accelerator를 구성합니다. NLB(Network Load Balancer)로 요청을 전달합니다. 다른 EC2 인스턴스에 대한 경로 기반 라우팅을 설정하도록 NLB를 구성합니다.\", \"A corporation just announced the worldwide launch of their retail website. The website is hosted on numerous Amazon EC2 instances, which are routed via an Elastic Load Balancer. The instances are distributed across several Availability Zones in an Auto Scaling group.\\nThe firm want to give its clients with customized material depending on the device from which they view the website.\\nWhich steps should a solutions architect perform in combination to satisfy these requirements? (Select two.)\\n\\nA.Configure Amazon CloudFront to cache multiple versions of the content.\\nB. Configure a host header in a Network Load Balancer to forward traffic to different instances.\\nC. Configure a Lambda@Edge function to send specific objects to users based on the User-Agent header.\\nD. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up host-based routing to different EC2 instances.\\nE. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up path-based routing to different EC2 instances.\", \"A, C. 7계층 헤더 정보가 필요하므로 NLB사용 불가.\"],\n[\"실험과 민첩성을 촉진하기 위해 비즈니스에서는 개발자가 현재 IAM 정책을 기존 IAM 역할에 연결할 수 있습니다. 반면 보안 운영 팀은 개발자가 현재 관리자 정책을 첨부하여 다른 보안 규칙을 우회할 수 있다고 우려하고 있습니다.\\n솔루션 설계자는 이 문제를 처리할 때 어떤 접근 방식을 사용해야 합니까?\\n\\nA.개발자가 새 정책을 생성할 때마다 알림을 보내도록 Amazon SNS 주제를 생성합니다.\\nB. 서비스 제어 정책을 사용하여 조직 단위의 모든 계정에서 IAM 활동을 비활성화합니다.\\nC. 개발자가 정책을 첨부하지 못하도록 하고 모든 IAM 업무를 보안 운영 팀에 할당합니다.\\nD. 관리자 정책 연결을 명시적으로 거부하는 개발자 IAM 역할에 대한 IAM 권한 경계를 설정합니다.\", \"To facilitate experimentation and agility, a business enables developers to link current IAM policies to existing IAM roles. The security operations team, on the other hand, is worried that the developers may attach the current administrator policy, allowing them to bypass any other security rules.\\nWhat approach should a solutions architect use in dealing with this issue?\\n\\nA.Create an Amazon SNS topic to send an alert every time a developer creates a new policy.\\nB. Use service control policies to disable IAM activity across all account in the organizational unit.\\nC. Prevent the developers from attaching any policies and assign all IAM duties to the security operations team.\\nD. Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy.\", \"D. 권한 경계를 통해 부여할 수 있는 최대 권한 제한\\n* 경계는 그룹이 아닌 사용자와 역할에만 할당 가능\"],\n[\"새로 형성된 회사는 3계층 웹 애플리케이션을 개발했습니다. 프런트 엔드는 완전히 정적 정보로 구성됩니다. 마이크로서비스는 애플리케이션 계층을 형성합니다. 사용자 데이터는 최소한의 지연으로 액세스할 수 있는 JSON 문서 형식으로 보관됩니다. 회사는 첫 해에 월별 트래픽 급증과 함께 최소한의 정규 트래픽을 예상합니다. 스타트업 팀의 운영 간접비는 최소한으로 유지되어야 합니다.\\n솔루션 설계자는 이를 달성하기 위한 수단으로 무엇을 제안해야 합니까?\\n\\nA.Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 AWS Elastic Beanstalk를 사용합니다. Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다.\\nB. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 Amazon Elastic KubernetesService(Amazon EKS)를 사용합니다. Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다.\\nC. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다.\\nD. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. 애플리케이션 계층에 Amazon API Gateway 및 AWS Lambda 함수를 사용합니다. 읽기 전용 복제본과 함께 Amazon RDS를 사용하여 사용자 데이터를 저장합니다.\", \"A newly formed company developed a three-tiered web application. The front end is comprised entirely of static information. Microservices form the application layer. User data is kept in the form of JSON documents that must be accessible with a minimum of delay. The firm anticipates minimal regular traffic in the first year, with monthly traffic spikes. The startup team's operational overhead expenditures must be kept to a minimum.\\nWhat should a solutions architect suggest as a means of achieving this?\\n\\nA.Use Amazon S3 static website hosting to store and serve the front end. Use AWS Elastic Beanstalk for the application layer. Use Amazon DynamoDB to store user data.\\nB. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon Elastic KubernetesService (Amazon EKS) for the application layer. Use Amazon DynamoDB to store user data.\\nC. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon DynamoDB to store user data.\\nD. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon RDS with read replicas to store user data.\", \"C. json 데이터이므로 DynamoDB 사용해야하고, 가장 저렴하게 app layer 구현할 수 있는건 lambda\"],\n[\"Amazon Elastic Container Service(Amazon ECS) 컨테이너 인스턴스는 ALB(Application Load Balancer) 뒤에 전자 상거래 웹 사이트의 웹 애플리케이션을 설치하는 데 사용됩니다. 사용량이 많은 순간에는 웹 사이트 속도가 느려지고 가용성이 감소합니다. 솔루션 설계자는 Amazon CloudWatch 경보를 활용하여 가용성 문제가 발생할 때 알림을 받고 리소스를 확장할 수 있습니다. 비즈니스 경영진은 이러한 상황에 자동으로 대응하는 시스템을 원합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.ALB에 시간 초과가 있을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\\nB. ALB CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\\nC. 서비스의 CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\\nD. ALB 대상 그룹 CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다.\", \"Amazon Elastic Container Service (Amazon ECS) container instances are used to install an ecommerce website's web application behind an Application Load Balancer (ALB). The website slows down and availability is decreased during moments of heavy usage. A solutions architect utilizes Amazon CloudWatch alarms to be notified when an availability problem occurs, allowing them to scale out resources. The management of the business want a system that automatically reacts to such circumstances.\\nWhich solution satisfies these criteria?\\n\\nA.Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\\nB. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Setup AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\\nC. Set up AWS Auto Scaling to scale out the ECS service when the service's CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\\nD. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\", \"C\"],\n[\"기업은 Site-to-Site VPN 연결을 사용하여 온프레미스에서 AWS 클라우드 서비스에 안전하게 액세스할 수 있도록 합니다. Amazon EC2 인스턴스에 대한 VPN 연결을 통한 트래픽 증가로 인해 사용자가 VPN 연결 속도가 느려지고 있습니다.\\n어떤 접근 방식이 VPN 처리량을 증가시킬까요?\\n\\nA.처리량을 확장하려면 동일한 네트워크에 대해 여러 고객 게이트웨이를 구현하십시오.\\nB. 동일한 비용의 다중 경로 라우팅이 있는 전송 게이트웨이를 사용하고 VPN 터널을 추가합니다.\\nC. 동일한 비용의 다중 경로 라우팅 및 다중 채널을 사용하여 가상 사설 게이트웨이를 구성합니다.\\nD. 기본 제한 이상으로 처리량을 확장하려면 VPN 구성의 터널 수를 늘립니다.\", \"A business uses Site-to-Site VPN connections to provide safe access to AWS Cloud services from on-premises. Users are experiencing slower VPN connectivity as a result of increased traffic through the VPN connections to the Amazon EC2 instances.\\nWhich approach will result in an increase in VPN throughput?\\n\\nA.Implement multiple customer gateways for the same network to scale the throughput.\\nB. Use a transit gateway with equal cost multipath routing and add additional VPN tunnels.\\nC. Configure a virtual private gateway with equal cost multipath routing and multiple channels.\\nD. Increase the number of tunnels in the VPN configuration to scale the throughput beyond the default limit.\", \"B\"],\n[\"Amazon EC2 Linux 인스턴스에서 비즈니스는 웹 사이트를 호스팅합니다. 몇 가지 예가 오작동하고 있습니다. 문제 해결은 실패한 인스턴스에 스왑 공간이 부족함을 나타냅니다. 운영 팀의 리더는 이를 위한 모니터링 솔루션이 필요합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon CloudWatch SwapUsage 지표 차원을 구성합니다. CloudWatch의 EC2 지표에서 SwapUsage 차원을 모니터링합니다.\\nB. EC2 메타데이터를 사용하여 정보를 수집한 다음 Amazon CloudWatch 사용자 지정 지표에 게시합니다. CloudWatch에서 SwapUsage 지표를 모니터링합니다.\\nC. 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 정해진 일정에 따라 적절한 스크립트를 실행합니다. CloudWatch에서 SwapUtilization 지표를 모니터링합니다.\\nD. EC2 콘솔에서 세부 모니터링을 활성화합니다. Amazon CloudWatch SwapUtilization 사용자 지정 지표를 생성합니다. CloudWatch에서 SwapUtilization 지표를 모니터링합니다.\", \"On Amazon EC2 Linux instances, a business hosts a website. Several of the examples are malfunctioning. The troubleshooting indicates that the unsuccessful instances lack swap space. The operations team's lead need a monitoring solution for this.\\nWhat recommendations should a solutions architect make?\\n\\nA.Configure an Amazon CloudWatch SwapUsage metric dimension. Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.\\nB. Use EC2 metadata to collect information, then publish it to Amazon CloudWatch custom metrics. Monitor SwapUsage metrics in CloudWatch.\\nC. Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilization metrics in CloudWatch.\\nD. Enable detailed monitoring in the EC2 console. Create an Amazon CloudWatch SwapUtilization custom metric. Monitor SwapUtilization metrics in CloudWatch.\", \"C. 인스턴스 내부의 메모리 사용량을 추적하려면 인스턴스에 cloud watch agent가 설치되어 있어야 함.\"],\n[\"AWS는 기업에서 OLTP(온라인 트랜잭션 처리) 부담을 수행하는 데 사용됩니다. 이 워크로드는 암호화되지 않은 Amazon RDS 데이터베이스 인스턴스를 사용하여 다중 AZ 환경에 배포됩니다. 이 인스턴스의 데이터베이스는 매일 백업됩니다.\\n데이터베이스와 스냅샷이 지속적으로 암호화되도록 보장하기 위해 솔루션 설계자는 앞으로 무엇을 해야 합니까?\\n\\nA.최신 DB 스냅샷 사본을 암호화합니다. 암호화된 스냅샷을 복원하여 기존 DB 인스턴스를 교체합니다.\\nB. 암호화된 새 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하고 여기에 스냅샷을 복사합니다. DB 인스턴스에서 암호화를 활성화합니다.\\nC. 스냅샷을 복사하고 AWS Key Management Service(AWS KMS)를 사용하여 암호화를 활성화합니다. 암호화된 스냅샷을 기존 DB 인스턴스로 복원합니다.\\nD. AWS Key Management Service(AWS KMS) 관리형 키(SSE-KMS)로 서버 측 암호화를 사용하여 암호화된 Amazon S3 버킷에 스냅샷을 복사합니다.\", \"AWS is used by a business to perform an online transaction processing (OLTP) burden. This workload is deployed in a Multi-AZ environment using an unencrypted Amazon RDS database instance. This instance's database is backed up daily.\\nWhat should a solutions architect do going forward to guarantee that the database and snapshots are constantly encrypted?\\n\\nA.Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.\\nB. Create a new encrypted Amazon Elastic Block Store (Amazon EBS) volume and copy the snapshots to it. Enable encryption on the DB instance.\\nC. Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS). Restore encrypted snapshot to an existing DB instance.\\nD. Copy the snapshots to an Amazon S3 bucket that is encrypted using server-side encryption with AWS Key Management Service (AWS KMS) managed keys (SSE-KMS).\", \"A. 암호화는 DB 생성시에만 설정 가능하므로, 중간에 설정하고싶으면 스냅샷을 뜨고 그걸 암호화 한 다음 새 인스턴스를 만들어야 함\"],\n[\"기업은 다양한 Amazon EC2 인스턴스를 통해 소비자로부터 데이터를 수집하는 애플리케이션을 운영합니다. 처리 후 데이터는 장기 저장을 위해 Amazon S3에 업로드됩니다. 애플리케이션 연구에 따르면 EC2 인스턴스가 장기간 비활성 상태인 것으로 나타났습니다. 솔루션 설계자는 비용을 최소화하면서 사용량을 최대화하는 시스템을 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.온디맨드 인스턴스가 있는 Auto Scaling 그룹에서 Amazon EC2를 사용합니다.\\nB. 온디맨드 인스턴스와 함께 Amazon Lightsail을 사용하도록 애플리케이션을 구축합니다.\\nC. Amazon CloudWatch 크론 작업을 생성하여 활동이 없을 때 EC2 인스턴스를 자동으로 중지합니다.\\nD. Amazon Simple Queue Service(Amazon SQS) 및 AWS Lambda에서 이벤트 중심 설계를 사용하도록 애플리케이션을 재설계합니다.\", \"A business operates an application that collects data from its consumers through various Amazon EC2 instances. After processing, the data is uploaded to Amazon S3 for long-term storage. A study of the application reveals that the EC2 instances were inactive for extended periods of time. A solutions architect must provide a system that maximizes usage while minimizing expenditures.\\nWhich solution satisfies these criteria?\\n\\nA.Use Amazon EC2 in an Auto Scaling group with On-Demand instances.\\nB. Build the application to use Amazon Lightsail with On-Demand Instances.\\nC. Create an Amazon CloudWatch cron job to automatically stop the EC2 instances when there is no activity.\\nD. Redesign the application to use an event-driven design with Amazon Simple Queue Service (Amazon SQS) and AWS Lambda.\", \"A. D가 비용이 가장 적게 들긴 하지만, 솔루션 설계자가 할 수 있는 일이 아님(재 개발 필요)\"],\n[\"기업은 많은 독립적인 Amazon Web Services 계정에서 통합된 다중 계정 설계로 마이그레이션하기를 원합니다. 조직은 사업부를 위해 많은 수의 새 AWS 계정을 생성할 계획입니다. 조직은 이러한 AWS 계정에 대한 액세스를 인증하기 위해 단일 회사 디렉터리 서비스를 사용해야 합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계를 옹호해야 합니까? (2개를 선택하세요.)\\n\\nA.모든 기능이 켜진 상태로 AWS Organizations에서 새 조직을 생성합니다. 조직에서 새 AWS 계정을 생성합니다.\\nB. Amazon Cognito 자격 증명 풀을 설정합니다. Amazon Cognito 인증을 수락하도록 AWS Single Sign-On을 구성합니다.\\nC. AWS 계정을 관리하기 위해 서비스 제어 정책(SCP)을 구성합니다. AWS Directory Service에 AWS Single Sign-On을 추가합니다.\\nD. AWS Organizations에서 새 조직을 생성합니다. AWS Directory Service를 직접 사용하도록 조직의 인증 메커니즘을 구성합니다.\\nE. 조직에서 AWS Single Sign-On(AWS SSO)을 설정합니다. AWS SSO를 구성하고 회사의 회사 디렉터리 서비스와 통합합니다.\", \"A business wishes to migrate from many independent Amazon Web Services accounts to a consolidated, multi-account design. The organization intends to generate a large number of new AWS accounts for its business divisions. The organization must use a single corporate directory service to authenticate access to these AWS accounts.\\nWhich steps should a solutions architect advocate in order to satisfy these requirements? (Select two.)\\n\\nA.Create a new organization in AWS Organizations with all features turned on. Create the new AWS accounts in the organization.\\nB. Set up an Amazon Cognito identity pool. Configure AWS Single Sign-On to accept Amazon Cognito authentication.\\nC. Configure a service control policy (SCP) to manage the AWS accounts. Add AWS Single Sign-On to AWS Directory Service.\\nD. Create a new organization in AWS Organizations. Configure the organization's authentication mechanism to use AWS Directory Service directly.\\nE. Set up AWS Single Sign-On (AWS SSO) in the organization. Configure AWS SSO, and integrate it with the company's corporate directory service.\", \"A, E\"],\n[\"솔루션 설계자는 완료하는 데 최대 2시간이 소요되는 일일 데이터 처리 작업을 개발하고 있습니다. 작업이 중지되면 처음부터 다시 시작해야 합니다.\\n솔루션 설계자가 이 문제를 해결하는 가장 비용 효율적인 방법은 무엇입니까?\\n\\nA.크론 작업에 의해 트리거되는 Amazon EC2 예약 인스턴스에서 로컬로 실행되는 스크립트를 생성합니다.\\nB. Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트에 의해 트리거되는 AWS Lambda 함수를 생성합니다.\\nC. Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트에 의해 트리거된 Amazon Elastic Container Service(Amazon ECS) Fargate 작업을 사용합니다.\\nD. Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트에 의해 트리거된 Amazon EC2에서 실행되는 Amazon Elastic Container Service(Amazon ECS) 작업을 사용합니다.\", \"A solutions architect is developing a daily data processing task that will take up to two hours to finish. If the task is stopped, it must be restarted from scratch.\\nWhat is the MOST cost-effective way for the solutions architect to solve this issue?\\n\\nA.Create a script that runs locally on an Amazon EC2 Reserved Instance that is triggered by a cron job.\\nB. Create an AWS Lambda function triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.\\nC. Use an Amazon Elastic Container Service (Amazon ECS) Fargate task triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.\\nD. Use an Amazon Elastic Container Service (Amazon ECS) task running on Amazon EC2 triggered by an Amazon EventBridge (Amazon CloudWatch Events) scheduled event.\", \"C. lambda는 시간제한이 있고, EC2 예약 인스턴스는 할인을 받긴 했지만 가동하지 않을때가 더 많기 때문에 비효율적.\"],\n[\"비즈니스에서 AWS를 사용하여 설문 조사 웹 사이트를 호스팅하려고 합니다. 회사는 많은 양의 트래픽을 예상했습니다. 이 트래픽의 결과로 데이터베이스는 비동기식으로 업데이트됩니다. 조직은 AWS에 보관된 데이터베이스에 대한 쓰기 삭제를 방지하기를 원합니다.\\n이러한 데이터베이스 요청을 처리하려면 비즈니스 애플리케이션을 어떻게 작성해야 합니까?\\n\\nA.Amazon Simple Notification Service(Amazon SNS) 주제에 게시하도록 애플리케이션을 구성합니다. SNS 주제에 데이터베이스를 구독합니다.\\nB. Amazon Simple Notification Service(Amazon SNS) 주제를 구독하도록 애플리케이션을 구성합니다. SNS 주제에 데이터베이스 업데이트를 게시합니다.\\nC. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 사용하여 데이터베이스에 데이터를 쓸 리소스가 생길 때까지 데이터베이스 연결을 대기열에 넣습니다.\\nD. 쓰기를 캡처하고 데이터베이스에 쓸 때마다 대기열을 비우기 위해 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 사용합니다.\", \"A business intends to use AWS to host a survey website. The firm anticipated a high volume of traffic. As a consequence of this traffic, the database is updated asynchronously. The organization want to avoid dropping writes to the database housed on AWS.\\nHow should the business's application be written to handle these database requests?\\n\\nA.Configure the application to publish to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the database to the SNS topic.\\nB. Configure the application to subscribe to an Amazon Simple Notification Service (Amazon SNS) topic. Publish the database updates to the SNS topic.\\nC. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the database connection until the database has resources to write the data.\\nD. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues for capturing the writes and draining the queue as each write is made to the database.\", \"D\"],\n[\"거대한 Amazon EC2 인스턴스 집합에서 기업은 애플리케이션을 실행합니다. 이 프로그램은 Amazon에서 호스팅하는 DynamoDB 데이터베이스에 항목을 읽고 씁니다. DynamoDB 데이터베이스의 크기는 정기적으로 증가하지만 애플리케이션에는 이전 30일 동안의 데이터만 필요합니다. 조직은 구현하기에 비용 효율적이고 시간 효율적인 솔루션이 필요합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS CloudFormation 템플릿을 사용하여 전체 솔루션을 배포합니다. 30일마다 CloudFormation 스택을 재배포하고 원래 스택을 삭제합니다.\\nB. AWS Marketplace에서 모니터링 애플리케이션을 실행하는 EC2 인스턴스를 사용합니다. Amazon DynamoDB 스트림을 사용하여 테이블에 새 항목이 생성될 때 타임스탬프를 저장하도록 모니터링 애플리케이션을 구성합니다. EC2 인스턴스에서 실행되는 스크립트를 사용하여 30일보다 오래된 타임스탬프가 있는 항목을 삭제합니다.\\nC. 테이블에 새 항목이 생성될 때 AWS Lambda 함수를 호출하도록 Amazon DynamoDB Streams를 구성합니다. 테이블에서 30일이 지난 항목을 삭제하도록 Lambda 함수를 구성합니다.\\nD. 애플리케이션을 확장하여 현재 타임스탬프 값에 30일을 더한 값을 테이블에 생성되는 각각의 새 항목에 추가합니다. 속성을 TTL 속성으로 사용하도록 DynamoDB를 구성합니다.\", \"On a huge fleet of Amazon EC2 instances, a business runs an application. The program reads and writes items to a DynamoDB database hosted by Amazon. The DynamoDB database increases in size regularly, yet the application requires just data from the previous 30 days. The organization need a solution that is both cost effective and time efficient to implement.\\nWhich solution satisfies these criteria?\\n\\nA.Use an AWS CloudFormation template to deploy the complete solution. Redeploy the CloudFormation stack every 30 days, and delete the original stack.\\nB. Use an EC2 instance that runs a monitoring application from AWS Marketplace. Configure the monitoring application to use Amazon DynamoDB Streams to store the timestamp when a new item is created in the table. Use a script that runs on the EC2 instance to delete items that have a timestamp that is older than 30 days.\\nC. Configure Amazon DynamoDB Streams to invoke an AWS Lambda function when a new item is created in the table. Configure the Lambda function to delete items in the table that are older than 30 days.\\nD. Extend the application to add an attribute that has a value of the current timestamp plus 30 days to each new item that is created in the table. Configure DynamoDB to use the attribute as the TTL attribute.\", \"D\"],\n[\"이전에는 기업에서 데이터 웨어하우징 솔루션을 AWS로 이전했습니다. 또한 회사에는 AWS Direct Connect 연결이 있습니다. 회사 사무실의 사용자는 시각화 도구를 사용하여 데이터 웨어하우스를 쿼리할 수 있습니다. 데이터 웨어하우스에서 응답하는 각 쿼리의 크기는 평균 50MB인 반면 시각화 도구에서 제공하는 각 웹 페이지의 크기는 약 500KB입니다. 데이터 웨어하우스는 반환하는 결과 집합을 캐시하지 않습니다.\\n회사의 가장 낮은 발신 데이터 전송 비용을 초래하는 접근 방식은 무엇입니까?\\n\\nA.온프레미스에서 시각화 도구를 호스팅하고 인터넷을 통해 직접 데이터 웨어하우스를 쿼리합니다.\\nB. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅합니다. 인터넷을 통해 액세스하십시오.\\nC. 온프레미스에서 시각화 도구를 호스팅하고 동일한 AWS 리전의 위치에서 Direct Connect 연결을 통해 직접 데이터 웨어하우스를 쿼리합니다.\\nD. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하고 동일한 리전의 위치에서 DirectConnect 연결을 통해 액세스합니다. \", \"Previously, a corporation moved their data warehousing solution to AWS. Additionally, the firm has an AWS Direct Connect connection. Through the use of a visualization tool, users in the corporate office may query the data warehouse. Each query answered by the data warehouse is on average 50 MB in size, whereas each webpage supplied by the visualization tool is around 500 KB in size. The data warehouse does not cache the result sets it returns.\\nWhich approach results in the LOWEST OUTGOING DATA TRANSFER COSTS FOR THE COMPANY?\\n\\nA.Host the visualization tool on premises and query the data warehouse directly over the internet.\\nB. Host the visualization tool in the same AWS Region as the data warehouse. Access it over the internet.\\nC. Host the visualization tool on premises and query the data warehouse directly over a Direct Connect connection at a location in the same AWS Region.\\nD. Host the visualization tool in the same AWS Region as the data warehouse and access it over a DirectConnect connection at a location in the same Region.\", \"D\"],\n[\"비즈니스에서 많은 마이크로서비스로 구성된 애플리케이션을 개발 중입니다. 조직은 컨테이너 기술을 통해 AWS에 소프트웨어를 배포하기로 결정했습니다. 비즈니스에는 유지 관리 및 성장을 위해 지속적인 작업이 거의 필요하지 않은 솔루션이 필요합니다. 추가 인프라는 비즈니스에서 관리할 수 없습니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계를 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.Amazon Elastic Container Service(Amazon ECS) 클러스터를 배포합니다.\\nB. 여러 가용 영역에 걸쳐 있는 Amazon EC2 인스턴스에 Kubernetes 제어 평면을 배포합니다.\\nC. Amazon EC2 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 서비스를 배포합니다. 원하는 작업 번호 수준을 2 이상으로 지정합니다.\\nD. Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 서비스를 배포합니다. 원하는 작업 번호 수준을 2 이상으로 지정합니다.\\nE. 여러 가용 영역에 걸쳐 있는 Amazon EC2 인스턴스에 Kubernetes 작업자 노드를 배포합니다. 각 마이크로 서비스에 대해 두 개 이상의 복제본을 지정하는 배포를 만듭니다.\", \"A business is developing an application that is composed of many microservices. The organization has chosen to deploy its software on AWS through container technology. The business need a solution that requires little ongoing work for maintenance and growth. Additional infrastructure cannot be managed by the business.\\nWhich steps should a solutions architect perform in combination to satisfy these requirements? (Select two.)\\n\\nA.Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.\\nB. Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.\\nC. Deploy an Amazon Elastic Container Service (Amazon ECS) service with an Amazon EC2 launch type. Specify a desired task number level of greater than or equal to 2.\\nD. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.\\nE. Deploy Kubernetes worker nodes on Amazon EC2 instances that span multiple Availability Zones. Create a deployment that specifies two or more replicas for each microservice.\", \"A, D. ‘인프라를 관리할 수 없음’은 서버리스 구조를 의미함. EC2 사용 불가\"],\n[\"다음 정책은 Amazon EC2 관리자가 개발했으며 수많은 사용자를 포함하는 IAM 그룹에 할당되었습니다.\\n이 정책은 어떤 영향을 미칩니까?\\n\\nA.사용자는 us-east-1을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다.\\nB. 사용자는 us-east-1 리전에서 IP 주소가 10.100.100.1인 EC2 인스턴스를 종료할 수 있습니다.\\nC. 사용자는 사용자의 소스 IP가 10.100.100.254일 때 us-east-1 리전에서 EC2 인스턴스를 종료할 수 있습니다.\\nD. 사용자의 소스 IP가 10.100.100.254인 경우 사용자는 us-east-1 리전에서 EC2 인스턴스를 종료할 수 없습니다.\", \"The following policy was developed by an Amazon EC2 administrator and assigned to an IAM group including numerous users:\\nWhat impact does this policy have?\\n\\nA.Users can terminate an EC2 instance in any AWS Region except us-east-1.\\nB. Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us-east-1 Region.\\nC. Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.\\nD. Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.\", \"C\"],\n[\"비즈니스의 웹 애플리케이션은 데이터를 Amazon RDS PostgreSQL 데이터베이스 인스턴스에 저장합니다. 회계사는 결산 기간 중 매월 초에 대량 쿼리를 수행하며 과도한 활용으로 인해 데이터베이스 성능에 부정적인 영향을 미칩니다. 비즈니스는 온라인 지원에 대한 보고의 영향을 줄이기를 원합니다.\\n가능한 한 최소한의 작업으로 데이터베이스의 영향을 최소화하기 위해 솔루션 설계자는 무엇을 해야 합니까?\\n\\nA.읽기 전용 복제본을 만들고 복제본으로 트래픽을 직접 보고합니다.\\nB. 다중 AZ 데이터베이스를 생성하고 대기 트래픽을 보고합니다.\\nC. 교차 리전 읽기 전용 복제본을 만들고 복제본으로 트래픽을 직접 보고합니다.\\nD. Amazon Redshift 데이터베이스를 만들고 Amazon Redshift 데이터베이스로 트래픽을 보고합니다.\", \"The web application of a business stores its data on an Amazon RDS PostgreSQL database instance. Accountants conduct massive queries at the start of each month during the financial closure period, which has a negative influence on the database's performance owing to excessive utilization. The business want to reduce the effect of reporting on the online application.\\nWhat should a solutions architect do to minimize the database's influence with the LEAST amount of work possible?\\n\\nA.Create a read replica and direct reporting traffic to the replica.\\nB. Create a Multi-AZ database and direct reporting traffic to the standby.\\nC. Create a cross-Region read replica and direct reporting traffic to the replica.\\nD. Create an Amazon Redshift database and direct reporting traffic to the Amazon Redshift database.\", \"A. 장애 조치와 무관하므로 multi AZ는 아님\"],\n[\"한 기업이 Amazon RDS에 MySQL 데이터베이스를 구현했습니다. 데이터베이스 지원팀은 트랜잭션 증가로 인해 DB 인스턴스에 대한 읽기 지연이 발생했다고 보고하고 읽기 전용 복제본을 설치할 것을 권고하고 있습니다.\\n솔루션 설계자는 이 변경 사항을 배포하기 전에 어떤 활동을 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.RDS 기본 노드에서 binlog 복제를 활성화합니다.\\nB. 원본 DB 인스턴스에 대한 장애 조치 우선 순위를 선택합니다.\\nC. 장기 실행 트랜잭션이 원본 DB 인스턴스에서 완료되도록 허용합니다.\\nD. 글로벌 테이블을 생성하고 테이블을 사용할 수 있는 AWS 리전을 지정합니다.\\nE. 백업 보존 기간을 0이 아닌 값으로 설정하여 원본 인스턴스에서 자동 백업을 활성화합니다.\", \"A business has implemented a MySQL database on Amazon RDS. The database support team is reporting delayed reads on the DB instance as a result of the increased transactions and advises installing a read replica.\\nWhich activities should a solutions architect do prior to deploying this change? (Select two.)\\n\\nA.Enable binlog replication on the RDS primary node.\\nB. Choose a failover priority for the source DB instance.\\nC. Allow long-running transactions to complete on the source DB instance.\\nD. Create a global table and specify the AWS Regions where the table will be available.\\nE. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0.\", \"C, E. 장기 실행 트랜젝션은 일긱 전용 복제본 생성을 느리게 함. 또한 자동 백업 활성화 되어 있어야 함.\"],\n[\"사용자는 회사 웹사이트에서 과거 실적 보고서를 받을 수 있습니다. 웹 사이트에는 회사의 전세계 웹 사이트 요구 사항에 맞게 확장할 수 있는 솔루션이 필요합니다. 솔루션은 비용 효율적이어야 하고, 인프라 리소스 프로비저닝을 최소화하고, 실현 가능한 가장 빠른 반응 시간을 제공해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 기술 조합을 제안할 수 있습니까?\\n\\nA.Amazon CloudFront 및 Amazon S3\\nB. AWS Lambda 및 Amazon DynamoDB\\nC. Amazon EC2 Auto Scaling이 있는 Application Load Balancer\\nD. 내부 Application Load Balancer가 있는 Amazon Route 53\\n \", \"Users may get past performance reports from a company's website. The website requires a solution that can grow to suit the company's worldwide website requirements. The solution should be cost-effective, minimize infrastructure resource provisioning, and deliver the quickest reaction time feasible.\\nWhich mix of technologies might a solutions architect propose in order to satisfy these requirements?\\n\\nA.Amazon CloudFront and Amazon S3\\nB. AWS Lambda and Amazon DynamoDB\\nC. Application Load Balancer with Amazon EC2 Auto Scaling\\nD. Amazon Route 53 with internal Application Load Balancers\", \"A\"],\n[\"솔루션 설계자는 Amazon Web Services(AWS) 클라우드에서 하이브리드 애플리케이션을 개발하고 있습니다. AWS Direct Link(DX)는 온프레미스 데이터 센터를 AWS에 연결하는 데 사용됩니다. AWS와 온프레미스 데이터 센터 간의 애플리케이션 연결은 매우 내구성이 있어야 합니다.\\n이러한 기준을 충족하려면 어떤 DX 설정을 사용해야 합니까?\\n\\nA.그 위에 VPN을 사용하여 DX 연결을 구성합니다.\\nB. 여러 DX 위치에서 DX 연결을 구성합니다.\\nC. 가장 신뢰할 수 있는 DX 파트너를 사용하여 DX 연결을 구성합니다.\\nD. DX 연결 위에 여러 가상 인터페이스를 구성합니다.\", \"A solutions architect is developing a hybrid application on the Amazon Web Services (AWS) cloud. AWS Direct Link (DX) will be used to connect the on-premises data center to AWS. Between AWS and the on-premises data center, the application connection must be very durable.\\nWhich DX setup should be used to satisfy these criteria?\\n\\nA.Configure a DX connection with a VPN on top of it.\\nB. Configure DX connections at multiple DX locations.\\nC. Configure a DX connection using the most reliable DX partner.\\nD. Configure multiple virtual interfaces on top of a DX connection.\", \"B\"],\n[\"금융 기관은 AWS를 사용하여 웹 애플리케이션을 호스팅합니다. 이 프로그램은 Amazon API Gateway 지역 API 엔드포인트를 사용하여 현재 주가를 검색합니다. 조직의 보안 직원이 API 쿼리의 급증을 감지했습니다. 보안 팀은 HTTP 플러드 공격으로 인해 애플리케이션이 작동하지 않을 수 있다고 우려하고 있습니다.\\n솔루션 설계자는 이러한 형태의 공격에 대한 방어책을 만들어야 합니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 방법은 무엇입니까?\\n\\nA.최대 TTL이 24시간인 API Gateway 리전 API 엔드포인트 앞에 Amazon CloudFront 배포를 생성합니다.\\nB. 요금 기반 규칙을 사용하여 리전 AWS WAF 웹 ACL을 생성합니다. 웹 ACL을 API Gateway 단계와 연결합니다.\\nC. Amazon CloudWatch 지표를 사용하여 Count 지표를 모니터링하고 사전 정의된 비율에 도달하면 보안 팀에 알립니다.\\nD. API Gateway 리전 API 엔드포인트 앞에 Lambda@Edge 를 사용하여 Amazon CloudFront 배포를 생성 합니다. 사전 정의된 속도를 초과하는 IP 주소의 요청을 차단하는 AWS Lambda 함수를 생성합니다.\", \"A financial institution uses AWS to host a web application. The program retrieves current stock prices using an Amazon API Gateway Regional API endpoint. The security staff at the organization has detected an upsurge in API queries. The security team is worried that HTTP flood attacks may result in the application being rendered inoperable.\\nA solutions architect must create a defense against this form of assault.\\nWhich method satisfies these criteria with the LEAST amount of operational overhead?\\n\\nA.Create an Amazon CloudFront distribution in front of the API Gateway Regional API endpoint with a maximum TTL of 24 hours.\\nB. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.\\nC. Use Amazon CloudWatch metrics to monitor the Count metric and alert the security team when the predefined rate is reached.\\nD. Create an Amazon CloudFront distribution with Lambda@Edge in front of the API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate.\", \"B\"],\n[\"비즈니스에서 Amazon EC2 인스턴스의 보안 평가를 자동화하려고 합니다. 조직은 개발 프로세스가 보안 및 규정 준수 요구 사항을 준수하는지 확인하고 보여야 합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon Macie를 사용하여 EC2 인스턴스를 자동으로 검색, 분류 및 보호합니다.\\nB. Amazon GuardDuty를 사용하여 Amazon Simple Notification Service(Amazon SNS) 알림을 게시합니다.\\nC. Amazon CloudWatch와 함께 Amazon Inspector를 사용하여 Amazon Simple Notification Service(Amazon SNS) 알림 게시\\nD. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Trusted Advisor 확인 상태의 변경 사항을 감지하고 이에 대응합니다.\", \"A business wishes to automate the evaluation of the security of its Amazon EC2 instances. The organization must verify and show that the development process adheres to security and compliance requirements.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Use Amazon Macie to automatically discover, classify and protect the EC2 instances.\\nB. Use Amazon GuardDuty to publish Amazon Simple Notification Service (Amazon SNS) notifications.\\nC. Use Amazon Inspector with Amazon CloudWatch to publish Amazon Simple Notification Service (Amazon SNS) notifications\\nD. Use Amazon EventBridge (Amazon CloudWatch Events) to detect and react to changes in the status of AWS Trusted Advisor checks.\", \"C.\\nMacie : AI를 사용해 S3 내부의 민감한 정보 탐색\\nInspector : 실제로 공격 받았을 때 어떤 일이 발생하는지 확인(사전 예방적)\\nGuardDuty : 실제 이벤트를 분석\\nEventBridge : 이벤트 기반 애플리케이션 구축\"],\n[\"Amazon EC2에서 기업은 Amazon RDS 데이터베이스에 의해 백업되는 매우 안전한 애플리케이션을 운영하고 있습니다. 모든 개인 식별 정보(PII)는 규정 준수 표준을 준수하기 위해 저장 시 암호화되어야 합니다.\\n최소한의 인프라 변경으로 이러한 요구 사항을 달성하기 위해 솔루션 설계자는 어떤 솔루션을 제안해야 합니까?\\n\\nA.AWS Certificate Manager를 배포하여 인증서를 생성합니다. 인증서를 사용하여 데이터베이스 볼륨을 암호화합니다.\\nB. AWS CloudHSM을 배포하고 암호화 키를 생성하고 고객 마스터 키(CMK)를 사용하여 데이터베이스 볼륨을 암호화합니다.\\nC. AWS Key Management Service 고객 마스터 키(AWS KMS CMK)를 사용하여 SSL 암호화를 구성하여 데이터베이스 볼륨을 암호화합니다.\\nD. 인스턴스 및 데이터베이스 볼륨을 암호화하도록 AWS Key Management Service(AWS KMS) 키로 Amazon Elastic Block Store(Amazon EBS) 암호화 및 Amazon RDS 암호화를 구성합니다.\", \"On Amazon EC2, a corporation is operating a highly secure application that is backed up by an Amazon RDS database. All personally identifiable information (PII) must be encrypted at rest to comply with compliance standards.\\nWhich solution should a solutions architect propose in order to achieve this need with the MINIMUM number of infrastructure changes?\\n\\nA.Deploy AWS Certificate Manager to generate certificates. Use the certificates to encrypt the database volume.\\nB. Deploy AWS CloudHSM, generate encryption keys, and use the customer master key (CMK) to encrypt database volumes.\\nC. Configure SSL encryption using AWS Key Management Service customer master keys (AWS KMS CMKs) to encrypt database volumes.\\nD. Configure Amazon Elastic Block Store (Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes.\", \"D\"],\n[\"다음 IAM 정책은 솔루션 설계자가 설정했습니다.\\nhttps://i.imgur.com/V0pOoXgl.png\\n정책은 어떤 조치를 허용합니까?\\n\\nA.AWS Lambda 함수는 모든 네트워크에서 삭제할 수 있습니다.\\nB. AWS Lambda 함수는 모든 네트워크에서 생성할 수 있습니다.\\nC. AWS Lambda 함수는 100.220.0.0/20 네트워크에서 삭제할 수 있습니다.\\nD. AWS Lambda 함수는 220.100.16.0/20 네트워크에서 삭제할 수 있습니다.\", \"The following IAM policy has been established by a solutions architect.\\nWhich actions will the policy permit?\\n\\nA.An AWS Lambda function can be deleted from any network.\\nB. An AWS Lambda function can be created from any network.\\nC. An AWS Lambda function can be deleted from the 100.220.0.0/20 network.\\nD. An AWS Lambda function can be deleted from the 220.100.16.0/20 network.\", \"C\"],\n[\"Amazon Aurora에서 기업은 데이터베이스를 운영하고 있습니다. 매일 밤 데이터베이스는 비활성화됩니다. 사용자 트래픽이 이른 시간에 급증하면 데이터베이스에서 많은 양의 읽기를 수행하는 애플리케이션이 성능 문제에 직면하게 됩니다. 이러한 피크 시간 동안 데이터베이스에서 읽을 때 프로그램에서 시간 초과 문제가 발생합니다. 전담 운영 인력이 없기 때문에 조직은 성능 문제를 해결하기 위한 자동화된 솔루션이 필요합니다.\\n데이터베이스가 증가하는 읽기 로드에 자동으로 조정되도록 솔루션 설계자가 취해야 하는 활동은 무엇입니까? (2개를 선택하세요.)\\n\\nA.데이터베이스를 Aurora Serverless로 마이그레이션합니다.\\nB. Aurora 데이터베이스의 인스턴스 크기를 늘립니다.\\nC. Aurora 복제본을 사용하여 Aurora Auto Scaling을 구성합니다.\\nD. 데이터베이스를 Aurora 멀티 마스터 클러스터로 마이그레이션합니다.\\nE. 데이터베이스를 Amazon RDS for MySQL 다중 AZ 배포로 마이그레이션합니다.\", \"On Amazon Aurora, a business is operating a database. Every nightfall, the database is inactive. When user traffic surges in the early hours, an application that makes large reads on the database will face performance concerns. When reading from the database during these peak hours, the program encounters timeout issues. Due to the lack of a dedicated operations crew, the organization need an automated solution to solve performance concerns.\\nWhich activities should a solutions architect take to ensure that the database automatically adjusts to the increasing read load? (Select two.)\\n\\nA.Migrate the database to Aurora Serverless.\\nB. Increase the instance size of the Aurora database.\\nC. Configure Aurora Auto Scaling with Aurora Replicas.\\nD. Migrate the database to an Aurora multi-master cluster.\\nE. Migrate the database to an Amazon RDS for MySQL Multi-AZ deployment.\", \"A, C\"],\n[\"Amazon EC2 인스턴스 기반 애플리케이션은 Amazon DynamoDB 데이터베이스에 대한 액세스 권한이 필요합니다. EC2 인스턴스와 DynamoDB 테이블은 모두 동일한 AWS 계정으로 관리됩니다. 권한은 솔루션 설계자가 구성해야 합니다.\\nDynamoDB 테이블에 대한 EC2 인스턴스 최소 권한 액세스를 제공하는 접근 방식은 무엇입니까?\\n\\nA.DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 역할을 생성합니다. 이 IAM 역할을 EC2 인스턴스에 할당하려면 인스턴스 프로파일을 생성하십시오.\\nB. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 역할을 생성합니다. 역할을 맡을 수 있도록 EC2 인스턴스를 신뢰 관계 정책 문서에 추가합니다.\\nC. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 사용자를 생성합니다. 자격 증명을 Amazon S3 버킷에 저장하고 애플리케이션 코드 내에서 직접 읽습니다.\\nD. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 사용자를 생성합니다. 애플리케이션이 IAM 자격 증명을 로컬 스토리지에 안전하게 저장하고 이를 사용하여 DynamoDB를 호출하는지 확인합니다.\", \"An Amazon EC2 instance-based application requires access to an Amazon DynamoDB database. The EC2 instance and DynamoDB table are both managed by the same AWS account. Permissions must be configured by a solutions architect.\\nWhich approach will provide the EC2 instance least privilege access to the DynamoDB table?\\n\\nA.Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Create an instance profile to assign this IAM role to the EC2 instance.\\nB. Create an IAM role with the appropriate policy to allow access to the DynamoDB table. Add the EC2 instance to the trust relationship policy document to allow it to assume the role.\\nC. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Store the credentials in an Amazon S3 bucket and read them from within the application code directly.\\nD. Create an IAM user with the appropriate policy to allow access to the DynamoDB table. Ensure that the application stores the IAM credentials securely on local storage and uses them to make the DynamoDB calls.\", \"A. 사용자가 아니라 역할을 생성하면 인스턴스에 바로 정책을 부여할 수 있음. (API KEY 사용하지 않고)\"],\n[\"비즈니스는 Amazon EC2 인스턴스를 사용하여 API 기반 인벤토리 보고 애플리케이션을 운영합니다. 이 프로그램은 Amazon DynamoDB 데이터베이스를 사용하여 데이터를 저장합니다. 기업의 물류 센터는 API와 통신하는 온프레미스 배송 애플리케이션을 사용하여 배송 라벨을 생성하기 전에 인벤토리를 업데이트합니다. 매일 조직은 애플리케이션 중단으로 인해 트랜잭션이 누락되는 것을 목격했습니다.\\n솔루션 설계자는 애플리케이션의 탄력성을 높이기 위해 무엇을 제안해야 합니까?\\n\\nA.로컬 데이터베이스에 쓰도록 배송 애플리케이션을 수정합니다.\\nB. AWS Lambda를 사용하여 서버리스를 실행하도록 애플리케이션 API 수정\\nC. EC2 인벤토리 애플리케이션 API를 호출하도록 Amazon API Gateway를 구성합니다.\\nD. Amazon Simple Queue Service(Amazon SQS)를 사용하여 인벤토리 업데이트를 보내도록 애플리케이션을 수정합니다.\", \"A business uses Amazon EC2 instances to operate an API-based inventory reporting application. The program makes use of an Amazon DynamoDB database to store data. The distribution centers of the corporation use an on-premises shipping application that communicates with an API to update inventory prior to generating shipping labels. Each day, the organization has seen application outages, resulting in missed transactions.\\nWhat should a solutions architect propose to increase the resilience of an application?\\n\\nA.Modify the shipping application to write to a local database.\\nB. Modify the application APIs to run serverless using AWS Lambda\\nC. Configure Amazon API Gateway to call the EC2 inventory application APIs.\\nD. Modify the application to send inventory updates using Amazon Simple Queue Service (Amazon SQS).\", \"D\"],\n[\"프라이빗 서브넷의 Amazon EC2 인스턴스는 애플리케이션을 실행하는 데 사용됩니다. 애플리케이션은 Amazon DynamoDB의 테이블에 액세스해야 합니다.\\n트래픽이 AWS 네트워크를 나가는 것을 허용하지 않고 테이블에 액세스하는 가장 안전한 방법은 무엇입니까?\\n\\nA.DynamoDB용 VPC 엔드포인트를 사용합니다.\\nB. 퍼블릭 서브넷에서 NAT 게이트웨이를 사용합니다.\\nC. 프라이빗 서브넷에서 NAT 인스턴스를 사용합니다.\\nD. VPC에 연결된 인터넷 게이트웨이를 사용합니다.\", \"Amazon EC2 instances on private subnets are used to execute an application. The application requires access to a table in Amazon DynamoDB.\\nWhat is the MOST SECURE method of accessing the table without allowing traffic to exit the AWS network?\\n\\nA.Use a VPC endpoint for DynamoDB.\\nB. Use a NAT gateway in a public subnet.\\nC. Use a NAT instance in a private subnet.\\nD. Use the internet gateway attached to the VPC.\", \"A\"],\n[\"단일 Amazon EC2 인스턴스에서 기업은 ASP.NET MVC 애플리케이션을 실행합니다. 최근 애플리케이션 사용량이 급증하면서 사용자는 점심 시간에 응답 시간이 좋지 않습니다. 회사는 가능한 최소한의 설정을 사용하여 이 문제를 해결해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.애플리케이션을 AWS Elastic Beanstalk로 이동합니다. 부하 기반 Auto Scaling 및 시간 기반 크기 조정을 구성하여 점심 시간에 조정을 처리합니다.\\nB. 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)로 이동합니다. 점심 시간 동안 조정을 처리하는 AWS Lambda 함수를 생성합니다.\\nC. 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)로 이동합니다. 점심 시간에 AWS Application Auto Scaling에 대한 예약 조정을 구성합니다.\\nD. 애플리케이션을 AWS Elastic Beanstalk로 이동합니다. 부하 기반 Auto Scaling을 구성하고 점심 시간 동안 조정을 처리하는 AWS Lambda 함수를 생성합니다.\", \"On a single Amazon EC2 instance, a business runs an ASP.NET MVC application. Due to a recent spike in application usage, users are experiencing poor response times during lunch hours. The firm must address this issue using the least amount of settings possible.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Move the application to AWS Elastic Beanstalk. Configure load-based auto scaling and time-based scaling to handle scaling during lunch hours.\\nB. Move the application to Amazon Elastic Container Service (Amazon ECS). Create an AWS Lambda function to handle scaling during lunch hours.\\nC. Move the application to Amazon Elastic Container Service (Amazon ECS). Configure scheduled scaling for AWS Application Auto Scaling during lunch hours.\\nD. Move the application to AWS Elastic Beanstalk. Configure load-based auto scaling, and create an AWS Lambda function to handle scaling during lunch hours.\", \"A. Beanstalk은 시간 기반 조정도 지원하기 때문에 최소한의 설정을 사용해 문제 해결 가능\"],\n[\"기업이 온프레미스 애플리케이션을 AWS로 마이그레이션하는 과정에 있습니다. 프로그램 서버와 Microsoft SQL Server 데이터베이스는 응용 프로그램을 구성합니다. SQL Server 기능을 사용하는 응용 프로그램의 NET 코드로 인해 데이터베이스를 다른 엔진으로 전송할 수 없습니다. 회사의 목표는 운영 및 관리 비용을 줄이는 동시에 가용성을 극대화하는 것입니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.다중 AZ 배포의 Amazon EC2에 SQL Server를 설치합니다.\\nB. 다중 AZ 배포에서 SQL Server용 Amazon RDS로 데이터를 마이그레이션합니다.\\nC. 다중 AZ 복제본이 있는 SQL Server용 Amazon RDS에 데이터베이스를 배포합니다.\\nD. 교차 리전 다중 AZ 배포에서 SQL Server용 Amazon RDS로 데이터를 마이그레이션합니다.\", \"A business is in the process of migrating its on-premises application to AWS. Program servers and a Microsoft SQL Server database comprise the application. The database cannot be transferred to another engine due to the application's NET code using SQL Server functionality. The company's goal is to maximize availability while decreasing operational and administration costs.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Install SQL Server on Amazon EC2 in a Multi-AZ deployment.\\nB. Migrate the data to Amazon RDS for SQL Server in a Multi-AZ deployment.\\nC. Deploy the database on Amazon RDS for SQL Server with Multi-AZ Replicas.\\nD. Migrate the data to Amazon RDS for SQL Server in a cross-Region Multi-AZ deployment.\", \"B. MS SQL Server는 교차 리전 다중 AZ 미지원\"],\n[\"Amazon Redshift는 비즈니스에서 분석을 수행하고 고객 보고서를 생성하는 데 사용됩니다. 이 회사는 고객에 대한 추가 50테라바이트의 인구 통계 데이터를 얻었습니다. 데이터는 Amazon S3 in.csv 파일에 저장됩니다. 조직에는 데이터를 효율적으로 병합하고 결과를 시각화하는 시스템이 필요합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon Redshift Spectrum을 사용하여 Amazon S3의 데이터를 직접 쿼리하고 해당 데이터를 Amazon Redshift의 기존 데이터와 결합합니다. Amazon QuickSight를 사용하여 시각화를 구축하십시오.\\nB. Amazon Athena를 사용하여 Amazon S3의 데이터를 쿼리합니다. Amazon QuickSight를 사용하여 Athena의 데이터를 Amazon Redshift의 기존 데이터와 결합하고 시각화를 구축하십시오.\\nC. Amazon Redshift 클러스터의 크기를 늘리고 Amazon S3에서 데이터를 로드합니다. Amazon EMR 노트북을 사용하여 Amazon Redshift에서 데이터를 쿼리하고 시각화를 구축하십시오.\\nD. Amazon Redshift 클러스터의 데이터를 Amazon S3의 Apache Parquet 파일로 내보냅니다. Amazon Elasticsearch Service(Amazon ES)를 사용하여 데이터를 쿼리합니다. Kibana를 사용하여 결과를 시각화하십시오.\", \"Amazon Redshift is being used by a business to do analytics and produce customer reports. The corporation just obtained an extra 50 terabytes of demographic data on its customers. The data is saved in Amazon S3 in.csv files. The organization need a system that efficiently merges data and visualizes the findings.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Use Amazon Redshift Spectrum to query the data in Amazon S3 directly and join that data with the existing data in Amazon Redshift. Use Amazon QuickSight to build the visualizations.\\nB. Use Amazon Athena to query the data in Amazon S3. Use Amazon QuickSight to join the data from Athena with the existing data in Amazon Redshift and to build the visualizations.\\nC. Increase the size of the Amazon Redshift cluster, and load the data from Amazon S3. Use Amazon EMR Notebooks to query the data and build the visualizations in Amazon Redshift.\\nD. Export the data from the Amazon Redshift cluster into Apache Parquet files in Amazon S3. Use Amazon Elasticsearch Service (Amazon ES) to query the data. Use Kibana to visualize the results.\", \"A\"],\n[\"매달 기업은 Amazon S3에 200GB의 데이터를 보관합니다. 매월 말에 회사는 이 데이터를 분석하여 전월 동안 각 판매 영역에서 판매된 물건 수를 계산해야 합니다.\\n비즈니스에 가장 비용 효율적인 옵션은 어떤 분석 접근 방식입니까?\\n\\nA.Amazon Elasticsearch Service(Amazon ES) 클러스터를 생성합니다. Amazon ES에서 데이터를 쿼리합니다. Kibana를 사용하여 데이터를 시각화합니다.\\nB. AWS Glue 데이터 카탈로그에 테이블을 생성합니다. Amazon Athena를 사용하여 Amazon S3의 데이터를 쿼리합니다. Amazon QuickSight에서 데이터를 시각화합니다.\\nC. Amazon EMR 클러스터를 생성합니다. Amazon EMR을 사용하여 데이터를 쿼리하고 결과를 Amazon S3에 저장합니다. Amazon QuickSight에서 데이터를 시각화합니다.\\nD. Amazon Redshift 클러스터를 생성합니다. Amazon Redshift에서 데이터를 쿼리하고 결과를 Amazon S3에 업로드합니다. Amazon QuickSight에서 데이터를 시각화합니다.\", \"Each month, a business keeps 200 GB of data on Amazon S3. At the conclusion of each month, the corporation must analyze this data to calculate the number of things sold in each sales area during the preceding month.\\nWhich analytics approach is the MOST cost-effective option for the business?\\n\\nA.Create an Amazon Elasticsearch Service (Amazon ES) cluster. Query the data in Amazon ES. Visualize the data by using Kibana.\\nB. Create a table in the AWS Glue Data Catalog. Query the data in Amazon S3 by using Amazon Athena. Visualize the data in Amazon QuickSight.\\nC. Create an Amazon EMR cluster. Query the data by using Amazon EMR, and store the results in Amazon S3. Visualize the data in Amazon QuickSight.\\nD. Create an Amazon Redshift cluster. Query the data in Amazon Redshift, and upload the results to Amazon S3. Visualize the data in Amazon QuickSight.\", \"B\"],\n[\"기업의 데이터 계층은 PostgreSQL 데이터베이스용 Amazon RDS를 기반으로 합니다. 조직은 데이터베이스 비밀번호 순환을 채택해야 합니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 옵션은 무엇입니까?\\n\\nA.AWS Secrets Manager에 암호를 저장합니다. 보안 비밀에 대한 자동 순환을 활성화합니다.\\nB. AWS Systems Manager Parameter Store에 암호를 저장합니다. 매개변수에서 자동 회전을 활성화합니다.\\nC. AWS Systems Manager Parameter Store에 암호를 저장합니다. 암호를 교체하는 AWS Lambda 함수를 작성합니다.\\nD. AWS Key Management Service(AWS KMS)에 암호를 저장합니다. 고객 마스터 키(CMK)에서 자동 교체를 활성화합니다.\", \"A business's data layer is powered by Amazon RDS for PostgreSQL databases. The organization must adopt database password rotation.\\nWhich option satisfies this criterion with the LEAST amount of operational overhead?\\n\\nA.Store the password in AWS Secrets Manager. Enable automatic rotation on the secret.\\nB. Store the password in AWS Systems Manager Parameter Store. Enable automatic rotation on the parameter.\\nC. Store the password in AWS Systems Manager Parameter Store. Write an AWS Lambda function that rotates the password.\\nD. Store the password in AWS Key Management Service (AWS KMS). Enable automatic rotation on the customer master key (CMK).\", \"A.\\nSystem Manager는 민감한 자격 증명을 저장하지 않고 리소스(S3, EC2, RDS 등)를 모니터링하고 구성하기 위한 것\\nLambda를 통해 구성하는게 아니라 자동 순환을 통해 구성해야 함\\nKMS는 인증 자격 증명 저장이 아니라 데이터 암호화/복호화에 사용되는 키 관리\"],\n[\"기업은 TCP 기반 애플리케이션을 회사의 가상 사설 클라우드(VPC)로 이전하려고 합니다. 이 프로그램은 회사 데이터 센터에 있는 물리적 장치를 통해 지원되지 않는 TCP 포트를 통해 대중에게 제공됩니다. 이 공용 엔드포인트의 지연 시간은 3밀리초 미만이며 초당 최대 3백만 개의 요청을 처리할 수 있습니다. 조직이 동일한 수준의 성능으로 작동하려면 AWS의 새로운 퍼블릭 엔드포인트가 필요합니다.\\n이 요구 사항을 충족하려면 어떤 솔루션 아키텍처 접근 방식을 권장해야 합니까?\\n\\nA.NLB(네트워크 로드 밸런서)를 배포합니다. 애플리케이션에 필요한 TCP 포트를 통해 공개적으로 액세스할 수 있도록 NLB를 구성합니다.\\nB. 애플리케이션 로드 밸런서(ALB)를 배포합니다. 애플리케이션에 필요한 TCP 포트를 통해 공개적으로 액세스할 수 있도록 ALB를 구성하십시오.\\nC. 애플리케이션에 필요한 TCP 포트에서 수신 대기하는 Amazon CloudFront 배포를 배포합니다. Application Load Balancer를 오리진으로 사용합니다.\\nD. 애플리케이션에 필요한 TCP 포트로 구성된 Amazon API Gateway API를 배포합니다. 프로비저닝된 동시성을 사용하여 AWS Lambda 함수를 구성하여 요청을 처리합니다.\", \"A business intends to transfer a TCP-based application onto the company's virtual private cloud (VPC). The program is available to the public over an unsupported TCP port via a physical device located in the company's data center. This public endpoint has a latency of less than 3 milliseconds and can handle up to 3 million requests per second. The organization needs the new public endpoint in AWS to function at the same level of performance.\\nWhat solution architecture approach should be recommended to satisfy this requirement?\\n\\nA.Deploy a Network Load Balancer (NLB). Configure the NLB to be publicly accessible over the TCP port that the application requires.\\nB. Deploy an Application Load Balancer (ALB). Configure the ALB to be publicly accessible over the TCP port that the application requires.\\nC. Deploy an Amazon CloudFront distribution that listens on the TCP port that the application requires. Use an Application Load Balancer as the origin.\\nD. Deploy an Amazon API Gateway API that is configured with the TCP port that the application requires. Configure AWS Lambda functions with provisioned concurrency to process the requests.\", \"A. 4계층이므로 ALB아니고 NLB사용해야 함. API gateway는 초당 요청 수가 10000개로 제한\"],\n[\"동일한 AWS 계정 내에서 회사는 us-west-2 리전에 위치한 두 개의 VPC를 가지고 있습니다. 비즈니스는 이러한 VPC 간의 네트워크 통신을 허용해야 합니다. 매월 약 500GB의 데이터가 VPC 간에 전송됩니다.\\n이러한 VPC를 연결하는 데 가장 비용 효율적인 접근 방식은 무엇입니까?\\n\\nA.AWS Transit Gateway를 구현하여 VPC를 연결합니다. VPC 간 통신에 전송 게이트웨이를 사용하도록 각 VPC의 라우팅 테이블을 업데이트합니다.\\nB. VPC 간에 AWS Site-to-Site VPN 터널을 구현합니다. VPC 간 통신에 VPN 터널을 사용하도록 각 VPC의 라우팅 테이블을 업데이트합니다.\\nC. VPC 간에 VPC 피어링 연결을 설정합니다. VPC 간 통신에 VPC 피어링 연결을 사용하도록 각 VPC의 라우팅 테이블을 업데이트합니다.\\nD. VPC 간에 1GB AWS Direct Connect 연결을 설정합니다. VPC 간 통신에 Direct Connect 연결을 사용하도록 각 VPC의 라우팅 테이블을 업데이트합니다.\", \"Within the same AWS account, a firm has two VPCs situated in the us-west-2 Region. The business must permit network communication between these VPCs. Each month, about 500 GB of data will be transferred between the VPCs.\\nWhich approach is the MOST cost-effective for connecting these VPCs?\\n\\nA.Implement AWS Transit Gateway to connect the VPCs. Update the route tables of each VPC to use the transit gateway for inter-VPC communication.\\nB. Implement an AWS Site-to-Site VPN tunnel between the VPCs. Update the route tables of each VPC to use the VPN tunnel for inter-VPC communication.\\nC. Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter-VPC communication.\\nD. Set up a 1 GB AWS Direct Connect connection between the VPCs. Update the route tables of each VPC to use the Direct Connect connection for inter-VPC communication.\", \"C\"],\n[\"비즈니스의 프로덕션 워크로드는 6개의 Aurora 복제본으로 구성된 Amazon Aurora MySQL DB 클러스터에서 호스팅됩니다. 회사는 세 개의 Aurora 복제본 간에 부서 중 하나의 거의 실시간 보고 요청 배포를 자동화하고자 합니다. 이 3개의 복사본은 계산 및 메모리 측면에서 나머지 DB 클러스터와 다르게 구성됩니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.작업 부하에 대한 사용자 지정 끝점을 만들고 사용합니다.\\nB. 3노드 클러스터 클론을 생성하고 리더 엔드포인트를 사용합니다.\\nC. 선택한 세 노드에 대해 인스턴스 끝점 중 하나를 사용합니다.\\nD. 판독기 끝점을 사용하여 읽기 전용 작업 부하를 자동으로 배포합니다.\", \"A business's production workload is hosted on an Amazon Aurora MySQL DB cluster comprised of six Aurora Replicas. The corporation wishes to automate the distribution of near-real-time reporting requests from one of its departments among three Aurora Replicas. These three copies are configured differently from the rest of the DB cluster in terms of computation and memory.\\nWhich solution satisfies these criteria?\\n\\nA.Create and use a custom endpoint for the workload.\\nB. Create a three-node cluster clone and use the reader endpoint.\\nC. Use any of the instance endpoints for the selected three nodes.\\nD. Use the reader endpoint to automatically distribute the read-only workload.\", \"A.\\n클러스터 엔드포인트 – 장애 조치 시, 즉 현재 기본 인스턴스가 강등되고 Aurora 복제본 중 하나가 그 자리에서 승격되는 경우 기본 인스턴스에 연결하고 자동으로 기본 인스턴스를 따릅니다.\\n리더 엔드포인트 – 단일 DNS CNAME 아래 DB 클러스터의 모든 Aurora 복제본을 포함합니다. 판독기 끝점을 사용하여 읽기 전용 연결에 대한 DNS 라운드 로빈 부하 분산을 구현할 수 있습니다.\\n인스턴스 엔드포인트 – DB 클러스터의 각 인스턴스에는 고유한 개별 엔드포인트가 있습니다. 이 끝점을 사용하여 특정 인스턴스에 직접 연결할 수 있습니다.\\n사용자 지정 끝점 – 주어진 클러스터에서 선택된 인스턴스 그룹을 포함하는 사용자 정의 DNS 끝점\"],\n[\"기업의 온프레미스 데이터 센터가 스토리지 한도에 도달했습니다. 조직은 대역폭 비용을 가능한 한 낮게 유지하면서 스토리지 시스템을 AWS로 전환하기를 원합니다. 솔루션은 빠르고 비용 없는 데이터 검색을 가능하게 해야 합니다.\\n이러한 조건은 어떻게 충족되어야 합니까?\\n\\nA.Amazon S3 Glacier Vault를 배포하고 신속 검색을 활성화합니다. 워크로드에 대해 프로비저닝된 검색 용량을 활성화합니다.\\nB. 캐시된 볼륨을 사용하여 AWS Storage Gateway를 배포합니다. Storage Gateway를 사용하여 Amazon S3에 데이터를 저장하는 동시에 자주 액세스하는 데이터 하위 집합의 복사본을 로컬에 유지합니다.\\nC. 저장된 볼륨을 사용하여 AWS Storage Gateway를 배포하여 데이터를 로컬에 저장합니다. Storage Gateway를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3에 비동기식으로 백업합니다.\\nD. AWS Direct Connect를 배포하여 온프레미스 데이터 센터에 연결합니다. 데이터를 로컬에 저장하도록 AWS Storage Gateway를 구성합니다. Storage Gateway를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3에 비동기식으로 백업합니다.\", \"A business's on-premises data center has reached its storage limit. The organization wishes to shift its storage system to AWS while keeping bandwidth costs as low as possible. The solution must enable rapid and cost-free data retrieval.\\nHow are these stipulations to be met?\\n\\nA.Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload.\\nB. Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally.\\nC. Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.\\nD. Deploy AWS Direct Connect to connect with the on-premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.\", \"B.\\n\\nA.즉시 검색이 불가능하므로 안됨.\\nC는 이미 스토리지 한도에 도달하였으므로 안됨.\\nD는 대역폭 비용이 많이 나옴\"],\n[\"새로 인수한 회사는 인수한 지 한 달 이내에 AWS에 자체 인프라를 구축하고 다양한 앱을 클라우드로 이전해야 합니다. 각 애플리케이션에는 약 50TB의 데이터 전송이 필요합니다. 이전 후 이 회사와 모회사는 데이터 센터와 앱 간에 처리량이 일정한 안전한 네트워크 연결이 필요합니다. 솔루션 설계자는 데이터 전송이 한 번만 발생하고 네트워크 연결이 유지되도록 보장해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.초기 전송 및 지속적인 연결을 위한 AWS Direct Connect.\\nB. 초기 전송 및 지속적인 연결을 위한 AWS Site-to-Site VPN.\\nC. 초기 전송을 위한 AWS Snowball 및 지속적인 연결을 위한 AWS Direct Connect.\\nD. 초기 전송을 위한 AWS Snowball 및 지속적인 연결을 위한 AWS Site-to-Site VPN.\", \"Within a month of being bought, a newly acquired firm is needed to establish its own infrastructure on AWS and transfer various apps to the cloud. Each application requires the transmission of around 50 TB of data. Following the transfer, this firm and its parent company will need secure network connection with constant throughput between its data centers and apps. A solutions architect must guarantee that data transfer occurs just once and that network connection is maintained.\\nWhich solution will satisfy these criteria?\\n\\nA.AWS Direct Connect for both the initial transfer and ongoing connectivity.\\nB. AWS Site-to-Site VPN for both the initial transfer and ongoing connectivity.\\nC. AWS Snowball for the initial transfer and AWS Direct Connect for ongoing connectivity.\\nD. AWS Snowball for the initial transfer and AWS Site-to-Site VPN for ongoing connectivity.\", \"C. Direct connect는 셋팅까지 1개월 이상 소요되므로, 초기 전송에 사용 불가. site-to-site VPN은 일관된 연결이 불가능함\"],\n[\"솔루션 설계자는 인터넷 기반 타사 웹 서비스에서 2분마다 데이터를 검색하는 솔루션을 만들어야 합니다. 각 데이터 검색은 Python 스크립트를 사용하여 100밀리초 미만으로 수행됩니다. 정답은 센서 데이터를 포함하여 크기가 1KB 미만인 JSON 객체입니다. 솔루션 설계자는 JSON 개체와 날짜를 모두 유지해야 합니다.\\n이러한 요구 사항을 충족하는 데 가장 비용 효율적인 접근 방식은 무엇입니까?\\n\\nA.Linux 운영 체제로 Amazon EC2 인스턴스를 배포합니다. 2분마다 스크립트를 실행하도록 크론 작업을 구성합니다. Amazon RDS DB 인스턴스에서 호스팅되는 MySQL 데이터베이스에 타임스탬프와 함께 JSON 객체를 저장하도록 스크립트를 확장합니다.\\nB. Linux 운영 체제와 함께 Amazon EC2 인스턴스를 배포하여 스크립트가 2분마다 무한 루프에서 실행되도록 확장합니다. 타임스탬프를 기본 키로 사용하는 Amazon DynamoDB 테이블에 타임스탬프와 함께 JSON 객체를 저장합니다. EC2 인스턴스에서 스크립트를 실행합니다.\\nC. AWS Lambda 함수를 배포하여 타임스탬프를 기본 키로 사용하는 Amazon DynamoDB 테이블에 타임스탬프와 함께 JSON 객체를 저장하도록 스크립트를 확장합니다. 2분마다 시작되는 Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트를 사용하여 Lambda 함수를 호출합니다.\\nD. AWS Lambda 함수를 배포하여 스크립트가 2분마다 무한 루프에서 실행되도록 확장합니다. 타임스탬프를 기본 키로 사용하는 Amazon DynamoDB 테이블에 타임스탬프와 함께 JSON 객체를 저장합니다. Lambda 함수에 대해 구성된 핸들러 함수에서 스크립트를 호출하는지 확인합니다.\", \"A solutions architect must create a solution that retrieves data every two minutes from an internet-based third-party web service. Each data retrieval is performed using a Python script in less than 100 milliseconds. The answer is a JSON object of less than 1 KB in size including sensor data. The architect of the solution must keep both the JSON object and the date.\\nWhich approach is the most cost-effective in meeting these requirements?\\n\\nA.Deploy an Amazon EC2 instance with a Linux operating system. Configure a cron job to run the script every 2 minutes. Extend the script to store the JSON object along with the timestamp in a MySQL database that is hosted on an Amazon RDS DB instance.\\nB. Deploy an Amazon EC2 instance with a Linux operating system to extend the script to run in an infinite loop every 2 minutes. Store the JSON object along with the timestamp in an Amazon DynamoDB table that uses the timestamp as the primary key. Run the script on the EC2 instance.\\nC. Deploy an AWS Lambda function to extend the script to store the JSON object along with the timestamp in an Amazon DynamoDB table that uses the timestamp as the primary key. Use an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that is initiated every 2 minutes to invoke the Lambda function.\\nD. Deploy an AWS Lambda function to extend the script to run in an infinite loop every 2 minutes. Store the JSON object along with the timestamp in an Amazon DynamoDB table that uses the timestamp as the primary key. Ensure that the script is called by the handler function that is configured for the Lambda function.\", \"C. \"],\n[\"비즈니스에는 현재 파일 공유 서비스가 없습니다. 새 프로젝트에는 온-프레미스 데스크톱 컴퓨터용 디스크로 탑재할 수 있는 파일 저장소가 필요합니다. 사용자가 저장소에 액세스하려면 먼저 파일 서버가 Active Directory 도메인에 대해 사용자를 인증해야 합니다.\\nActive Directory 사용자가 워크스테이션에 드라이브로 스토리지를 배포할 수 있는 서비스는 무엇입니까?\\n\\nA.Amazon S3 Glacier\\nB. AWS DataSync\\nC. AWS Snowball Edge\\nD. AWS Storage Gateway\", \"A business does not currently have any file sharing services. A new project needs file storage that can be mounted as a disk for on-premises desktop computers. Before users can access the storage, the file server must authenticate them against an Active Directory domain.\\nWhich service enables Active Directory users to deploy storage on their workstations as a drive?\\n\\nA.Amazon S3 Glacier\\nB. AWS DataSync\\nC. AWS Snowball Edge\\nD. AWS Storage Gateway\", \"D\"],\n[\"온프레미스 애플리케이션을 보유한 기업은 애플리케이션의 유연성과 가용성을 높이기 위해 AWS로 전환하고 있습니다. 현재 설계에서는 Microsoft SQL Server 데이터베이스를 많이 사용합니다. 회사는 다른 데이터베이스 솔루션을 조사하고 필요한 경우 데이터베이스 엔진을 마이그레이션하려고 합니다.\\n개발 팀은 테스트 데이터베이스를 만들기 위해 4시간마다 프로덕션 데이터베이스의 전체 복사본을 만듭니다. 이 기간 동안 사용자는 지연이 발생합니다.\\n솔루션 설계자는 대체 데이터베이스로 어떤 데이터베이스를 제안해야 합니까?\\n\\nA.다중 AZ Aurora 복제본과 함께 Amazon Aurora를 사용하고 테스트 데이터베이스에 대해 mysqldump에서 복원합니다.\\nB. 다중 AZ Aurora 복제본과 함께 Amazon Aurora를 사용하고 테스트 데이터베이스에 대해 Amazon RDS에서 스냅샷을 복원합니다.\\nC. 다중 AZ 배포 및 읽기 전용 복제본과 함께 MySQL용 Amazon RDS를 사용하고 테스트 데이터베이스에 대기 인스턴스를 사용합니다.\\nD. 다중 AZ 배포 및 읽기 전용 복제본과 함께 SQL Server용 Amazon RDS를 사용하고 테스트 데이터베이스용으로 RDS에서 스냅샷을 복원합니다.\", \"A corporation with an on-premises application is transitioning to AWS to boost the flexibility and availability of the application. The present design makes considerable use of a Microsoft SQL Server database. The firm want to investigate other database solutions and, if necessary, migrate database engines.\\nThe development team does a complete copy of the production database every four hours in order to create a test database. Users will encounter delay during this time period.\\nWhat database should a solution architect propose as a replacement?\\n\\nA.Use Amazon Aurora with Multi-AZ Aurora Replicas and restore from mysqldump for the test database.\\nB. Use Amazon Aurora with Multi-AZ Aurora Replicas and restore snapshots from Amazon RDS for the test database.\\nC. Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas, and use the standby instance for the test database.\\nD. Use Amazon RDS for SQL Server with a Multi-AZ deployment and read replicas, and restore snapshots from RDS for the test database.\", \"D. 데이터베이스 엔진을 마이그레이션하는게 필수 조건이라면 B가 답이라는 의견 있음\"],\n[\"Amazon EC2 인스턴스에서 기업은 애플리케이션을 실행합니다. 웹 페이지에 대한 트래픽 양은 업무 시간 동안 크게 증가했다가 감소합니다.\\nAmazon EC2 인스턴스의 CPU 사용량은 애플리케이션의 최종 사용자 수요를 측정하는 좋은 방법입니다. 조직은 Auto Scaling 그룹에 대해 2개의 EC2 인스턴스의 최소 그룹 크기와 10개의 EC2 인스턴스의 최대 그룹 크기를 지정했습니다.\\n회사에서는 Auto Scaling 그룹의 기존 스케일링 정책이 잘못된 것은 아닐까 걱정하고 있습니다. 조직은 과도한 EC2 인스턴스 프로비저닝 및 불필요한 요금 지불을 방지해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon EC2 Auto Scaling이 예약된 확장 계획을 사용하도록 구성하고 업무 시간 동안 8개의 EC2 인스턴스를 추가로 시작합니다.\\nB. 예측 조정을 활성화하는 조정 계획을 사용하도록 AWS Auto Scaling을 구성합니다. 예측 및 규모 조정 모드로 예측 조정을 구성하고 조정 중에 최대 용량 설정을 적용합니다.\\nC. 50% CPU 사용률에서 4개의 EC2 인스턴스를 추가하고 90% CPU 사용률에서 4개의 EC2 인스턴스를 추가하도록 단계 조정 정책을 구성합니다. 역방향을 수행하고 두 값을 기반으로 EC2 인스턴스를 제거하도록 축소 정책을 구성합니다.\\nD. 5개의 EC2 인스턴스의 원하는 용량을 갖도록 AWS Auto Scaling을 구성하고 기존 조정 정책을 비활성화합니다. 1주일 동안 CPU 사용률 메트릭을 모니터링합니다. 그런 다음 관찰된 값을 기반으로 하는 동적 조정 정책을 만듭니다.\", \"On Amazon EC2 instances, a business runs an application. The volume of traffic to the webpage grows significantly during business hours and then falls.\\nThe CPU usage of an Amazon EC2 instance is a good measure of the application's end-user demand. The organization has specified a minimum group size of two EC2 instances and a maximum group size of ten EC2 instances for an Auto Scaling group.\\nThe firm is worried that the Auto Scaling group's existing scaling policy may be incorrect. The organization must prevent excessive EC2 instance provisioning and paying unneeded fees.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Configure Amazon EC2 Auto Scaling to use a scheduled scaling plan and launch an additional 8 EC2 instances during business hours.\\nB. Configure AWS Auto Scaling to use a scaling plan that enables predictive scaling. Configure predictive scaling with a scaling mode of forecast and scale, and to enforce the maximum capacity setting during scaling.\\nC. Configure a step scaling policy to add 4 EC2 instances at 50% CPU utilization and add another 4 EC2 instances at 90% CPU utilization. Configure scale-in policies to perform the reverse and remove EC2 instances based on the two values.\\nD. Configure AWS Auto Scaling to have a desired capacity of 5 EC2 instances, and disable any existing scaling policies. Monitor the CPU utilization metric for 1 week. Then create dynamic scaling policies that are based on the observed values.\", \"B. 업무 시간은 예측가능한 시간이므로. C도 가능하다는 의견 존재\"],\n[\"한 기업이 모바일 멀티플레이어 게임을 출시했습니다. 이 게임은 참가자의 위도 및 경도 위치를 실시간으로 모니터링해야 합니다. 게임의 데이터 저장소는 빠른 업데이트와 위치 검색이 가능해야 합니다.\\n이 게임은 읽기 전용 복제본이 있는 PostgreSQL용 Amazon RDS DB 인스턴스에 위치 데이터를 저장합니다. 데이터베이스는 사용량이 많은 시간 동안 변경 사항을 읽고 쓰는 데 필요한 속도를 유지할 수 없습니다. 게임의 사용자 기반은 빠르게 성장하고 있습니다.\\n솔루션 설계자는 데이터 계층의 성능을 최적화하기 위해 무엇을 해야 합니까?\\n\\nA.기존 DB 인스턴스의 스냅샷을 생성합니다. 다중 AZ가 활성화된 스냅샷을 복원합니다.\\nB. Kibana를 사용하여 Amazon RDS에서 Amazon Elasticsearch Service(Amazon ES)로 마이그레이션합니다.\\nC. 기존 DB 인스턴스 앞에 Amazon DynamoDB Accelerator(DAX)를 배포합니다. DAX를 사용하도록 게임을 수정합니다.\\nD. 기존 DB 인스턴스 앞에 Redis용 Amazon ElastiCache 클러스터를 배포합니다. Redis를 사용하도록 게임을 수정합니다.\", \"A business has launched a mobile multiplayer game. The game demands real-time monitoring of participants' latitude and longitude positions. The game's data storage must be capable of quick updates and location retrieval.\\nThe game stores location data on an Amazon RDS for PostgreSQL DB instance with read replicas. The database is unable to sustain the speed required for reading and writing changes during high use times. The game's user base is rapidly growing.\\nWhat should a solutions architect do to optimize the data tier's performance?\\n\\nA.Take a snapshot of the existing DB instance. Restore the snapshot with Multi-AZ enabled.\\nB. Migrate from Amazon RDS to Amazon Elasticsearch Service (Amazon ES) with Kibana.\\nC. Deploy Amazon DynamoDB Accelerator (DAX) in front of the existing DB instance. Modify the game to use DAX.\\nD. Deploy an Amazon ElastiCache for Redis cluster in front of the existing DB instance. Modify the game to use Redis.\", \"D. DAX는 DynamoDB만 사용 가능\"],\n[\"회사의 온프레미스 인프라와 AWS에는 보안 연결이 필요합니다. 이 연결은 많은 양의 대역폭이 필요하지 않으며 제한된 양의 트래픽을 처리할 수 있습니다. 링크는 즉시 설정되어야 합니다.\\n이러한 종류의 연결을 설정하는 데 가장 저렴한 방법은 무엇입니까?\\n\\nA.클라이언트 VPN을 구현합니다.\\nB. AWS Direct Connect를 구현합니다.\\nC. Amazon EC2에서 배스천 호스트를 구현합니다.\\nD. AWS Site-to-Site VPN 연결을 구현합니다.\", \"A company's on-premises infrastructure and AWS need a secure connection. This connection does not need a large quantity of bandwidth and is capable of handling a limited amount of traffic. The link should be established immediately.\\nWhich way is the MOST CHEAPEST for establishing this sort of connection?\\n\\nA.Implement a client VPN.\\nB. Implement AWS Direct Connect.\\nC. Implement a bastion host on Amazon EC2.\\nD. Implement an AWS Site-to-Site VPN connection.\", \"D\"],\n[\"한 기업이 여러 가용 영역에 분산된 Amazon EC2 인스턴스에서 작동할 웹 기반 애플리케이션을 개발 중입니다. 온라인 애플리케이션을 통해 900TB 이상의 텍스트 콘텐츠 컬렉션에 액세스할 수 있습니다. 회사는 온라인 지원에 대한 수요가 많을 것으로 예상합니다. 솔루션 설계자는 텍스트 문서 스토리지 구성 요소가 항상 애플리케이션의 요구 사항을 충족하도록 확장할 수 있음을 보장해야 합니다. 회사는 솔루션의 총 비용에 대해 우려하고 있습니다.\\n비용 효율성 측면에서 이러한 기준을 가장 잘 충족하는 스토리지 시스템은 무엇입니까?\\n\\nA.Amazon Elastic Block Store(Amazon EBS)\\nB. Amazon Elastic File System(Amazon EFS)\\nC. Amazon Elasticsearch Service(Amazon ES)\\nD. 아마존 S3\", \"A business is developing a web-based application that will operate on Amazon EC2 instances distributed across several Availability Zones. The online application will enable access to a collection of over 900 TB of text content. The corporation expects times of heavy demand for the online application. A solutions architect must guarantee that the text document storage component can scale to meet the application's demand at all times. The corporation is concerned about the solution's total cost.\\nWhich storage system best satisfies these criteria in terms of cost-effectiveness?\\n\\nA.Amazon Elastic Block Store (Amazon EBS)\\nB. Amazon Elastic File System (Amazon EFS)\\nC. Amazon Elasticsearch Service (Amazon ES)\\nD. Amazon S3\", \"D\"],\n[\"한 기업에서 중요한 애플리케이션 데이터를 해외에 저장하기 위해 테이프 백업 시스템을 사용하고 있습니다. 일일 데이터 볼륨은 약 50TB입니다. 규정 요구 사항에 따라 회사는 7년 동안 백업을 유지해야 합니다. 백업은 자주 볼 수 없으며 일반적으로 백업을 복원하기 전에 일주일 전에 통지해야 합니다.\\n조직은 현재 테이프 관리와 관련된 스토리지 비용 및 운영 부하를 줄이기 위해 클라우드 기반 솔루션을 조사하고 있습니다. 또한 조직은 테이프 백업에서 클라우드로 최대한 원활하게 이동하기를 원합니다.\\n가장 저렴한 스토리지 옵션은 무엇입니까?\\n\\nA.Amazon Storage Gateway를 사용하여 Amazon Glacier Deep Archive에 백업합니다.\\nB. AWS Snowball Edge를 사용하여 백업을 Amazon S3 Glacier와 직접 통합합니다.\\nC. 백업 데이터를 Amazon S3에 복사하고 수명 주기 정책을 생성하여 데이터를 Amazon S3 Glacier로 이동합니다.\\nD. Amazon Storage Gateway를 사용하여 Amazon S3에 백업하고 수명 주기 정책을 생성하여 백업을 Amazon S3 Glacier로 이동합니다.\", \"A business is using a tape backup system to offshore store critical application data. Daily data volume is in the neighborhood of 50 TB. For regulatory requirements, the firm must maintain backups for seven years. Backups are infrequently viewed, and a week's notice is normally required before restoring a backup.\\nThe organization is now investigating a cloud-based solution in order to cut storage expenses and the operational load associated with tape management. Additionally, the organization wants to ensure that the move from tape backups to the cloud is as seamless as possible.\\nWhich storage option is the CHEAPEST?\\n\\nA.Use Amazon Storage Gateway to back up to Amazon Glacier Deep Archive.\\nB. Use AWS Snowball Edge to directly integrate the backups with Amazon S3 Glacier.\\nC. Copy the backup data to Amazon S3 and create a lifecycle policy to move the data to Amazon S3 Glacier.\\nD. Use Amazon Storage Gateway to back up to Amazon S3 and create a lifecycle policy to move the backup to Amazon S3 Glacier.\", \"A.\"],\n[\"기업의 데이터 웨어하우스는 Amazon Redshift를 기반으로 합니다. 이 회사는 구성 요소 오류 발생 시 데이터의 장기적인 생존 가능성을 보장하기를 원합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.동시성 확장을 활성화합니다.\\nB. 교차 리전 스냅샷을 활성화합니다.\\nC. 데이터 보유 기간을 늘립니다.\\nD. 다중 AZ에 Amazon Redshift를 배포합니다.\", \"A business's data warehouse is powered by Amazon Redshift. The firm want to assure the long-term viability of its data in the event of component failure.\\nWhat recommendations should a solutions architect make?\\n\\nA.Enable concurrency scaling.\\nB. Enable cross-Region snapshots.\\nC. Increase the data retention period.\\nD. Deploy Amazon Redshift in Multi-AZ.\", \"B. Redshift는 다중 AZ 없음\"],\n[\"기업은 품목 가격을 기반으로 세금 계산을 자동화하는 API를 고객에게 제공합니다. 크리스마스 시즌에는 회사에 문의가 증가하여 응답 시간이 지연됩니다. 솔루션 설계자는 확장 가능하고 탄력적인 시스템을 만들어야 합니다.\\n이를 달성하기 위한 솔루션 설계자의 역할은 무엇입니까?\\n\\nA.Amazon EC2 인스턴스에서 호스팅되는 API를 제공합니다. EC2 인스턴스는 API 요청이 있을 때 필요한 계산을 수행합니다.\\nB. 항목 이름을 허용하는 Amazon API Gateway를 사용하여 REST API를 설계합니다. API Gateway는 세금 계산을 위해 항목 이름을 AWS Lambda에 전달합니다.\\nC. 뒤에 두 개의 Amazon EC2 인스턴스가 있는 Application Load Balancer를 생성합니다. EC2 인스턴스는 수신된 항목 이름에 대한 세금을 계산합니다.\\nD. Amazon EC2 인스턴스에서 호스팅되는 API와 연결하는 Amazon API Gateway를 사용하여 REST API를 설계합니다. API Gateway는 세금 계산을 위해 항목 이름을 수락하고 EC2 인스턴스에 전달합니다.\", \"A business offers its customers with an API that automates tax calculations based on item pricing. During the Christmas season, the firm receives an increased volume of queries, resulting in delayed response times. A solutions architect must create a scalable and elastic system.\\nWhat is the solution architect's role in achieving this?\\n\\nA.Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made.\\nB. Design a REST API using Amazon API Gateway that accepts the item names. API Gateway passes item names to AWS Lambda for tax computations.\\nC. Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received item names.\\nD. Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance. API Gateway accepts and passes the item names to the EC2 instance for tax computations.\", \"B\"],\n[\"개발 팀에는 다른 개발 팀이 액세스할 수 있는 웹 사이트가 있어야 합니다. HTML, CSS, 클라이언트측 JavaScript 및 그래픽은 웹사이트의 콘텐츠를 구성합니다.\\n어떤 형태의 웹사이트 호스팅이 가장 비용 효율적입니까?\\n\\nA.웹 사이트를 컨테이너화하고 AWS Fargate에서 호스팅합니다.\\nB. Amazon S3 버킷을 생성하고 거기에서 웹 사이트를 호스팅합니다.\\nC. Amazon EC2 인스턴스에 웹 서버를 배포하여 웹 사이트를 호스팅합니다.\\nD. Express.js 프레임워크를 사용하는 AWS Lambda 대상으로 Application Load Balancer를 구성합니다.\", \"A development team must have a website that is accessible to other development teams. HTML, CSS, client-side JavaScript, and graphics comprise the website's content.\\nWhich form of website hosting is the MOST cost-effective?\\n\\nA.Containerize the website and host it in AWS Fargate.\\nB. Create an Amazon S3 bucket and host the website there.\\nC. Deploy a web server on an Amazon EC2 instance to host the website.\\nD. Configure an Application Load Balancer with an AWS Lambda target that uses the Express.js framework.\", \"B\"],\n[\"한 비즈니스가 전 세계적으로 애플리케이션을 운영하고 있습니다. 사용자는 다양한 비디오를 업로드하고 나중에 하나의 비디오 파일로 결합됩니다. 프로그램은 us-east-1 리전의 단일 Amazon S3 버킷을 통해 사용자로부터 업로드를 수신합니다. 동일한 S3 버킷은 생성된 비디오 파일의 다운로드 지점으로도 사용됩니다. 완성된 비디오 파일의 크기는 약 250GB입니다.\\n조직에는 Amazon S3에 저장된 비디오 파일을 더 빠르게 업로드 및 다운로드할 수 있는 솔루션이 필요합니다. 회사는 더 빠른 속도를 지불하기로 선택한 소비자에게 월별 요금을 청구합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.S3 엔드포인트에 대해 AWS Global Accelerator를 활성화합니다. 구독이 있는 사용자를 위해 Global Accelerator S3 끝점을 사용하도록 애플리케이션의 업로드 및 다운로드 링크를 조정합니다.\\nB. 다른 모든 AWS 리전의 S3 버킷에 대한 S3 교차 리전 복제를 활성화합니다. Amazon Route 53 지리적 위치 라우팅 정책을 사용하여 구독이 있는 사용자의 위치를 ​​기반으로 S3 요청을 라우팅합니다.\\nC. Amazon CloudFront 배포를 생성하고 us-east-1의 S3 버킷을 오리진으로 사용합니다. 구독이 있는 사용자의 업로드 및 다운로드 링크로 CloudFront URL을 사용하도록 애플리케이션을 조정합니다.\\nD. us-east-1의 S3 버킷에 대해 S3 Transfer Acceleration을 활성화합니다. 구독이 있는 사용자의 업로드 및 다운로드 링크에 버킷의 S3-accelerate 엔드포인트 도메인 이름을 사용하도록 애플리케이션을 구성합니다.\", \"A business is operating a worldwide application. Users upload various videos, which are subsequently combined into a single video file. The program receives uploads from users through a single Amazon S3 bucket in the us-east-1 Region. The same S3 bucket also serves as the download point for the generated video file. The finished video file is around 250 GB in size.\\nThe organization requires a solution that enables quicker uploads and downloads of video files stored in Amazon S3. The corporation will charge consumers who choose to pay for the faster speed a monthly fee.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Enable AWS Global Accelerator for the S3 endpoint. Adjust the application's upload and download links to use the Global Accelerator S3 endpoint for users who have a subscription.\\nB. Enable S3 Cross-Region Replication to S3 buckets in all other AWS Regions. Use an Amazon Route 53 geolocation routing policy to route S3 requests based on the location of users who have a subscription.\\nC. Create an Amazon CloudFront distribution and use the S3 bucket in us-east-1 as an origin. Adjust the application to use the CloudFront URL as the upload and download links for users who have a subscription.\\nD. Enable S3 Transfer Acceleration for the S3 bucket in us-east-1. Configure the application to use the bucket's S3-accelerate endpoint domain name for the upload and download links for users who have a subscription.\", \"D. Cloudfront는 20GB의 용량 제한 있음.\"],\n[\"솔루션 설계자는 다양한 서브넷이 있는 VPC 아키텍처를 설계하고 있습니다. 2개의 가용 영역에서 6개의 서브넷이 사용됩니다. 서브넷은 공용, 사설 및 데이터베이스별 서브넷으로 분류됩니다. 데이터베이스에 대한 액세스는 사설 서브넷에서 작동하는 Amazon EC2 인스턴스로 제한되어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 now route table을 생성합니다. 라우팅 테이블을 데이터베이스 서브넷에 연결합니다.\\nB. 퍼블릭 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 거부하는 보안 그룹을 생성합니다. 보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다.\\nC. 프라이빗 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 허용하는 보안 그룹을 생성합니다. 보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다.\\nD. 퍼블릭 서브넷과 프라이빗 서브넷 간에 새 피어링 연결을 만듭니다. 프라이빗 서브넷과 데이터베이스 서브넷 간에 다른 피어링 연결을 만듭니다.\", \"A solutions architect is designing a VPC architecture with various subnets. Six subnets will be used in two Availability Zones. Subnets are classified as public, private, and database-specific. Access to a database should be restricted to Amazon EC2 instances operating on private subnets.\\nWhich solution satisfies these criteria?\\n\\nA.Create a now route table that excludes the route to the public subnets' CIDR blocks. Associate the route table to the database subnets.\\nB. Create a security group that denies ingress from the security group used by instances in the public subnets. Attach the security group to an Amazon RDS DB instance.\\nC. Create a security group that allows ingress from the security group used by instances in the private subnets. Attach the security group to an Amazon RDS DB instance.\\nD. Create a new peering connection between the public subnets and the private subnets. Create a different peering connection between the private subnets and the database subnets.\", \"C. 보안 그룹에는 거부 기능이 없음\"],\n[\"기업에서 웹 게이트웨이를 구현하고 있습니다. 회사는 프로그램에 대한 공개 액세스를 온라인 부분으로 제한하려고 합니다. 이를 달성하기 위해 VPC는 ​​2개의 퍼블릭 서브넷과 2개의 프라이빗 서브넷으로 생성되었습니다. 애플리케이션은 Auto Scaling 그룹을 통해 관리될 많은 Amazon EC2 인스턴스에서 호스팅됩니다. SSL 종료는 Amazon EC2의 별도 인스턴스에 위임해야 합니다.\\n이러한 요구 사항의 준수를 보장하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.퍼블릭 서브넷에서 Network Load Balancer를 구성합니다. 프라이빗 서브넷에서 Auto Scaling 그룹을 구성하고 이를 Application Load Balancer와 연결합니다.\\nB. 퍼블릭 서브넷에서 Network Load Balancer를 구성합니다. 퍼블릭 서브넷에서 Auto Scaling 그룹을 구성하고 이를 Application Load Balancer와 연결합니다.\\nC. 퍼블릭 서브넷에서 Application Load Balancer를 구성합니다. 프라이빗 서브넷에서 Auto Scaling 그룹을 구성하고 이를 Application Load Balancer와 연결합니다.\\nD. 프라이빗 서브넷에서 Application Load Balancer를 구성합니다. 프라이빗 서브넷에서 Auto Scaling 그룹을 구성하고 이를 Application Load Balancer와 연결합니다.\", \"A business is implementing a web gateway. The firm want to limit public access to the program to the online part. The VPC was created with two public subnets and two private subnets to achieve this. The application will be hosted on many Amazon EC2 instances that will be managed through an Auto Scaling group. SSL termination must be delegated to a separate instance on Amazon EC2.\\nWhat actions should a solutions architect take to guarantee compliance with these requirements?\\n\\nA.Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer.\\nB. Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the public subnets and associate it with the Application Load Balancer.\\nC. Configure the Application Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer.\\nD. Configure the Application Load Balancer in the private subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer.\", \"C. SSL 종료가 필요하므로 ALB사용\"],\n[\"비즈니스에서 Amazon Aurora 데이터베이스에 연결된 Amazon EC2 인스턴스 컬랙션을 운영하려고 합니다. EC2 인스턴스와 Aurora DB 클러스터를 배포하기 위해 비즈니스는 AWS Cloud Formation 템플릿을 사용했습니다. 조직은 데이터베이스에 대한 인스턴스의 안전한 인증을 제공하기를 원합니다. 기업은 정적 데이터베이스 자격 증명을 추적하고 싶지 않습니다.\\n운영 노력의 최소량으로 이러한 기준을 충족하는 방법은 무엇입니까?\\n\\nA.사용자 이름과 암호를 사용하여 데이터베이스 사용자를 만듭니다. CloudFormation 템플릿에 데이터베이스 사용자 이름 및 비밀번호에 대한 매개변수를 추가합니다. 인스턴스가 시작될 때 EC2 인스턴스에 매개변수를 전달합니다.\\nB. 사용자 이름과 암호를 사용하여 데이터베이스 사용자를 만듭니다. AWS Systems Manager Parameter Store에 사용자 이름과 암호 저장 Parameter Store에서 데이터베이스 자격 증명을 검색하도록 EC2 인스턴스를 구성합니다.\\nC. IAM 데이터베이스 인증을 사용하도록 DB 클러스터를 구성합니다. IAM 인증에 사용할 데이터베이스 사용자를 생성합니다. 인스턴스의 애플리케이션이 데이터베이스에 액세스할 수 있도록 역할을 EC2 인스턴스와 연결합니다.\\nD. IAM 사용자와 함께 IAM 데이터베이스 인증을 사용하도록 DB 클러스터를 구성합니다. IAM 사용자와 이름이 일치하는 데이터베이스 사용자를 생성합니다. IAM 사용자를 EC2 인스턴스와 연결하여 인스턴스의 애플리케이션이 데이터베이스에 액세스할 수 있도록 합니다.\", \"A business intends to operate a collection of Amazon EC2 instances connected to an Amazon Aurora database. To deploy the EC2 instances and Aurora DB cluster, the business used an AWS Cloud Formation template. The organization wishes to provide safe authentication of instances to the database. The business does not want to keep track of static database credentials.\\nWhich method satisfies these criteria with the LEAST amount of operational effort?\\n\\nA.Create a database user with a user name and password. Add parameters for the database user name and password to the CloudFormation template. Pass the parameters to the EC2 instances when the instances are launched.\\nB. Create a database user with a user name and password. Store the user name and password in AWS Systems Manager Parameter Store Configure the EC2 instances to retrieve the database credentials from Parameter Store.\\nC. Configure the DB cluster to use IAM database authentication. Create a database user to use with IAM authentication. Associate a role with the EC2 instances to allow applications on the instances to access the database.\\nD. Configure the DB cluster to use IAM database authentication with an IAM user. Create a database user that has a name that matches the IAM user. Associate the IAM user with the EC2 instances to allow applications on the instances to access the database.\", \"C\"],\n[\"기업은 SMB 프로토콜을 사용하여 온프레미스 데이터베이스를 로컬 파일 서버 공유에 백업합니다. 복구 목표를 달성하려면 일주일 분량의 백업 데이터에 즉시 액세스할 수 있어야 합니다. 일주일이 지나면 복구 가능성이 줄어들고 비즈니스는 이전 백업 데이터를 검색하는 데 지연이 발생할 수 있습니다.\\n이러한 기준이 가능한 최소한의 운영 작업으로 충족되도록 하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Windows 파일 서버용 Amazon FSx를 배포하여 원하는 모든 백업을 보관하기에 충분한 스토리지가 있는 노출된 파일 공유가 있는 파일 시스템을 생성합니다.\\nB. 1주일의 백업을 저장할 수 있는 충분한 스토리지가 있는 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 파일 게이트웨이에서 백업이 SMB 공유를 가리키도록 합니다.\\nC. Amazon Elastic File System(Amazon EFS)을 배포하여 원하는 모든 백업을 보관하기에 충분한 스토리지가 있는 노출된 NFS 공유가 있는 파일 시스템을 생성합니다.\\nD. 계속해서 기존 파일 공유에 백업합니다. AWS Database Migration Service(AWS DMS)를 배포하고 복사 작업을 정의하여 1주일이 지난 백업 파일을 Amazon S3에 복사하고 로컬 파일 저장소에서 백업 파일을 삭제합니다.\", \"A business uses the SMB protocol to back up on-premises databases to local file server shares. To accomplish recovery goals, the organization needs instant access to one week's worth of backup data. After a week, recovery is less possible, and the business may live with a delay in retrieving those earlier backup data.\\nWhat actions should a solutions architect take to ensure that these criteria are met with the LEAST amount of operational work possible?\\n\\nA.Deploy Amazon FSx for Windows File Server to create a file system with exposed file shares with sufficient storage to hold all the desired backups.\\nB. Deploy an AWS Storage Gateway file gateway with sufficient storage to hold 1 week of backups. Point the backups to SMB shares from the file gateway.\\nC. Deploy Amazon Elastic File System (Amazon EFS) to create a file system with exposed NFS shares with sufficient storage to hold all the desired backups.\\nD. Continue to back up to the existing file shares. Deploy AWS Database Migration Service (AWS DMS) and define a copy task to copy backup files older than 1 week to Amazon S3, and delete the backup files from the local file store.\", \"B\"],\n[\"분석 목적으로 판매 통계를 수집하고 필터링하려면 전자 상거래 비즈니스에서 매일 예약된 작업을 실행해야 합니다. 판매 기록은 Amazon S3 버킷에 저장됩니다. 각 개체의 최대 파일 크기는 10GB입니다. 판매 이벤트의 양에 따라 작업을 완료하는 데 최대 1시간이 소요될 수 있습니다. 작업의 CPU 및 메모리 요구 사항은 일관되고 미리 알려져 있습니다.\\n솔루션 설계자의 목표는 작업을 완료하는 데 필요한 운영 작업의 양을 줄이는 것입니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon EventBridge(Amazon CloudWatch Events) 알림이 있는 AWS Lambda 함수를 생성합니다. EventBridge(CloudWatch 이벤트) 이벤트가 하루에 한 번 실행되도록 예약합니다.\\nB. AWS Lambda 함수를 생성합니다. Amazon API Gateway HTTP API를 생성합니다. API를 기능과 통합합니다. API를 호출하고 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다.\\nC. AWS Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 작업을 실행하기 위해 클러스터에서 ECS 작업을 시작하는 Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다.\\nD. Amazon EC2 시작 유형이 있는 Amazon Elastic Container Service(Amazon ECS) 클러스터와 하나 이상의 EC2 인스턴스가 있는 Auto Scaling 그룹을 생성합니다. 작업을 실행하기 위해 클러스터에서 ECS 작업을 시작하는 Amazon EventBridge(Amazon CloudWatch Events) 예약 이벤트를 생성합니다.\", \"A daily scheduled task must be executed by an ecommerce business to collect and filter sales statistics for analytics purposes. The sales records are stored in an Amazon S3 bucket. Each object has a maximum file size of 10 GB. The work might take up to an hour to complete depending on the amount of sales events. The job's CPU and memory requirements are consistent and known in advance.\\nA solutions architect's goal is to reduce the amount of operational work required to complete the task.\\nWhich solution satisfies these criteria?\\n\\nA.Create an AWS Lambda function that has an Amazon EventBridge (Amazon CloudWatch Events) notification. Schedule the EventBridge (CloudWatch Events) event to run once a day.\\nB. Create an AWS Lambda function. Create an Amazon API Gateway HTTP API. and integrate the API with the function. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that calls the API and invokes the function.\\nC. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that launches an ECS task on the cluster to run the job.\\nD. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type and an Auto Scaling group with at least one EC2 instance. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that launches an ECS task on the cluster to run the job.\", \"C\"],\n[\"장바구니 애플리케이션은 Amazon RDS 다중 AZ 데이터베이스 인스턴스에 연결됩니다. 데이터베이스 성능으로 인해 애플리케이션이 느려집니다. 차세대 인스턴스 유형으로 업그레이드한 후에도 성능이 크게 향상되지 않았습니다.\\n분석에 따르면 약 700 IOPS가 유지되고 일반적인 쿼리가 장기간 실행되며 메모리 사용량이 상당합니다.\\n솔루션 설계자는 이러한 문제를 해결하기 위해 어떤 애플리케이션 수정을 제안할 수 있습니까?\\n\\nA.RDS 인스턴스를 Amazon Redshift 클러스터로 마이그레이션하고 매주 가비지 수집을 활성화합니다.\\nB. 장기 실행 쿼리를 새로운 다중 AZ RDS 데이터베이스로 분리하고 필요한 데이터베이스를 쿼리하도록 애플리케이션을 수정합니다.\\nC. 2노드 Amazon ElastiCache 클러스터를 배포하고 클러스터를 먼저 쿼리하고 필요한 경우에만 데이터베이스를 쿼리하도록 애플리케이션을 수정합니다.\\nD. 일반적인 쿼리를 위한 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 생성하고 먼저 쿼리하고 필요한 경우에만 데이터베이스를 쿼리합니다.\", \"A shopping cart application connects to an Amazon RDS Multi-AZ database instance. The database performance is causing the application to slow down. There was no significant performance improvement after upgrading to the next-generation instance type.\\nAccording to the analysis, around 700 IOPS are maintained, typical queries execute for extended periods of time, and memory use is significant.\\nWhich application modification might a solutions architect propose to address these concerns?\\n\\nA.Migrate the RDS instance to an Amazon Redshift cluster and enable weekly garbage collection.\\nB. Separate the long-running queries into a new Multi-AZ RDS database and modify the application to query whichever database is needed.\\nC. Deploy a two-node Amazon ElastiCache cluster and modify the application to query the cluster first and query the database only if needed.\\nD. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue for common queries and query it first and query the database only if needed.\", \"C\"],\n[\"한 스타트업이 AWS 클라우드 호스팅 게임 애플리케이션을 위한 공유 스토리지 솔루션을 개발하고 있습니다. 조직은 SMB 클라이언트를 통해 데이터에 액세스할 수 있는 능력이 필요합니다. 솔루션은 완전히 제어되어야 합니다.\\n이 기준을 충족하는 AWS 솔루션은 무엇입니까?\\n\\nA.데이터를 탑재 가능한 파일 시스템으로 공유하는 AWS DataSync 작업을 생성합니다. 파일 시스템을 애플리케이션 서버에 마운트합니다.\\nB. Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 설치하고 구성합니다. 응용 프로그램 서버를 파일 공유에 연결합니다.\\nC. Windows 파일 서버용 Amazon FSx 파일 시스템을 생성합니다. 파일 시스템을 원본 서버에 연결합니다. 응용 프로그램 서버를 파일 시스템에 연결합니다.\\nD. Amazon S3 버킷을 생성합니다. 애플리케이션에 IAM 역할을 할당하여 S3 버킷에 대한 액세스 권한을 부여합니다. S3 버킷을 애플리케이션 서버에 마운트합니다.\", \"A startup is developing a shared storage solution for an AWS Cloud-hosted gaming application. The organization need the capacity to access data through SMB clients. The solution must be controlled completely.\\nWhich AWS solution satisfies these criteria?\\n\\nA.Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.\\nB. Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.\\nC. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.\\nD. Create an Amazon S3 bucket. Assign an IAM role to the application to grant access to the S3 bucket. Mount the S3 bucket to the application server.\", \"C\"],\n[\"기업은 객체 스토리지에 Amazon S3를 사용합니다. 조직은 수백 개의 S3 버킷에 데이터를 저장합니다. 특정 S3 버킷에는 다른 버킷보다 액세스 빈도가 낮은 데이터가 포함되어 있습니다. 솔루션 설계자에 따르면 수명 주기 규칙이 일관되게 따르지 않거나 부분적으로 시행되어 데이터가 고가의 스토리지에 보관됩니다.\\n객체 가용성을 위협하지 않으면서 비용을 절감할 수 있는 옵션은 무엇입니까?\\n\\nA.S3 ACL을 사용합니다.\\nB. Amazon Elastic Block Store(Amazon EBS) 자동 스냅샷을 사용합니다.\\nC. S3 Intelligent-Tiering 스토리지를 사용합니다.\\nD. S3 One Zone-Infrequent Access(S3 One Zone-IA)를 사용합니다.\", \"A business relies on Amazon S3 for object storage. The organization stores data in hundreds of S3 buckets. Certain S3 buckets contain less frequently accessed data than others. According to a solutions architect, lifecycle rules are either not followed consistently or are enforced in part, resulting in data being held in high-cost storage.\\nWhich option will reduce expenses without jeopardizing object availability?\\n\\nA.Use S3 ACLs.\\nB. Use Amazon Elastic Block Store (Amazon EBS) automated snapshots.\\nC. Use S3 Intelligent-Tiering storage.\\nD. Use S3 One Zone-Infrequent Access (S3 One Zone-IA).\", \"C\"],\n[\"기업은 느슨하게 결합되도록 밀접하게 연결된 애플리케이션을 재설계하고 있습니다. 이전에는 프로그램이 요청/응답 패턴을 통해 계층 간에 통신했습니다. 조직은 Amazon Simple Queue Service(Amazon SQS)를 사용하여 이를 수행하려고 합니다. 첫 번째 아키텍처는 요청 큐와 응답 큐를 포함합니다. 그러나 프로그램이 커질 때 이 전략은 모든 메시지를 처리하지 않습니다.\\n솔루션 아키텍트가 이 문제를 해결하기 위해 취해야 할 가장 좋은 조치는 무엇입니까?\\n\\nA.SQS 대기열의 ReceiveMessage API 작업에서 배달 못한 편지 대기열을 구성합니다.\\nB. FIFO 대기열을 구성하고 메시지 중복 제거 ID 및 메시지 그룹 ID를 사용합니다.\\nC. 각 응답 메시지를 수신할 임시 대기열 클라이언트를 사용하여 임시 대기열을 만듭니다.\\nD. 각 생산자에 대한 시작 시 각 요청 및 응답에 대한 대기열을 만들고 상관 ID 메시지 속성을 사용합니다.\", \"A business is re-architecting a tightly connected application in order to make it loosely coupled. Previously, the program communicated across layers through a request/response pattern. The organization intends to do this via the usage of Amazon Simple Queue Service (Amazon SQS). The first architecture includes a request queue and a response queue. However, when the program grows, this strategy will not handle all messages.\\nWhat is the best course of action for a solutions architect to take in order to tackle this issue?\\n\\nA.Configure a dead-letter queue on the ReceiveMessage API action of the SQS queue.\\nB. Configure a FIFO queue, and use the message deduplication ID and message group ID.\\nC. Create a temporary queue, with the Temporary Queue Client to receive each response message.\\nD. Create a queue for each request and response on startup for each producer, and use a correlation ID message attribute.\", \"C\"],\n[\"Amazon S3는 기업에서 개인 감사 기록을 저장하는 데 사용됩니다. 최소 권한 개념에 따라 S3 버킷은 버킷 제한을 구현하여 감사 팀 IAM 사용자 자격 증명에 대한 액세스를 제한합니다. 회사 경영진은 S3 버킷에서 의도하지 않은 문서 파괴에 대해 우려하고 있으며 보다 안전한 솔루션이 필요합니다.\\n솔루션 설계자는 감사 문서의 보안을 보장하기 위해 어떤 단계를 수행해야 합니까?\\n\\nA.S3 버킷에서 버전 관리 및 MFA 삭제 기능을 활성화합니다.\\nB. 각 감사 팀 IAM 사용자 계정의 IAM 사용자 자격 증명에 대해 다단계 인증(MFA)을 활성화합니다.\\nC. 감사 날짜 동안 s3:DeleteObject 작업을 거부하도록 감사 팀의 IAM 사용자 계정에 S3 수명 주기 정책을 추가합니다.\\nD. AWS Key Management Service(AWS KMS)를 사용하여 S3 버킷을 암호화하고 감사 팀 IAM 사용자 계정이 KMS 키에 액세스하지 못하도록 제한합니다.\", \"Amazon S3 is used by a business to store private audit records. According to the concept of least privilege, the S3 bucket implements bucket restrictions to limit access to audit team IAM user credentials. Company executives are concerned about inadvertent document destruction in the S3 bucket and need a more secure solution.\\nWhat steps should a solutions architect take to ensure the security of audit documents?\\n\\nA.Enable the versioning and MFA Delete features on the S3 bucket.\\nB. Enable multi-factor authentication (MFA) on the IAM user credentials for each audit team IAM user account.\\nC. Add an S3 Lifecycle policy to the audit team's IAM user accounts to deny the s3:DeleteObject action during audit dates.\\nD. Use AWS Key Management Service (AWS KMS) to encrypt the S3 bucket and restrict audit team IAM user accounts from accessing the KMS key.\", \"A\"],\n[\"매일 회사의 수백 대의 에지 장치에서 1TB의 상태 알림이 생성됩니다. 각 경고의 파일 크기는 약 2KB입니다. 솔루션 설계자는 추가 조사를 위해 경고를 수집하고 저장하는 시스템을 제공해야 합니다.\\n비즈니스에는 액세스 가능성이 매우 높은 솔루션이 필요합니다. 그러나 비즈니스는 저비용 구조를 가져야 하며 추가 인프라를 처리하기를 원하지 않습니다.\\n또한 회사는 즉각적인 검사를 위해 14일 동안 데이터를 보유하고 오래된 데이터를 보관할 계획입니다.\\n이러한 요구 사항을 충족하는 가장 최적의 옵션은 무엇입니까?\\n\\nA.Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon S3 버킷에 알림을 전달하도록 Kinesis Data Firehose 스트림을 구성합니다. 14일 후에 데이터를 Amazon S3 Glacier로 전환하도록 S3 수명 주기 구성을 설정합니다.\\nB. 두 가용 영역에서 Amazon EC2 인스턴스를 시작하고 Elastic Load Balancer 뒤에 배치하여 알림을 수집합니다. Amazon S3 버킷에 경고를 저장할 EC2 인스턴스에 대한 스크립트를 생성합니다. 14일 후에 데이터를 Amazon S3 Glacier로 전환하도록 S3 수명 주기 구성을 설정합니다.\\nC. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon Elasticsearch Service(Amazon ES) 클러스터에 알림을 전달하도록 Kinesis Data Firehose 스트림을 구성합니다. Amazon ES 클러스터를 설정하여 매일 수동 스냅샷을 만들고 클러스터에서 14일이 지난 데이터를 삭제합니다.\\nD. Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 생성하여 알림을 수집하고 메시지 보존 기간을 14일로 설정합니다. SQS 대기열을 폴링하고, 메시지의 수명을 확인하고, 필요에 따라 메시지 데이터를 분석하도록 소비자를 구성합니다. 메시지가 14일이 지난 경우 소비자는 메시지를 Amazon S3 버킷에 복사하고 SQS 대기열에서 메시지를 삭제해야 합니다.\", \"Each day, a company's hundreds of edge devices create 1 TB of status alerts. Each alert has a file size of roughly 2 KB. A solutions architect must provide a system for ingesting and storing warnings for further investigation.\\nThe business need a solution that is extremely accessible. However, the business must have a low cost structure and does not want to handle extra infrastructure.\\nAdditionally, the corporation intends to retain 14 days of data for instant examination and archive any older data.\\nWhat is the MOST OPTIMAL option that satisfies these requirements?\\n\\nA.Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.\\nB. Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts. Create a script on the EC2 instances that will store the alerts in an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.\\nC. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon Elasticsearch Service (Amazon ES) cluster. Set up the Amazon ES cluster to take manual snapshots every day and delete data from the cluster that is older than 14 days.\\nD. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to ingest the alerts, and set the message retention period to 14 days. Configure consumers to poll the SQS queue, check the age of the message, and analyze the message data as needed. If the message is 14 days old, the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue.\", \"A\"],\n[\"회사는 2계층 이미지 처리 프로그램을 운영합니다. 애플리케이션은 각각 고유한 퍼블릭 서브넷과 프라이빗 서브넷이 있는 두 개의 가용 영역으로 나뉩니다.\\n웹 계층의 ALB(Application Load Balancer)는 퍼블릭 서브넷을 사용합니다. 프라이빗 서브넷은 애플리케이션 계층의 Amazon EC2 인스턴스에서 사용됩니다.\\n사용자에 따르면 프로그램이 계획보다 느리게 작동하고 있습니다. 웹 서버 로그 파일의 보안 감사에 따르면 애플리케이션은 소수의 IP 주소에서 수백만 건의 무단 요청을 수신합니다. 조직이 보다 영구적인 솔루션을 찾는 동안 솔루션 설계자는 긴급한 성능 문제를 해결해야 합니다.\\n이 요구 사항을 충족하려면 어떤 솔루션 아키텍처 접근 방식을 권장해야 합니까?\\n\\nA.웹 계층에 대한 인바운드 보안 그룹을 수정합니다. 리소스를 소비하는 IP 주소에 대한 거부 규칙을 추가합니다.\\nB. 웹 계층 서브넷에 대한 네트워크 ACL을 수정합니다. 리소스를 소비하는 IP 주소에 대한 인바운드 거부 규칙을 추가합니다.\\nC. 애플리케이션 계층에 대한 인바운드 보안 그룹을 수정합니다. 리소스를 소비하는 IP 주소에 대한 거부 규칙을 추가합니다.\\nD. 애플리케이션 계층 서브넷에 대한 네트워크 ACL을 수정합니다. 리소스를 소비하는 IP 주소에 대한 인바운드 거부 규칙을 추가합니다.\", \"A firm runs a two-tier image processing program. The application is divided into two Availability Zones, each with its own public and private subnets.\\nThe web tier's Application Load Balancer (ALB) makes use of public subnets. Private subnets are used by Amazon EC2 instances at the application layer.\\nThe program is functioning more slowly than planned, according to users. According to a security audit of the web server log files, the application receives millions of unauthorized requests from a tiny number of IP addresses. While the organization finds a more permanent solution, a solutions architect must tackle the urgent performance issue.\\nWhat solution architecture approach should be recommended to satisfy this requirement?\\n\\nA.Modify the inbound security group for the web tier. Add a deny rule for the IP addresses that are consuming resources.\\nB. Modify the network ACL for the web tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.\\nC. Modify the inbound security group for the application tier. Add a deny rule for the IP addresses that are consuming resources.\\nD. Modify the network ACL for the application tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.\", \"B\"],\n[\"기업은 Amazon Elastic Container Service(Amazon ECS)를 사용하여 2개의 프라이빗 서브넷에서 이미지 처리 워크로드를 수행합니다. 각 프라이빗 서브넷은 NAT 인스턴스를 통해 인터넷에 연결됩니다. Amazon S3 버킷은 모든 사진을 저장하는 데 사용됩니다. 비즈니스는 Amazon ECS와 Amazon S3 간의 데이터 전송과 관련된 비용을 걱정하고 있습니다.\\n솔루션 설계자는 비용을 절감하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.NAT 인스턴스를 대체하도록 NAT 게이트웨이를 구성합니다.\\nB. Amazon S3로 향하는 트래픽에 대한 게이트웨이 엔드포인트를 구성합니다.\\nC. Amazon S3로 향하는 트래픽에 대한 인터페이스 엔드포인트를 구성합니다.\\nD. 이미지를 저장하는 S3 버킷에 대해 Amazon CloudFront를 구성합니다.\", \"A business uses Amazon Elastic Container Service (Amazon ECS) to perform an image processing workload on two private subnets. Each private subnet connects to the internet through a NAT instance. Amazon S3 buckets are used to store all photos. The business is worried about the expenses associated with data transfers between Amazon ECS and Amazon S3.\\nWhat actions should a solutions architect do to save money?\\n\\nA.Configure a NAT gateway to replace the NAT instances.\\nB. Configure a gateway endpoint for traffic destined to Amazon S3.\\nC. Configure an interface endpoint for traffic destined to Amazon S3.\\nD. Configure Amazon CloudFront for the S3 bucket storing the images.\", \"B\"],\n[\"온라인 사진 프로그램을 통해 사용자는 사진을 업로드하고 수정할 수 있습니다. 이 응용 프로그램은 무료 및 유료의 두 가지 서비스 수준을 제공합니다. 유료 사용자의 사진은 무료 사용자가 제출한 사진보다 먼저 처리됩니다. Amazon S3는 사진을 저장하는 데 사용되며 Amazon SQS는 작업 정보를 저장하는 데 사용됩니다.\\n솔루션 설계자는 구성을 어떻게 제안해야 합니까?\\n\\nA.하나의 SQS FIFO 대기열을 사용합니다. 유료 사진이 먼저 처리되도록 더 높은 우선 순위를 지정합니다.\\nB. 두 개의 SQS FIFO 대기열을 사용합니다. 하나는 유료이고 다른 하나는 무료입니다. 짧은 폴링을 사용하려면 무료 대기열을 설정하고 긴 폴링을 사용하려면 유료 대기열을 설정합니다.\\nC. 두 개의 SQS 표준 대기열을 사용합니다. 하나는 유료이고 다른 하나는 무료입니다. 무료 대기열보다 유료 대기열에 대한 폴링의 우선 순위를 지정하도록 Amazon EC2 인스턴스를 구성합니다.\\nD. 하나의 SQS 표준 대기열을 사용합니다. 유료 사진의 표시 제한 시간을 0으로 설정합니다. 유료 사진이 먼저 처리되도록 가시성 설정의 우선 순위를 지정하도록 Amazon EC2 인스턴스를 구성합니다.\", \"An online picture program enables users to upload photographs and modify them. The application provides two distinct service levels: free and paid. Paid users' photos are processed ahead of those submitted by free users. Amazon S3 is used to store the photos, while Amazon SQS is used to store the job information.\\nHow should a solutions architect propose a configuration?\\n\\nA.Use one SQS FIFO queue. Assign a higher priority to the paid photos so they are processed first.\\nB. Use two SQS FIFO queues: one for paid and one for free. Set the free queue to use short polling and the paid queue to use long polling.\\nC. Use two SQS standard queues: one for paid and one for free. Configure Amazon EC2 instances to prioritize polling for the paid queue over the free queue.\\nD. Use one SQS standard queue. Set the visibility timeout of the paid photos to zero. Configure Amazon EC2 instances to prioritize visibility settings so paid photos are processed first.\", \"C. SQS는 FIFO만 지원. 우선순위를 주기 위해서는 두 개의 SQS 사용\"],\n[\"애플리케이션 개발자는 비즈니스 보고 사용자가 애플리케이션을 구동하는 Amazon RDS 인스턴스에 대한 대규모 프로덕션 보고서를 실행할 때 애플리케이션이 매우 느려지는 것을 발견했습니다. 보고 쿼리가 실행되는 동안 RDS 인스턴스의 CPU 및 메모리 사용량 지표는 60%를 초과하지 않습니다.\\n비즈니스 보고 사용자는 응용 프로그램의 기능을 손상시키지 않고 보고서를 생성할 수 있어야 합니다.\\n이를 달성하려면 어떤 조치가 필요합니까?\\n\\nA.RDS 인스턴스의 크기를 늘립니다.\\nB. 읽기 전용 복제본을 생성하고 여기에 애플리케이션을 연결합니다.\\nC. RDS 인스턴스에서 여러 가용 영역을 활성화합니다.\\nD. 읽기 전용 복제본을 만들고 비즈니스 보고서를 여기에 연결합니다.\", \"Application developers have found that when business reporting users run big production reports to the Amazon RDS instance that powers the application, the application becomes very sluggish. While the reporting queries are executing, the RDS instance's CPU and memory usage metrics do not surpass 60%.\\nBusiness reporting users must be able to produce reports without impairing the functionality of the application.\\nWhich action is necessary to achieve this?\\n\\nA.Increase the size of the RDS instance.\\nB. Create a read replica and connect the application to it.\\nC. Enable multiple Availability Zones on the RDS instance.\\nD. Create a read replica and connect the business reports to it.\", \"D\"],\n[\"회사에서 배포 엔지니어로 신입 사원을 고용했습니다. 배포 엔지니어는 AWS CloudFormation 템플릿을 사용하여 여러 AWS 리소스를 구성합니다. 솔루션 설계자는 배포 엔지니어가 가능한 최소한의 권한으로 작업 기능을 실행하기를 원합니다.\\n이 목표를 달성하기 위해 솔루션 설계자는 어떤 단계를 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.배포 엔지니어가 AWS CloudFormation 스택 작업을 수행하기 위해 AWS 계정 루프 사용자 자격 증명을 사용하도록 하십시오.\\nB. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 PowerUsers IAM 정책이 연결된 그룹에 IAM 사용자를 추가합니다.\\nC. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 IAM 관리/액세스 정책이 연결된 그룹에 IAM 사용자를 추가합니다.\\nD. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AWS CloudFormation 작업만 허용하는 IAM 정책이 있는 그룹에 IAM 사용자를 추가합니다.\\nE. 배포 엔지니어가 Dial IAM 역할을 사용하여 AWS CloudFormation 스택 및 시작 스택과 관련된 권한을 명시적으로 정의하도록 IAM 역할을 생성합니다.\", \"A new employee has been hired as a deployment engineer by a corporation. The deployment engineer will construct several AWS resources using AWS CloudFormation templates. A solutions architect desires that the deployment engineer execute job functions with the least amount of privilege possible.\\nWhich steps should the solutions architect do in conjunction to reach this goal? (Select two.)\\n\\nA.Have the deployment engineer use AWS account roof user credentials for performing AWS CloudFormation stack operations.\\nB. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.\\nC. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the Administrate/Access IAM policy attached.\\nD. Create a new IAM User for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.\\nE. Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using Dial IAM role.\", \"D, E\"],\n[\"한 기업에서 AWS를 사용하여 새로운 기계 학습 모델 솔루션을 구축하고 있습니다. 모델은 Amazon S3에서 약 1GB의 모델 데이터를 가져와 시작하는 동안 메모리에 저장하는 독립형 마이크로서비스로 구성됩니다. 모델은 비동기 API를 통해 사용자가 액세스합니다. 사용자는 단일 요청 또는 일괄 요청을 제출하고 결과의 대상을 지정할 수 있습니다.\\n수백 명의 사람들이 회사 모델의 혜택을 받습니다. 모델의 사용 습관이 불규칙합니다. 특정 모델은 사용하지 않고 며칠 또는 몇 주가 소요될 수 있습니다. 다른 모델은 동시에 수백 개의 쿼리를 받을 수 있습니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.API의 요청은 ALB(Application Load Balancer)로 전송됩니다. 모델은 ALB에서 호출하는 AWS Lambda 함수로 배포됩니다.\\nB. API의 요청은 Amazon Simple Queue Service(Amazon SQS) 대기열 모델로 전송됩니다. 모델은 SQS 이벤트에 의해 트리거되는 AWS Lambda 함수로 배포됩니다. AWS Auto Scaling은 SQS 대기열 크기에 따라 vCPU 수를 늘리기 위해 Lambda에서 활성화됩니다.\\nC. API의 요청은 모델의 Amazon Simple Queue Service(Amazon SQS) 대기열로 전송됩니다. 모델은 대기열에서 읽는 Amazon Elastic Container Service(Amazon ECS) 서비스로 배포됩니다. AWS App Mesh는 SQS 대기열 크기를 기반으로 ECS 클러스터의 인스턴스를 확장합니다.\\nD. API의 요청은 Amazon Simple Queue Service(Amazon SQS) 대기열 모델로 전송됩니다. 모델은 Amazon Elastic Container Service(Amazon ECS) 서비스로 배포되며 대기열 크기에 따라 클러스터 및 서비스 사본 모두에 대해 Amazon ECS에서 AWS Auto Scaling이 활성화됩니다.\", \"A corporation is using AWS to construct a new machine learning model solution. The models are constructed as self-contained microservices that get around 1 GB of model data from Amazon S3 and put it into memory during startup. The models are accessed by users through an asynchronous API. Users may submit a single request or a batch of requests and designate the destination for the results.\\nHundreds of people benefit from the company's models. The models' use habits are erratic. Certain models may go days or weeks without being used. Other models may get hundreds of queries concurrently.\\nWhich solution satisfies these criteria?\\n\\nA.The requests from the API are sent to an Application Load Balancer (ALB). Models are deployed as AWS Lambda functions invoked by the ALB.\\nB. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as AWS Lambda functions triggered by SQS events AWS Auto Scaling is enabled on Lambda to increase the number of vCPUs based on the SQS queue size.\\nC. The requests from the API are sent to the model's Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size.\\nD. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling is enabled on Amazon ECS for both the cluster and copies of the service based on the queue size.\", \"D\"],\n[\"기업은 향후 연구를 위해 사용자 데이터를 수집하고 유지 관리하는 식사 주문 응용 프로그램을 개발했습니다. Amazon EC2 인스턴스에서 애플리케이션의 정적 프런트 엔드가 설치됩니다. 프런트엔드 애플리케이션은 다른 EC2 인스턴스에서 호스팅되는 백엔드 애플리케이션과 통신합니다. 데이터는 이후 백엔드 애플리케이션에 의해 Amazon RDS에 저장됩니다.\\n솔루션 설계자는 아키텍처를 분리하고 확장하기 위해 무엇을 해야 합니까?\\n\\nA.Amazon S3를 사용하여 백엔드 애플리케이션을 실행하기 위해 Amazon EC2에 요청을 보내는 프런트엔드 애플리케이션을 제공합니다. 백엔드 애플리케이션은 Amazon RDS에서 데이터를 처리하고 저장합니다.\\nB. Amazon S3를 사용하여 프런트 엔드 애플리케이션을 제공하고 Amazon Simple Notification Service(Amazon SNS) 주제에 대한 요청을 작성합니다. 주제의 HTTP/HTTPS 엔드포인트에 Amazon EC2 인스턴스를 구독하고 Amazon RDS에서 데이터를 처리 및 저장합니다.\\nC. EC2 인스턴스를 사용하여 프런트 엔드를 제공하고 Amazon SQS 대기열에 요청을 작성합니다. 백엔드 인스턴스를 Auto Scaling 그룹에 배치하고 대기열 깊이에 따라 확장하여 Amazon RDS에서 데이터를 처리하고 저장합니다.\\nD. Amazon S3를 사용하여 정적 프런트 엔드 애플리케이션을 제공하고 Amazon SQS 대기열에 요청을 쓰는 Amazon API Gateway에 요청을 보냅니다. 백엔드 인스턴스를 Auto Scaling 그룹에 배치하고 대기열 깊이에 따라 확장하여 Amazon RDS에서 데이터를 처리하고 저장합니다.\", \"A business developed a meal ordering application that collects and maintains user data for future research. On an Amazon EC2 instance, the application's static front end is installed. The front-end application communicates with the back-end application, which is hosted on a different EC2 instance. The data is subsequently stored in Amazon RDS by the backend application.\\nWhat should a solutions architect do to decouple and scalability the architecture?\\n\\nA.Use Amazon S3 to serve the front-end application, which sends requests to Amazon EC2 to execute the backend application. The backend application will process and store the data in Amazon RDS.\\nB. Use Amazon S3 to serve the front-end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic, and process and store the data in Amazon RDS.\\nC. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue. Place the backend instance in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.\\nD. Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.\", \"D\"],\n[\"매달 임대 회사는 PDF 명세서를 준비하여 모든 고객에게 전달합니다. 각 명세서의 길이는 약 400KB입니다. 고객은 명세서가 생성된 후 최대 30일 동안 웹사이트에서 명세서를 얻을 수 있습니다. 고객은 3년 임대 계약이 종료될 때 모든 명세서가 포함된 ZIP 파일을 받게 됩니다.\\n이 상황에서 가장 비용 효율적인 저장 방법은 무엇입니까?\\n\\nA.Amazon S3 Standard 스토리지 클래스를 사용하여 명령문을 저장합니다. 1일 후에 명령문을 Amazon S3 Glacier 스토리지로 이동하는 수명 주기 정책을 생성합니다.\\nB. Amazon S3 Glacier 스토리지 클래스를 사용하여 명령문을 저장합니다. 30일 후에 명령문을 Amazon S3 Glacier Deep Archive 스토리지로 이동하는 수명 주기 정책을 생성합니다.\\nC. Amazon S3 Standard 스토리지 클래스를 사용하여 명령문을 저장합니다. 30일 후에 명령문을 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA) 스토리지로 이동하는 수명 주기 정책을 생성합니다.\\nD. Amazon S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용하여 명령문을 저장합니다. 30일 후에 명령문을 Amazon S3 Glacier 스토리지로 이동하는 수명 주기 정책을 생성합니다.\", \"Each month, a leasing firm prepares and delivers PDF statements to all of its clients. Each statement is around 400 KB in length. Customers may obtain their statements from the website for a period of up to 30 days after they are created. Customers are sent a ZIP file containing all of their statements at the conclusion of their three-year lease.\\nWhich storage method is the MOST cost-effective in this situation?\\n\\nA.Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 1 day.\\nB. Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier Deep Archive storage after 30 days.\\nC. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) storage after 30 days.\\nD. Store the statements using the Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 30 days.\", \"D\"],\n[\"회사의 전자 상거래 사이트 방문자 수가 증가하고 있습니다. 회사의 상점은 웹 계층과 별도의 데이터베이스 계층이 있는 Amazon EC2 인스턴스에서 2계층 2 애플리케이션으로 구현됩니다. 트래픽이 증가함에 따라 조직은 설계로 인해 소비자에게 적시에 마케팅 및 구매 확인 이메일을 전달하는 데 심각한 지연을 감지합니다. 조직은 어려운 이메일 전달 문제를 해결하는 데 소요되는 시간을 줄이고 운영 비용을 절감하고자 합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 생성합니다.\\nB. Amazon Simple Email Service(Amazon SES)를 통해 이메일을 보내도록 웹 인스턴스를 구성합니다.\\nC. Amazon Simple Notification Service(Amazon SNS)를 통해 이메일을 보내도록 웹 인스턴스를 구성합니다.\\nD. 이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 생성합니다. Auto Scaling 그룹에 인스턴스를 배치합니다.\", \"A company's ecommerce site is seeing a rise in visitor visits. The company's shop is implemented as a two-tier two application on Amazon EC2 instances, with a web layer and a separate database tier. As traffic rises, the organization detects severe delays in delivering timely marketing and purchase confirmation emails to consumers due to the design. The organization wishes to decrease the amount of time spent addressing difficult email delivery problems and to cut operating costs.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Create a separate application tier using EC2 instances dedicated to email processing.\\nB. Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).\\nC. Configure the web instance to send email through Amazon Simple Notification Service (Amazon SNS).\\nD. Create a separate application tier using EC2 instances dedicated to email processing. Place the instances in an Auto Scaling group.\", \"B\"],\n[\"비즈니스 애플리케이션은 AWS Lambda 기능을 사용합니다. 코드 검사 결과 데이터베이스 자격 증명이 Lambda 함수의 소스 코드에 보관되고 있으며 이는 회사의 보안 정책을 위반하는 것으로 나타났습니다. 보안 정책 요구 사항을 준수하려면 자격 증명을 안전하게 유지 관리하고 정기적으로 자동으로 순환해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하는 가장 안전한 방법으로 무엇을 제안해야 합니까?\\n\\nA.AWS CloudHSM에 암호를 저장합니다. 키 ID를 사용하여 CloudHSM에서 암호를 검색할 수 있는 역할과 Lambda 함수를 연결합니다. CloudHSM을 사용하여 비밀번호를 자동으로 교체합니다.\\nB. AWS Secrets Manager에 암호를 저장합니다. 보안 ID를 사용하여 Secrets Manager에서 비밀번호를 검색할 수 있는 역할과 Lambda 함수를 연결합니다. Secrets Manager를 사용하여 암호를 자동으로 교체합니다.\\nC. AWS Key Management Service(AWS KMS)에 암호를 저장합니다. 키 ID를 사용하여 AWS KMS에서 암호를 검색할 수 있는 역할과 Lambda 함수를 연결합니다. AWS KMS를 사용하여 업로드된 암호를 자동으로 교체합니다.\\nD. 데이터베이스 암호를 Lambda 함수와 연결된 환경 변수로 이동합니다. 함수를 호출하여 환경 변수에서 암호를 검색합니다. 암호를 자동으로 교체하는 배포 스크립트를 만듭니다.\", \"A business's application makes use of AWS Lambda functions. A code examination reveals that database credentials are being kept in the source code of a Lambda function, which violates the company's security policy. To comply with security policy requirements, credentials must be safely maintained and automatically cycled on a regular basis.\\nWhat should a solutions architect propose as the MOST SECURE method of meeting these requirements?\\n\\nA.Store the password in AWS CloudHSM. Associate the Lambda function with a role that can use the key ID to retrieve the password from CloudHSM. Use CloudHSM to automatically rotate the password.\\nB. Store the password in AWS Secrets Manager. Associate the Lambda function with a role that can use the secret ID to retrieve the password from Secrets Manager. Use Secrets Manager to automatically rotate the password.\\nC. Store the password in AWS Key Management Service (AWS KMS). Associate the Lambda function with a role that can use the key ID to retrieve the password from AWS KMS. Use AWS KMS to automatically rotate the uploaded password.\\nD. Move the database password to an environment variable that is associated with the Lambda function. Retrieve the password from the environment variable by invoking the function. Create a deployment script to automatically rotate the password.\", \"B\"],\n[\"한 회사가 us-east-1 리전의 2개 가용 영역에서 2계층 애플리케이션을 시작했습니다. 데이터베이스는 프라이빗 서브넷에 있는 반면 웹 서버는 퍼블릭 서브넷에 있습니다. VPC는 인터넷 게이트웨이를 통해 인터넷에 연결됩니다. Amazon EC2 인스턴스는 애플리케이션과 데이터베이스를 호스팅하는 데 사용됩니다. 데이터베이스 서버가 수정 사항을 얻기 위해 인터넷에 연결할 수 없습니다. 솔루션 설계자는 운영 비용을 최소화하면서 데이터베이스 보안을 보장하는 시스템을 만들어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.각 가용 영역의 퍼블릭 서브넷 내부에 NAT 게이트웨이를 배포하고 이를 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.\\nB. 각 가용 영역의 프라이빗 서브넷 내부에 NAT 게이트웨이를 배포하고 이를 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.\\nC. 각 가용 영역에 대해 퍼블릭 서브넷 내부에 두 개의 NAT 인스턴스를 배포하고 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.\\nD. 각 가용 영역의 프라이빗 서브넷 내부에 두 개의 NAT 인스턴스를 배포하고 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.\", \"A firm just launched a two-tier application in the us-east-1 Region's two Availability Zones. Databases are located on a private subnet, whereas web servers are located on a public subnet. The VPC is connected to the internet through an internet gateway. Amazon EC2 instances are used to host the application and database. The database servers are unable to connect to the internet in order to get fixes. A solutions architect must create a system that ensures database security while incurring the fewest operating costs.\\nWhich solution satisfies these criteria?\\n\\nA.Deploy a NAT gateway inside the public subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route.\\nB. Deploy a NAT gateway inside the private subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route.\\nC. Deploy two NAT instances inside the public subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route.\\nD. Deploy two NAT instances inside the private subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route.\", \"A\"],\n[\"기업은 각 개발자 계정에 대해 Amazon S3 버킷으로 로그 파일을 전송하도록 AWS CloudTrail 로그를 구성했습니다. 조직은 관리 및 감사를 용이하게 하기 위해 중앙 집중식 AWS 계정을 설정했습니다. 내부 감사자는 CloudTrail 로그에 액세스해야 하지만 모든 개발자 계정 사용자에 대한 액세스는 제한되어야 합니다. 솔루션은 안전하고 효율적이어야 합니다.\\n솔루션 설계자는 이러한 고려 사항을 어떻게 해결해야 합니까?\\n\\nA.각 개발자 계정에서 AWS Lambda 함수를 구성하여 로그 파일을 중앙 계정에 복사합니다. 감사자의 중앙 계정에서 IAM 역할을 생성합니다. 버킷에 읽기 전용 권한을 제공하는 IAM 정책을 연결합니다.\\nB. 각 개발자 계정에서 CloudTrail을 구성하여 로그 파일을 중앙 계정의 S3 버킷으로 전달합니다. 감사자의 중앙 계정에 IAM 사용자를 생성합니다. 버킷에 대한 전체 권한을 제공하는 IAM 정책을 연결합니다.\\nC. 각 개발자 계정에서 CloudTrail을 구성하여 로그 파일을 중앙 계정의 S3 버킷으로 전달합니다. 감사자의 중앙 계정에서 IAM 역할을 생성합니다. 버킷에 읽기 전용 권한을 제공하는 IAM 정책을 연결합니다.\\nD. 각 개발자 계정의 S3 버킷에서 로그 파일을 복사하도록 중앙 계정에서 AWS Lambda 함수를 구성합니다. 감사자의 중앙 계정에 IAM 사용자를 생성합니다. 버킷에 대한 전체 권한을 제공하는 IAM 정책을 연결합니다.\", \"For each of its developer accounts, a corporation has configured AWS CloudTrail logs to transport log files to an Amazon S3 bucket. The organization has established a centralized AWS account for the purpose of facilitating administration and auditing. Internal auditors need access to CloudTrail logs, however access to all developer account users must be limited. The solution should be both secure and efficient.\\nHow should a solutions architect address these considerations?\\n\\nA.Configure an AWS Lambda function in each developer account to copy the log files to the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read-only permissions to the bucket.\\nB. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.\\nC. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read-only permissions to the bucket.\\nD. Configure an AWS Lambda function in the central account to copy the log files from the S3 bucket in each developer account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket.\", \"C\"],\n[\"솔루션 아키텍트가 다가오는 음악 공연을 준비하기 위해 웹사이트를 개선하고 있습니다. 공연의 실시간 스트리밍은 물론 주문형 시청도 가능합니다. 이 행사는 전 세계에서 많은 인터넷 청중을 끌어들일 것으로 예상됩니다.\\n실시간 및 주문형 스트리밍 성능을 모두 최적화하는 서비스는 무엇입니까?\\n\\nA.Amazon CloudFront\\nB. AWS Global Accelerator\\nC. Amazon Route S3\\nD. Amazon S3 Transfer Acceleration\", \"A solutions architect is improving a website in preparation for a forthcoming musical performance. Real-time streaming of the performances will be accessible, as well as on-demand viewing. The event is anticipated to draw a large internet audience from across the world.\\nWhich service will optimize both real-time and on-demand steaming performance?\\n\\nA.Amazon CloudFront\\nB. AWS Global Accelerator\\nC. Amazon Route S3\\nD. Amazon S3 Transfer Acceleration\", \"A\"],\n[\"데이터베이스는 대용량 읽기의 대상이 되는 Amazon RDS MySQL 5.6 다중 AZ DB 인스턴스에서 호스팅됩니다. 보조 AWS 리전에서 읽기 성능을 평가할 때 애플리케이션 개발자는 상당한 지연을 감지합니다. 개발자는 읽기 복제 대기 시간이 1초 미만인 솔루션이 필요합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.보조 리전의 Amazon EC2에 MySQL을 설치합니다.\\nB. 교차 리전 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션합니다.\\nC. 보조 리전에 또 다른 MySQL용 RDS 읽기 전용 복제본을 생성합니다.\\nD. Amazon ElastiCache를 구현하여 데이터베이스 쿼리 성능을 개선합니다.\", \"A database is hosted on an Amazon RDS MySQL 5.6 Multi-AZ DB instance that is subjected to high-volume reads. When evaluating read performance from a secondary AWS Region, application developers detect a considerable lag. The developers need a solution that has a read replication latency of less than one second.\\nWhat recommendations should the solutions architect make?\\n\\nA.Install MySQL on Amazon EC2 in the secondary Region.\\nB. Migrate the database to Amazon Aurora with cross-Region replicas.\\nC. Create another RDS for MySQL read replica in the secondary Region.\\nD. Implement Amazon ElastiCache to improve database query performance.\", \"B. mysql rds 읽기 전용 복제본은 복제본과 원본의 데이터가 1초 이상 지연되는 경우 존재함.\"],\n[\"현재 기업은 Amazon RDS MySQL 데이터베이스에 의해 백업되는 웹 애플리케이션을 실행합니다. 암호화되지 않은 일일 자동 백업 기능이 있습니다. 보안 감사에는 향후 백업의 암호화와 암호화되지 않은 백업의 파괴가 수반됩니다. 이전 백업을 삭제하기 전에 회사는 하나 이상의 암호화된 백업을 생성합니다.\\n향후 암호화된 백업을 허용하려면 어떻게 해야 합니까?\\n\\nA.백업이 저장되는 Amazon S3 버킷에 대한 기본 암호화를 활성화합니다.\\nB. 암호화 활성화 확인란을 토글하도록 데이터베이스 구성의 백업 섹션을 수정합니다.\\nC. 데이터베이스의 스냅샷을 생성합니다. 암호화된 스냅샷에 복사합니다. 암호화된 스냅샷에서 데이터베이스를 복원합니다.\\nD. RDS for MySQL에서 암호화된 읽기 전용 복제본을 활성화합니다. 암호화된 읽기 전용 복제본을 기본으로 승격합니다. 원래 데이터베이스 인스턴스를 제거하십시오.\", \"Currently, a business runs a web application that is backed up by an Amazon RDS MySQL database. It features daily automatic backups that are not encrypted. A security audit entails the encryption of future backups and the destruction of unencrypted backups. Before deleting the previous backups, the firm will create at least one encrypted backup.\\nWhat should be done to allow encrypted backups in the future?\\n\\nA.Enable default encryption for the Amazon S3 bucket where backups are stored.\\nB. Modify the backup section of the database configuration to toggle the Enable encryption check box.\\nC. Create a snapshot of the database. Copy it to an encrypted snapshot. Restore the database from the encrypted snapshot.\\nD. Enable an encrypted read replica on RDS for MySQL. Promote the encrypted read replica to primary. Remove the original database instance.\", \"C\"],\n[\"회사 시설의 각 입구에는 배지 판독기가 장착되어 있습니다. 배지가 스캔되면 리더는 해당 특정 항목을 입력하려고 시도한 사람을 나타내는 HTTPS 메시지를 전송합니다.\\n솔루션 설계자는 이러한 센서 신호를 처리할 시스템을 개발해야 합니다. 솔루션은 회사의 보안 직원이 분석할 수 있도록 결과를 제공하여 액세스 가능성이 높아야 합니다.\\n솔루션 아키텍트가 권장해야 하는 시스템 설계는 무엇입니까?\\n\\nA.Amazon EC2 인스턴스를 시작하여 HTTPS 엔드포인트 역할을 하고 메시지를 처리합니다. 결과를 Amazon S3 버킷에 저장하도록 EC2 인스턴스를 구성합니다.\\nB. Amazon API Gateway에서 HTTPS 엔드포인트를 생성합니다. AWS Lambda 함수를 호출하여 메시지를 처리하고 결과를 Amazon DynamoDB 테이블에 저장하도록 API Gateway 엔드포인트를 구성합니다.\\nC. Amazon Route 53을 사용하여 수신 센서 메시지를 AWS Lambda 함수로 보냅니다. 메시지를 처리하고 결과를 Amazon DynamoDB 테이블에 저장하도록 Lambda 함수를 구성합니다.\\nD. Amazon S3용 게이트웨이 VPC 엔드포인트를 생성합니다. 센서 데이터가 VPC 엔드포인트를 통해 S3 버킷에 직접 기록될 수 있도록 시설 네트워크에서 VPC로의 Site-to-Site VPN 연결을 구성합니다.\", \"Each entry to a company's facility is equipped with badge readers. When badges are scanned, the readers transmit an HTTPS message indicating who tried to enter that specific entry.\\nA solutions architect must develop a system that will handle these sensor signals. The solution must be highly accessible, with the findings made available for analysis by the company's security staff.\\nWhich system design should be recommended by the solutions architect?\\n\\nA.Launch an Amazon EC2 instance to serve as the HTTPS endpoint and to process the messages. Configure the EC2 instance to save the results to an Amazon S3 bucket.\\nB. Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.\\nC. Use Amazon Route 53 to direct incoming sensor messages to an AWS Lambda function. Configure the Lambda function to process the messages and save the results to an Amazon DynamoDB table.\\nD. Create a gateway VPC endpoint for Amazon S3. Configure a Site-to-Site VPN connection from the facility network to the VPC so that sensor data can be written directly to an S3 bucket by way of the VPC endpoint.\", \"B\"],\n[\"기업은 관계형 데이터베이스를 운영하는 온프레미스 서버를 유지 관리합니다. 기존 데이터베이스는 다양한 위치에서 사용자의 대량 읽기 요청을 처리합니다. 조직은 적은 노력으로 AWS로 전환하기를 원합니다. 데이터베이스 솔루션은 비즈니스의 기존 트래픽 흐름을 방해하지 않으면서 재해 복구를 촉진해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.다중 AZ와 하나 이상의 읽기 전용 복제본이 있는 Amazon RDS의 데이터베이스를 사용합니다.\\nB. 다중 AZ와 하나 이상의 대기 복제본이 있는 Amazon RDS의 데이터베이스를 사용합니다.\\nC. 서로 다른 AWS 리전의 여러 Amazon EC2 인스턴스에서 호스팅되는 데이터베이스를 사용합니다.\\nD. 다른 가용 영역의 Application Load Balancer 뒤에서 Amazon EC2 인스턴스에서 호스팅되는 데이터베이스를 사용합니다.\", \"A business maintains on-premises servers that operate a relational database. The existing database handles a large volume of read requests from users in various places. The organization want to transition to AWS with little effort. The database solution should facilitate catastrophe recovery while not interfering with the existing traffic flow of the business.\\nWhich solution satisfies these criteria?\\n\\nA.Use a database in Amazon RDS with Multi-AZ and at least one read replica.\\nB. Use a database in Amazon RDS with Multi-AZ and at least one standby replica.\\nC. Use databases hosted on multiple Amazon EC2 instances in different AWS Regions.\\nD. Use databases hosted on Amazon EC2 instances behind an Application Load Balancer in different Availability Zones.\", \"A\"],\n[\"AWS에서 기업은 문서 스토리지 솔루션을 개발하고 있습니다. 애플리케이션은 다양한 Amazon EC2 가용 영역에 배포됩니다. 회사는 접근성이 높은 문서 저장소를 요구합니다. 요청 시 문서를 신속하게 반환해야 합니다. 수석 엔지니어는 Amazon Elastic Block Store(Amazon EBS)에 문서를 저장하도록 애플리케이션을 설정했지만 가용성 요구 사항을 충족하기 위해 추가 솔루션을 검토할 수 있습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.EBS 볼륨을 정기적으로 스냅샷하고 추가 가용 영역에서 해당 스냅샷을 사용하여 새 볼륨을 빌드합니다.\\nB. EC2 인스턴스 루트 볼륨에 Amazon Elastic Block Store(Amazon EBS)를 사용합니다. Amazon S3에 문서 저장소를 구축하도록 애플리케이션을 구성합니다.\\nC. EC2 인스턴스 루트 볼륨에 Amazon Elastic Block Store(Amazon EBS)를 사용합니다. Amazon S3 Glacier에 문서 저장소를 구축하도록 애플리케이션을 구성합니다.\\nD. EC2 인스턴스에 대해 최소 3개의 프로비저닝된 IOPS EBS 볼륨을 사용합니다. RAID 5 구성의 EC2 인스턴스에 볼륨을 탑재합니다.\", \"On AWS, a business is developing a document storage solution. The application is deployed across different Amazon EC2 Availability Zones. The firm demands a highly accessible document storage. When requested, documentation must be returned quickly. The lead engineer has setup the application to store documents in Amazon Elastic Block Store (Amazon EBS), but is open to examine additional solutions to fulfill the availability requirement.\\nWhat recommendations should a solutions architect make?\\n\\nA.Snapshot the EBS volumes regularly and build new volumes using those snapshots in additional Availability Zones.\\nB. Use Amazon Elastic Block Store (Amazon EBS) for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3.\\nC. Use Amazon Elastic Block Store (Amazon EBS) for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3 Glacier.\\nD. Use at least three Provisioned IOPS EBS volumes for EC2 instances. Mount the volumes to the EC2 instances in a RAID 5 configuration.\", \"B\"],\n[\"기업은 재무 보고 목적으로 AWS 요금을 추적하기를 원합니다. 클라우드 운영 팀은 AWS Organizations 관리 계정의 모든 구성원 계정에 대한 AWS 비용 및 사용 보고서를 쿼리하기 위한 아키텍처를 개발하고 있습니다. 한 달에 한 번 팀은 이 쿼리를 실행하고 청구서에 대한 전체 분석을 제공해야 합니다.\\n어떤 솔루션이 가장 확장 가능하고 비용 효율적인 방식으로 이러한 요구 사항을 충족합니까?\\n\\nA.관리 계정에서 비용 및 사용 보고서를 활성화합니다. Amazon Kinesis에 보고서를 전달합니다. 분석에 Amazon EMR을 사용합니다.\\nB. 관리 계정에서 비용 및 사용 보고서를 활성화합니다. 보고서를 Amazon S3에 전달합니다. 분석에 Amazon Athena를 사용하십시오.\\nC. 회원 계정에 대한 비용 및 사용 보고서를 활성화합니다. 보고서를 Amazon S3에 전달합니다. 분석을 위해 Amazon Redshift를 사용하십시오.\\nD. 회원 계정에 대한 비용 및 사용 보고서를 활성화합니다. 보고서를 Amazon Kinesis에 전달합니다. 분석을 위해 Amazon QuickSight를 사용하십시오.\", \"A business wishes to keep track of its AWS charges for financial reporting purposes. The cloud operations team is developing an architecture for querying AWS Cost and Usage Reports for all member accounts in the AWS Organizations management account. Once a month, the team must execute this query and give a full analysis of the bill.\\nWhich solution meets these needs in the MOST scalable and cost-effective manner?\\n\\nA.Enable Cost and Usage Reports in the management account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.\\nB. Enable Cost and Usage Reports in the management account. Deliver the reports to Amazon S3. Use Amazon Athena for analysis.\\nC. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3. Use Amazon Redshift for analysis.\\nD. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuickSight for analysis.\", \"B\"],\n[\"솔루션 설계자는 모든 신규 사용자가 특정 난이도 표준을 충족하고 정기적으로 IAM 사용자 암호를 교체해야 하는 것을 원합니다.\\n이를 달성하기 위한 솔루션 설계자의 역할은 무엇입니까?\\n\\nA.전체 AWS 계정에 대한 전체 암호 정책 설정\\nB. AWS 계정의 각 IAM 사용자에 대한 암호 정책을 설정합니다.\\nC. 타사 공급업체 소프트웨어를 사용하여 암호 요구 사항을 설정합니다.\\nD. Amazon CloudWatch 규칙을 Create_newuser 이벤트에 연결하여 적절한 요구 사항으로 암호를 설정합니다.\", \"A solutions architect desires that all new users meet particular difficulty standards and are required to rotate their IAM user passwords on a regular basis.\\nWhat is the solution architect's role in achieving this?\\n\\nA.Set an overall password policy for the entire AWS account\\nB. Set a password policy for each IAM user in the AWS account.\\nC. Use third-party vendor software to set password requirements.\\nD. Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements.\", \"A\"],\n[\"비즈니스는 AWS를 사용하여 웹 사이트를 호스팅합니다. 조직은 극도로 변동하는 수요를 수용하기 위해 Amazon EC2 Auto Scaling을 활용했습니다. 경영진은 회사가 특히 3계층 애플리케이션의 프런트 엔드에서 인프라를 과도하게 프로비저닝하고 있다고 우려하고 있습니다. 솔루션 설계자의 주요 책임은 성능 저하 없이 비용이 최소화되도록 보장하는 것입니다.\\n이를 달성하기 위한 솔루션 설계자의 역할은 무엇입니까?\\n\\nA.예약 인스턴스에서 Auto Scaling을 사용합니다.\\nB. 예약된 조정 정책으로 Auto Scaling을 사용합니다.\\nC. 일시 중단-재개 기능과 함께 Auto Scaling을 사용합니다.\\nD. 대상 추적 조정 정책과 함께 Auto Scaling을 사용합니다.\", \"A business uses AWS to host its website. The organization has utilized Amazon EC2 Auto Scaling to accommodate the extremely fluctuating demand. Management is worried that the firm is overprovisioning its infrastructure, particularly at the three-tier application's front end. A solutions architect's primary responsibility is to guarantee that costs are minimized without sacrificing performance.\\nWhat is the solution architect's role in achieving this?\\n\\nA.Use Auto Scaling with Reserved Instances.\\nB. Use Auto Scaling with a scheduled scaling policy.\\nC. Use Auto Scaling with the suspend-resume feature.\\nD. Use Auto Scaling with a target tracking scaling policy.\", \"D. 가변 수요가 있는 경우 사용\"],\n[\"기업에서 앱을 AWS로 이전하는 중입니다. 현재 온프레미스 앱은 공유 파일 시스템에 보관되는 수백 테라바이트의 데이터를 생성합니다. 조직은 클라우드 기반 분석 솔루션을 사용하여 시간 단위로 이 데이터에서 통찰력을 도출합니다.\\n비즈니스에는 온프레미스 공유 파일 시스템과 Amazon S3 간의 지속적인 데이터 전송을 관리하는 솔루션이 필요합니다. 또한 솔루션은 인터넷 액세스의 짧은 간격에 대처할 수 있어야 합니다.\\n이러한 요구 사항을 달성하기 위해 기업은 어떤 데이터 전송 옵션을 사용해야 합니까?\\n\\nA.AWS 데이터싱크\\nB. AWS 마이그레이션 허브\\nC. AWS Snowball Edge 스토리지 최적화\\nD. SFTP를 위한 AWS 전송\", \"A business is in the process of transferring its apps to AWS. At the moment, on-premises apps create hundreds of terabytes of data, which is kept on a shared file system. The organization is using a cloud-based analytics solution to derive insights from this data on an hourly basis.\\nThe business requires a solution to manage continuous data transfer between its on-premises shared file system and Amazon S3. Additionally, the solution must be capable of coping with brief gaps in internet access.\\nWhich data transmission options should the business utilize to achieve these requirements?\\n\\nA.AWS DataSync\\nB. AWS Migration Hub\\nC. AWS Snowball Edge Storage Optimized\\nD. AWS Transfer for SFTP\", \"A\"],\n[\"기업에서 AWS Systems Manager를 사용하여 Amazon EC2 인스턴스 집합을 관리하려고 합니다. 회사의 보안 요구 사항에 따라 EC2 인스턴스는 인터넷 액세스가 허용되지 않습니다. 솔루션 설계자는 이 보안 요구 사항을 준수하면서 EC2 인스턴스와 Systems Manager 간의 네트워크 연결 설계를 담당합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.EC2 인스턴스를 인터넷 경로가 없는 프라이빗 서브넷에 배포합니다.\\nB. Systems Manager에 대한 인터페이스 VPC 엔드포인트를 구성합니다. 끝점을 사용하도록 경로를 업데이트합니다.\\nC. NAT 게이트웨이를 퍼블릭 서브넷에 배포합니다. NAT 게이트웨이에 대한 기본 경로를 사용하여 프라이빗 서브넷을 구성합니다.\\nD. 인터넷 게이트웨이를 배포합니다. Systems Manager를 제외한 모든 대상에 대한 트래픽을 거부하도록 네트워크 ACL을 구성합니다.\", \"A business wishes to manage a fleet of Amazon EC2 instances using AWS Systems Manager. No EC2 instances are permitted to have internet access, per the company's security needs. A solutions architect is responsible for designing network connection between EC2 instances and Systems Manager while adhering to this security requirement.\\nWhich solution will satisfy these criteria?\\n\\nA.Deploy the EC2 instances into a private subnet with no route to the internet.\\nB. Configure an interface VPC endpoint for Systems Manager. Update routes to use the endpoint.\\nC. Deploy a NAT gateway into a public subnet. Configure private subnets with a default route to the NAT gateway.\\nD. Deploy an internet gateway. Configure a network ACL to deny traffic to all destinations except Systems Manager.\", \"B\"],\n[\"Amazon EC2 인스턴스에서 기업은 애플리케이션을 실행합니다. 애플리케이션은 us-east-1 리전의 3개 가용 영역 내 프라이빗 서브넷에 배포됩니다. 파일을 다운로드하려면 인스턴스가 인터넷에 액세스할 수 있어야 합니다. 조직은 지역 전체에서 쉽게 액세스할 수 있는 디자인을 찾고 있습니다.\\n인터넷 액세스가 중단되지 않도록 하려면 어떤 솔루션을 수행해야 합니까?\\n\\nA.각 가용 영역의 프라이빗 서브넷에 NAT 인스턴스를 배포합니다.\\nB. 각 가용 영역의 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다.\\nC. 각 가용 영역의 프라이빗 서브넷에 전송 게이트웨이를 배포합니다.\\nD. 각 가용 영역의 퍼블릭 서브넷에 인터넷 게이트웨이를 배포합니다.\", \"On Amazon EC2 instances, a business runs an application. The application is deployed on private subnets inside the us-east-1 Region's three Availability Zones. The instances must have internet access in order to download files. The organization is looking for a design that is readily accessible across the Region.\\nWhich solution should be done to guarantee that internet access is not disrupted?\\n\\nA.Deploy a NAT instance in a private subnet of each Availability Zone.\\nB. Deploy a NAT gateway in a public subnet of each Availability Zone.\\nC. Deploy a transit gateway in a private subnet of each Availability Zone.\\nD. Deploy an internet gateway in a public subnet of each Availability Zone.\", \"B\"],\n[\"기업이 연결이 불안정한 원거리 공장을 운영하고 있습니다. 공장은 컨베이어 벨트의 항목을 감지하고 로봇 이동을 시작하여 적절한 지점으로 이동하기 위해 기계 및 센서 데이터를 수집 및 해석해야 합니다. 온프레미스 제어 시스템의 경우 예측 가능한 저지연 컴퓨팅 처리가 중요합니다.\\n제조업체는 어떤 데이터 처리 솔루션을 사용해야 합니까?\\n\\nA.Amazon CloudFront Lambda@Edge 함수\\nB. 향상된 네트워킹이 활성화된 Amazon EC2 인스턴스\\nC. AWS Global Accelerator를 사용하는 Amazon EC2 인스턴스\\nD. AWS Snowball Edge 클러스터의 Amazon Elastic Block Store(Amazon EBS) 볼륨\", \"A business operates a distant plant with unstable connection. The factory must collect and interpret machine and sensor data in order to detect items on its conveyor belts and begin robotic movement to route them to the appropriate spot. For on-premises control systems, predictable low-latency computing processing is critical.\\nWhich data processing solution should the manufacturer use?\\n\\nA.Amazon CloudFront Lambda@Edge functions\\nB. An Amazon EC2 instance that has enhanced networking enabled\\nC. An Amazon EC2 instance that uses an AWS Global Accelerator\\nD. An Amazon Elastic Block Store (Amazon EBS) volume on an AWS Snowball Edge cluster\", \"A, D가 모두 가능하다는 논란이 있음. 기업이 인터넷 연결이 불가하다면 D, 가능하다면 저지연 처리를 위해 A\"],\n[\"애플리케이션은 Amazon EC2 인스턴스를 사용하여 다양한 가용 영역에 배포됩니다. 인스턴스는 Amazon EC2 Auto Scaling 그룹의 Application Load Balancer 뒤에 배포됩니다. 프로그램은 Amazon EC2 인스턴스의 CPU 사용량이 40%에 가깝거나 같을 때 최적으로 작동합니다.\\n솔루션 설계자는 모든 그룹 인스턴스에서 필요한 성능을 유지하기 위해 무엇을 해야 합니까?\\n\\nA.Auto Scaling 그룹을 동적으로 확장하려면 간단한 확장 정책을 사용합니다.\\nB. 대상 추적 정책을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다.\\nC. AWS Lambda 함수를 사용하여 원하는 Auto Scaling 그룹 용량을 업데이트합니다.\\nD. 예약된 조정 작업을 사용하여 Auto Scaling 그룹을 확장 및 축소합니다.\", \"An application is deployed across various Availability Zones using Amazon EC2 instances. The instances are deployed behind an Application Load Balancer in an Amazon EC2 Auto Scaling group. The program operates optimally when the CPU usage of the Amazon EC2 instances is close to or equal to 40%.\\nWhat should a solutions architect do to ensure that the required performance is maintained throughout all group instances?\\n\\nA.Use a simple scaling policy to dynamically scale the Auto Scaling group.\\nB. Use a target tracking policy to dynamically scale the Auto Scaling group.\\nC. Use an AWS Lambda function to update the desired Auto Scaling group capacity.\\nD. Use scheduled scaling actions to scale up and scale down the Auto Scaling group.\", \"B\"],\n[\"비즈니스의 웹 애플리케이션은 Amazon EC2 인스턴스에서 호스팅되며 Application Load Balancer로 보호됩니다. 이 회사는 최근 정책을 변경하여 단일 국가에서만 애플리케이션에 액세스할 수 있도록 했습니다.\\n어떤 설정이 이 기준을 만족할까요?\\n\\nA.EC2 인스턴스에 대한 보안 그룹을 구성합니다.\\nB. Application Load Balancer에서 보안 그룹을 구성합니다.\\nC. VPC의 Application Load Balancer에서 AWS WAF를 구성합니다.\\nD. EC2 인스턴스가 포함된 서브넷에 대해 네트워크 ACL을 구성합니다.\", \"The web application of a business is hosted on Amazon EC2 instances and is protected by an Application Load Balancer. The corporation recently altered its policy, requiring that the application be accessible exclusively from a single nation.\\nWhich setup will satisfy this criterion?\\n\\nA.Configure the security group for the EC2 instances.\\nB. Configure the security group on the Application Load Balancer.\\nC. Configure AWS WAF on the Application Load Balancer in a VPC.\\nD. Configure the network ACL for the subnet that contains the EC2 instances.\", \"C\"],\n[\"AWS Lambda 함수는 엔지니어링 팀에서 개발 및 배포 중입니다. 팀은 Lambda 함수의 권한을 설정하기 위해 AWS IAM에서 역할을 구축하고 정책을 관리해야 합니다.\\n최소 권한 원칙에 맞게 팀의 권한을 어떻게 조정해야 합니까?\\n\\nA.관리형 정책이 연결된 IAM 역할을 생성합니다. 엔지니어링 팀과 Lambda 함수가 이 역할을 맡도록 허용합니다.\\nB. IAMFullAccess 정책이 연결된 엔지니어링 팀을 위한 IAM 그룹을 생성합니다. 팀의 모든 사용자를 이 IAM 그룹에 추가합니다.\\nC. Lambda 함수에 대한 실행 역할을 생성합니다. 이러한 Lambda 함수와 관련된 권한 경계가 있는 관리형 정책을 연결합니다.\\nD. Lambda 함수와 관련된 권한 경계가 있는 관리형 정책이 연결된 IAM 역할을 생성합니다. 엔지니어링 팀이 이 역할을 맡도록 허용합니다.\", \"AWS Lambda functions are being developed and deployed by an engineering team. The team must build roles and administer policies in AWS IAM in order to set the Lambda functions' rights.\\nHow should the team's permissions be adjusted to correspond to the principle of least privilege?\\n\\nA.Create an IAM role with a managed policy attached. Allow the engineering team and the Lambda functions to assume this role.\\nB. Create an IAM group for the engineering team with an IAMFullAccess policy attached. Add all the users from the team to this IAM group.\\nC. Create an execution role for the Lambda functions. Attach a managed policy that has permission boundaries specific to these Lambda functions.\\nD. Create an IAM role with a managed policy attached that has permission boundaries specific to the Lambda functions. Allow the engineering team to assume this role.\", \"D\"],\n[\"기업이 온프레미스 Oracle에서 Amazon Aurora PostgreSQL로 마이그레이션하고 있습니다. 수많은 앱이 데이터베이스의 동일한 테이블에 씁니다. 앱은 마이그레이션 사이에 한 달을 두고 순차적으로 전송해야 합니다. 경영진은 데이터베이스의 과도한 읽기 및 쓰기 활동에 대한 우려를 제기했습니다. 전체 마이그레이션 프로세스 동안 데이터는 두 데이터베이스에서 동기화된 상태로 유지되어야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.초기 마이그레이션에는 AWS DataSync를 사용하십시오. AWS DMS(AWS Database Migration Service)를 사용하여 변경 데이터 캡처(CDC) 복제 작업을 생성하고 테이블 매핑을 생성하여 모든 케이블을 선택합니다.\\nB. 초기 마이그레이션에 AWS DataSync를 사용합니다. AWS Database Migration Service(AWS DMS)를 사용하여 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업을 생성하고 테이블 매핑을 생성하여 모든 테이블을 선택합니다.\\nC. 메모리 최적화 복제 인스턴스를 사용하여 AWS DataBase Migration Service(AWS DMS)와 함께 AWS Schema Conversion Tool을 사용합니다. 전체 로드 및 변경 데이터 캡처(CDC) 복제 작업을 생성하고 모든 테이블을 선택하는 테이블 매핑을 생성합니다.\\nD. 컴퓨팅 최적화 복제 인스턴스를 사용하여 AWS DMS(AWS Database Migration Service)와 함께 AWS Schema Conversion Tool을 사용합니다. 전체 로드 및 CDC(변경 데이터 캡처) 복제 작업 및 테이블 매핑을 생성하여 가장 큰 테이블을 선택합니다.\", \"A business is migrating from on-premises Oracle to Amazon Aurora PostgreSQL. Numerous apps write to the same tables in the database. The apps must be transferred sequentially, with a month between migrations. Management has raised worry about the database's heavy read and write activity. Throughout the entire migration process, the data must be maintained in sync across both databases.\\nWhat recommendations should a solutions architect make?\\n\\nA.Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a change data capture (CDC) replication task and a table mapping to select all cables.\\nB. Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.\\nC. Use the AWS Schema Conversion Tool with AWS DataBase Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.\\nD. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables.\", \"C\"],\n[\"솔루션 설계자는 Amazon EC2 인스턴스 호스팅 공개 웹 사이트에서 Amazon S3 버킷으로 정적 콘텐츠를 마이그레이션하고 있습니다. 정적 자산은 Amazon CloudFront 배포를 사용하여 배포됩니다. EC2 인스턴스의 보안 그룹은 IP 범위의 하위 집합에 대한 액세스를 제한합니다. 정적 물질에 대한 접근은 유사한 방식으로 규제되어야 합니다.\\n이러한 기준을 충족하는 작업 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.오리진 액세스 ID(OAI)를 생성하고 이를 배포와 연결합니다. OAI만 객체를 읽을 수 있도록 버킷 정책의 권한을 변경합니다.\\nB. EC2 보안 그룹에 존재하는 것과 동일한 IP 제한을 포함하는 AWS WAF 웹 ACL을 생성합니다. 이 새 웹 ACL을 CloudFront 배포와 연결합니다.\\nC. 현재 EC2 보안 그룹에 존재하는 것과 동일한 IP 제한을 포함하는 새 보안 그룹을 생성합니다. 이 새 보안 그룹을 CloudFront 배포와 연결합니다.\\nD. 현재 EC2 보안 그룹에 존재하는 것과 동일한 IP 제한을 포함하는 새 보안 그룹을 생성합니다. 이 새 보안 그룹을 정적 콘텐츠를 호스팅하는 S3 버킷과 연결합니다.\\nE. 새 IAM 역할을 생성하고 해당 역할을 배포와 연결합니다. 새로 생성된 IAM 역할만 읽기 및 다운로드 권한을 갖도록 S3 버킷 또는 S3 버킷 내의 파일에 대한 권한을 변경합니다.\", \"A solutions architect is migrating static content from an Amazon EC2 instance-hosted public website to an Amazon S3 bucket. The static assets will be distributed using an Amazon CloudFront distribution. The EC2 instances' security group limits access to a subset of IP ranges. Access to static material should be regulated in a similar manner.\\nWhich combination of actions will satisfy these criteria? (Select two.)\\n\\nA.Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects.\\nB. Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution.\\nC. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution.\\nD. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content.\\nE. Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions.\", \"A, B. 보안그룹은 S3, CF에 적용 불가하므로 C,D는 답이 될 수 없음.\"],\n[\"AWS는 전자 상거래 회사에서 다중 계층 애플리케이션을 운영하는 데 사용됩니다. Amazon EC2는 프런트 엔드 및 백엔드 계층을 모두 호스팅하는 반면 Amazon RDS for MySQL은 데이터베이스를 호스팅합니다. 백엔드 계층은 RDS 인스턴스와의 통신을 담당합니다. 동일한 데이터 세트를 얻기 위해 데이터베이스에 대한 요청이 많아 성능이 저하됩니다.\\n백엔드의 성능을 최적화하려면 어떤 작업을 수행해야 합니까?\\n\\nA.Amazon SNS를 구현하여 데이터베이스 호출을 저장합니다.\\nB. Amazon ElastiCache를 구현하여 대규모 데이터 세트를 캐시합니다.\\nC. RDS for MySQL 읽기 전용 복제본을 구현하여 데이터베이스 호출을 캐시합니다.\\nD. Amazon Kinesis Data Firehose를 구현하여 데이터베이스에 대한 호출을 스트리밍합니다.\", \"AWS is used by an ecommerce firm to operate a multi-tier application. Amazon EC2 hosts both the front-end and back-end layers, while Amazon RDS for MySQL hosts the database. The backend tier is responsible for communication with the RDS instance. There are many requests to the database to get identical datasets, which results in performance slowdowns.\\nWhich actions should be performed to optimize the backend's performance?\\n\\nA.Implement Amazon SNS to store the database calls.\\nB. Implement Amazon ElastiCache to cache the large datasets.\\nC. Implement an RDS for MySQL read replica to cache database calls.\\nD. Implement Amazon Kinesis Data Firehose to stream the calls to the database.\", \"B\"],\n[\"사용자는 쿼리에서 최대 100밀리초의 지연을 예상하는 다양한 고객이 사용하는 MySQL 데이터베이스를 소유하고 있습니다. 항목이 데이터베이스에 기록되면 거의 수정되지 않습니다. 클라이언트는 한 번에 최대 하나의 레코드에 액세스할 수 있습니다.\\n증가하는 고객 요구로 인해 데이터베이스 액세스가 엄청나게 확장되었습니다. 결과적으로 결과 부하는 사용 가능한 가장 값비싼 하드웨어의 용량을 빠르게 능가합니다. 사용자는 AWS로 이동하기를 원하며 새로운 데이터베이스 시스템을 실험할 준비가 되어 있습니다.\\n데이터베이스 로드 문제를 해결하고 거의 무한한 미래 확장성을 제공하는 솔루션은 무엇입니까?\\n\\nA.아마존 RDS\\nB. Amazon DynamoDB\\nC. 아마존 레드시프트\\nD. AWS 데이터 파이프라인\", \"A user owns a MySQL database, which is used by a variety of customers that anticipate a maximum delay of 100 milliseconds on queries. Once an entry is recorded in the database, it is almost never modified. Clients get access to a maximum of one record at a time.\\nDue to rising customer demand, database access has expanded tremendously. As a consequence, the resulting load will quickly surpass the capability of even the most costly hardware available. The user want to move to AWS and is open to experimenting with new database systems.\\nWhich solution would resolve the database load problem and provide nearly limitless future scalability?\\n\\nA.Amazon RDS\\nB. Amazon DynamoDB\\nC. Amazon Redshift\\nD. AWS Data Pipeline\", \"B. 그러나 기존에 RDS를 사용했으므로 A가 답이라는 의견 존재. 하지만 “한 번에 최대 하나의 레코드에 엑세스”가 dynamoDB와 잘 어울리므로 B가 답이라는 의견 우세.\"],\n[\"Amazon DynamoDB는 엔터테인먼트 회사에서 미디어 메타데이터를 저장하는 데 사용하고 있습니다. 응용 프로그램은 광범위한 읽기가 필요하며 종종 지연이 발생합니다. 조직에는 추가 운영 비용을 관리하는 데 필요한 인력이 부족하고 애플리케이션을 변경하지 않고 DynamoDB의 성능 효율성을 높여야 합니다.\\n이 요구 사항을 충족하려면 어떤 솔루션 아키텍처 접근 방식을 권장해야 합니까?\\n\\nA.Redis용 Amazon ElastiCache를 사용합니다.\\nB. Amazon DynamoDB 가속기(DAX)를 사용합니다.\\nC. DynamoDB 전역 테이블을 사용하여 데이터를 복제합니다.\\nD. 자동 검색이 활성화된 Memcached용 Amazon ElastiCache를 사용합니다.\", \"Amazon DynamoDB is being used by an entertainment firm to store media metadata. The application requires extensive reading and often encounters delays. The organization lacks the people necessary to manage extra operational expenses and requires an increase in DynamoDB's performance efficiency without changing the application.\\nWhat solution architecture approach should be recommended to satisfy this requirement?\\n\\nA.Use Amazon ElastiCache for Redis.\\nB. Use Amazon DynamoDB Accelerator (DAX).\\nC. Replicate data by using DynamoDB global tables.\\nD. Use Amazon ElastiCache for Memcached with Auto Discovery enabled.\", \"B\"],\n[\"지점 사무실에서 회사는 가상화된 컴퓨팅 리소스가 없는 작은 데이터 클로짓에서 애플리케이션을 실행합니다. 애플리케이션의 데이터는 NFS(네트워크 파일 시스템) 볼륨에 저장됩니다. 규정 준수 요구 사항에 따라 NFS 볼륨의 일일 오프사이트 백업이 필요합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Storage Gateway 파일 게이트웨이를 온프레미스에 설치하여 Amazon S3에 데이터를 복제합니다.\\nB. AWS Storage Gateway 파일 게이트웨이 하드웨어 어플라이언스를 온프레미스에 설치하여 데이터를 Amazon S3에 복제합니다.\\nC. 데이터를 Amazon S3에 복제하기 위해 온프레미스에 볼륨이 저장된 AWS Storage Gateway 볼륨 게이트웨이를 설치합니다.\\nD. 온프레미스에 캐시된 볼륨이 있는 AWS Storage Gateway 볼륨 게이트웨이를 설치하여 Amazon S3에 데이터를 복제합니다.\", \"In a branch office, a firm runs an application in a tiny data closet with no virtualized computing resources. The application's data is saved on a network file system (NFS) volume. Daily offsite backups of the NFS volume are required by compliance requirements.\\nWhich solution satisfies these criteria?\\n\\nA.Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3.\\nB. Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3.\\nC. Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3.\\nD. Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3.\", \"B\"],\n[\"한 비즈니스에서 AWS를 사용하여 전 세계 소비자를 위한 선거 보고 웹 사이트를 호스팅하고 있습니다. 웹 사이트는 웹 및 애플리케이션 계층용 Application Load Balancer가 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용합니다. 데이터베이스 계층은 MySQL용 Amazon RDS로 구동됩니다. 웹사이트는 선거 결과로 한 시간에 한 번씩 업데이트되며 이전에는 수백 명의 개인이 데이터를 확인하는 것을 보았습니다.\\n이 회사는 많은 국가에서 임박한 선거의 결과로 앞으로 몇 달 동안 수요가 크게 증가할 것으로 예상합니다. 솔루션 설계자의 목표는 더 많은 EC2 인스턴스에 대한 요구 사항을 제한하면서 증가하는 수요를 관리할 수 있는 웹 사이트의 용량을 늘리는 것입니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Amazon ElastiCache 클러스터를 시작하여 공통 데이터베이스 쿼리를 캐시합니다.\\nB. Amazon CloudFront 웹 배포를 시작하여 일반적으로 요청되는 웹 사이트 콘텐츠를 캐시합니다.\\nC. EC2 인스턴스에서 디스크 기반 캐싱을 활성화하여 일반적으로 요청되는 웹사이트 콘텐츠를 캐싱합니다.\\nD. 일반적으로 요청되는 웹 사이트 콘텐츠에 대해 캐싱이 활성화된 EC2 인스턴스를 사용하여 역방향 프록시를 설계에 배포합니다.\", \"A business is using AWS to host an election reporting website for consumers worldwide. The website makes use of Amazon EC2 instances in an Auto Scaling group with Application Load Balancers for the web and application layers. The database layer is powered by Amazon RDS for MySQL. The website is updated once an hour with election results and has previously seen hundreds of individuals check the data.\\nThe firm anticipates a big boost in demand in the coming months as a result of impending elections in many nations. A solutions architect's objective is to increase the website's capacity to manage increased demand while limiting the requirement for more EC2 instances.\\nWhich solution will satisfy these criteria?\\n\\nA.Launch an Amazon ElastiCache cluster to cache common database queries.\\nB. Launch an Amazon CloudFront web distribution to cache commonly requested website content.\\nC. Enable disk-based caching on the EC2 instances to cache commonly requested website content.\\nD. Deploy a reverse proxy into the design using an EC2 instance with caching enabled for commonly requested website content.\", \"B\"],\n[\"Amazon S3는 기업에서 날씨 기록을 저장하는 데 사용됩니다. 기록은 회사 웹사이트의 도메인 이름을 참조하는 URL을 통해 액세스됩니다. 구독을 통해 전 세계 사용자가 이 자료에 액세스할 수 있습니다. 조직의 핵심 도메인 이름은 타사 운영자가 호스팅하지만 이 회사는 최근 일부 서비스를 Amazon Route 53으로 이전했습니다. 회사는 계약을 통합하고, 사용자 지연 시간을 최소화하고, 구독자에게 애플리케이션을 제공하는 비용을 낮추기를 원합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon CloudFront에서 웹 배포를 생성하여 애플리케이션에 대한 S3 콘텐츠를 제공합니다. CloudFront 배포를 가리키는 Route 53 호스팅 영역에서 CNAME 레코드를 생성하여 애플리케이션의 URL 도메인 이름을 확인합니다.\\nB. Amazon CloudFront에서 웹 배포를 생성하여 애플리케이션에 대한 S3 콘텐츠를 제공합니다. CloudFront 배포를 가리키는 Amazon Route 53 호스팅 영역에서 ALIAS 레코드를 생성하여 애플리케이션의 URL 도메인 이름을 확인합니다.\\nC. 애플리케이션에 대한 Route 53 호스팅 영역에서 A 레코드를 생성합니다. 웹 애플리케이션에 대한 Route 53 트래픽 정책을 생성하고 지리적 위치 규칙을 구성합니다. 엔드포인트의 상태를 확인하고 엔드포인트가 비정상인 경우 DNS 쿼리를 다른 엔드포인트로 라우팅하도록 상태 확인을 구성합니다.\\nD. 애플리케이션에 대한 Route 53 호스팅 영역에서 A 레코드를 생성합니다. 웹 애플리케이션에 대한 Route 53 트래픽 정책을 생성하고 지리 근접 규칙을 구성합니다. 엔드포인트의 상태를 확인하고 엔드포인트가 비정상인 경우 DNS 쿼리를 다른 엔드포인트로 라우팅하도록 상태 확인을 구성합니다.\", \"Amazon S3 is used by a corporation to store historical weather recordings. The records are accessed through a URL that refers to a domain name on the company's website. Subscriptions enable users from all around the globe to access this material. Although the organization's core domain name is hosted by a third-party operator, the company recently transferred some of its services to Amazon Route 53. The corporation want to consolidate contracts, minimize user latency, and lower the cost of offering the application to subscribers.\\nWhich solution satisfies these criteria?\\n\\nA.Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create a CNAME record in a Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.\\nB. Create a web distribution on Amazon CloudFront to serve the S3 content for the application. Create an ALIAS record in the Amazon Route 53 hosted zone that points to the CloudFront distribution, resolving to the application's URL domain name.\\nC. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geolocation rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.\\nD. Create an A record in a Route 53 hosted zone for the application. Create a Route 53 traffic policy for the web application, and configure a geoproximity rule. Configure health checks to check the health of the endpoint and route DNS queries to other endpoints if an endpoint is unhealthy.\", \"B\"],\n[\"기업은 인터넷을 통해 액세스할 수 있는 웹 응용 프로그램을 개발 중입니다. 애플리케이션은 Amazon RDS MySQL 다중 AZ DB 인스턴스를 활용하여 민감한 사용자 데이터를 저장하는 Linux 인스턴스용 Amazon EC2에서 호스팅됩니다. 퍼블릭 서브넷은 EC2 인스턴스에 사용되는 반면 프라이빗 서브넷은 RDS DB 인스턴스에 사용됩니다. 보안 팀은 데이터베이스 인스턴스에 대한 웹 기반 공격을 방지할 것을 요구했습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.EC2 인스턴스가 Auto Scaling 그룹의 일부이고 Application Load Balancer 뒤에 있는지 확인하십시오. 의심스러운 웹 트래픽을 삭제하도록 EC2 인스턴스 iptables 규칙을 구성합니다. DB 인스턴스에 대한 보안 그룹을 생성합니다. 개별 EC2 인스턴스에서 들어오는 포트 3306만 허용하도록 RDS 보안 그룹을 구성합니다.\\nB. EC2 인스턴스가 Auto Scaling 그룹의 일부이고 Application Load Balancer 뒤에 있는지 확인합니다. DB 인스턴스를 EC2 인스턴스가 있는 동일한 서브넷으로 이동합니다. DB 인스턴스에 대한 보안 그룹을 생성합니다. 개별 EC2 인스턴스에서 들어오는 포트 3306만 허용하도록 RDS 보안 그룹을 구성합니다.\\nC. EC2 인스턴스가 Auto Scaling 그룹의 일부이고 Application Load Balancer 뒤에 있는지 확인합니다. AWS WAF를 사용하여 위협에 대한 인바운드 웹 트래픽을 모니터링합니다. 웹 애플리케이션 서버용 보안 그룹과 DB 인스턴스용 보안 그룹을 생성합니다. 웹 응용 프로그램 서버 보안 그룹에서 들어오는 포트 3306만 허용하도록 RDS 보안 그룹을 구성합니다.\\nD. EC2 인스턴스가 Auto Scaling 그룹의 일부이고 Application Load Balancer 뒤에 있는지 확인합니다. AWS WAF를 사용하여 위협에 대한 인바운드 웹 트래픽을 모니터링합니다. 트래픽이 많은 경우 새 DB 인스턴스를 자동으로 생성하도록 Auto Scaling 그룹을 구성합니다. RDS DB 인스턴스에 대한 보안 그룹을 생성합니다. 포트 3306 인바운드만 허용하도록 RDS 보안 그룹을 구성합니다.\", \"A business is developing a web application that will be accessible over the internet. The application is hosted on Amazon EC2 for Linux instances that leverage Amazon RDS MySQL Multi-AZ DB instances to store sensitive user data. Public subnets are used for EC2 instances, whereas private subnets are used for RDS DB instances. The security team has required that web-based attacks on database instances be prevented.\\nWhat recommendations should a solutions architect make?\\n\\nA.Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Configure the EC2 instance iptables rules to drop suspicious web traffic. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.\\nB. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Move DB instances to the same subnets that EC2 instances are located in. Create a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the individual EC2 instances.\\nC. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Create a security group for the web application servers and a security group for the DB instances. Configure the RDS security group to only allow port 3306 inbound from the web application server security group.\\nD. Ensure the EC2 instances are part of an Auto Scaling group and are behind an Application Load Balancer. Use AWS WAF to monitor inbound web traffic for threats. Configure the Auto Scaling group to automatically create new DB instances under heavy traffic. Create a security group for the RDS DB instances. Configure the RDS security group to only allow port 3306 inbound.\", \"C\"],\n[\"솔루션 설계자는 온프레미스에서 AWS로 영구 데이터베이스를 마이그레이션하기 위한 솔루션 설계를 담당합니다. 데이터베이스 관리자에 따르면 데이터베이스에는 64,000 IOPS가 필요합니다. 가능한 경우 데이터베이스 관리자는 단일 Amazon Elastic Block Store(Amazon EBS) 볼륨에서 데이터베이스 인스턴스를 호스팅하려고 합니다.\\n데이터베이스 관리자의 요구 사항을 가장 효과적으로 충족시키는 옵션은 무엇입니까?\\n\\nA.I3 I/O 최적화 제품군의 인스턴스를 사용하고 로컬 임시 스토리지를 활용하여 IOPS 요구 사항을 달성합니다.\\nB. Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS SSD(io1) 볼륨이 연결된 Nitro 기반 Amazon EC2 인스턴스를 생성합니다. 64,000 IOPS를 갖도록 볼륨을 구성합니다.\\nC. Amazon Elastic File System(Amazon EFS) 볼륨을 생성하여 데이터베이스 인스턴스에 매핑하고 볼륨을 사용하여 데이터베이스에 필요한 IOPS를 달성합니다.\\nD. 두 개의 볼륨을 프로비저닝하고 각각에 32,000IOPS를 할당합니다. IOPS 요구 사항을 달성하기 위해 두 볼륨을 집계하는 논리 볼륨을 운영 체제 수준에서 만듭니다.\", \"A solutions architect is responsible for designing a solution for migrating a persistent database from on-premises to AWS. According to the database administrator, the database needs 64,000 IOPS. If feasible, the database administrator wishes to host the database instance on a single Amazon Elastic Block Store (Amazon EBS) volume.\\nWhich option satisfies the database administrator's requirements the most effectively?\\n\\nA.Use an instance from the I3 I/O optimized family and leverage local ephemeral storage to achieve the IOPS requirement.\\nB. Create a Nitro-based Amazon EC2 instance with an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS.\\nC. Create and map an Amazon Elastic File System (Amazon EFS) volume to the database instance and use the volume to achieve the required IOPS for the database.\\nD. Provision two volumes and assign 32,000 IOPS to each. Create a logical volume at the operating system level that aggregates both volumes to achieve the IOPS requirements.\", \"B\"],\n[\"솔루션 아키텍트는 AWS 클라우드에 배포할 새 애플리케이션에 대한 아키텍처를 생성하는 책임이 있습니다. Amazon EC2 온디맨드 인스턴스는 애플리케이션을 실행하는 데 사용되며 다른 가용 영역에서 자동으로 확장됩니다. 하루 종일 EC2 인스턴스는 주기적으로 확장 및 축소됩니다. 부하 분산은 ALB(Application Load Balancer)에서 처리합니다. 아키텍처는 분산된 세션 데이터를 관리할 수 있어야 합니다. 회사는 코드에 필요한 조정을 할 준비가 되어 있습니다.\\n설계에서 분산 세션 데이터 관리가 가능하도록 하는 솔루션 설계자의 책임은 무엇입니까?\\n\\nA.Amazon ElastiCache를 사용하여 세션 데이터를 관리하고 저장합니다.\\nB. ALB의 세션 선호도(고정 세션)를 사용하여 세션 데이터를 관리합니다.\\nC. AWS Systems Manager의 Session Manager를 사용하여 세션을 관리합니다.\\nD. AWS Security Token Service(AWS STS)에서 GetSessionToken API 작업을 사용하여 세션을 관리합니다.\", \"A solutions architect is tasked with the responsibility of creating the architecture for a new application that will be deployed to the AWS Cloud. Amazon EC2 On-Demand Instances will be used to execute the application, which will automatically scale across different Availability Zones. Throughout the day, the EC2 instances will scale up and down periodically. The load distribution will be handled by an Application Load Balancer (ALB). The architecture must be capable of managing dispersed session data. The firm is ready to make necessary adjustments to the code.\\nWhat is the solution architect's responsibility in ensuring that the design enables distributed session data management?\\n\\nA.Use Amazon ElastiCache to manage and store session data.\\nB. Use session affinity (sticky sessions) of the ALB to manage session data.\\nC. Use Session Manager from AWS Systems Manager to manage the session.\\nD. Use the GetSessionToken API operation in AWS Security Token Service (AWS STS) to manage the session.\", \"A. B는 인스턴스가 축소될 경우 세션 데이터 손실\"],\n[\"여러 Amazon EC2 Linux 인스턴스는 계층적 디렉터리 구조가 필요한 애플리케이션을 실행하기 위해 VPC의 비즈니스에서 사용됩니다. 앱은 빠르고 동시에 공유 저장소에 액세스하고 쓸 수 있어야 합니다.\\n이것은 어떻게 이루어지나요?\\n\\nA.Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성하고 각 EC2 인스턴스에서 탑재합니다.\\nB. Amazon S3 버킷을 생성하고 VPC의 모든 EC2 인스턴스에서 액세스를 허용합니다.\\nC. Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS SSD(io1) 볼륨에 파일 시스템을 생성합니다. 볼륨을 모든 EC2 인스턴스에 연결합니다.\\nD. 각 EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 시스템을 생성합니다. 다양한 EC2 인스턴스에서 Amazon Elastic Block Store(Amazon EBS) 볼륨을 동기화합니다.\", \"Multiple Amazon EC2 Linux instances are used by a business in a VPC to execute applications that need a hierarchical directory structure. The apps must be able to access and write to shared storage fast and simultaneously.\\nHow is this accomplished?\\n\\nA.Create an Amazon Elastic File System (Amazon EFS) file system and mount it from each EC2 instance.\\nB. Create an Amazon S3 bucket and permit access from all the EC2 instances in the VPC.\\nC. Create a file system on an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1) volume. Attach the volume to all the EC2 instances.\\nD. Create file systems on Amazon Elastic Block Store (Amazon EBS) volumes attached to each EC2 instance. Synchronize the Amazon Elastic Block Store (Amazon EBS) volumes across the different EC2 instances.\", \"A\"],\n[\"솔루션 설계자가 문서 관리 작업을 Amazon Web Services로 이전하는 중입니다. 워크로드는 공유 스토리지 파일 시스템 및 외부 데이터베이스에 7테라바이트의 계약 문서를 저장하고 추적합니다. 대부분의 기록은 보관되고 궁극적으로 나중에 참조할 수 있도록 복구됩니다. 마이그레이션 중에는 애플리케이션을 업데이트할 수 없으며 스토리지 솔루션은 고가용성이어야 합니다.\\nAmazon EC2의 Auto Scaling 그룹에 속한 웹 서버는 문서를 수집하고 저장합니다. Auto Scaling 그룹에는 최대 12개의 인스턴스가 있을 수 있습니다.\\n비용 효율성 측면에서 이러한 기준에 가장 적합한 옵션은 무엇입니까?\\n\\nA.공유 NFS 스토리지 시스템으로 사용할 향상된 네트워킹 최적화 EC2 인스턴스를 프로비저닝합니다.\\nB. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용하는 Amazon S3 버킷을 생성합니다. Auto Scaling 그룹의 EC2 인스턴스에 S3 버킷을 탑재합니다.\\nC. AWS Transfer for SFTP 및 Amazon S3 버킷을 사용하여 SFTP 서버 엔드포인트를 생성합니다. SFTP 서버에 연결하도록 Auto Scaling 그룹의 EC2 인스턴스를 구성합니다.\\nD. EFS Standard-Infrequent Access(EFS Standard-IA) 스토리지 클래스를 사용하는 Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. Auto Scaling 그룹의 EC2 인스턴스에 파일 시스템을 탑재합니다.\", \"A solutions architect is in the process of transferring a document management task to Amazon Web Services. The workload stores and tracks 7 terabytes of contract documents on a shared storage file system and an external database. The majority of records are archived and ultimately recovered for future reference. During the migration, the application cannot be updated, and the storage solution must be highly available.\\nWeb servers that are part of an Auto Scaling group on Amazon EC2 collect and store documents. There may be up to 12 instances in the Auto Scaling group.\\nWhich option best fits these criteria in terms of cost-effectiveness?\\n\\nA.Provision an enhanced networking optimized EC2 instance to serve as a shared NFS storage system.\\nB. Create an Amazon S3 bucket that uses the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Mount the S3 bucket to the EC2 instances in the Auto Scaling group.\\nC. Create an SFTP server endpoint by using AWS Transfer for SFTP and an Amazon S3 bucket. Configure the EC2 instances in the Auto Scaling group to connect to the SFTP server.\\nD. Create an Amazon Elastic File System (Amazon EFS) file system that uses the EFS Standard-Infrequent Access (EFS Standard-IA) storage class. Mount the file system to the EC2 instances in the Auto Scaling group.\", \"D\"],\n[\"회사는 월별 전화 기록을 유지합니다. 통계적으로 기록된 데이터는 1년 이내에 무작위로 참조될 수 있지만 해당 기간을 초과하여 검색되는 경우는 거의 없습니다.\\n1년 미만의 파일은 즉시 쿼리하고 검색해야 합니다. 오래된 파일을 가져오는 데 지연이 있는 것은 괜찮습니다. 솔루션 설계자는 캡처된 데이터가 가능한 가장 낮은 비용으로 저장되도록 해야 합니다.\\n가장 저렴한 옵션은 무엇입니까?\\n\\nA.Amazon S3 Glacier에 개별 파일을 저장하고 S3 Glacier에서 생성된 객체 태그에 검색 메타데이터를 저장하고 S3 Glacier 태그를 쿼리하고 S3 Glacier에서 파일을 검색합니다.\\nB. Amazon S3에 개별 파일을 저장합니다. 수명 주기 정책을 사용하여 1년 후에 파일을 Amazon S3 Glacier로 이동합니다. Amazon S3 또는 S3 Glacier에서 파일을 쿼리하고 검색합니다.\\nC. 개별 파일을 아카이브하고 Amazon S3의 각 아카이브에 대한 검색 메타데이터를 저장합니다. 수명 주기 정책을 사용하여 1년 후에 파일을 Amazon S3 Glacier로 이동합니다. Amazon S3에서 메타데이터를 검색하여 파일을 쿼리하고 검색합니다.\\nD. Amazon S3에 개별 파일을 보관합니다. 수명 주기 정책을 사용하여 1년 후에 파일을 Amazon S3 Glacier로 이동합니다. Amazon DynamoDB에 검색 메타데이터를 저장합니다. DynamoDB에서 파일을 쿼리하고 Amazon S3 또는 S3 Glacier에서 검색합니다.\", \"A business maintains monthly phone records. Statistically, recorded data may be referred to randomly within a year but is seldom retrieved beyond that time period.\\nFiles less than a year old must be queried and retrieved immediately. It is okay for there to be a delay in obtaining older files. A solutions architect must ensure that the captured data is stored at the lowest possible cost.\\nWhich option is the MOST CHEAPEST?\\n\\nA.Store individual files in Amazon S3 Glacier and store search metadata in object tags created in S3 Glacier Query S3 Glacier tags and retrieve the files from S3 Glacier.\\nB. Store individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after1 year. Query and retrieve the files from Amazon S3 or S3 Glacier.\\nC. Archive individual files and store search metadata for each archive in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files by searching for metadata from Amazon S3.\\nD. Archive individual files in Amazon S3. Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Store search metadata in Amazon DynamoDB. Query the files from DynamoDB and retrieve them from Amazon S3 or S3 Glacier.\", \"B\"],\n[\"비즈니스에서 워크로드를 AWS로 이동하려고 합니다. 최고 정보 보안 책임자(CIO)는 클라우드에 저장된 모든 데이터를 미사용 시 암호화할 것을 요구합니다. 조직은 암호화 키 수명 주기 관리 프로세스를 완전히 제어하기를 원합니다.\\n조직은 AWS CloudTrail과 별도로 키 자료를 즉시 삭제하고 키 사용을 감사할 수 있어야 합니다. 선택한 서비스는 다른 AWS 스토리지 서비스와 인터페이스해야 합니다.\\n이러한 보안 표준을 준수하는 서비스는 무엇입니까?\\n\\nA.CloudHSM 클라이언트가 있는 AWS CloudHSM\\nB. AWS CloudHSM을 사용한 AWS 키 관리 서비스(AWS KMS)\\nC. 외부 키 구성 요소 출처가 있는 AWS Key Management Service(AWS KMS)\\nD. AWS 관리형 고객 마스터 키(CMK)가 있는 AWS Key Management Service(AWS KMS)\", \"A business want to move a workload to AWS. The chief information security officer demands that any data stored in the cloud be encrypted at rest. The organization desires total control over the encryption key lifecycle management process.\\nIndependent of AWS CloudTrail, the organization must be able to promptly delete key material and audit key use. The selected services should interface with other AWS storage services.\\nWhich services adhere to these security standards?\\n\\nA.AWS CloudHSM with the CloudHSM client\\nB. AWS Key Management Service (AWS KMS) with AWS CloudHSM\\nC. AWS Key Management Service (AWS KMS) with an external key material origin\\nD. AWS Key Management Service (AWS KMS) with AWS managed customer master keys (CMKs)\", \"B, D 논란\"],\n[\"기업은 Amazon Web Services(AWS)에서 애플리케이션을 호스팅하고 Amazon DynamoDB를 데이터베이스로 활용합니다. 데이터베이스의 데이터를 처리하기 위해 조직은 Amazon EC2 인스턴스를 사설 네트워크에 추가합니다. 조직은 2개의 NAT 인스턴스를 사용하여 DynamoDB에 연결합니다.\\n회사는 NAT 인스턴스를 폐기하려고 합니다. 솔루션 설계자는 DynamoDB에 연결되고 자체 관리되는 솔루션을 개발해야 합니다.\\n이러한 요구 사항을 충족하는 측면에서 가장 비용 효율적인 접근 방식은 무엇입니까?\\n\\nA.DynamoDB에 대한 연결을 제공하기 위해 게이트웨이 VPC 엔드포인트를 생성합니다.\\nB. DynamoDB에 대한 연결을 제공하도록 관리형 NAT 게이트웨이를 구성합니다.\\nC. 사설 네트워크와 DynamoDB 간에 AWS Direct Connect 연결을 설정합니다.\\nD. 사설 네트워크와 DynamoDB 간에 AWS PrivateLink 엔드포인트 서비스를 배포합니다.\", \"A business hosts an application on Amazon Web Services (AWS) and utilizes Amazon DynamoDB as the database. To handle data from the database, the organization adds Amazon EC2 instances to a private network. The organization connects to DynamoDB using two NAT instances.\\nThe corporation want to decommission its NAT instances. A solutions architect must develop a solution that connects to DynamoDB and is self-managing.\\nWhich approach is the MOST cost-effective in terms of meeting these requirements?\\n\\nA.Create a gateway VPC endpoint to provide connectivity to DynamoDB.\\nB. Configure a managed NAT gateway to provide connectivity to DynamoDB.\\nC. Establish an AWS Direct Connect connection between the private network and DynamoDB.\\nD. Deploy an AWS PrivateLink endpoint service between the private network and DynamoDB.\", \"A\"],\n[\"기업은 다양한 가용 영역에 걸쳐 있는 가상 사설 클라우드(VPC)에서 3계층 웹 애플리케이션을 호스팅합니다. 애플리케이션 계층의 경우 Amazon EC2 인스턴스는 Auto Scaling 그룹에 배포됩니다.\\n조직은 각 리소스에 대한 일일 및 주간 워크로드 패턴을 분석하는 자동화된 확장 전략을 개발해야 합니다. 설정은 소비의 예측 및 실제 변경 모두에 대응하여 리소스를 올바르게 확장해야 합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자가 제안해야 하는 확장 접근 방식(있는 경우)은 무엇입니까?\\n\\nA.EC2 인스턴스의 평균 CPU 사용률을 기반으로 한 단계적 확장으로 동적 확장을 구현합니다.\\nB. 예측 및 확장을 위해 예측 확장을 활성화합니다. 대상 추적으로 동적 확장을 구성합니다.\\nC. 웹 애플리케이션의 트래픽 패턴을 기반으로 자동화된 예약된 조정 작업을 생성합니다.\\nD. 간단한 확장 정책을 설정합니다. EC2 인스턴스 시작 시간에 따라 휴지 기간을 늘립니다.\", \"A business hosts a three-tier web application on a virtual private cloud (VPC) that spans various Availability Zones. For the application layer, Amazon EC2 instances are deployed in an Auto Scaling group.\\nThe organization must develop an automated scaling strategy that analyzes the daily and weekly workload patterns for each resource. The setup must correctly scale resources in response to both forecasted and actual changes in consumption.\\nWhich scaling approach, if any, should a solutions architect propose in order to satisfy these requirements?\\n\\nA.Implement dynamic scaling with step scaling based on average CPU utilization from the EC2 instances.\\nB. Enable predictive scaling to forecast and scale. Configure dynamic scaling with target tracking.\\nC. Create an automated scheduled scaling action based on the traffic patterns of the web application.\\nD. Set up a simple scaling policy. Increase the cooldown period based on the EC2 instance startup time.\", \"B\"],\n[\"기업은 MySQL 데이터베이스를 운영하도록 구성된 자체 Amazon EC2 인스턴스를 관리합니다. 회사는 수요가 증가하거나 감소함에 따라 수동으로 복제 및 확장을 관리합니다. 조직에는 필요에 따라 데이터베이스 계층에서 컴퓨팅 리소스를 더 쉽게 추가하거나 제거할 수 있는 새로운 솔루션이 필요합니다. 또한 솔루션은 운영 부분에서 거의 작업을 수행하지 않고도 속도, 확장성 및 내구성을 높여야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.데이터베이스를 Aurora MySQL용 Amazon Aurora Serverless로 마이그레이션합니다.\\nB. 데이터베이스를 Aurora PostgreSQL용 Amazon Aurora Serverless로 마이그레이션합니다.\\nC. 데이터베이스를 하나의 더 큰 MySQL 데이터베이스로 결합합니다. 더 큰 EC2 인스턴스에서 더 큰 데이터베이스를 실행합니다.\\nD. 데이터베이스 계층에 대한 EC2 Auto Scaling 그룹을 생성합니다. 기존 데이터베이스를 새 환경으로 마이그레이션합니다.\", \"A business administers its own Amazon EC2 instances, which are configured to operate MySQL databases. The firm manages replication and scaling manually as demand grows or falls. The organization need a new solution that makes it easier to add or remove computing resources from its database layer as required. Additionally, the solution must increase speed, scalability, and durability with little work on the part of operations.\\nWhich solution satisfies these criteria?\\n\\nA.Migrate the databases to Amazon Aurora Serverless for Aurora MySQL.\\nB. Migrate the databases to Amazon Aurora Serverless for Aurora PostgreSQL.\\nC. Combine the databases into one larger MySQL database. Run the larger database on larger EC2 instances.\\nD. Create an EC2 Auto Scaling group for the database tier. Migrate the existing databases to the new environment.\", \"A\"],\n[\"비즈니스에서 두 개의 앱을 AWS로 이전하려고 합니다. 두 앱 모두 동일한 파일에 액세스하여 엄청난 수의 파일을 동시에 처리합니다. 두 프로그램 모두 최소한의 지연으로 파일을 읽어야 합니다.\\n이 경우 솔루션 아키텍트가 제안하는 아키텍처는 무엇입니까?\\n\\nA.두 개의 AWS Lambda 함수를 구성하여 애플리케이션을 실행합니다. 데이터를 저장할 인스턴스 스토어 볼륨이 있는 Amazon EC2 인스턴스를 생성합니다.\\nB. 애플리케이션을 실행하도록 두 개의 AWS Lambda 함수를 구성합니다. 데이터를 저장할 Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 Amazon EC2 인스턴스를 생성합니다.\\nC. 두 애플리케이션을 동시에 실행하도록 하나의 메모리 최적화 Amazon EC2 인스턴스를 구성합니다. 프로비저닝된 IOPS로 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하여 데이터를 저장합니다.\\nD. 두 애플리케이션을 모두 실행하도록 두 개의 Amazon EC2 인스턴스를 구성합니다. 범용 성능 모드 및 버스팅 처리량 모드로 Amazon Elastic File System(Amazon EFS)을 구성하여 데이터를 저장합니다.\", \"A business want to transfer two apps to AWS. Both apps handle a huge number of files concurrently by accessing the same files. Both programs must read files with a minimum of delay.\\nWhich architecture would a solutions architect suggest in this case?\\n\\nA.Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an instance store volume to store the data.\\nB. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an Amazon Elastic Block Store (Amazon EBS) volume to store the data.\\nC. Configure one memory optimized Amazon EC2 instance to run both applications simultaneously. Create an Amazon Elastic Block Store (Amazon EBS) volume with Provisioned IOPS to store the data.\\nD. Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data.\", \"D\"],\n[\"기업은 Kubernetes 클러스터를 사용하여 온프레미스 데이터 센터에서 컨테이너화된 애플리케이션을 운영합니다. 조직은 데이터를 MongoDB 데이터베이스에 저장합니다.\\n조직은 이러한 환경 중 일부를 AWS로 전환하기를 원하지만 현재 코드 또는 배포 방법을 수정할 수 없습니다. 비즈니스에는 운영 비용을 낮추는 솔루션이 필요합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.컴퓨팅용 Amazon EC2 작업자 노드와 데이터 저장용 EC2의 MongoDB와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.\\nB. 컴퓨팅용 AWS Fargate 및 데이터 저장용 Amazon DynamoDB와 함께 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.\\nC. 컴퓨팅용 Amazon EC2 작업자 노드 및 데이터 저장용 Amazon DynamoDB와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다.\\nD. 컴퓨팅용 AWS Fargate 및 데이터 저장용 Amazon DocumentDB(MongoDB 호환 가능)와 함께 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다.\", \"A corporation operates a containerized application in an on-premises data center using a Kubernetes cluster. The organization stores data in a MongoDB database.\\nThe organization want to transition some of these environments to AWS, but no modifications to the code or deployment methods are currently feasible. The business need a solution that lowers operating costs.\\nWhich solution satisfies these criteria?\\n\\nA.Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 worker nodes for compute and MongoDB on EC2 for data storage.\\nB. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute and Amazon DynamoDB for data storage.\\nC. Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 worker nodes for compute and Amazon DynamoDB for data storage.\\nD. Use Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate for compute and Amazon DocumentDB (with MongoDB compatibility) for data storage.\", \"D\"],\n[\"비즈니스에 Amazon DynamoDB 데이터 스토리지를 활용하는 모바일 채팅 애플리케이션이 있습니다. 사용자는 새로운 메시지를 읽는 동안 가능한 한 짧은 지연을 원합니다. 솔루션 설계자의 목표는 가능한 최소한의 애플리케이션 수정으로 최적의 솔루션을 제공하는 것입니다.\\n솔루션 아키텍트가 선택해야 하는 기술은 무엇입니까?\\n\\nA.새 메시지 테이블에 대해 Amazon DynamoDB Accelerator(DAX)를 구성합니다. DAX 끝점을 사용하도록 코드를 업데이트합니다.\\nB. 증가된 읽기 로드를 처리하기 위해 DynamoDB 읽기 전용 복제본을 추가합니다. 읽기 전용 복제본의 읽기 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다.\\nC. DynamoDB의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다. 기존 DynamoDB 엔드포인트를 계속 사용합니다.\\nD. Redis용 Amazon ElastiCache 캐시를 애플리케이션 스택에 추가합니다. DynamoDB 대신 Redis 캐시 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다.\", \"A business has a mobile chat application that utilizes an Amazon DynamoDB data storage. Users want as low delay as possible while reading fresh messages. A solutions architect's objective is to provide the optimum solution with the fewest possible application modifications.\\nWhich technique should be chosen by the solutions architect?\\n\\nA.Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint.\\nB. Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas.\\nC. Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint.\\nD. Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB.\", \"A\"],\n[\"기업은 Amazon Web Services를 활용하여 3계층 애플리케이션의 모든 구성 요소를 호스팅합니다. 조직은 환경 내부의 가능한 보안 취약성을 자동으로 식별하기를 원합니다. 조직은 발견을 추적하고 위반이 의심되는 경우 관리자에게 경고하기를 원합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.의심스러운 웹 트래픽을 평가하도록 AWS WAF를 설정합니다. AWS Lambda 함수를 생성하여 Amazon CloudWatch의 모든 결과를 기록하고 관리자에게 이메일 알림을 보냅니다.\\nB. AWS Shield를 설정하여 의심스러운 웹 트래픽을 평가합니다. AWS Lambda 함수를 생성하여 Amazon CloudWatch의 모든 결과를 기록하고 관리자에게 이메일 알림을 보냅니다.\\nC. Amazon Inspector를 배포하여 환경을 모니터링하고 Amazon CloudWatch에서 결과를 생성합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 구성하여 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시하여 이메일로 관리자에게 알립니다.\\nD. Amazon GuardDuty를 배포하여 환경을 모니터링하고 Amazon CloudWatch에서 결과를 생성합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 구성하여 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시하여 이메일로 관리자에게 알립니다.\", \"A business utilizes Amazon Web Services to host all components of its three-tier application. The organization want to identify any possible security vulnerabilities inside the environment automatically. The organization want to keep track of any discoveries and to warn administrators in the event of a suspected breach.\\nWhich solution satisfies these criteria?\\n\\nA.Set up AWS WAF to evaluate suspicious web traffic. Create AWS Lambda functions to log any findings in Amazon CloudWatch and send email notifications to administrators.\\nB. Set up AWS Shield to evaluate suspicious web traffic. Create AWS Lambda functions to log any findings in Amazon CloudWatch and send email notifications to administrators.\\nC. Deploy Amazon Inspector to monitor the environment and generate findings in Amazon CloudWatch. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic to notify administrators by email.\\nD. Deploy Amazon GuardDuty to monitor the environment and generate findings in Amazon CloudWatch. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic to notify administrators by email.\", \"C. Inspector가 사전 예방에 사용되기 때문. 그러나 Inspector는 EC2전용이라 D가 답이라는 의견 존재.\"],\n[\"Amazon RDS MySQL DB 인스턴스에서 회사의 프로덕션 애플리케이션은 OLTP(온라인 트랜잭션 처리) 트랜잭션을 처리합니다. 이 회사는 또한 동일한 데이터 액세스 권한을 가진 새로운 보고 도구를 제공하고 있습니다. 보고 도구는 액세스 가능성이 높아야 하며 프로덕션 응용 프로그램의 성능에 부정적인 영향을 미치지 않아야 합니다.\\n이것은 어떻게 이루어지나요?\\n\\nA.프로덕션 RDS DB 인스턴스의 시간별 스냅샷을 생성합니다.\\nB. 프로덕션 RDS DB 인스턴스의 다중 AZ RDS 읽기 전용 복제본을 생성합니다.\\nC. 프로덕션 RDS DB 인스턴스의 여러 RDS 읽기 전용 복제본을 생성합니다. Auto Scaling 그룹에 읽기 전용 복제본을 배치합니다.\\nD. 프로덕션 RDS DB 인스턴스의 단일 AZ RDS 읽기 전용 복제본을 생성합니다. 복제본에서 두 번째 단일 AZ RDS 읽기 전용 복제본을 생성합니다.\", \"On an Amazon RDS MySQL DB instance, a company's production application processes online transaction processing (OLTP) transactions. The firm is also offering a new reporting tool with the same data access. The reporting tool must be highly accessible and have no adverse effect on the production application's performance.\\nHow is this accomplished?\\n\\nA.Create hourly snapshots of the production RDS DB instance.\\nB. Create a Multi-AZ RDS Read Replica of the production RDS DB instance.\\nC. Create multiple RDS Read Replicas of the production RDS DB instance. Place the Read Replicas in an Auto Scaling group.\\nD. Create a Single-AZ RDS Read Replica of the production RDS DB instance. Create a second Single-AZ RDS Read Replica from the replica.\", \"B\"],\n[\"솔루션 설계자는 작업자와 파트너 간의 파일 교환을 가능하게 하는 온프레미스 시스템에 대한 완전 관리형 대안을 제공해야 합니다. 온프레미스 시스템, 원격 직원 및 외부 파트너에서 연결하는 작업자는 솔루션에 쉽게 액세스할 수 있어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Transfer for SFTP를 사용하여 Amazon S3 안팎으로 파일을 전송합니다.\\nB. 로컬 스토리지 및 대규모 데이터 전송에 AWS Snowball Edge를 사용합니다.\\nC. Amazon FSx를 사용하여 파일을 저장하고 전송하여 원격으로 사용할 수 있도록 합니다.\\nD. AWS Storage Gateway를 사용하여 Amazon S3에 파일을 저장하고 전송할 볼륨 게이트웨이를 생성합니다.\", \"A solutions architect must offer a fully managed alternative to an on-premises system that enables file interchange between workers and partners. Workers connecting from on-premises systems, remote employees, and external partners must have easy access to the solution.\\nWhich solution satisfies these criteria?\\n\\nA.Use AWS Transfer for SFTP to transfer files into and out of Amazon S3.\\nB. Use AWS Snowball Edge for local storage and large-scale data transfers.\\nC. Use Amazon FSx to store and transfer files to make them available remotely.\\nD. Use AWS Storage Gateway to create a volume gateway to store and transfer files to Amazon S3.\", \"A\"],\n[\"기업은 프라이빗 서브넷의 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 프로그램은 Amazon S3에서 데이터를 저장하고 검색할 수 있어야 합니다. 비용을 절감하기 위해 회사는 AWS 리소스 구성을 최적화하려고 합니다.\\n비즈니스는 이 작업을 어떻게 수행해야 합니까?\\n\\nA.NAT 게이트웨이를 배포하여 S3 버킷에 액세스합니다.\\nB. AWS Storage Gateway를 배포하여 S3 버킷에 액세스합니다.\\nC. S3 버킷에 액세스하기 위해 S3 게이트웨이 엔드포인트를 배포합니다.\\nD. S3 버킷에 액세스하기 위해 S3 인터페이스 엔드포인트를 배포합니다.\", \"A business is operating an application on Amazon EC2 instances on a private subnet. The program must be capable of storing and retrieving data from Amazon S3. To save expenses, the corporation wishes to optimize the configuration of its AWS resources.\\nHow should the business go about doing this?\\n\\nA.Deploy a NAT gateway to access the S3 buckets.\\nB. Deploy AWS Storage Gateway to access the S3 buckets.\\nC. Deploy an S3 gateway endpoint to access the S3 buckets.\\nD. Deploy an S3 interface endpoint to access the S3 buckets.\", \"C\"],\n[\"AWS는 기업에서 사용자 데이터를 저장하는 데 사용합니다. 데이터는 지속적으로 액세스되며 작업 시간 동안 최대 사용량이 발생합니다. 액세스 패턴은 다양하며 일부 데이터는 액세스하지 않고 몇 개월이 걸립니다. 솔루션 설계자는 높은 수준의 가용성을 유지하면서 비용 효율적이고 내구성 있는 솔루션을 선택해야 합니다.\\n이 기준을 충족하는 스토리지 옵션은 무엇입니까?\\n\\nA.Amazon S3 표준\\nB. Amazon S3 지능형 계층화\\nC. Amazon S3 Glacier 딥 아카이브\\nD. Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)\", \"AWS is used by a business to store user data. The data is continually accessed, with peak consumption occurring during work hours. Access patterns vary, with some data going months without being accessed. A solutions architect must pick a solution that is both cost efficient and durable, while also maintaining a high degree of availability.\\nWhich storage option satisfies these criteria?\\n\\nA.Amazon S3 Standard\\nB. Amazon S3 Intelligent-Tiering\\nC. Amazon S3 Glacier Deep Archive\\nD. Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"B\"],\n[\"기업은 Amazon EC2 인스턴스를 사용하여 레거시 데이터 처리 애플리케이션을 운영합니다. 데이터는 순차적으로 처리되지만 결과의 순서는 중요하지 않습니다.\\n응용 프로그램은 모놀리식 방식으로 설계되었습니다. 비즈니스가 증가하는 수요에 대응하여 애플리케이션을 확장할 수 있는 유일한 방법은 인스턴스 크기를 늘리는 것입니다.\\n조직의 엔지니어는 Amazon Elastic Container Service(Amazon ECS)를 사용하는 마이크로서비스 아키텍처를 사용하여 프로그램을 재설계하기로 결정했습니다.\\n솔루션 설계자는 마이크로서비스 간 통신을 위해 무엇을 제안해야 합니까?\\n\\nA.Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. 데이터 생산자에 코드를 추가하고 큐에 데이터를 보냅니다. 데이터 소비자에게 코드를 추가하여 대기열의 데이터를 처리합니다.\\nB. Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. 데이터 생산자에 코드를 추가하고 주제에 알림을 게시합니다. 데이터 소비자에 코드를 추가하여 주제를 구독합니다.\\nC. 메시지를 전달할 AWS Lambda 함수를 생성합니다. 데이터 생성자에 코드를 추가하여 데이터 객체로 Lambda 함수를 호출합니다. 데이터 소비자에게 코드를 추가하여 Lambda 함수에서 전달된 데이터 객체를 수신합니다.\\nD. Amazon DynamoDB 테이블을 생성합니다. DynamoDB 스트림을 활성화합니다. 데이터 생산자에 코드를 추가하여 테이블에 데이터를 삽입합니다. 데이터 소비자에 코드를 추가하여 DynamoDB Streams API를 사용하여 새 테이블 항목을 감지하고 데이터를 검색합니다.\", \"A business uses Amazon EC2 instances to operate a legacy data processing application. Although data is processed sequentially, the order of the findings is irrelevant.\\nThe application is designed in a monolithic fashion. The only method for the business to expand the application in response to rising demand is to raise the instance size.\\nThe engineers at the organization have chosen to redesign the program using a microservices architecture using Amazon Elastic Container Service (Amazon ECS).\\nWhat should a solutions architect propose for inter-microservice communication?\\n\\nA.Create an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue.\\nB. Create an Amazon Simple Notification Service (Amazon SNS) topic. Add code to the data producers, and publish notifications to the topic. Add code to the data consumers to subscribe to the topic.\\nC. Create an AWS Lambda function to pass messages. Add code to the data producers to call the Lambda function with a data object. Add code to the data consumers to receive a data object that is passed from the Lambda function.\\nD. Create an Amazon DynamoDB table. Enable DynamoDB Streams. Add code to the data producers to insert data into the table. Add code to the data consumers to use the DynamoDB Streams API to detect new table entries and retrieve the data.\", \"A\"],\n[\"한 기업이 클래식 애플리케이션을 AWS로 마이그레이션하는 것을 고려하고 있습니다. 현재 애플리케이션은 NFS를 통해 온프레미스 스토리지 시스템과 통신합니다. NFS 이외의 다른 통신 프로토콜을 사용하여 이 기능을 수행하도록 프로그램을 변경할 수 없습니다.\\n솔루션 설계자는 마이그레이션 후 사용을 위해 어떤 스토리지 솔루션을 제안해야 합니까?\\n\\nA.AWS 데이터싱크\\nB. Amazon Elastic Block Store(Amazon EBS)\\nC. Amazon Elastic File System(Amazon EFS)\\nD. Amazon EMR 파일 시스템(Amazon EMRFS)\", \"A business is considering migrating a classic application to AWS. Currently, the application communicates with an on-premises storage system through NFS. The program cannot be changed to perform this function using any other communication protocol than NFS.\\nWhich storage solution, if any, should a solutions architect propose for post-migration use?\\n\\nA.AWS DataSync\\nB. Amazon Elastic Block Store (Amazon EBS)\\nC. Amazon Elastic File System (Amazon EFS)\\nD. Amazon EMR File System (Amazon EMRFS)\", \"C. EFS는 NFS 프로토콜을 사용함.\"],\n[\"기업은 확장성 및 가용성 요구 사항을 충족하기 위해 컨테이너에서 미션 크리티컬 앱을 실행하려고 합니다. 회사는 오히려 주요 애플리케이션 유지 관리에 집중할 것입니다. 회사는 컨테이너화된 워크로드의 기본 인프라 프로비저닝 및 유지 관리에 대한 책임을 원하지 않습니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon EC2 인스턴스를 사용하고 인스턴스에 Docker를 설치합니다.\\nB. Amazon EC2 작업자 노드에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.\\nC. AWS Fargate에서 Amazon Elastic Container Service(Amazon ECS)를 사용합니다.\\nD. Amazon Elastic Container Service(Amazon ECS)에 최적화된 Amazon 머신 이미지(AMI)의 Amazon EC2 인스턴스를 사용합니다.\", \"A business wishes to run its mission-critical apps in containers in order to fulfill scalability and availability requirements. The corporation would rather concentrate on key application maintenance. The firm does not want to be responsible for provisioning and maintaining the containerized workload's underlying infrastructure.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Use Amazon EC2 instances, and install Docker on the instances.\\nB. Use Amazon Elastic Container Service (Amazon ECS) on Amazon EC2 worker nodes.\\nC. Use Amazon Elastic Container Service (Amazon ECS) on AWS Fargate.\\nD. Use Amazon EC2 instances from an Amazon Elastic Container Service (Amazon ECS)-optimized Amazon Machine Image (AMI).\", \"C. fargate는 서버리스이기 때문에 관리에 대한 필요성 없음\"],\n[\"기업은 이벤트 데이터를 생성하는 서비스를 운영합니다. 회사는 이벤트 데이터를 수신하는 대로 처리하기 위해 AWS를 사용하고자 합니다. 데이터는 처리 중에 보존되어야 하는 특정 순서로 구조화됩니다. 회사는 가능한 가장 낮은 운영 비용으로 솔루션을 배포하기를 원합니다.\\n솔루션 아키텍트가 이 작업을 어떻게 수행합니까?\\n\\nA.메시지를 보관할 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 생성합니다. 대기열의 메시지를 처리하도록 AWS Lambda 함수를 설정합니다.\\nB. 처리할 페이로드가 포함된 알림을 전달하기 위해 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. AWS Lambda 함수를 구독자로 구성합니다.\\nC. 메시지를 보관할 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 생성합니다. 대기열의 메시지를 독립적으로 처리하도록 AWS Lambda 함수를 설정합니다.\\nD. 처리할 페이로드가 포함된 알림을 전달하기 위해 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. Amazon Simple Queue Service(Amazon SQS) 대기열을 구독자로 구성합니다.\", \"A business operates a service that generates event data. The firm wishes to use AWS for the purpose of processing event data as it is received. The data is structured in a certain sequence that must be preserved during processing. The firm wishes to deploy a solution with the lowest possible operating costs.\\nHow is this to be accomplished by a solution architect?\\n\\nA.Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.\\nB. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an AWS Lambda function as a subscriber.\\nC. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to hold messages. Set up an AWS Lambda function to process messages from the queue independently.\\nD. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a subscriber.\", \"A\"],\n[\"비즈니스 데이터베이스는 Amazon Aurora MySQL DB 클러스터의 us-east-1 리전에서 호스팅됩니다. 데이터베이스 크기는 약 4TB입니다. 회사의 재해 복구 계획은 us-west-2 지역을 포함하도록 확장되어야 합니다. 회사는 15분 RTO(복구 시간 목표) 내에 us-west-2로 장애 조치할 수 있어야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.us-east-1 및 use-west-2에 다중 리전 Aurora MySQL DB 클러스터를 생성합니다. Amazon Route 53 상태 확인을 사용하여 us-east-1을 모니터링하고 실패 시 us-west-2로 장애 조치합니다.\\nB. us-east-1에서 DB 클러스터의 스냅샷을 생성합니다. 리소스 이벤트 수신 시 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 구성합니다. 스냅샷을 us-west-2에 복사하고 실패가 감지되면 us-west-2에서 스냅샷을 복원하도록 Lambda 함수를 구성합니다.\\nC. AWS CloudFormation 스크립트를 생성하여 실패 시 us-west-2에 다른 Aurora MySQL DB 클러스터를 생성합니다. 리소스 이벤트 수신 시 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 구성합니다. 장애가 감지되면 us-west-2에 AWS CloudFormation 스택을 배포하도록 Lambda 함수를 구성합니다.\\nD. us-east-1의 기본 DB 클러스터와 us-west-2의 보조 DB 클러스터를 사용하여 데이터베이스를 Aurora 글로벌 데이터베이스로 다시 생성합니다. 리소스 이벤트 수신 시 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 구성합니다. 장애가 감지되면 us-west-2에서 DB 클러스터를 승격하도록 Lambda 함수를 구성합니다.\", \"The database of a business is hosted in the us-east-1 Region on an Amazon Aurora MySQL DB cluster. The database is around 4 terabytes in size. The company's disaster recovery plan should be expanded to include the us-west-2 region. The firm must be able to fail over to us-west-2 within a 15-minute recovery time goal (RTO).\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Create a Multi-Region Aurora MySQL DB cluster in us-east-1 and use-west-2. Use an Amazon Route 53 health check to monitor us-east-1 and fail over to us- west-2 upon failure.\\nB. Take a snapshot of the DB cluster in us-east-1. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function upon receipt of resource events. Configure the Lambda function to copy the snapshot to us-west-2 and restore the snapshot in us-west-2 when failure is detected.\\nC. Create an AWS CloudFormation script to create another Aurora MySQL DB cluster in us-west-2 in case of failure. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function upon receipt of resource events. Configure the Lambda function to deploy the AWS CloudFormation stack in us-west-2 when failure is detected.\\nD. Recreate the database as an Aurora global database with the primary DB cluster in us-east-1 and a secondary DB cluster in us-west-2. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that invokes an AWS Lambda function upon receipt of resource events. Configure the Lambda function to promote the DB cluster in us-west-2 when failure is detected.\", \"D. A에서 Multi region aurora는 존재하지 않음. 나머지는 RTO를 만족시키지 않음.\"],\n[\"기업에서 거의 실시간 스트리밍 데이터를 처리하는 애플리케이션을 설치하고 있습니다. 워크로드는 Amazon EC2 인스턴스에서 실행됩니다. 네트워크 아키텍처는 노드 간의 대기 시간이 가능한 한 최소화되도록 구성해야 합니다.\\n이러한 요구 사항에 적합한 네트워크 솔루션 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.각 EC2 인스턴스에서 향상된 네트워킹을 활성화하고 구성합니다.\\nB. EC2 인스턴스를 별도의 계정으로 그룹화합니다.\\nC. 클러스터 배치 그룹에서 EC2 인스턴스를 실행합니다.\\nD. 각 EC2 인스턴스에 여러 개의 탄력적 네트워크 인터페이스를 연결합니다.\\nE. Amazon Elastic Block Store(Amazon EBS)에 최적화된 인스턴스 유형을 사용합니다.\", \"A business is installing an application that handles near-real-time streaming data. The workload will be run on Amazon EC2 instances. The network architecture must be configured in such a way that the latency between nodes is as minimal as feasible.\\nWhich network solution combination will suit these requirements? (Select two.)\\n\\nA.Enable and configure enhanced networking on each EC2 instance.\\nB. Group the EC2 instances in separate accounts.\\nC. Run the EC2 instances in a cluster placement group.\\nD. Attach multiple elastic network interfaces to each EC2 instance.\\nE. Use Amazon Elastic Block Store (Amazon EBS) optimized instance types.\", \"A, C\"],\n[\"기업은 시장 분석 관리를 제3자 파트너에게 아웃소싱합니다. 공급업체는 회사 계정의 리소스에 대한 제한된 프로그래밍 방식 액세스를 요구합니다. 허용 가능한 액세스를 보장하기 위해 필요한 모든 정책이 수립되었습니다.\\n공급업체에 계정에 대한 가장 안전한 액세스를 제공하는 새로운 구성 요소는 무엇입니까?\\n\\nA.IAM 사용자를 생성합니다.\\nB. 서비스 제어 정책(SCP) 구현\\nC. 외부 ID가 있는 교차 계정 역할을 사용합니다.\\nD. SSO(Single Sign-On) ID 공급자를 구성합니다.\", \"A business outsources its marketplace analytics management to a third-party partner. The vendor requires restricted programmatic access to the company's account's resources. All necessary policies have been established to ensure acceptable access.\\nWhich new component provides the vendor the MOST SECURE access to the account?\\n\\nA.Create an IAM user.\\nB. Implement a service control policy (SCP)\\nC. Use a cross-account role with an external ID.\\nD. Configure a single sign-on (SSO) identity provider.\", \"C\"],\n[\"비즈니스는 두 개의 Amazon EC2 인스턴스를 사용하여 동적 웹 애플리케이션을 실행합니다. 조직에는 각 인스턴스에서 SSL 종료를 완료하는 데 사용되는 자체 SSL 인증서가 있습니다.\\n최근 트래픽이 증가하고 있으며, 운영팀은 SSL 암호화 및 복호화로 인해 웹 서버의 컴퓨팅 용량이 한도를 초과한다는 결론을 내렸습니다.\\n솔루션 설계자는 애플리케이션의 성능을 최적화하기 위해 무엇을 해야 합니까?\\n\\nA.AWS Certificate Manager(ACM)를 사용하여 새 SSL 인증서를 생성합니다. 각 인스턴스에 ACM 인증서를 설치합니다.\\nB. Amazon S3 버킷을 생성합니다. SSL 인증서를 S3 버킷으로 마이그레이션합니다. SSL 종료를 위해 버킷을 참조하도록 EC2 인스턴스를 구성합니다.\\nC. 다른 EC2 인스턴스를 프록시 서버로 생성합니다. SSL 인증서를 새 인스턴스로 마이그레이션하고 기존 EC2 인스턴스에 직접 연결하도록 구성합니다.\\nD. SSL 인증서를 AWS Certificate Manager(ACM)로 가져옵니다. ACM의 SSL 인증서를 사용하는 HTTPS 리스너로 Application Load Balancer를 생성합니다.\", \"A business uses two Amazon EC2 instances to run a dynamic web application. The organization has its own SSL certificate, which is used to complete SSL termination on each instance.\\nRecently, there has been an increase in traffic, and the operations team concluded that SSL encryption and decryption is causing the web servers' compute capacity to surpass its limit.\\nWhat should a solutions architect do to optimize the performance of an application?\\n\\nA.Create a new SSL certificate using AWS Certificate Manager (ACM). Install the ACM certificate on each instance.\\nB. Create an Amazon S3 bucket. Migrate the SSL certificate to the S3 bucket. Configure the EC2 instances to reference the bucket for SSL termination.\\nC. Create another EC2 instance as a proxy server. Migrate the SSL certificate to the new instance and configure it to direct connections to the existing EC2 instances.\\nD. Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM.\", \"D\"],\n[\"한 기업이 AWS Well-Architected 프레임워크를 사용하여 AWS에 배치된 기존 워크로드를 평가하고 있습니다. 평가 결과 다른 AWS 서비스를 지원하기 위해 새로 설치된 Microsoft Active Directory 도메인 컨트롤러와 동일한 Amazon EC2 인스턴스에서 작동하는 공개 웹 사이트를 발견했습니다. 솔루션 설계자는 아키텍처의 보안을 강화하고 IT 작업자의 관리 부담을 줄이는 새로운 설계를 제공해야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.AWS Directory Service를 사용하여 관리형 Active Directory를 생성합니다. 현재 EC2 인스턴스에서 Active Directory를 제거합니다.\\nB. 동일한 서브넷에 다른 EC2 인스턴스를 생성하고 여기에 Active Directory를 다시 설치합니다. Active Directory를 제거합니다.\\nC. AWS Directory Service를 사용하여 Active Directory 커넥터를 생성합니다. 현재 EC2 인스턴스에서 실행 중인 Active 도메인 컨트롤러에 Active Directory 요청을 프록시합니다.\\nD. 현재 Active Directory 컨트롤러와 SAML(Security Assertion Markup Language) 2.0 연동으로 AWS Single Sign-On(AWS SSO)을 활성화합니다. Active Directory에 대한 공개 액세스를 거부하도록 EC2 인스턴스의 보안 그룹을 수정합니다.\", \"A corporation is doing an evaluation of an existing workload placed on AWS using the AWS Well-Architected Framework. The evaluation discovered a public-facing website operating on the same Amazon EC2 instance as a freshly installed Microsoft Active Directory domain controller to support other AWS services. A solutions architect must offer a new design that increases the architecture's security and reduces the administrative burden on IT workers.\\nWhat recommendations should the solutions architect make?\\n\\nA.Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance.\\nB. Create another EC2 instance in the same subnet and reinstall Active Directory on it. Uninstall Active Directory.\\nC. Use AWS Directory Service to create an Active Directory connector. Proxy Active Directory requests to the Active domain controller running on the current EC2 instance.\\nD. Enable AWS Single Sign-On (AWS SSO) with Security Assertion Markup Language (SAML) 2.0 federation with the current Active Directory controller. Modify the EC2 instance's security group to deny public access to Active Directory.\", \"A\"],\n[\"Amazon Aurora는 최근 회사의 전 세계 전자 상거래 플랫폼을 위한 데이터 리포지토리로 선택되었습니다. 개발자가 광범위한 보고서를 실행할 때 전자 상거래 애플리케이션의 성능이 좋지 않음을 발견합니다. 월별 보고서를 수행할 때 솔루션 설계자는 ReadIOPS 및 CPUUtilization 메트릭이 급증하는 것을 확인합니다.\\n어떤 접근 방식이 가장 비용 효율적입니까?\\n\\nA.월별 보고를 Amazon Redshift로 마이그레이션합니다.\\nB. 월별 보고를 Aurora 복제본으로 마이그레이션합니다.\\nC. Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다.\\nD. Aurora 인스턴스에서 프로비저닝된 IOPS를 늘립니다.\", \"Amazon Aurora was recently selected as the data repository for a company's worldwide ecommerce platform. When developers run extensive reports, they discover that the ecommerce application is performing badly. When monthly reports are performed, a solutions architect notices that the ReadIOPS and CPUUtilization metrics spike.\\nWhich approach is the MOST cost-effective?\\n\\nA.Migrate the monthly reporting to Amazon Redshift.\\nB. Migrate the monthly reporting to an Aurora Replica.\\nC. Migrate the Aurora database to a larger instance class.\\nD. Increase the Provisioned IOPS on the Aurora instance.\", \"B\"],\n[\"기업의 백업 데이터는 총 700TB이며 데이터 센터의 NAS(Network Attached Storage)에 보관됩니다. 이 백업 데이터는 규제 관련 문의가 있을 경우 사용할 수 있어야 하며 7년 동안 보존해야 합니다. 조직은 백업 데이터를 온프레미스 데이터 센터에서 Amazon Web Services(AWS)로 재배치하기로 결정했습니다. 한 달 이내에 마이그레이션을 완료해야 합니다. 회사의 공용 인터넷 연결은 500Mbps의 데이터 전송 전용 용량을 제공합니다.\\n가장 낮은 비용으로 데이터를 마이그레이션하고 저장하기 위해 솔루션 설계자는 무엇을 해야 합니까?\\n\\nA.AWS Snowball 디바이스에 데이터를 전송하도록 주문합니다. 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier Deep Archive로 전환합니다.\\nB. 데이터 센터와 Amazon VPC 간에 VPN 연결을 배포합니다. AWS CLI를 사용하여 온프레미스에서 Amazon S3 Glacier로 데이터를 복사합니다.\\nC. 500Mbps AWS Direct Connect 연결을 프로비저닝하고 데이터를 Amazon S3로 전송합니다. 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier Deep Archive로 전환합니다.\\nD. AWS DataSync를 사용하여 데이터를 전송하고 DataSync 에이전트를 온프레미스에 배포합니다. DataSync 작업을 사용하여 온프레미스 NAS 스토리지에서 Amazon S3 Glacier로 파일을 복사합니다.\", \"A business's backup data totals 700 terabytes (TB) and is kept in network attached storage (NAS) at its data center. This backup data must be available in the event of occasional regulatory inquiries and preserved for a period of seven years. The organization has chosen to relocate its backup data from its on-premises data center to Amazon Web Services (AWS). Within one month, the migration must be completed. The company's public internet connection provides 500 Mbps of dedicated capacity for data transport.\\nWhat should a solutions architect do to ensure that data is migrated and stored at the LOWEST possible cost?\\n\\nA.Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.\\nB. Deploy a VPN connection between the data center and Amazon VPC. Use the AWS CLI to copy the data from on premises to Amazon S3 Glacier.\\nC. Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.\\nD. Use AWS DataSync to transfer the data and deploy a DataSync agent on premises. Use the DataSync task to copy files from the on-premises NAS storage to Amazon S3 Glacier.\", \"A\"],\n[\"기업의 주 데이터 센터와 보조 데이터 센터는 500마일(804.7km) 떨어져 있으며 고속 광섬유 케이블로 연결되어 있습니다. 미션 크리티컬 워크로드의 경우 조직은 데이터 센터와 AWS VPC 간에 가용성이 높고 안전한 네트워크 링크가 필요합니다. 솔루션 설계자는 최대한 탄력적인 연결 솔루션을 선택해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.2개의 개별 디바이스에 있는 2개의 Direct Connect 위치에서 종료되는 기본 데이터 센터의 2개의 AWS Direct Connect 연결\\nB. 동일한 디바이스의 하나의 Direct Connect 위치에서 종료되는 각 기본 및 보조 데이터 센터의 단일 AWS Direct Connect 연결\\nC. 2개의 개별 디바이스에 있는 2개의 Direct Connect 위치에서 종료되는 각 기본 및 보조 데이터 센터의 2개의 AWS Direct Connect 연결\\nD. 각 기본 및 보조 데이터 센터의 단일 AWS Direct Connect 연결은 두 개의 개별 디바이스에서 하나의 Direct Connect 위치에서 종료됩니다.\", \"The main and secondary data centers of a business are located 500 miles (804.7 kilometers) apart and are linked through high-speed fiber-optic cable. For a mission-critical workload, the organization requires a highly available and secure network link between its data centers and an AWS VPC. A solutions architect must choose a connectivity solution that is as resilient as possible.\\nWhich solution satisfies these criteria?\\n\\nA.Two AWS Direct Connect connections from the primary data center terminating at two Direct Connect locations on two separate devices\\nB. A single AWS Direct Connect connection from each of the primary and secondary data centers terminating at one Direct Connect location on the same device\\nC. Two AWS Direct Connect connections from each of the primary and secondary data centers terminating at two Direct Connect locations on two separate devices\\nD. A single AWS Direct Connect connection from each of the primary and secondary data centers terminating at one Direct Connect location on two separate devices\", \"C\"],\n[\"비즈니스의 동적 웹 사이트는 미국 내에서 호스팅됩니다. 이 회사는 유럽 전역으로 확장하고 있으며 새로운 유럽 방문자를 위해 사이트 로딩 속도를 줄이기를 원합니다. 웹사이트의 백본은 미국에 있어야 합니다. 이제 며칠 후면 제품이 출시될 예정인데, 즉석 답변이 필요합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.us-east-1에서 Amazon EC2 인스턴스를 시작하고 사이트를 마이그레이션합니다.\\nB. 웹사이트를 Amazon S3로 이동합니다. 리전 간 교차 리전 복제를 사용합니다.\\nC. 온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront를 사용합니다.\\nD. 온프레미스 서버를 가리키는 Amazon Route 53 지리적 근접 라우팅 정책을 사용합니다.\", \"The dynamic website of a business is hosted on-premises in the United States. The firm is expanding throughout Europe and want to reduce site loading speeds for new European visitors. The backbone of the website must stay in the United States. A few days from now, the product will be introduced, and an instant answer is required.\\nWhat recommendations should the solutions architect make?\\n\\nA.Launch an Amazon EC2 instance in us-east-1 and migrate the site to it.\\nB. Move the website to Amazon S3. Use cross-Region replication between Regions.\\nC. Use Amazon CloudFront with a custom origin pointing to the on-premises servers.\\nD. Use an Amazon Route 53 geo-proximity routing policy pointing to on-premises servers.\", \"C\"],\n[\"한 기업은 AWS Direct Connect 연결을 사용하여 코로케이션 시설에서 us-east-1 리전의 Amazon S3 버킷으로 1PB의 데이터를 복사했습니다. 이제 비즈니스는 us-west-2 리전에 있는 다른 S3 버킷에 데이터를 복제하려고 합니다. AWS Snowball은 코로케이션 시설에서 허용되지 않습니다.\\n솔루션 설계자는 이를 달성하기 위한 수단으로 무엇을 제안해야 합니까?\\n\\nA.한 리전에서 다른 리전으로 데이터를 복사하도록 Snowball Edge 장치를 주문합니다.\\nB. S3 콘솔을 사용하여 소스 S3 버킷에서 대상 S3 버킷으로 콘텐츠를 전송합니다.\\nC. aws S3 sync 명령을 사용하여 소스 버킷에서 대상 버킷으로 데이터를 복사합니다.\\nD. 교차 리전 복제 구성을 추가하여 다른 리전의 S3 버킷 간에 객체를 복사합니다.\", \"A corporation used an AWS Direct Connect connection to copy 1 PB of data from a colocation facility to an Amazon S3 bucket in the us-east-1 Region. The business now wishes to replicate the data in another S3 bucket located in the us-west-2 Region. AWS Snowball is not permitted at the colocation facility.\\nWhat should a solutions architect suggest as a means of achieving this?\\n\\nA.Order a Snowball Edge device to copy the data from one Region to another Region.\\nB. Transfer contents from the source S3 bucket to a target S3 bucket using the S3 console.\\nC. Use the aws S3 sync command to copy data from the source bucket to the destination bucket.\\nD. Add a cross-Region replication configuration to copy objects across S3 buckets in different Regions.\", \"D. C는 대용량 파일 복사에 적합하지 않음\"],\n[\"솔루션 설계자는 Amazon DynamoDB에 대한 API 요청이 VPC 내부의 Amazon EC2 인스턴스에서 인터넷을 통해 라우팅되지 않는지 확인해야 합니다.\\n이를 달성하기 위한 솔루션 설계자의 역할은 무엇입니까? (2개를 선택하세요.)\\n\\nA.끝점에 대한 라우팅 테이블 항목을 만듭니다.\\nB. DynamoDB용 게이트웨이 엔드포인트를 생성합니다.\\nC. 엔드포인트를 사용하는 새 DynamoDB 테이블을 생성합니다.\\nD. VPC의 각 서브넷에서 엔드포인트에 대한 ENI를 생성합니다.\\nE. 기본 보안 그룹에 보안 그룹 항목을 생성하여 액세스를 제공합니다.\", \"A solutions architect must verify that API requests to Amazon DynamoDB are not routed across the internet from Amazon EC2 instances inside a VPC.\\nWhat is the solution architect's role in achieving this? (Select two.)\\n\\nA.Create a route table entry for the endpoint.\\nB. Create a gateway endpoint for DynamoDB.\\nC. Create a new DynamoDB table that uses the endpoint.\\nD. Create an ENI for the endpoint in each of the subnets of the VPC.\\nE. Create a security group entry in the default security group to provide access.\", \"A, B\"],\n[\"비즈니스 애플리케이션은 Elastic Load Balancer 뒤에 있는 Auto Scaling 그룹의 일부인 Amazon EC2 인스턴스에서 호스팅됩니다. 회사는 매년 애플리케이션의 기록을 기반으로 휴일 동안 트래픽 증가를 예측합니다. 솔루션 설계자는 애플리케이션 사용자의 성능에 미치는 영향을 최소화하기 위해 Auto Scaling 그룹이 사전에 용량을 늘리도록 보장하는 계획을 개발해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Amazon CloudWatch 경보를 생성하여 CPU 사용률이 90%를 초과할 때 EC2 인스턴스를 확장합니다.\\nB. 예상되는 피크 수요 기간 전에 Auto Scaling 그룹을 확장하기 위해 반복되는 예약된 작업을 생성합니다.\\nC. 최대 수요 기간 동안 Auto Scaling 그룹의 최소 및 최대 EC2 인스턴스 수를 늘립니다.\\nD. Autoscaling EC2_INSTANCE_LAUNCH 이벤트가 있을 때 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS) 알림을 구성합니다.\", \"The application of a business is hosted on Amazon EC2 instances that are part of an Auto Scaling group behind an Elastic Load Balancer. Each year, the firm predicts a rise in traffic over a holiday, based on the application's history. A solutions architect must develop a plan to guarantee that the Auto Scaling group raises capacity proactively in order to minimize any effect on application users' performance.\\nWhich solution will satisfy these criteria?\\n\\nA.Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90%.\\nB. Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand.\\nC. Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period.\\nD. Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are autoscaling EC2_INSTANCE_LAUNCH events.\", \"B\"],\n[\"비즈니스에서 라이브 데이터 세트를 온프레미스 NFS 서버에서 DOC-EXAMPLE-BUCKET이라는 Amazon S3 버킷으로 온라인으로 마이그레이션하려고 합니다. 데이터 무결성 검증은 전송 중과 전송 후에 모두 필수적입니다. 또한 데이터를 암호화해야 합니다.\\n솔루션 설계자가 AWS 솔루션을 사용하여 데이터를 마이그레이션하고 있습니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Storage Gateway 파일 게이트웨이\\nB. S3 Transfer Acceleration\\nC. AWS 데이터싱크\\nD. AWS Snowball Edge 스토리지 최적화\", \"A business wishes to migrate live datasets online from an on-premises NFS server to an Amazon S3 bucket called DOC-EXAMPLE-BUCKET. Verification of data integrity is essential both during and after the transmission. Additionally, the data must be encrypted.\\nA solutions architect is migrating the data using an AWS solution.\\nWhich solution satisfies these criteria?\\n\\nA.AWS Storage Gateway file gateway\\nB. S3 Transfer Acceleration\\nC. AWS DataSync\\nD. AWS Snowball Edge Storage Optimized\", \"C\"],\n[\"기업은 여러 AWS 리전에서 ALB(Application Load Balancer)를 활용합니다. ALB는 일년 내내 변동하는 트래픽을 경험합니다.\\n회사의 네트워킹 담당자는 사내 방화벽을 통해 ALB의 IP 주소를 허용하여 연결을 활성화해야 합니다.\\n어떤 솔루션이 가장 확장 가능하고 설정 변경이 가장 적게 필요합니까?\\n\\nA.AWS Lambda 스크립트를 작성하여 다른 리전에 있는 ALB의 IP 주소를 가져옵니다. ALB의 IP 주소를 허용하도록 사내 구축형 방화벽의 규칙을 업데이트하십시오.\\nB. 다른 리전의 모든 ALB를 NLB(Network Load Balancer)로 마이그레이션합니다. 모든 NLB의 탄력적 IP 주소를 허용하도록 온프레미스 방화벽의 규칙을 업데이트합니다.\\nC. AWS Global Accelerator를 시작합니다. 액셀러레이터에 다른 리전의 ALB를 등록합니다. 가속기와 연결된 고정 IP 주소를 허용하도록 온프레미스 방화벽의 규칙을 업데이트합니다.\\nD. 한 리전에서 NLB(Network Load Balancer)를 시작합니다. 다른 지역에 있는 ALB의 사설 IP 주소를 NLB에 등록합니다. NLB에 연결된 탄력적 IP 주소를 허용하도록 온프레미스 방화벽의 규칙을 업데이트합니다.\", \"A business utilizes Application Load Balancers (ALBs) across many AWS Regions. The ALBs experience fluctuating traffic throughout the year.\\nThe company's networking personnel must enable connection by allowing the ALBs' IP addresses over the on-premises firewall.\\nWhich solution is the MOST scalable and requires the least amount of setup changes?\\n\\nA.Write an AWS Lambda script to get the IP addresses of the ALBs in different Regions. Update the on-premises firewall's rule to allow the IP addresses of the ALBs.\\nB. Migrate all ALBs in different Regions to the Network Load Balancer (NLBs). Update the on-premises firewall's rule to allow the Elastic IP addresses of all the NLBs.\\nC. Launch AWS Global Accelerator. Register the ALBs in different Regions to the accelerator. Update the on-premises firewall's rule to allow static IP addresses associated with the accelerator.\\nD. Launch a Network Load Balancer (NLB) in one Region. Register the private IP addresses of the ALBs in different Regions with the NLB. Update the on- premises firewall's rule to allow the Elastic IP address attached to the NLB.\", \"C\"],\n[\"매달 기업은 판매 보고서를 작성해야 합니다. 매월 1일에 보고 절차가 20개의 Amazon EC2 인스턴스를 시작합니다. 절차는 7일 동안 지속되며 일시 중지할 수 없습니다. 회사는 비용을 낮게 유지하기를 원합니다.\\n기업은 어떤 가격 전략을 추구해야 합니까?\\n\\nA.예약 인스턴스\\nB. 스팟 블록 인스턴스\\nC. 온디맨드 인스턴스\\nD. 정기 예약 인스턴스\", \"Each month, a business must create sales reports. On the first day of each month, the reporting procedure starts 20 Amazon EC2 instances. The procedure lasts seven days and cannot be paused. The corporation wishes to keep expenses low.\\nWhich pricing strategy should the business pursue?\\n\\nA.Reserved Instances\\nB. Spot Block Instances\\nC. On-Demand Instances\\nD. Scheduled Reserved Instances\", \"C. Scheduled Reserved Instance는 더 이상 서비스 되지 않음.\"],\n[\"기업은 모든 모바일 장치에서 사용할 수 있도록 비디오 자료를 업로드하고 트랜스코딩하는 온라인 서비스를 제공합니다. 애플리케이션 설계는 Amazon Elastic File System(Amazon EFS) 표준을 사용하여 수많은 Amazon EC2 Linux 인스턴스에서 처리할 수 있도록 영화를 수집하고 저장합니다. 서비스의 인기가 높아짐에 따라 스토리지 비용이 엄청나게 비쌌습니다.\\n가장 저렴한 스토리지 옵션은 무엇입니까?\\n\\nA.파일에 AWS Storage Gateway를 사용하여 비디오 콘텐츠를 저장하고 처리합니다.\\nB. 볼륨에 AWS Storage Gateway를 사용하여 비디오 콘텐츠를 저장하고 처리합니다.\\nC. 비디오 콘텐츠를 저장하기 위해 Amazon Elastic File System(Amazon EFS)을 사용합니다. 처리가 완료되면 파일을 Amazon Elastic Block Store(Amazon EBS)로 전송합니다.\\nD. 비디오 콘텐츠를 저장하기 위해 Amazon S3를 사용합니다. 처리를 위해 서버에 연결된 Amazon ElasticBlock Store(Amazon EBS) 볼륨으로 파일을 임시로 이동합니다.\", \"A business offers an online service for uploading and transcoding video material for usage on any mobile device. The application design makes use of Amazon Elastic File System (Amazon EFS) Standard to gather and store the films so that they may be processed by numerous Amazon EC2 Linux instances. As the service's popularity has increased, the storage charges have become prohibitively costly.\\nWhich storage option is the MOST CHEAPEST?\\n\\nA.Use AWS Storage Gateway for files to store and process the video content.\\nB. Use AWS Storage Gateway for volumes to store and process the video content.\\nC. Use Amazon Elastic File System (Amazon EFS) for storing the video content. Once processing is complete, transfer the files to Amazon Elastic Block Store (Amazon EBS).\\nD. Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon ElasticBlock Store (Amazon EBS) volume attached to the server for processing.\", \"D\"],\n[\"매일 기업은 단일 공장에 있는 많은 기계에서 10테라바이트의 계측 데이터를 얻습니다. 데이터는 공장 온프레미스 데이터 센터 내부의 SAN(Storage Area Network)에서 JSON 파일로 저장됩니다. 조직은 이 데이터를 Amazon S3에 업로드하여 중요한 거의 실시간 분석을 수행하는 다른 여러 시스템에서 액세스할 수 있도록 하려고 합니다. 데이터는 민감한 것으로 간주되기 때문에 안전한 전송이 중요합니다.\\n가장 안전한 데이터 전송 방법을 제공하는 옵션은 무엇입니까?\\n\\nA.공용 인터넷을 통한 AWS DataSync\\nB. AWS Direct Connect를 통한 AWS DataSync\\nC. 공용 인터넷을 통한 AWS Database Migration Service(AWS DMS)\\nD. AWS Direct Connect를 통한 AWS Database Migration Service(AWS DMS)\", \"Each day, a corporation gets ten terabytes of instrumentation data from many machines situated in a single plant. The data is saved in JSON files on a storage area network (SAN) inside the factory's on-premises data center. The organization want to upload this data to Amazon S3 so that it may be accessible by a number of other systems that do crucial near-real-time analytics. Because the data is deemed sensitive, a secure transmission is critical.\\nWhich option provides the MOST SECURE method of data transfer?\\n\\nA.AWS DataSync over public internet\\nB. AWS DataSync over AWS Direct Connect\\nC. AWS Database Migration Service (AWS DMS) over public internet\\nD. AWS Database Migration Service (AWS DMS) over AWS Direct Connect\", \"B\"],\n[\"데이터 과학 팀은 야간에 로그를 분석하기 위해 스토리지가 필요합니다. 로그의 양과 수는 불명확하나, 24시간 동안 보관됩니다.\\n어떤 접근 방식이 가장 비용 효율적입니까?\\n\\nA.Amazon S3 Glacier\\nB. Amazon S3 Standard\\nC. Amazon S3 Intelligent-Tiering\\nD. Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"A data science team needs storage to analyze logs on a nightly basis. The amount and quantity of logs are unclear, however they will be retained for 24 hours.\\nWhich approach is the MOST cost-effective?\\n\\nA.Amazon S3 Glacier\\nB. Amazon S3 Standard\\nC. Amazon S3 Intelligent-Tiering\\nD. Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"B. 나머지는 최소 기간 요금체계가 있음. 30일 이상의 요금 청구됨.\"],\n[\"개발 팀이 AWS에서 신제품을 출시하고 있으며 출시의 일환으로 AWS Lambda를 사용하고 있습니다. Lambda 함수 중 하나를 위해 팀은 512MB의 RAM을 할당합니다. 이 메모리 할당으로 함수는 2분 안에 완료됩니다. 함수는 월간 수백만 번 실행되고 개발 팀은 비용에 대해 걱정하고 있습니다. 팀은 다양한 Lambda 메모리 할당이 함수 비용에 미치는 영향을 확인하기 위해 실험을 수행합니다.\\n어떤 조치로 제품의 Lambda 비용이 감소합니까? (2개를 선택하세요.)\\n\\nA.이 변경으로 인해 각 함수의 실행 시간이 1분 미만이 되는 경우 이 Lambda 함수에 대한 메모리 할당을 1,024MB로 늘립니다.\\nB. 이 변경으로 인해 각 함수의 실행 시간이 90초 미만이 되는 경우 이 Lambda 함수에 대한 메모리 할당을 1,024MB로 늘립니다.\\nC. 이 변경으로 인해 각 함수의 실행 시간이 4분 미만이 되는 경우 이 Lambda 함수에 대한 메모리 할당을 256MB로 줄이십시오.\\nD. 이 변경으로 인해 각 함수의 실행 시간이 1분 미만이 되는 경우 이 Lambda 함수에 대한 메모리 할당을 2,048MB로 늘립니다.\\nE. 이 변경으로 인해 각 함수의 실행 시간이 5분 미만이 되는 경우 이 Lambda 함수에 대한 메모리 할당을 256MB로 줄이십시오.\", \"A development team is releasing a new product on AWS, and as part of the rollout, they are use AWS Lambda. For one of the Lambda functions, the team allocates 512 MB of RAM. The function is finished in two minutes with this memory allocation. Monthly, the function is executed millions of times, and the development team is worried about the cost. The team does experiments to determine the effect of various Lambda memory allocations on the function's cost.\\nWhich measures will result in a decrease in the product's Lambda costs? (Select two.)\\n\\nA.Increase the memory allocation for this Lambda function to 1,024 MB if this change causes the execution time of each function to be less than 1 minute.\\nB. Increase the memory allocation for this Lambda function to 1,024 MB if this change causes the execution time of each function to be less than 90 seconds.\\nC. Reduce the memory allocation for this Lambda function to 256 MB if this change causes the execution time of each function to be less than 4 minutes.\\nD. Increase the memory allocation for this Lambda function to 2,048 MB if this change causes the execution time of each function to be less than 1 minute.\\nE. Reduce the memory allocation for this Lambda function to 256 MB if this change causes the execution time of each function to be less than 5 minutes.\", \"A, C\"],\n[\"기업은 중앙 집중식 Amazon Web Services 계정을 사용하여 많은 Amazon S3 버킷에 로그 데이터를 저장하고 있습니다. S3 버킷에 데이터를 업로드하기 전에 솔루션 설계자는 데이터가 암호화되어 있는지 확인해야 합니다. 또한 데이터는 전송 중에 암호화되어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.클라이언트 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다.\\nB. 서버 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다.\\nC. S3 업로드를 위해 S3 관리형 암호화 키(SSE-S3)로 서버 측 암호화를 사용해야 하는 버킷 정책을 생성합니다.\\nD. 기본 AWS Key Management Service(AWS KMS) 키를 사용하여 S3 버킷을 암호화하는 보안 옵션을 활성화합니다.\", \"A business is using a centralized Amazon Web Services account to store log data in many Amazon S3 buckets. Prior to uploading data to S3 buckets, a solutions architect must guarantee that the data is encrypted at rest. Additionally, data must be encrypted during transit.\\nWhich solution satisfies these criteria?\\n\\nA.Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.\\nB. Use server-side encryption to encrypt the data that is being uploaded to the S3 buckets.\\nC. Create bucket policies that require the use of server-side encryption with S3 managed encryption keys (SSE-S3) for S3 uploads.\\nD. Enable the security option to encrypt the S3 buckets through the use of a default AWS Key Management Service (AWS KMS) key.\", \"A\"],\n[\"비즈니스에서는 Microsoft Windows 기반 애플리케이션을 AWS로 마이그레이션해야 합니다. 이 프로그램은 수많은 Amazon EC2 Windows 시스템에 연결된 공유 Windows 파일 시스템을 활용합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.Amazon Elastic File System(Amazon EFS)을 사용하여 볼륨을 구성합니다. 각 Windows 인스턴스에 EFS 볼륨을 탑재합니다.\\nB. 볼륨 게이트웨이 모드에서 AWS Storage Gateway를 구성합니다. 각 Windows 인스턴스에 볼륨을 탑재합니다.\\nC. Windows 파일 서버용 Amazon FSx를 구성합니다. Amazon FSx 볼륨을 각 Windows 인스턴스에 탑재합니다.\\nD. 필요한 크기로 Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성합니다. 각 EC2 인스턴스를 볼륨에 연결합니다. 볼륨 내의 파일 시스템을 각 Windows 인스턴스에 마운트합니다.\", \"A business requires the migration of a Microsoft Windows-based application to AWS. This program utilizes a shared Windows file system that is tied to numerous Amazon EC2 Windows machines.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Configure a volume using Amazon Elastic File System (Amazon EFS). Mount the EFS volume to each Windows instance.\\nB. Configure AWS Storage Gateway in Volume Gateway mode. Mount the volume to each Windows instance.\\nC. Configure Amazon FSx for Windows File Server. Mount the Amazon FSx volume to each Windows instance.\\nD. Configure an Amazon Elastic Block Store (Amazon EBS) volume with the required size. Attach each EC2 instance to the volume. Mount the file system within the volume to each Windows instance.\", \"C\"],\n[\"IAM 그룹은 다음 IAM 정책과 연결됩니다. 이것이 그룹의 유일한 정책입니다.\\nhttps://i.imgur.com/rFLujbFl.png\\n그룹 구성원에 대한 정책의 유효 IAM 권한은 무엇입니까?\\n\\nA.그룹 구성원은 us-east-1 리전 내에서 모든 Amazon EC2 작업이 허용됩니다. Allow 권한 이후의 문장은 적용되지 않습니다.\\nB. 그룹 구성원은 MFA(다단계 인증)로 로그인하지 않는 한 us-east-1 리전에서 Amazon EC2 권한이 거부됩니다.\\nC. 그룹 구성원은 MFA(다단계 인증)로 로그인할 때 모든 리전에 대해 ec2:StopInstances 및 ec2:TerminateInstances 권한이 허용됩니다. 그룹 구성원은 다른 모든 Amazon EC2 작업이 허용됩니다.\\nD. 그룹 구성원은 MFA(다단계 인증)로 로그인한 경우에만 us-east-1 리전에 대한 ec2:StopInstances 및 ec2:TerminateInstances 권한이 허용됩니다. 그룹 구성원은 us-east-1 리전 내에서 다른 모든 Amazon EC2 작업이 허용됩니다.\", \"An IAM group is associated with the following IAM policy. This is the group's sole policy.\\nWhat are the policy's effective IAM permissions for group members?\\n\\nA.Group members are permitted any Amazon EC2 action within the us-east-1 Region. Statements after the Allow permission are not applied.\\nB. Group members are denied any Amazon EC2 permissions in the us-east-1 Region unless they are logged in with multi-factor authentication (MFA).\\nC. Group members are allowed the ec2:StopInstances and ec2:TerminateInstances permissions for all Regions when logged in with multi-factor authentication (MFA). Group members are permitted any other Amazon EC2 action.\\nD. Group members are allowed the ec2:StopInstances and ec2:TerminateInstances permissions for the us-east-1 Region only when logged in with multi-factor authentication (MFA). Group members are permitted any other Amazon EC2 action within the us-east-1 Region.\", \"D\"],\n[\"한 비즈니스에서 아카이브된 뉴스 장면에서 생성된 비디오 아카이브를 AWS에 저장할 수 있는 솔루션을 찾고 있습니다. 기업은 비용을 절감해야 하며 이러한 데이터를 거의 복구할 필요가 없습니다. 파일이 필요한 경우 5분 이내에 제공해야 합니다.\\n어떤 접근 방식이 가장 비용 효율적입니까?\\n\\nA.비디오 아카이브를 Amazon S3 Glacier에 저장하고 신속 검색을 사용합니다.\\nB. 비디오 아카이브를 Amazon S3 Glacier에 저장하고 표준 검색을 사용합니다.\\nC. 비디오 아카이브를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 저장합니다.\\nD. 비디오 아카이브를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)에 저장합니다.\", \"A business is searching for a solution that would enable them to store video archives created from archived news footage on AWS. The business must keep expenses down and will seldom need to recover these data. When files are required, they must be provided within a five-minute window.\\nWhich approach is the MOST cost-effective?\\n\\nA.Store the video archives in Amazon S3 Glacier and use Expedited retrievals.\\nB. Store the video archives in Amazon S3 Glacier and use Standard retrievals.\\nC. Store the video archives in Amazon S3 Standard-Infrequent Access (S3 Standard-IA).\\nD. Store the video archives in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA).\", \"D. 신속 검색을 통해 Glacier에서 5분 이내에 데이터를 받아올 수 있으나 250MB 미만인 경우에만 제공되므로 비디오에는 적합하지 않음. 자료가 손실되더라도 원본 자료를 바탕으로 다시 만들 수 있기 때문에 One Zone이 적합.\"],\n[\"이제 온프레미스에서 웹 애플리케이션을 호스팅하는 회사는 AWS로 마이그레이션하고 최신 버전의 프로그램을 시작할 준비가 되었습니다. 조직은 URL 쿼리 문자열에 따라 AWS 또는 온프레미스 호스팅 애플리케이션으로 요청을 라우팅해야 합니다. 온프레미스 애플리케이션은 인터넷을 통해 액세스할 수 없으며 Amazon VPC와 회사 데이터 센터 간에 VPN 연결이 형성됩니다. 회사는 ALB(Application Load Balancer)를 사용하여 이 애플리케이션을 배포할 계획입니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.두 개의 ALB를 사용하십시오. 하나는 온프레미스용이고 다른 하나는 AWS 리소스용입니다. 각 ALB의 각 대상 그룹에 호스트를 추가하십시오. URL 쿼리 문자열을 기반으로 Amazon Route 53으로 라우팅합니다.\\nB. 두 개의 ALB를 사용합니다. 하나는 온프레미스용이고 다른 하나는 AWS 리소스용입니다. 각 ALB의 대상 그룹에 호스트를 추가하십시오. URL 쿼리 문자열을 기반으로 EC2 인스턴스에 소프트웨어 라우터를 생성합니다.\\nC. 하나의 ALB를 두 개의 대상 그룹(AWS 리소스용 하나와 온프레미스용 하나)과 함께 사용합니다. ALB의 각 대상 그룹에 호스트를 추가합니다. URL 쿼리 문자열을 기반으로 리스너 규칙을 구성합니다.\\nD. 2개의 AWS Auto Scaling 그룹과 함께 하나의 ALB를 사용합니다. 하나는 AWS 리소스용이고 다른 하나는 온프레미스용입니다. 각 Auto Scaling 그룹에 호스트를 추가합니다. URL 쿼리 문자열을 기반으로 Amazon Route 53으로 라우팅합니다.\", \"A firm that now hosts a web application on-premises is ready to migrate to AWS and launch a newer version of the program. The organization must route requests depending on the URL query string to either the AWS- or on-premises-hosted application. The on-premises application is inaccessible over the internet, and a VPN connection between Amazon VPC and the company's data center is formed. The firm intends to deploy this application using an Application Load Balancer (ALB).\\nWhich solution satisfies these criteria?\\n\\nA.Use two ALBs: one for on-premises and one for the AWS resource. Add hosts to each target group of each ALB. Route with Amazon Route 53 based on the URL query string.\\nB. Use two ALBs: one for on-premises and one for the AWS resource. Add hosts to the target group of each ALB. Create a software router on an EC2 instance based on the URL query string.\\nC. Use one ALB with two target groups: one for the AWS resource and one for on premises. Add hosts to each target group of the ALB. Configure listener rules based on the URL query string.\\nD. Use one ALB with two AWS Auto Scaling groups: one for the AWS resource and one for on premises. Add hosts to each Auto Scaling group. Route with Amazon Route 53 based on the URL query string.\", \"C\"],\n[\"등록된 상위 ​​도메인에서 회사는 다양한 비즈니스 라인을 위한 많은 웹사이트를 호스팅합니다. 하위 도메인에 따르면 이러한 웹 사이트를 방문하는 모든 사람은 적절한 백엔드 Amazon EC2 인스턴스로 연결됩니다. 정적 웹 페이지, 그림 및 PHP 및 JavaScript와 같은 서버 측 프로그래밍은 모두 웹 사이트에서 호스팅됩니다.\\n특정 웹 사이트는 비즈니스 시작 후 처음 2시간 동안 트래픽이 급증한 후 나머지 시간 동안 지속적으로 사용됩니다. 솔루션 설계자는 비용 효율적이면서도 특정 트래픽 패턴에 자동으로 용량을 조정하는 시스템을 구축해야 합니다.\\n이러한 요구 사항에 적합한 AWS 서비스 또는 기능 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.AWS 배치\\nB. 네트워크 로드 밸런서\\nC. 애플리케이션 로드 밸런서\\nD. Amazon EC2 Auto Scaling\\nE. Amazon S3 웹사이트 호스팅\", \"Under its registered parent domain, a firm hosts many websites for various lines of business. According to the subdomain, anyone visiting these websites will be directed to the proper backend Amazon EC2 instance. Static webpages, pictures, and server-side programming such as PHP and JavaScript are all hosted on the websites.\\nCertain websites see a spike in traffic during the first two hours of business, followed by consistent use throughout the remainder of the day. A solutions architect must build a system that adapts capacity automatically to certain traffic patterns while being cost effective.\\nWhich AWS service or feature combination will suit these requirements? (Select two.)\\n\\nA.AWS Batch\\nB. Network Load Balancer\\nC. Application Load Balancer\\nD. Amazon EC2 Auto Scaling\\nE. Amazon S3 website hosting\", \"C, D\"],\n[\"웹 애플리케이션으로서 한 기업이 새로운 비디오 게임을 구축했습니다. 애플리케이션은 VPC의 MySQL용 Amazon RDS를 사용하여 3계층 설계로 배포됩니다. 여러 플레이어가 데이터베이스 계층을 통해 온라인에서 동시에 경쟁합니다. 게임 제작자는 거의 실시간으로 상위 10개 점수판을 표시하고 플레이어가 기존 점수를 유지하면서 게임을 일시 중지했다가 다시 시작할 수 있기를 원합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.웹 애플리케이션이 표시할 점수를 캐시하도록 Amazon ElastiCache for Memcached 클러스터를 설정합니다.\\nB. Redis용 Amazon ElastiCache 클러스터를 설정하여 웹 애플리케이션이 표시할 점수를 계산하고 캐시합니다.\\nC. 웹 애플리케이션 앞에 Amazon CloudFront 배포판을 배치하여 애플리케이션 섹션의 스코어보드를 캐시합니다.\\nD. MySQL용 Amazon RDS에서 읽기 전용 복제본을 생성하여 쿼리를 실행하여 스코어보드를 계산하고 웹 애플리케이션에 읽기 트래픽을 제공합니다.\", \"As a web application, a corporation has built a new video game. The application is deployed in a three-tier design using Amazon RDS for MySQL in a VPC. Multiple players will compete simultaneously online through the database layer. The makers of the game want to show a top-10 scoreboard in near-real time and to enable players to pause and resume the game while retaining their existing scores.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Set up an Amazon ElastiCache for Memcached cluster to cache the scores for the web application to display.\\nB. Set up an Amazon ElastiCache for Redis cluster to compute and cache the scores for the web application to display.\\nC. Place an Amazon CloudFront distribution in front of the web application to cache the scoreboard in a section of the application.\\nD. Create a read replica on Amazon RDS for MySQL to run queries to compute the scoreboard and serve the read traffic to the web application.\", \"B\"],\n[\"기업에서 온프레미스 NAS(Network Attached Storage)를 Amazon Web Services(AWS)로 마이그레이션하려고 합니다. 회사는 VPC 내부의 모든 Linux 인스턴스에서 데이터에 액세스할 수 있도록 하고 데이터 저장소에 대한 변경 사항이 이를 사용하는 모든 인스턴스에서 즉시 동기화되도록 보장하고자 합니다. 대량의 데이터는 드물게 보는 반면 특정 파일은 많은 사람들이 동시에 읽습니다.\\n이 기준을 충족하고 가장 비용 효율적인 옵션은 무엇입니까?\\n\\nA.데이터가 포함된 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. VPC 내의 사용자와 공유하십시오.\\nB. 적절한 일 수 후에 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하도록 설정된 수명 주기 정책이 있는 Amazon S3 버킷을 생성합니다.\\nC. VPC 내에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 처리량 모드를 프로비저닝됨으로 설정하고 동시 사용을 지원하는 데 필요한 IOPS 양으로 설정합니다.\\nD. VPC 내에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 적절한 일 수 후에 데이터를 EFS IA(EFS Infrequent Access)로 전환하도록 수명 주기 정책을 설정합니다.\", \"A business wishes to migrate its on-premises network attached storage (NAS) to Amazon Web Services (AWS). The corporation wishes to make the data accessible to any Linux instance inside its VPC and to guarantee that changes to the data store are immediately synced across all instances that use it. The bulk of data is viewed infrequently, whereas certain files are read concurrently by numerous people.\\nWhich option satisfies these criteria and is the MOST cost-effective?\\n\\nA.Create an Amazon Elastic Block Store (Amazon EBS) snapshot containing the data. Share it with users within the VPC.\\nB. Create an Amazon S3 bucket that has a lifecycle policy set to transition the data to S3 Standard-Infrequent Access (S3 Standard-IA) after the appropriate number of days.\\nC. Create an Amazon Elastic File System (Amazon EFS) file system within the VPC. Set the throughput mode to Provisioned and to the required amount of IOPS to support concurrent usage.\\nD. Create an Amazon Elastic File System (Amazon EFS) file system within the VPC. Set the lifecycle policy to transition the data to EFS Infrequent Access (EFS IA) after the appropriate number of days.\", \"D\"],\n[\"수년 동안 비즈니스는 Amazon RDS 인스턴스에 분석 데이터를 저장해 왔습니다. 이 회사는 소비자가 이 데이터에 액세스할 수 있도록 하는 API를 개발하기 위해 솔루션 설계자를 고용했습니다. 이 프로그램은 유휴 기간이 있을 것으로 예상되지만 몇 초 안에 트래픽이 급증할 수 있습니다.\\n건축가는 어떤 옵션을 추천해야 합니까?\\n\\nA.Amazon API Gateway를 설정하고 Amazon ECS를 사용합니다.\\nB. Amazon API Gateway를 설정하고 AWS Elastic Beanstalk를 사용합니다.\\nC. Amazon API Gateway를 설정하고 AWS Lambda 함수를 사용합니다.\\nD. Amazon API Gateway를 설정하고 Auto Scaling과 함께 Amazon EC2를 사용합니다.\", \"For many years, a business has stored analytics data on an Amazon RDS instance. The firm hired a solutions architect to develop an API that would enable consumers to access this data. The program is expected to have periods of idleness but may get surges of traffic within seconds.\\nWhich option should the architect recommend?\\n\\nA.Set up an Amazon API Gateway and use Amazon ECS.\\nB. Set up an Amazon API Gateway and use AWS Elastic Beanstalk.\\nC. Set up an Amazon API Gateway and use AWS Lambda functions.\\nD. Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling.\", \"C\"],\n[\"모바일 게임 스타트업은 Amazon EC2 인스턴스를 사용하여 애플리케이션 서버를 호스팅합니다. 15분마다 서버는 플레이어로부터 업데이트를 받습니다. 모바일 게임은 마지막 업데이트 이후 게임의 진행 상황을 포함하는 JSON 객체를 생성하고 이를 Application Load Balancer에 전달합니다. 모바일 게임을 플레이하면 게임 업데이트가 손실됩니다. 이 회사는 오래된 장치가 업데이트를 받을 수 있는 오래 지속되는 방법을 개발할 계획입니다.\\n솔루션 설계자는 시스템 디커플링을 위해 무엇을 제안해야 합니까?\\n\\nA.Amazon Kinesis Data Streams를 사용하여 데이터를 캡처하고 Amazon S3에 JSON 객체를 저장합니다.\\nB. Amazon Kinesis Data Firehose를 사용하여 데이터를 캡처하고 Amazon S3에 JSON 객체를 저장합니다.\\nC. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 사용하여 데이터를 캡처하고 EC2 인스턴스를 사용하여 대기열의 메시지를 처리합니다.\\nD. Amazon Simple Notification Service(Amazon SNS)를 사용하여 데이터를 캡처하고 EC2 인스턴스를 사용하여 Application Load Balancer로 전송된 메시지를 처리합니다.\", \"A mobile gaming startup uses Amazon EC2 instances to host application servers. Every 15 minutes, the servers get updates from players. The mobile game generates a JSON object containing the game's progress since the last update and delivers it to an Application Load Balancer. As the mobile game is played, it loses game updates. The business intends to develop a long-lasting method for older devices to get updates.\\nWhat should a solution architect propose for system decoupling?\\n\\nA.Use Amazon Kinesis Data Streams to capture the data and store the JSON object in Amazon S3.\\nB. Use Amazon Kinesis Data Firehose to capture the data and store the JSON object in Amazon S3.\\nC. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue.\\nD. Use Amazon Simple Notification Service (Amazon SNS) to capture the data and EC2 instances to process the messages sent to the Application Load Balancer.\", \"C\"],\n[\"회사의 IT 지출에 대한 최근 검토는 백업 비용 절감의 중요성을 보여줍니다. 조직의 CIO는 물리적 백업 테이프를 단계적으로 폐지하여 온프레미스 백업 아키텍처를 단순화하고 비용을 절감하기를 원합니다. 사내 백업 시스템 및 절차에 대한 회사의 현재 투자는 보호되어야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway를 설정합니다.\\nB. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon Elastic File System(Amazon EFS) 파일 시스템을 설정합니다.\\nC. iSCSI 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon Elastic File System(Amazon EFS) 파일 시스템을 설정합니다.\\nD. iSCSI VTL(가상 테이프 라이브러리) 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway를 설정합니다.\", \"A recent review of a company's IT spending demonstrates the critical necessity of lowering backup costs. The chief information officer of the organization want to simplify the on-premises backup architecture and cut expenses by phasing out physical backup tapes. The company's current investment in on-premises backup systems and procedures must be protected.\\nWhat recommendations should a solutions architect make?\\n\\nA.Set up AWS Storage Gateway to connect with the backup applications using the NFS interface.\\nB. Set up an Amazon Elastic File System (Amazon EFS) file system that connects with the backup applications using the NFS interface.\\nC. Set up an Amazon Elastic File System (Amazon EFS) file system that connects with the backup applications using the iSCSI interface.\\nD. Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface.\", \"D\"],\n[\"기업은 내부 웹 기반 응용 프로그램을 유지 관리합니다. 애플리케이션은 Application Load Balancer를 통해 라우팅되는 Amazon EC2 인스턴스에 배포됩니다. 인스턴스는 Amazon EC2 Auto Scaling 그룹을 통해 여러 가용 영역에 분산됩니다. 업무 시간 동안 Auto Scaling 그룹은 최대 20개의 인스턴스로 확장한 다음 하룻밤 사이에 2개의 인스턴스로 축소합니다. 직원들은 프로그램이 하루를 시작하기에는 매우 느리지만 오전 중반까지는 잘 수행된다고 말합니다.\\n비용을 낮게 유지하면서 직원의 우려를 수용하기 위해 규모를 어떻게 변경할 수 있습니까?\\n\\nA.사무실이 열리기 직전에 원하는 용량을 20으로 설정하는 예정된 작업을 구현합니다.\\nB. 더 낮은 CPU 임계값에서 트리거된 단계 조정 작업을 구현하고 휴지 기간을 줄입니다.\\nC. 더 낮은 CPU 임계값에서 트리거된 대상 추적 작업을 구현하고 휴지 기간을 줄입니다.\\nD. 사무실이 열리기 직전에 최소 및 최대 수용 인원을 20명으로 설정하는 예정된 작업을 구현합니다.\", \"A business maintains an internal web-based application. The application is deployed on Amazon EC2 instances that are routed via an Application Load Balancer. The instances are distributed across several Availability Zones through an Amazon EC2 Auto Scaling group. During business hours, the Auto Scaling group grows up to 20 instances, then scales down to two instances overnight. Staff are saying that the program is very sluggish to start the day, but performs fine by mid-morning.\\nHow might the scale be altered to accommodate employee concerns while keeping expenses low?\\n\\nA.Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.\\nB. Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.\\nC. Implement a target tracking action triggered at a lower CPU threshold, and decrease the cooldown period.\\nD. Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens.\", \"A, C 논쟁. A로 하는 경우 20개를 다 사용하지 못해 비효율적이라는 의견과, 부하가 많은 시간이 충분히 예측 가능하기 때문에 A가 맞다는 의견 충돌.\"],\n[\"기업은 모든 이메일을 7년 동안 외부에 저장 및 보존해야 하는 규제 의무를 준수해야 합니다. 관리자가 온프레미스에서 압축된 이메일 파일을 준비했으며 관리형 서비스를 통해 데이터를 AWS 스토리지로 전송하기를 원합니다.\\n솔루션 아키텍트가 추천해야 하는 관리형 서비스는 무엇입니까?\\n\\nA.Amazon Elastic File System(Amazon EFS)\\nB. 아마존 S3 빙하\\nC. AWS 백업\\nD. AWS 스토리지 게이트웨이\", \"A business must adhere to a regulatory obligation that all emails be saved and preserved outside for a period of seven years. An administrator has prepared compressed email files on-premises and wishes to have the data transferred to AWS storage through a managed service.\\nWhich managed service should be recommended by a solutions architect?\\n\\nA.Amazon Elastic File System (Amazon EFS)\\nB. Amazon S3 Glacier\\nC. AWS Backup\\nD. AWS Storage Gateway\", \"D. 전송 서비스를 요청했으므로 B가 아님.\"],\n[\"기업은 Elastic Load Balancer를 통해 여러 가용 영역에 분산된 Amazon EC2 인스턴스에서 웹 사이트를 호스팅합니다. 인스턴스는 EC2 Auto Scaling 그룹의 일부로 관리됩니다. 웹 사이트는 Amazon Elastic Block Store(Amazon EBS) 볼륨을 통해 다운로드할 수 있는 제품 설명서를 저장합니다. 조직에서 종종 제품 정보를 변경하므로 Auto Scaling 그룹에서 생성한 새 인스턴스에는 오래된 데이터가 있는 경우가 많습니다. 새 인스턴스에서 모든 변경 사항을 수신하는 데 최대 30분이 소요될 수 있습니다. 또한 변경 사항에는 업무 시간 동안 EBS 볼륨 크기 조정이 포함됩니다.\\n회사는 제품 설명서가 지속적으로 최신 상태이고 아키텍처가 증가하는 고객 요구에 빠르게 적응할 수 있도록 보장하기를 원합니다.\\n솔루션 설계자는 기업이 애플리케이션 코드나 웹사이트를 업그레이드하지 않고도 이러한 목표를 충족해야 합니다.\\n솔루션 설계자는 이 목표를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.제품 매뉴얼을 EBS 볼륨에 보관하십시오. 해당 볼륨을 EC2 인스턴스에 탑재합니다.\\nB. 제품 설명서를 Amazon S3 버킷에 저장합니다. 다운로드를 이 버킷으로 리디렉션합니다.\\nC. 제품 설명서를 Amazon Elastic File System(Amazon EFS) 볼륨에 저장합니다. 해당 볼륨을 EC2 인스턴스에 탑재합니다.\\nD. Amazon S3 Standard-Infrequent Access(S3 Standard-IA) 버킷에 제품 설명서를 저장합니다. 다운로드를 이 버킷으로 리디렉션합니다.\", \"A business hosts its website on Amazon EC2 instances that are distributed across several Availability Zones through an Elastic Load Balancer. The instances are managed as part of an EC2 Auto Scaling group. The website stores product manuals for download through Amazon Elastic Block Store (Amazon EBS) volumes. The organization often changes the product information, which means that new instances created by the Auto Scaling group frequently have out-of-date data. It may take up to 30 minutes for all changes to be received by fresh instances. Additionally, the changes involve resizing the EBS volumes during business hours.\\nThe corporation want to guarantee that product manuals are constantly current and that the architecture adapts fast to rising customer demand.\\nA solutions architect must satisfy these objectives without requiring the business to upgrade its application code or website.\\nWhat actions should the solutions architect take to achieve this objective?\\n\\nA.Store the product manuals in an EBS volume. Mount that volume to the EC2 instances.\\nB. Store the product manuals in an Amazon S3 bucket. Redirect the downloads to this bucket.\\nC. Store the product manuals in an Amazon Elastic File System (Amazon EFS) volume. Mount that volume to the EC2 instances.\\nD. Store the product manuals in an Amazon S3 Standard-Infrequent Access (S3 Standard-IA) bucket. Redirect the downloads to this bucket.\", \"C. B를 사용하는 경우 응용 프로그램에서 파일을 읽는 코드를 변경해야 함.\"],\n[\"Amazon EC2에서 비즈니스는 전자 상거래 애플리케이션을 호스팅합니다. 애플리케이션은 실행을 위해 최소 10개의 인스턴스와 최대 250개의 인스턴스가 필요한 상태 비저장 웹 계층으로 구성됩니다. 80%의 경우 프로그램에는 50개의 인스턴스가 필요합니다.\\n비용을 줄이려면 어떤 솔루션을 채택해야 합니까?\\n\\nA.예약 인스턴스를 구매하여 250개의 인스턴스를 처리합니다.\\nB. 예약 인스턴스를 구매하여 80개의 인스턴스를 처리합니다. 스팟 인스턴스를 사용하여 나머지 인스턴스를 처리합니다.\\nC. 온디맨드 인스턴스를 구매하여 40개의 인스턴스를 처리합니다. 스팟 인스턴스를 사용하여 나머지 인스턴스를 처리합니다.\\nD. 예약 인스턴스를 구매하여 50개의 인스턴스를 처리합니다. 온디맨드 및 스팟 인스턴스를 사용하여 나머지 인스턴스를 처리합니다.\", \"On Amazon EC2, a business hosts an ecommerce application. The application is composed of a stateless web layer that needs a minimum of 10 instances and a maximum of 250 instances to run. 80% of the time, the program needs 50 instances.\\nWhich solution should be adopted in order to keep expenses down?\\n\\nA.Purchase Reserved Instances to cover 250 instances.\\nB. Purchase Reserved Instances to cover 80 instances. Use Spot Instances to cover the remaining instances.\\nC. Purchase On-Demand Instances to cover 40 instances. Use Spot Instances to cover the remaining instances.\\nD. Purchase Reserved Instances to cover 50 instances. Use On-Demand and Spot Instances to cover the remaining instances.\", \"D\"],\n[\"비즈니스에서 Amazon Aurora 기반 Amazon RDS 데이터베이스 인스턴스를 설치하려고 합니다. 조직에는 90일 백업 보존 정책이 있습니다.\\n솔루션 아키텍트가 제안해야 하는 솔루션은 무엇입니까?\\n\\nA.RDS DB 인스턴스 생성 시 백업 보존 기간을 90일로 설정합니다.\\nB. 수명 주기 정책이 90일 후에 삭제되도록 설정된 사용자 관리형 Amazon S3 버킷에 자동 스냅샷을 복사하도록 RDS를 구성합니다.\\nC. 보존을 90일로 설정하여 RDS 데이터베이스의 일일 스냅샷을 수행하는 AWS Backup 계획을 생성합니다. 매일 백업 계획 실행을 예약하는 AWS Backup 작업을 생성합니다.\\nD. Amazon CloudWatch Events에서 매일 예약된 이벤트를 사용하여 RDS 자동 스냅샷의 복사본을 만드는 사용자 지정 AWS Lambda 함수를 실행합니다. 90일이 지난 스냅샷을 제거합니다.\", \"A business intends to install an Amazon RDS database instance powered by Amazon Aurora. The organization has a 90-day backup retention policy.\\nWhich solution, if any, should a solutions architect suggest?\\n\\nA.Set the backup retention period to 90 days when creating the RDS DB instance.\\nB. Configure RDS to copy automated snapshots to a user-managed Amazon S3 bucket with a lifecycle policy set to delete after 90 days.\\nC. Create an AWS Backup plan to perform a daily snapshot of the RDS database with the retention set to 90 days. Create an AWS Backup job to schedule the execution of the backup plan daily.\\nD. Use a daily scheduled event with Amazon CloudWatch Events to execute a custom AWS Lambda function that makes a copy of the RDS automated snapshot. Purge snapshots older than 90 days.\", \"C. A는 최대 저장 기간이 35일까지만 지원하므로 불가능. C가 다수 의견이지만 B도 가능하다는 의견 있음.\"],\n[\"솔루션 설계자는 공용 및 사설 서브넷으로 가상 사설 클라우드(VPC)를 구성하고 있습니다. VPC 및 서브넷은 IPv4 CIDR 블록을 사용하여 구성됩니다. 3개의 가용 영역(AZ) 각각에는 하나의 퍼블릭 서브넷과 하나의 프라이빗 서브넷이 있습니다. 인터넷 게이트웨이는 퍼블릭 서브넷을 인터넷에 연결하는 데 사용됩니다. Amazon EC2 인스턴스가 소프트웨어 업그레이드를 받으려면 프라이빗 서브넷이 인터넷에 연결되어 있어야 합니다.\\n솔루션 설계자는 프라이빗 서브넷이 인터넷에 연결되도록 허용하려면 어떻게 해야 합니까?\\n\\nA.각 AZ의 각 퍼블릭 서브넷에 대해 하나씩 3개의 NAT 게이트웨이를 생성합니다. 비 VPC 트래픽을 해당 AZ의 NAT 게이트웨이로 전달하는 각 AZ에 대한 프라이빗 라우팅 테이블을 생성합니다.\\nB. 각 AZ의 프라이빗 서브넷마다 하나씩 3개의 NAT 인스턴스를 생성합니다. 비 VPC 트래픽을 해당 AZ의 NAT 인스턴스로 전달하는 각 AZ에 대한 프라이빗 라우팅 테이블을 생성합니다.\\nC. 프라이빗 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 생성합니다. VPC가 아닌 트래픽을 프라이빗 인터넷 게이트웨이로 전달하는 프라이빗 서브넷에 대한 라우팅 테이블을 업데이트합니다.\\nD. 퍼블릭 서브넷 중 하나에 외부 전용 인터넷 게이트웨이를 생성합니다. VPC가 아닌 트래픽을 외부 전용 인터넷 게이트웨이로 전달하는 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다.\", \"A solutions architect is configuring a virtual private cloud (VPC) with public and private subnets. The VPC and subnets are configured using IPv4 CIDR blocks. Each of the three Availability Zones (AZs) has one public and one private subnet. An internet gateway is used to connect public subnets to the internet. Private subnets must have internet connectivity in order for Amazon EC2 instances to obtain software upgrades.\\nWhat should the solutions architect do to allow private subnets to connect to the internet?\\n\\nA.Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT gateway in its AZ.\\nB. Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT instance in its AZ.\\nC. Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non-VPC traffic to the private internet gateway.\\nD. Create an egress-only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non-VPC traffic to the egress- only internet gateway.\", \"A\"],\n[\"현재 한 기업에서 공급업체별 형식을 사용하여 Amazon S3에 250TB의 백업 데이터를 저장했습니다. 이 회사는 Amazon S3에서 파일을 추출하여 업계 표준 형식으로 변환한 다음 Amazon S3에 다시 업로드하려고 합니다. 회사는 이 세션의 데이터 전송과 관련된 비용을 줄이기를 원합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.Amazon S3를 벗어나지 않고 데이터가 변환되도록 변환 소프트웨어를 Amazon S3 배치 작업으로 설치합니다.\\nB. 온프레미스 가상 머신에 변환 소프트웨어를 설치합니다. 변환을 수행하고 가상 머신에서 Amazon S3로 파일을 다시 업로드합니다.\\nC. AWS Snowball Edge 장치를 사용하여 데이터를 내보내고 변환 소프트웨어를 장치에 설치합니다. 데이터 변환을 수행하고 Snowball Edge 디바이스에서 Amazon S3로 파일을 다시 업로드합니다.\\nD. Amazon S3와 동일한 리전에서 Amazon EC2 인스턴스를 시작하고 인스턴스에 변환 소프트웨어를 설치합니다. 변환을 수행하고 EC2 인스턴스에서 Amazon S3로 파일을 다시 업로드합니다.\", \"Currently, a corporation has 250 TB of backup data saved in Amazon S3 using a vendor-specific format. The firm wishes to extract files from Amazon S3, convert them to an industry-standard format, and then re-upload them to Amazon S3. The firm want to reduce the costs connected with data transmission for this session.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Install the conversion software as an Amazon S3 batch operation so the data is transformed without leaving Amazon S3.\\nB. Install the conversion software onto an on-premises virtual machine. Perform the transformation and re-upload the files to Amazon S3 from the virtual machine.\\nC. Use AWS Snowball Edge devices to export the data and install the conversion software onto the devices. Perform the data transformation and re-upload the files to Amazon S3 from the Snowball Edge devices.\\nD. Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re- upload the files to Amazon S3 from the EC2 instance.\", \"D\"],\n[\"비즈니스 애플리케이션은 온프레미스 서버에서 호스팅됩니다. 회사는 스토리지 용량을 빠르게 고갈시키고 있습니다. 프로그램은 블록 및 네트워크 파일 저장소를 모두 사용합니다. 기업은 현재 애플리케이션을 다시 설계할 필요 없이 로컬 캐싱을 가능하게 하는 고성능 솔루션이 필요합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 단계를 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.Amazon S3를 온프레미스 서버에 파일 시스템으로 탑재합니다.\\nB. AWS Storage Gateway 파일 게이트웨이를 배포하여 NFS 스토리지를 대체합니다.\\nC. AWS Snowball Edge를 배포하여 온프레미스 서버에 NFS 탑재를 프로비저닝합니다.\\nD. AWS Storage Gateway 볼륨 게이트웨이를 배포하여 블록 스토리지를 교체합니다.\\nE. Amazon Elastic Fife System(Amazon EFS) 볼륨을 배포하고 온프레미스 서버에 탑재합니다.\", \"A business's applications are hosted on on-premises servers. The corporation is rapidly depleting its storage capacity. The programs make use of both block and network file storage. The business need a high-performance solution that enables local caching without requiring it to re-architect its current applications.\\nWhich steps should a solutions architect perform in combination to satisfy these requirements? (Select two.)\\n\\nA.Mount Amazon S3 as a file system to the on-premises servers.\\nB. Deploy an AWS Storage Gateway file gateway to replace NFS storage.\\nC. Deploy AWS Snowball Edge to provision NFS mounts to on-premises servers.\\nD. Deploy an AWS Storage Gateway volume gateway to replace the block storage.\\nE. Deploy Amazon Elastic Fife System (Amazon EFS) volumes and mount them to on-premises servers.\", \"B, D. EFS는 캐싱 X\"],\n[\"비즈니스는 Application Load Balancer를 통해 라우팅되는 Amazon EC2 인스턴스에서 웹 서비스를 호스팅합니다. 인스턴스는 Amazon EC2 Auto Scaling 그룹을 통해 2개의 가용 영역에 분산됩니다. 기업은 비용을 낮게 유지하면서 필요한 SLA(서비스 수준 계약) 요구 사항을 달성하기 위해 항상 최소 4개의 인스턴스가 필요합니다.\\n가용 영역에 장애가 발생하는 경우 조직은 어떻게 SLA 준수를 유지할 수 있습니까?\\n\\nA.휴지 기간이 짧은 대상 추적 조정 정책을 추가합니다.\\nB. 더 큰 인스턴스 유형을 사용하도록 Auto Scaling 그룹 시작 구성을 변경합니다.\\nC. 3개의 가용 영역에서 6개의 서버를 사용하도록 Auto Scaling 그룹을 변경합니다.\\nD. 2개의 가용 영역에서 8개의 서버를 사용하도록 Auto Scaling 그룹을 변경합니다.\", \"A business hosts a web service on Amazon EC2 instances that are routed via an Application Load Balancer. The instances are distributed across two Availability Zones through an Amazon EC2 Auto Scaling group. At all times, the corporation requires a minimum of four instances to achieve the needed service level agreement (SLA) requirements while keeping expenses low.\\nHow can the organization maintain compliance with the SLA if an Availability Zone fails?\\n\\nA.Add a target tracking scaling policy with a short cooldown period.\\nB. Change the Auto Scaling group launch configuration to use a larger instance type.\\nC. Change the Auto Scaling group to use six servers across three Availability Zones.\\nD. Change the Auto Scaling group to use eight servers across two Availability Zones.\", \"C. \"],\n[\"한 회사에서 AWS 클라우드를 사용하여 3계층 전자상거래 애플리케이션을 실행하고 있습니다. 이 회사는 Amazon S3에서 웹사이트를 호스팅하고 이를 판매 API와 결합합니다. API는 ALB(Application Load Balancer)를 통해 연결된 3개의 Amazon EC2 인스턴스에서 회사에서 호스팅합니다. API는 정적 및 동적 프런트 엔드 콘텐츠와 판매 요청을 비동기적으로 실행하는 백엔드 작업자로 구성됩니다.\\n회사는 신제품 출시를 축하하는 이벤트 기간 동안 판매 요청이 갑자기 급증할 것으로 예상합니다.\\n솔루션 설계자는 모든 요청의 효과적인 처리를 보장하기 위해 무엇을 처방해야 합니까?\\n\\nA.동적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. 트래픽 증가를 처리하기 위해 EC2 인스턴스 수를 늘립니다.\\nB. 정적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. EC2 인스턴스를 Auto Scaling 그룹에 배치하여 네트워크 트래픽을 기반으로 새 인스턴스를 시작합니다.\\nC. 동적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. API가 처리할 트래픽을 줄이려면 ALB 앞에 Amazon ElastiCache 인스턴스를 추가합니다.\\nD. 정적 콘텐츠에 대한 Amazon CloudFront 배포를 추가합니다. Amazon Simple Queue Service(Amazon SQS) 대기열을 추가하여 나중에 EC2 인스턴스에서 처리하기 위해 웹 사이트에서 요청을 수신합니다.\", \"A firm is using the AWS Cloud to run a three-tier ecommerce application. The firm hosts the website on Amazon S3 and combines it with a sales API. The API is hosted by the firm on three Amazon EC2 instances that are connected through an Application Load Balancer (ALB). The API is composed of static and dynamic front-end content, as well as back-end workers that asynchronously execute sales requests.\\nThe corporation anticipates a big and abrupt surge in sales requests during events celebrating the introduction of new items.\\nWhat should a solutions architect prescribe to assure the effective processing of all requests?\\n\\nA.Add an Amazon CloudFront distribution for the dynamic content. Increase the number of EC2 instances to handle the increase in traffic.\\nB. Add an Amazon CloudFront distribution for the static content. Place the EC2 instances in an Auto Scaling group to launch new instances based on network traffic.\\nC. Add an Amazon CloudFront distribution for the dynamic content. Add an Amazon ElastiCache instance in front of the ALB to reduce traffic for the API to handle.\\nD. Add an Amazon CloudFront distribution for the static content. Add an Amazon Simple Queue Service (Amazon SQS) queue to receive requests from the website for later processing by the EC2 instances.\", \"D\"],\n[\"Amazon EC2 인스턴스는 애플리케이션을 실행하는 데 사용됩니다. 애플리케이션의 민감한 데이터는 Amazon S3 버킷에 보관됩니다. 버킷은 인터넷 액세스로부터 보호되어야 하며 VPC 내부의 서비스에 대한 액세스는 허용해야 합니다.\\n이를 위해 아카이브 솔루션은 어떤 활동을 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.Amazon S3용 VPC 엔드포인트를 생성합니다.\\nB. 버킷에서 서버 액세스 로깅을 활성화합니다.\\nC. 버킷 ​​정책을 적용하여 S3 엔드포인트에 대한 액세스를 제한합니다.\\nD. 민감한 정보가 있는 버킷에 S3 ACL을 추가합니다.\\nE. IAM 정책을 사용하는 사용자가 특정 버킷을 사용하도록 제한합니다.\", \"Amazon EC2 instances are used to execute an application. The application's sensitive data is housed in an Amazon S3 bucket. The bucket must be shielded from internet access while yet allowing access to it for services inside the VPC.\\nWhich activities should solutions archived take in order to do this? (Select two.)\\n\\nA.Create a VPC endpoint for Amazon S3.\\nB. Enable server access logging on the bucket.\\nC. Apply a bucket policy to restrict access to the S3 endpoint.\\nD. Add an S3 ACL to the bucket that has sensitive information.\\nE. Restrict users using the IAM policy to use the specific bucket.\", \"A, C\"],\n[\"기업의 프로그램은 각각 크기가 약 5MB인 방대한 수의 파일을 생성합니다. Amazon S3는 파일을 저장하는 데 사용됩니다. 회사 정책에 따라 파일은 삭제되기 전에 4년 동안 보관되어야 합니다. 파일에 복제하기 어려운 중요한 비즈니스 데이터가 포함되어 있기 때문에 즉각적인 액세스는 항상 필수적입니다. 파일은 일반적으로 항목 설정 후 처음 30일 이내에 조회되지만 해당 기간 이후에는 거의 액세스되지 않습니다.\\n가장 저렴한 스토리지 옵션은 무엇입니까?\\n\\nA.객체 생성 후 30일 동안 S3 Standard에서 S3 Glacier로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제합니다.\\nB. 객체 생성 후 30일 동안 S3 Standard에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제합니다.\\nC. 객체 생성 후 30일 동안 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제합니다.\\nD. 객체 생성 후 30일 동안 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 4년 후 파일을 S3 Glacier로 이동합니다.\", \"A business's program creates a vast number of files, each around 5 MB in size. Amazon S3 is used to store the files. According to company policy, files must be retained for a period of four years before they may be erased. Immediate access is always essential due to the fact that the files contain vital business data that is difficult to replicate. The files are commonly viewed within the first 30 days after the establishment of the item, but are seldom accessed beyond that time period.\\nWhich storage option is the MOST CHEAPEST?\\n\\nA.Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation.\\nB. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 days from object creation. Delete the files 4 years after object creation.\\nC. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation.\\nD. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation.\", \"C\"],\n[\"비즈니스에 미션 크리티컬 데이터가 포함된 버킷이 Amazon S3에 있습니다. 회사는 의도하지 않은 삭제로부터 이 데이터를 보호하기를 원합니다. 데이터는 계속 사용할 수 있어야 하며 사용자는 의도적으로 데이터를 지울 수 있어야 합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 함께 사용해야 합니까? (2개를 선택하세요.)\\n\\nA.S3 버킷에서 버전 관리를 활성화합니다.\\nB. S3 버킷에서 MFA 삭제를 활성화합니다.\\nC. S3 버킷에 버킷 정책을 생성합니다.\\nD. S3 버킷에서 기본 암호화를 활성화합니다.\\nE. S3 버킷의 객체에 대한 수명 주기 정책을 생성합니다.\", \"A business has a bucket on Amazon S3 that includes mission-critical data. The firm wishes to safeguard this data against inadvertent deletion. The data should remain available, and the user should be able to erase it on purpose.\\nWhich actions should a solutions architect use in conjunction to achieve this? (Select two.)\\n\\nA.Enable versioning on the S3 bucket.\\nB. Enable MFA Delete on the S3 bucket.\\nC. Create a bucket policy on the S3 bucket.\\nD. Enable default encryption on the S3 bucket.\\nE. Create a lifecycle policy for the objects in the S3 bucket.\", \"A, B\"],\n[\"기업은 들어오는 통신을 처리하는 응용 프로그램을 유지 관리합니다. 그런 다음 이러한 메시지는 수십 개의 다른 앱과 마이크로서비스에 의해 몇 초 만에 요약됩니다.\\n통신량은 크게 변동하며 때로는 초당 100,000개 이상으로 정점을 찍습니다. 이 회사는 솔루션을 기본 인프라와 분리하여 확장성을 높이고자 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon Kinesis Data Analytics에 대한 메시지를 유지합니다. 모든 응용 프로그램은 메시지를 읽고 처리합니다.\\nB. CPU 지표를 기반으로 EC2 인스턴스 수를 조정하는 Auto Scaling 그룹의 Amazon EC2 인스턴스에 애플리케이션을 배포합니다.\\nC. 단일 샤드를 사용하여 Amazon Kinesis Data Streams에 메시지를 씁니다. 모든 애플리케이션은 스트림에서 읽고 메시지를 처리합니다.\\nD. 하나 이상의 Amazon Simple Queue Service(Amazon SQS) 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다. 그러면 모든 애플리케이션이 대기열의 메시지를 처리합니다.\", \"A business maintains an application that processes incoming communications. These messages are then digested in a matter of seconds by dozens of other apps and microservices.\\nThe quantity of communications fluctuates significantly and sometimes peaks above 100,000 per second. The firm wishes to divorce the solution from its underlying infrastructure and thereby boost its scalability.\\nWhich solution satisfies these criteria?\\n\\nA.Persist the messages to Amazon Kinesis Data Analytics. All the applications will read and process the messages.\\nB. Deploy the application on Amazon EC2 instances in an Auto Scaling group, which scales the number of EC2 instances based on CPU metrics.\\nC. Write the messages to Amazon Kinesis Data Streams with a single shard. All applications will read from the stream and process the messages.\\nD. Publish the messages to an Amazon Simple Notification Service (Amazon SNS) topic with one or more Amazon Simple Queue Service (Amazon SQS) subscriptions. All applications then process the messages from the queues.\", \"D\"],\n[\"기업이 인프라를 온프레미스에서 AWS 클라우드로 이전하고 있습니다. 회사 앱 중 하나는 DFSR(분산 파일 시스템 복제)을 활용하여 데이터 일관성을 유지하는 Windows 파일 서버 팜에 데이터를 저장합니다. 파일 서버 팜은 솔루션 설계자가 교체해야 합니다.\\n어떤 솔루션 아키텍트 서비스를 사용해야 합니까?\\n\\nA.Amazon Elastic File System(Amazon EFS)\\nB. 아마존 FSx\\nC. 아마존 S3\\nD. AWS 스토리지 게이트웨이\", \"A business is transferring its infrastructure from on-premises to the AWS Cloud. One of the company's apps stores data on a Windows file server farm that utilizes Distributed File System Replication (DFSR) to maintain data consistency. The file server farm must be replaced by a solutions architect.\\nWhich solution architect service should be used?\\n\\nA.Amazon Elastic File System (Amazon EFS)\\nB. Amazon FSx\\nC. Amazon S3\\nD. AWS Storage Gateway\", \"B\"],\n[\"AWS에서 기업은 고성능 컴퓨팅(HPC) 워크로드를 운영합니다. 요구 사항은 밀접하게 연결된 노드 간 통신을 통해 낮은 네트워크 대기 시간과 높은 네트워크 처리량을 필요로 했습니다. Amazon EC2 인스턴스는 기본 구성으로 시작되며 계산 및 스토리지 기능에 맞게 적절하게 확장됩니다.\\n솔루션 설계자는 워크로드의 성능을 최적화하기 위해 무엇을 조언해야 합니까?\\n\\nA.Amazon EC2 인스턴스를 시작하는 동안 클러스터 배치 그룹을 선택하십시오.\\nB. Amazon EC2 인스턴스를 시작하는 동안 전용 인스턴스 테넌시를 선택합니다.\\nC. Amazon EC2 인스턴스를 시작하는 동안 Elastic Inference 액셀러레이터를 선택합니다.\\nD. Amazon EC2 인스턴스를 시작하는 동안 필요한 용량 예약을 선택합니다.\", \"On AWS, a business operates a high-performance computing (HPC) workload. The demand necessitated low network latency and high network throughput through closely linked node-to-node communication. Amazon EC2 instances are started with default configurations and are appropriately scaled for computation and storage capabilities.\\nWhat should a solutions architect advise to optimize the workload's performance?\\n\\nA.Choose a cluster placement group while launching Amazon EC2 instances.\\nB. Choose dedicated instance tenancy while launching Amazon EC2 instances.\\nC. Choose an Elastic Inference accelerator while launching Amazon EC2 instances.\\nD. Choose the required capacity reservation while launching Amazon EC2 instances.\", \"A\"],\n[\"비즈니스에는 처리할 페이로드가 포함된 메시지를 보내는 응용 프로그램과 페이로드가 포함된 메시지를 받는 응용 프로그램의 두 가지 응용 프로그램이 있습니다. 조직은 두 앱 간의 통신을 관리하기 위해 Amazon Web Services(AWS) 솔루션을 만들고자 합니다. 발신자 프로그램은 매시간 약 1,000개의 메시지를 보낼 수 있습니다. 통신 처리에는 최대 2일이 소요될 수 있습니다. 메시지가 처리되지 않으면 후속 메시지 처리를 방해하지 않도록 보관해야 합니다.\\n어떤 솔루션이 이러한 매개변수를 충족하고 운영 효율성 측면에서 가장 최적입니까?\\n\\nA.Redis 데이터베이스를 실행하는 Amazon EC2 인스턴스를 설정합니다. 인스턴스를 사용하도록 두 애플리케이션을 모두 구성합니다. 메시지를 각각 저장, 처리 및 삭제합니다.\\nB. Amazon Kinesis 데이터 스트림을 사용하여 발신자 애플리케이션에서 메시지를 수신합니다. 처리 애플리케이션을 Kinesis 클라이언트 라이브러리(KCL)와 통합합니다.\\nC. 발신자 및 프로세서 애플리케이션을 Amazon Simple Queue Service(Amazon SQS) 대기열과 통합합니다. 처리에 실패한 메시지를 수집하도록 배달 못한 편지 대기열을 구성합니다.\\nD. 처리할 알림을 수신하려면 처리 애플리케이션을 Amazon Simple Notification Service(Amazon SNS) 주제에 등록합니다. SNS 주제에 쓸 발신자 애플리케이션을 통합합니다.\", \"A business has two applications: one that sends messages with payloads to be processed and another that receives messages with payloads. The organization wishes to create an Amazon Web Services (AWS) solution to manage communications between the two apps. The sender program is capable of sending around 1,000 messages every hour. Processing of communications may take up to two days. If the messages do not process, they must be kept to avoid interfering with the processing of subsequent messages.\\nWhich solution satisfies these parameters and is the MOST OPTIMAL in terms of operational efficiency?\\n\\nA.Set up an Amazon EC2 instance running a Redis database. Configure both applications to use the instance. Store, process, and delete the messages, respectively.\\nB. Use an Amazon Kinesis data stream to receive the messages from the sender application. Integrate the processing application with the Kinesis Client Library (KCL).\\nC. Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Configure a dead-letter queue to collect the messages that failed to process.\\nD. Subscribe the processing application to an Amazon Simple Notification Service (Amazon SNS) topic to receive notifications to process. Integrate the sender application to write to the SNS topic.\", \"C\"],\n[\"기업은 단일 지역의 AWS에서 기업 콘텐츠 관리 플랫폼을 호스팅하지만 플랫폼이 여러 지역에서 작동해야 합니다. 조직은 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터에서 마이크로서비스를 운영합니다. EKS 클러스터는 Amazon S3에서 항목을 저장하고 검색하는 역할을 합니다. 또한 EKS 클러스터는 Amazon DynamoDB를 활용하여 정보를 저장하고 검색합니다.\\n솔루션 설계자는 여러 지역에 플랫폼을 배포하기 위해 어떤 작업을 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.교차 리전 복제로 EKS 클러스터를 복제합니다.\\nB. Amazon API Gateway를 사용하여 EKS 클러스터에 대한 글로벌 엔드포인트를 생성합니다.\\nC. AWS Global Accelerator 엔드포인트를 사용하여 트래픽을 여러 리전에 분산합니다.\\nD. Amazon S3 액세스 포인트를 사용하여 여러 리전의 객체에 대한 액세스 권한을 부여합니다. DynamoDB 가속기(DAX)를 구성합니다. DAX를 관련 테이블에 연결합니다.\\nE. 다른 리전에 EKS 클러스터와 S3 버킷을 배포합니다. 두 S3 버킷에서 교차 리전 복제를 구성합니다. DynamoDB에 대한 전역 테이블을 켭니다.\", \"A business hosts its corporate content management platform on AWS in a single region but requires the platform to function across several regions. The organization operates its microservices on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. The EKS cluster is responsible for storing and retrieving items from Amazon S3. Additionally, the EKS cluster utilizes Amazon DynamoDB to store and retrieve information.\\nWhich actions should a solutions architect do in combination to deploy the platform across several regions? (Select two.)\\n\\nA.Replicate the EKS cluster with cross-Region replication.\\nB. Use Amazon API Gateway to create a global endpoint to the EKS cluster.\\nC. Use AWS Global Accelerator endpoints to distribute the traffic to multiple Regions.\\nD. Use Amazon S3 access points to give access to the objects across multiple Regions. Configure DynamoDB Accelerator (DAX). Connect DAX to the relevant tables.\\nE. Deploy an EKS cluster and an S3 bucket in another Region. Configure cross-Region replication on both S3 buckets. Turn on global tables for DynamoDB.\", \"C, E\"],\n[\"기업은 10.10.1.0/24의 CIDR 블록으로 프로비저닝된 VPC를 사용합니다. 지속적인 확장으로 인해 이 블록의 IP 주소 공간이 곧 소모될 수 있습니다. 솔루션 설계자는 VPC의 IP 주소 용량을 확장해야 합니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 방법은 무엇입니까?\\n\\nA.새 VPC를 생성합니다. 더 큰 CIDR 블록을 연결합니다.\\nB. 10.10.2.0/24의 보조 CIDR 블록을 VPC에 추가합니다.\\nC. 기존 VPC CIDR 블록의 크기를 10.10.1.0/24에서 10.10.1.0/16으로 조정합니다.\\nD. CIDR 블록이 10.10.1.0/16인 새 VPC와 VPC 피어링을 설정합니다.\", \"A business use a VPC that is provisioned with a CIDR block of 10.10.1.0/24. Due to continuing expansion, this block's IP address space may soon be consumed. A solutions architect must expand the VPC's IP address capacity.\\nWhich method satisfies these criteria with the LEAST amount of operational overhead?\\n\\nA.Create a new VPC. Associate a larger CIDR block.\\nB. Add a secondary CIDR block of 10.10.2.0/24 to the VPC.\\nC. Resize the existing VPC CIDR block from 10.10.1.0/24 to 10.10.1.0/16.\\nD. Establish VPC peering with a new VPC that has a CIDR block of 10.10.1.0/16.\", \"B. VPC 설정 후에는 CIDR을 변경할 수 없으므로 보조 CIDR 블록을 연결해야 함.\"],\n[\"기업은 ELB Application Load Balancer를 통해 라우팅되는 Amazon EC2 인스턴스에서 웹사이트를 호스팅합니다. DNS는 Amazon Route 53을 통해 처리됩니다. 회사는 원래 웹사이트를 사용할 수 없게 된 경우 사용자가 연락할 수 있는 메시지, 전화번호 및 이메일 주소가 포함된 백업 웹사이트를 구축하려고 합니다.\\n이 솔루션을 어떻게 구현해야 합니까?\\n\\nA.백업 웹사이트에 Amazon S3 웹사이트 호스팅을 사용하고 Route 53 장애 조치 라우팅 정책을 사용합니다.\\nB. 백업 웹사이트에 Amazon S3 웹사이트 호스팅을 사용하고 Route 53 지연 라우팅 정책을 사용합니다.\\nC. 다른 AWS 리전에 애플리케이션을 배포하고 장애 조치 라우팅을 위해 ELB 상태 확인을 사용합니다.\\nD. 다른 AWS 리전에 애플리케이션을 배포하고 기본 웹 사이트에서 서버 측 리디렉션을 사용합니다.\", \"A business hosts its website on Amazon EC2 instances that are routed via an ELB Application Load Balancer. The DNS is handled via Amazon Route 53. The firm want to establish a backup website with a message, phone number, and email address for users to contact in the event that the original website becomes unavailable.\\nHow should this solution be implemented?\\n\\nA.Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy.\\nB. Use Amazon S3 website hosting for the backup website and Route 53 latency routing policy.\\nC. Deploy the application in another AWS Region and use ELB health checks for failover routing.\\nD. Deploy the application in another AWS Region and use server-side redirection on the primary website.\", \"A\"],\n[\"회사의 사내 비즈니스 프로그램은 매일 수백 개의 파일을 생성합니다. 이러한 파일은 SMB 파일 공유에 보관되며 짧은 대기 시간으로 애플리케이션 서버에 연결해야 합니다. 새로운 비즈니스 정책에 따라 애플리케이션에서 생성한 모든 파일은 AWS로 이동해야 합니다. AWS에 대한 VPN 연결이 이미 설정되어 있습니다.\\n애플리케이션 개발 팀은 AWS로 마이그레이션하기 위해 애플리케이션 코드를 수정하는 데 필요한 시간이 부족합니다.\\n애플리케이션이 Amazon Web Services(AWS)로 파일을 전송할 수 있도록 하려면 솔루션 설계자가 어떤 서비스를 제안해야 합니까?\\n\\nA.Amazon Elastic File System(Amazon EFS)\\nB. Windows 파일 서버용 Amazon FSx\\nC. AWS 스노우볼\\nD. AWS 스토리지 게이트웨이\", \"A firm's on-premises business program creates hundreds of files daily. These files are kept on an SMB file share and need a connection to the application servers with a low latency. A new business policy requires that all files created by applications be moved to AWS. A VPN connection to AWS is already established.\\nThe application development team lacks the time required to modify the application's code in order to migrate it to AWS.\\nWhich service should a solutions architect propose to enable an application to transfer files to Amazon Web Services (AWS)?\\n\\nA.Amazon Elastic File System (Amazon EFS)\\nB. Amazon FSx for Windows File Server\\nC. AWS Snowball\\nD. AWS Storage Gateway\", \"D\"],\n[\"기업은 WebSocket을 사용하여 온프레미스 서버에서 라이브 채팅 애플리케이션을 호스팅합니다. 회사는 애플리케이션을 Amazon Web Services(AWS)로 이전하려고 합니다.\\n애플리케이션에 대한 트래픽은 고르지 않으며 회사는 미래에 갑자기 급증할 더 많은 트래픽을 예상합니다.\\n비즈니스에는 최소한의 서버 유지 관리 또는 정교한 용량 계획이 필요한 확장성이 뛰어난 솔루션이 필요합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Amazon API Gateway 및 AWS Lambda를 사용합니다. 프로비저닝된 용량에 대해 DynamoDB 테이블을 구성합니다.\\nB. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Amazon API Gateway 및 AWS Lambda를 사용합니다. 온디맨드 용량에 대해 DynamoDB 테이블을 구성합니다.\\nC. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Auto Scaling 그룹의 Application Load Balancer 뒤에서 Amazon EC2 인스턴스를 실행합니다. 온디맨드 용량에 대해 DynamoDB 테이블을 구성합니다.\\nD. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Auto Scaling 그룹의 Network Load Balancer 뒤에서 Amazon EC2 인스턴스를 실행합니다. 프로비저닝된 용량에 대해 DynamoDB 테이블을 구성합니다.\", \"A business uses WebSockets to host a live chat application on its on-premises servers. The firm want to transfer the application to Amazon Web Services (AWS).\\nTraffic to the application is uneven, and the firm anticipates more traffic with sudden spikes in the future.\\nThe business need a highly scalable solution that requires minimal server maintenance or sophisticated capacity planning.\\nWhich solution satisfies these criteria?\\n\\nA.Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for provisioned capacity.\\nB. Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for on-demand capacity.\\nC. Run Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for on-demand capacity.\\nD. Run Amazon EC2 instances behind a Network Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store. Configure the DynamoDB table for provisioned capacity.\", \"B. 최소한의 서버유지 -> serverless / API Gateway는 Websocket도 지원함.\"],\n[\"비즈니스에서 수 기가바이트의 데이터를 AWS로 마이그레이션하려고 합니다. 오프라인 데이터는 선박에서 얻습니다. 조직은 데이터를 전송하기 전에 복잡한 변환을 수행하려고 합니다.\\n솔루션 설계자는 이 마이그레이션을 위해 어떤 Amazon Web Services(AWS) 서비스를 제안해야 합니까?\\n\\nA.AWS 스노우볼\\nB. AWS 스노우모빌\\nC. AWS Snowball Edge 스토리지 최적화\\nD. AWS Snowball Edge 컴퓨팅 최적화\", \"A business intends to migrate many gigabytes of data to AWS. Offline data is obtained from ships. Before transmitting the data, the organization want to do complicated transformations.\\nWhich Amazon Web Services (AWS) service should a solutions architect suggest for this migration?\\n\\nA.AWS Snowball\\nB. AWS Snowmobile\\nC. AWS Snowball Edge Storage Optimize\\nD. AWS Snowball Edge Compute Optimize\", \"D\"],\n[\"Amazon EC2 인스턴스의 미디어 조직에서 두 개의 비디오 변환 프로그램을 사용하고 있습니다. 하나의 유틸리티는 Windows 기반이고 다른 유틸리티는 Linux 기반입니다. 각 비디오 파일은 다소 방대하며 두 프로그램에서 모두 처리해야 합니다.\\n조직에는 이 작업에 사용되는 모든 EC2 인스턴스에 탑재할 수 있는 중앙 집중식 파일 시스템을 생성할 수 있는 스토리지 솔루션이 필요합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Windows 인스턴스용 Amazon FSx for Windows 파일 서버를 사용하십시오. Linux 인스턴스에 대해 최대 I/O 성능 모드로 Amazon Elastic File System(Amazon EFS)을 사용합니다.\\nB. Windows 인스턴스용 Windows 파일 서버용 Amazon FSx를 사용합니다. Linux 인스턴스용 Lustre용 Amazon FSx를 사용합니다. 두 Amazon FSx 파일 시스템을 동일한 Amazon S3 버킷에 연결합니다.\\nC. Windows 인스턴스 및 Linux 인스턴스에 대해 범용 성능 모드로 Amazon Elastic File System(Amazon EFS) 사용\\nD. Windows 인스턴스 및 Linux 인스턴스에 대해 Windows 파일 서버용 Amazon FSx를 사용합니다.\", \"Two video conversion programs are being used by a media organization on Amazon EC2 instances. One utility is Windows-based, while the other is Linux-based. Each video file is rather huge and both programs must process it.\\nThe organization requires a storage solution that enables the creation of a centralized file system that can be mounted on all of the EC2 instances utilized in this operation.\\nWhich solution satisfies these criteria?\\n\\nA.Use Amazon FSx for Windows File Server for the Windows instances. Use Amazon Elastic File System (Amazon EFS) with Max I/O performance mode for the Linux instances.\\nB. Use Amazon FSx for Windows File Server for the Windows instances. Use Amazon FSx for Lustre for the Linux instances. Link both Amazon FSx file systems to the same Amazon S3 bucket.\\nC. Use Amazon Elastic File System (Amazon EFS) with General Purpose performance mode for the Windows instances and the Linux instances\\nD. Use Amazon FSx for Windows File Server for the Windows instances and the Linux instances.\", \"D\"],\n[\"기업은 Amazon RDS를 사용하여 웹 애플리케이션을 구동합니다. 새로운 데이터베이스 관리자가 실수로 데이터베이스 테이블에서 데이터를 삭제했습니다. 이러한 상황에서 복구를 지원하기 위해 조직은 데이터베이스를 지난 30일 동안 변경이 발생하기 5분 전의 상태로 복원할 수 있는 능력을 원합니다.\\n이 요구 사항을 충족하기 위해 솔루션 설계자가 설계에 포함해야 하는 기능은 무엇입니까?\\n\\nA.읽기 복제본\\nB. 수동 스냅샷\\nC. 자동 백업\\nD. 다중 AZ 배포\", \"A business uses Amazon RDS to power a web application. A fresh database administrator mistakenly deleted data from a database table. To aid in recovery from such an occurrence, the organization desires the capacity to restore the database to the condition it was in five minutes prior to any alteration during the past 30 days.\\nWhich capability should the solutions architect include into the design to satisfy this requirement?\\n\\nA.Read replicas\\nB. Manual snapshots\\nC. Automated backups\\nD. Multi-AZ deployments\", \"C\"],\n[\"한 기업이 AWS에서 호스팅될 비디오 변환기 애플리케이션을 구축하고 있습니다. 이 프로그램은 무료 버전과 프리미엄 버전의 두 가지 버전으로 제공됩니다. 프리미엄 계층의 사용자가 먼저 비디오를 변환하고 트리 계층의 사용자가 그 다음으로 변환합니다.\\n이 기준을 충족하고 가장 비용 효율적인 옵션은 무엇입니까?\\n\\nA.유료 계층을 위한 하나의 FIFO 대기열과 무료 계층을 위한 하나의 표준 대기열.\\nB. 모든 파일 유형에 대한 단일 FIFO Amazon Simple Queue Service(Amazon SQS) 대기열.\\nC. 모든 파일 유형에 대한 단일 표준 Amazon Simple Queue Service(Amazon SQS) 대기열.\\nD. 2개의 표준 Amazon Simple Queue Service(Amazon SQS) 대기열이 하나는 유료 계층용이고 다른 하나는 프리 계층용입니다.\", \"A business is building a video converter application that will be hosted on AWS. The program will be offered in two flavors: a free version and a premium version. People on the premium tier will get their videos converted first, followed by users on the tree tier.\\nWhich option satisfies these criteria and is the MOST cost-effective?\\n\\nA.One FIFO queue for the paid tier and one standard queue for the free tier.\\nB. A single FIFO Amazon Simple Queue Service (Amazon SQS) queue for all file types.\\nC. A single standard Amazon Simple Queue Service (Amazon SQS) queue for all file types.\\nD. Two standard Amazon Simple Queue Service (Amazon SQS) queues with one for the paid tier and one for the free tier.\", \"D\"],\n[\"비즈니스에 Amazon Simple Queue Service에 메시지를 보내는 애플리케이션이 있습니다. 다른 프로그램은 큐를 폴링하고 메시지에 대해 I/O 집약적인 작업을 수행합니다. 조직에는 메시지 수신과 사용자 응답 사이에 허용되는 최대 시간을 규정하는 서비스 수준 계약(SLA)이 있습니다. 메시지 볼륨의 증가로 인해 조직은 지속적으로 SLA를 이행하는 데 어려움을 겪고 있습니다.\\n솔루션 설계자는 애플리케이션의 처리 속도를 높이고 모든 수준의 로드를 관리할 수 있도록 지원하기 위해 무엇을 해야 합니까?\\n\\nA.처리에 사용되는 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 인스턴스를 종료하고 더 큰 크기로 교체합니다.\\nB. 처리에 사용되는 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 인스턴스를 종료하고 Amazon EC2 전용 인스턴스로 교체합니다.\\nC. 처리에 사용된 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 시작 구성에서 이 이미지를 사용하여 Auto Scaling 그룹을 생성합니다. 총 CPU 사용률을 70% 미만으로 유지하도록 대상 추적 정책으로 그룹을 구성합니다.\\nD. 처리에 사용되는 인스턴스에서 Amazon 머신 이미지(AMI)를 생성합니다. 시작 구성에서 이 이미지를 사용하여 Auto Scaling 그룹을 생성합니다. SQS 대기열에서 가장 오래된 메시지의 수명을 기반으로 하는 대상 추적 정책으로 그룹을 구성합니다.\", \"A business has an application that sends messages to Amazon Simple Queue Service. Another program polls the queue and performs I/O-intensive operations on the messages. The organization has a service level agreement (SLA) that stipulates the maximum time allowed between message receipt and response to users. Due to the rise in message volume, the organization is having trouble fulfilling its SLA on a constant basis.\\nWhat should a solutions architect do to assist in increasing the application's processing speed and ensuring that it can manage any level of load?\\n\\nA.Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with a larger size.\\nB. Create an Amazon Machine Image (AMI) from the instance used for processing. Terminate the instance and replace it with an Amazon EC2 Dedicated Instance.\\nC. Create an Amazon Machine image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy to keep its aggregate CPU utilization below 70%.\\nD. Create an Amazon Machine Image (AMI) from the instance used for processing. Create an Auto Scaling group using this image in its launch configuration. Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue.\", \"D\"],\n[\"AWS 클라우드에서 기업은 다계층 전자 상거래 웹 애플리케이션을 운영하고 있습니다. 애플리케이션은 Amazon RDS MySQL 다중 AZ 데이터베이스에 연결된 Amazon EC2 인스턴스에서 호스팅됩니다. Amazon RDS는 Amazon Elastic Block Store(Amazon EBS)의 범용 SSD(gp2) 볼륨에 최신 세대 인스턴스와 2,000GB의 스토리지로 설정됩니다. 수요가 많은 순간에는 데이터베이스 성능이 애플리케이션에 영향을 미칩니다.\\nAmazon CloudWatch Logs의 로그를 연구한 후 데이터베이스 관리자는 읽기 및 쓰기 IOPS 수가 6.000을 초과하면 애플리케이션의 성능이 지속적으로 떨어지는 것을 발견했습니다.\\n솔루션 설계자는 애플리케이션의 성능을 최적화하기 위해 무엇을 해야 합니까?\\n\\nA.볼륨을 마그네틱 볼륨으로 교체합니다.\\nB. gp2 볼륨의 IOPS 수를 늘립니다.\\nC. 볼륨을 프로비저닝된 IOPS(PIOPS) 볼륨으로 교체합니다.\\nD. 2,000GB gp2 볼륨을 2개의 1,000GBgp2 볼륨으로 교체합니다.\", \"In the AWS Cloud, a business is operating a multi-tier ecommerce web application. The application is hosted on Amazon EC2 instances that are connected to an Amazon RDS MySQL Multi-AZ database. Amazon RDS is setup with the latest generation instance and 2,000 GB of storage in a General Purpose SSD (gp2) volume from Amazon Elastic Block Store (Amazon EBS). During moments of heavy demand, the database performance has an effect on the application.\\nAfter studying the logs in Amazon CloudWatch Logs, a database administrator discovers that when the number of read and write IOPS exceeds 6.000, the application's performance constantly drops.\\nWhat should a solutions architect do to optimize the performance of an application?\\n\\nA.Replace the volume with a Magnetic volume.\\nB. Increase the number of IOPS on the gp2 volume.\\nC. Replace the volume with a Provisioned IOPS (PIOPS) volume.\\nD. Replace the 2,000 GB gp2 volume with two 1,000 GBgp2 volumes.\", \"C\"],\n[\"전자상거래 웹사이트를 위해 기업은 다계층 애플리케이션을 개발했습니다. 이 웹 사이트는 Amazon EC2 인스턴스에서 호스팅되는 퍼블릭 서브넷 기반 Application Load Balancer, 퍼블릭 서브넷 기반 웹 계층 및 프라이빗 서브넷 기반 MySQL 클러스터를 사용합니다. MySQL 데이터베이스는 타사 공급자의 웹 사이트에서 제품 카탈로그 및 가격 정보를 가져와야 합니다. 솔루션 설계자의 목표는 운영 비용을 높이지 않고 보안을 최적화하는 계획을 개발하는 것입니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.VPC에 NAT 인스턴스를 배포합니다. NAT 인스턴스를 통해 모든 인터넷 기반 트래픽을 라우팅합니다.\\nB. 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다. 모든 인터넷 바인딩 트래픽을 NAT 게이트웨이로 보내도록 프라이빗 서브넷 라우팅 테이블을 수정합니다.\\nC. 인터넷 게이트웨이를 구성하고 VPC에 연결합니다. 인터넷 바인딩 트래픽을 인터넷 게이트웨이로 보내도록 프라이빗 서브넷 라우팅 테이블을 수정합니다.\\nD. 가상 프라이빗 게이트웨이를 구성하고 VPC에 연결합니다. 인터넷 바인딩된 트래픽을 가상 프라이빗 게이트웨이로 보내도록 프라이빗 서브넷 라우팅 테이블을 수정합니다.\", \"For its ecommerce website, a business developed a multi-tier application. The website makes use of a public subnet-based Application Load Balancer, a public subnet-based web tier, and a private subnet-based MySQL cluster hosted on Amazon EC2 instances. The MySQL database must obtain product catalog and price information from a third-party provider's website. A solutions architect's objective is to develop a plan that optimizes security without raising operating costs.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Deploy a NAT instance in the VPC. Route all the internet-based traffic through the NAT instance.\\nB. Deploy a NAT gateway in the public subnets. Modify the private subnet route table to direct all internet-bound traffic to the NAT gateway.\\nC. Configure an internet gateway and attach it to the VPC. Modify the private subnet route table to direct internet-bound traffic to the internet gateway.\\nD. Configure a virtual private gateway and attach it to the VPC. Modify the private subnet route table to direct internet-bound traffic to the virtual private gateway.\", \"B\"],\n[\"최근 한 기업에서 새로운 형태의 인터넷 연결 센서를 도입했습니다. 이 기업은 초당 대량의 데이터를 중앙 위치에 공급하기 위한 수천 개의 센서를 판매할 것으로 예상합니다. 솔루션 아키텍트는 엔지니어링 팀이 검사할 수 있도록 밀리초 응답으로 거의 실시간으로 데이터를 수집하고 저장하는 시스템을 개발해야 합니다.\\n솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\\n\\nA.Amazon SQS 대기열을 사용하여 데이터를 수집합니다. AWS Lambda 함수로 데이터를 소비한 다음 Amazon Redshift에 데이터를 저장합니다.\\nB. Amazon SQS 대기열을 사용하여 데이터를 수집합니다. AWS Lambda 함수로 데이터를 소비한 다음 Amazon DynamoDB에 데이터를 저장합니다.\\nC. Amazon Kinesis Data Streams를 사용하여 데이터를 수집합니다. AWS Lambda 함수로 데이터를 소비한 다음 Amazon Redshift에 데이터를 저장합니다.\\nD. Amazon Kinesis Data Streams를 사용하여 데이터를 수집합니다. AWS Lambda 함수로 데이터를 소비한 다음 Amazon DynamoDB에 데이터를 저장합니다.\", \"Recently, a business introduced a new form of internet-connected sensor. The business anticipates selling thousands of sensors that are intended to feed large amounts of data to a central location every second. A solutions architect must develop a system that ingests and stores data in near-real time with millisecond responsiveness for engineering teams to examine.\\nWhich solution should the architect of solutions recommend?\\n\\nA.Use an Amazon SQS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift.\\nB. Use an Amazon SQS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB.\\nC. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift.\\nD. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB.\", \"D\"],\n[\"비즈니스는 Amazon S3 버킷을 타사 공급자와 공유해야 합니다. 모든 항목은 버킷 소유자가 액세스할 수 있어야 합니다.\\nS3 버킷을 공유하려면 어떤 절차를 따라야 합니까?\\n\\nA.버킷을 요청자 지불 버킷으로 업데이트합니다.\\nB. 교차 출처 리소스 공유(CORS)를 활성화하도록 버킷을 업데이트합니다.\\nC. 사용자가 객체를 업로드할 때 버킷 소유자에게 모든 권한을 부여하도록 요구하는 버킷 정책을 생성합니다.\\nD. 사용자가 객체를 업로드할 때 버킷 소유자에게 모든 권한을 부여하도록 요구하는 IAM 정책을 생성합니다.\", \"A business must share an Amazon S3 bucket with a third-party provider. All items must be accessible to the bucket owner.\\nWhich procedure should be followed in order to share the S3 bucket?\\n\\nA.Update the bucket to be a Requester Pays bucket.\\nB. Update the bucket to enable cross-origin resource sharing (CORS).\\nC. Create a bucket policy to require users to grant bucket-owner-full-control when uploading objects.\\nD. Create an IAM policy to require users to grant bucket-owner-full-control when uploading objects.\", \"C\"],\n[\"한 기업에서 143TB MySQL 데이터베이스를 AWS로 옮기려고 합니다. 목표는 Amazon Aurora MySQL을 플랫폼으로 계속 사용하는 것입니다. 조직은 100Mbps AWS Direct Connect 연결을 사용하여 Amazon VPC에 연결합니다.\\n다음 중 비즈니스 요구 사항을 가장 잘 충족하고 가장 적은 시간이 필요한 옵션은 무엇입니까?\\n\\nA.Amazon S3용 게이트웨이 엔드포인트를 사용하십시오. 데이터를 Amazon S3로 마이그레이션합니다. 데이터를 Aurora로 가져옵니다.\\nB. Direct Connect 링크를 500Mbps로 업그레이드합니다. 데이터를 Amazon S3에 복사합니다. 데이터를 Aurora로 가져옵니다.\\nC. AWS Snowmobile을 주문하고 데이터베이스 백업을 복사합니다. AWS에서 데이터를 Amazon S3로 가져오도록 합니다. 백업을 Aurora로 가져옵니다.\\nD. 50TB AWS Snowball 디바이스 4개를 주문하고 여기에 데이터베이스 백업을 복사합니다. AWS에서 데이터를 Amazon S3로 가져오도록 합니다. 데이터를 Aurora로 가져옵니다.\", \"A corporation want to move a 143 TB MySQL database to AWS. The objective is to continue using Amazon Aurora MySQL as the platform. The organization connects to Amazon VPC using a 100 Mbps AWS Direct Connect connection.\\nWhich option best satisfies the requirements of the business and requires the LEAST amount of time?\\n\\nA.Use a gateway endpoint for Amazon S3. Migrate the data to Amazon S3. Import the data into Aurora.\\nB. Upgrade the Direct Connect link to 500 Mbps. Copy the data to Amazon S3. Import the data into Aurora.\\nC. Order an AWS Snowmobile and copy the database backup to it. Have AWS import the data into Amazon S3. Import the backup into Aurora.\\nD. Order four 50-TB AWS Snowball devices and copy the database backup onto them. Have AWS import the data into Amazon S3. Import the data into Aurora.\", \"D\"],\n[\"기업은 웹 사이트의 정적 사진을 Amazon S3 버킷에 저장합니다. 권한이 있는 사용자만 Amazon S3 항목에 액세스할 수 있도록 권한이 지정되었습니다.\\n솔루션 설계자는 데이터 손실을 방지하기 위해 어떤 조치를 취해야 합니까? (2개를 선택하세요.)\\n\\nA.S3 버킷에서 버전 관리를 활성화합니다.\\nB. S3 버킷에서 액세스 로깅을 활성화합니다.\\nC. S3 버킷에서 서버 측 암호화를 활성화합니다.\\nD. 객체를 Amazon S3 Glacier로 전환하도록 S3 수명 주기 규칙을 구성합니다.\\nE. MFA 삭제를 사용하여 개체를 삭제하기 위해 다단계 인증을 요구합니다.\", \"A business stores static photos for its website in an Amazon S3 bucket. Permissions were specified to restrict access to Amazon S3 items to privileged users only.\\nWhat steps should a solutions architect take to prevent data loss? (Select two.)\\n\\nA.Enable versioning on the S3 bucket.\\nB. Enable access logging on the S3 bucket.\\nC. Enable server-side encryption on the S3 bucket.\\nD. Configure an S3 lifecycle rule to transition objects to Amazon S3 Glacier.\\nE. Use MFA Delete to require multi-factor authentication to delete an object.\", \"A, E\"],\n[\"솔루션 설계자는 Amazon S3 버킷에 저장할 문서 검토 애플리케이션을 개발 중입니다. 솔루션은 의도하지 않은 문서 삭제를 방지하고 모든 문서 버전에 액세스할 수 있도록 보장해야 합니다. 사용자가 문서를 다운로드, 변경 및 업로드할 수 있는 기능이 필요합니다.\\n이러한 요구 사항을 달성하기 위해 어떤 조치를 조합하여 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.읽기 전용 버킷 ACL을 활성화합니다.\\nB. 버킷에서 버전 관리를 활성화합니다.\\nC. IAM 정책을 버킷에 연결합니다.\\nD. 버킷에서 MFA 삭제를 활성화합니다.\\nE. AWS KMS를 사용하여 버킷을 암호화합니다.\", \"A solutions architect is developing a document review application that will be stored in an Amazon S3 bucket. The solution must prevent unintentional document deletion and guarantee that all document versions are accessible. The ability for users to download, change, and upload documents is required.\\nWhich measures should be conducted in combination to achieve these requirements? (Select two.)\\n\\nA.Enable a read-only bucket ACL.\\nB. Enable versioning on the bucket.\\nC. Attach an IAM policy to the bucket.\\nD. Enable MFA Delete on the bucket.\\nE. Encrypt the bucket using AWS KMS.\", \"B, D\"],\n[\"기업은 전 세계적으로 300개 이상의 웹사이트와 앱을 호스팅합니다. 조직은 매일 30TB 이상의 클릭스트림 데이터를 분석할 수 있는 플랫폼을 원합니다.\\n솔루션 설계자는 전송 및 처리 중에 클릭스트림 데이터로 무엇을 해야 합니까?\\n\\nA.AWS Data Pipeline을 설계하여 데이터를 Amazon S3 버킷에 보관하고 데이터로 Amazon EMR 클러스터를 실행하여 분석을 생성합니다.\\nB. Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하여 데이터를 처리하고 Amazon Redshift가 분석에 사용할 수 있도록 Amazon S3 데이터 레이크로 보냅니다.\\nC. 데이터를 Amazon CloudFront에 캐시합니다. Amazon S3 버킷에 데이터를 저장합니다. S3 버킷에 객체가 추가되면 AWS Lambda 함수를 실행하여 분석할 데이터를 처리합니다.\\nD. Amazon Kinesis Data Streams에서 데이터를 수집합니다. Amazon Kinesis Data Firehose를 사용하여 Amazon S3 데이터 레이크로 데이터를 전송합니다. 분석을 위해 Amazon Redshift에 데이터를 로드합니다.\", \"A corporation hosts more than 300 websites and apps on a worldwide scale. Each day, the organization wants a platform capable of analyzing more than 30 TB of clickstream data.\\nWhat should a solutions architect do with the clickstream data during transmission and processing?\\n\\nA.Design an AWS Data Pipeline to archive the data to an Amazon S3 bucket and run an Amazon EMR cluster with the data to generate analytics.\\nB. Create an Auto Scaling group of Amazon EC2 instances to process the data and send it to an Amazon S3 data lake for Amazon Redshift to use for analysis.\\nC. Cache the data to Amazon CloudFront. Store the data in an Amazon S3 bucket. When an object is added to the S3 bucket, run an AWS Lambda function to process the data for analysis.\\nD. Collect the data from Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to transmit the data to an Amazon S3 data lake. Load the data in Amazon Redshift for analysis.\", \"D\"],\n[\"한 기업에서 웹 서버, 응용 프로그램 서버 및 데이터베이스 서버를 포함하는 3계층 온라인 응용 프로그램을 개발하고 있습니다. 소포가 배달되는 동안 프로그램은 GPS 위치를 모니터링합니다. 데이터베이스는 프로그램에 의해 0-5초마다 업데이트됩니다.\\n추적 정보는 사용자가 배송 상태를 확인할 수 있도록 가능한 한 빨리 읽어야 합니다. 어떤 날에는 몇 개의 소포만 모니터링될 수 있지만 다른 날에는 수백만 개의 소포가 추적될 수 있습니다. 추적 시스템은 추적 ID, 고객 ID 및 주문 ID를 사용하여 검색할 수 있어야 합니다. 1개월 이후에 이루어진 주문은 더 이상 모니터링되지 않습니다.\\n가능한 가장 낮은 총 소유 비용으로 이를 수행하기 위해 솔루션 설계자는 무엇을 제안해야 합니까?\\n\\nA.Amazon DynamoDB를 사용하여 DynamoDB 테이블에서 Auto Scaling 활성화. 1개월보다 오래된 항목에 대한 자동 삭제 스크립트를 예약합니다.\\nB. 글로벌 보조 인덱스와 함께 Amazon DynamoDB를 사용합니다. DynamoDB 테이블 및 글로벌 보조 인덱스에서 Auto Scaling을 활성화합니다. DynamoDB 테이블에서 TTL을 활성화합니다.\\nC. 프로비저닝된 IOPS(PIOPS)가 있는 Amazon RDS 온디맨드 인스턴스를 사용합니다. PIOPS가 초과될 때 알림을 보내도록 Amazon CloudWatch 경보를 활성화합니다. 필요에 따라 PIOPS를 늘리거나 줄입니다.\\nD. 프로비저닝된 IOPS(PIOPS)가 있는 Amazon RDS 예약 인스턴스를 사용합니다. Amazon CloudWatch 경보가 PIOPS 초과 시 알림을 보내도록 활성화합니다. 필요에 따라 PIOPS를 늘리거나 줄입니다.\", \"A business is developing a three-tier online application that will include a web server, an application server, and a database server. While packages are being delivered, the program will monitor their GPS locations. The database will be updated every 0-5 seconds by the program.\\nTracking information must be read as quickly as possible to allow users to verify the status of their deliveries. On certain days, just a few parcels may be monitored, while on others, millions of packages may be tracked. The tracking system must be searchable using the tracking ID, the customer ID, and the order ID. Orders placed after one month will no longer be monitored.\\nWhat should a solution architect propose in order to do this with the lowest possible total cost of ownership?\\n\\nA.Use Amazon DynamoDB Enable Auto Scaling on the DynamoDB table. Schedule an automatic deletion script for items older than 1 month.\\nB. Use Amazon DynamoDB with global secondary indexes. Enable Auto Scaling on the DynamoDB table and the global secondary indexes. Enable TTL on the DynamoDB table.\\nC. Use an Amazon RDS On-Demand instance with Provisioned IOPS (PIOPS). Enable Amazon CloudWatch alarms to send notifications when PIOPS are exceeded. Increase and decrease PIOPS as needed.\\nD. Use an Amazon RDS Reserved Instance with Provisioned IOPS (PIOPS). Enable Amazon CloudWatch alarms to send notification when PIOPS are exceeded. Increase and decrease PIOPS as needed.\", \"B\"],\n[\"전 세계에 특파원이 있는 한 뉴스 조직은 AWS를 사용하여 방송 시스템을 호스팅합니다. 기자는 방송 시스템에 라이브 피드를 제공합니다. 기자는 자신의 전화기에 설치된 소프트웨어(RTMP)를 사용하여 실시간 메시징 프로토콜을 통해 생방송을 전송합니다.\\n솔루션 설계자는 기자가 가능한 최고 품질의 스트림을 제공할 수 있는 시스템을 제공해야 합니다. 솔루션은 브로드캐스트 시스템에 대한 TCP 연결이 신속하게 이루어지도록 해야 합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 접근 방식을 사용해야 합니까?\\n\\nA.아마존 클라우드프론트\\nB. AWS 글로벌 액셀러레이터\\nC. AWS 클라이언트 VPN\\nD. Amazon EC2 인스턴스 및 AWS 탄력적 IP 주소\", \"A news organization with correspondents located around the globe uses AWS to host its broadcast system. The reporters provide the broadcast system with live feeds. The reporters transmit live broadcasts through the Real Time Messaging Protocol using software installed on their phones (RTMP).\\nA solutions architect must provide a system that enables reporters to deliver the highest-quality streams possible. The solution must ensure that TCP connections to the broadcast system are expedited.\\nWhat approach should the solutions architect use in order to satisfy these requirements?\\n\\nA.Amazon CloudFront\\nB. AWS Global Accelerator\\nC. AWS Client VPN\\nD. Amazon EC2 instances and AWS Elastic IP addresses\", \"B. CloudFront는 HTTP 프로토콜을 처리하도록 설계되었으며 Global Accelerator는 HTTP 및 TCP 및 UDP와 같은 HTTP가 아닌 프로토콜 모두에 가장 잘 사용됨,\"],\n[\"한 기업이 Linux 기반 웹 서버 세트를 AWS로 이전하고 있습니다. 특정 콘텐츠의 경우 웹 서버는 공유 파일 저장소에 저장된 파일에 액세스해야 합니다. 마이그레이션 기한을 맞추기 위해 약간의 조정만 필요합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.웹 서버에 액세스할 수 있는 Amazon S3 Standard 버킷을 생성합니다.\\nB. Amazon S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다.\\nC. Amazon Elastic File System(Amazon EFS) 볼륨을 생성하고 모든 웹 서버에 탑재합니다.\\nD. Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS SSD(io1) 볼륨을 구성하고 모든 웹 서버에 탑재합니다.\", \"A business is transferring a set of Linux-based web servers to AWS. For certain content, the web servers must access files stored in a shared file storage. To fulfill the migration deadline, only minor adjustments are necessary.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Create an Amazon S3 Standard bucket with access to the web server.\\nB. Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin.\\nC. Create an Amazon Elastic File System (Amazon EFS) volume and mount it on all web servers.\\nD. Configure Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1) volumes and mount them on all web servers.\", \"C\"],\n[\"매일 기업은 다양한 소스에서 정형 및 반정형 데이터를 얻습니다. 솔루션 설계자는 빅 데이터 처리를 위한 프레임워크를 사용하는 솔루션을 만들어야 합니다. SQL 쿼리 및 비즈니스 인텔리전스 도구는 데이터에 액세스할 수 있어야 합니다.\\n가장 성능이 뛰어난 솔루션을 제공하기 위해 솔루션 설계자는 무엇을 옹호해야 합니까?\\n\\nA.AWS Glue를 사용하여 데이터를 처리하고 Amazon S3를 사용하여 데이터를 저장합니다.\\nB. Amazon EMR을 사용하여 데이터를 처리하고 Amazon Redshift를 사용하여 데이터를 저장합니다.\\nC. Amazon EC2를 사용하여 데이터를 처리하고 Amazon Elastic Block Store(Amazon EBS)를 사용하여 데이터를 저장합니다.\\nD. Amazon Kinesis Data Analytics를 사용하여 데이터를 처리하고 Amazon Elastic File System(Amazon EFS)을 사용하여 데이터를 저장합니다.\", \"Every day, a business gets structured and semi-structured data from a variety of sources. A solutions architect must create a solution that makes use of frameworks for big data processing. SQL queries and business intelligence tools should be able to access the data.\\nWhat should the solutions architect advocate in order to provide the MOST performant solution possible?\\n\\nA.Use AWS Glue to process data and Amazon S3 to store data.\\nB. Use Amazon EMR to process data and Amazon Redshift to store data.\\nC. Use Amazon EC2 to process data and Amazon Elastic Block Store (Amazon EBS) to store data.\\nD. Use Amazon Kinesis Data Analytics to process data and Amazon Elastic File System (Amazon EFS) to store data.\", \"B\"],\n[\"Amazon RDS의 MySQL 데이터베이스 인스턴스는 애플리케이션에서 사용됩니다. RDS 데이터베이스는 스토리지 용량을 빠르게 고갈시키고 있습니다. 솔루션 설계자는 다운타임 없이 디스크 용량을 확장하려고 합니다.\\n최소 노력량으로 이러한 기준을 충족하는 방법은 무엇입니까?\\n\\nA.RDS에서 스토리지 자동 크기 조정을 활성화합니다.\\nB. RDS 데이터베이스 인스턴스 크기를 늘립니다.\\nC. RDS 데이터베이스 인스턴스 스토리지 유형을 프로비저닝된 IOPS로 변경합니다.\\nD. RDS 데이터베이스를 백업하고 저장 용량을 늘리고 데이터베이스를 복원하고 이전 인스턴스를 중지합니다.\", \"A MySQL database instance on Amazon RDS is used by an application. The RDS database is rapidly depleting its storage capacity. A solutions architect wants to expand disk capacity without causing downtime.\\nWhich method satisfies these criteria with the MINIMUM amount of effort?\\n\\nA.Enable storage auto scaling in RDS.\\nB. Increase the RDS database instance size.\\nC. Change the RDS database instance storage type to Provisioned IOPS.\\nD. Back up the RDS database, increase the storage capacity, restore the database and stop the previous instance.\", \"A\"],\n[\"비즈니스는 단일 VPC에서 전자 상거래 애플리케이션을 실행합니다. 단일 웹 서버와 Amazon RDS 다중 AZ 데이터베이스 인스턴스는 애플리케이션 스택을 구성합니다.\\n한 달에 두 번, 회사는 새로운 항목을 소개합니다. 그 결과 최소 72시간 동안 웹사이트 트래픽이 400% 증가합니다. 사용자의 브라우저는 제품 출시 중에 응답 시간이 느리고 시간 초과 문제가 많이 발생합니다.\\n솔루션 설계자는 최소한의 운영 오버헤드를 유지하면서 응답 시간과 시간 초과 실패를 최소화하기 위해 무엇을 해야 합니까?\\n\\nA.웹 서버의 인스턴스 크기를 늘립니다.\\nB. Application Load Balancer 및 추가 웹 서버를 추가합니다.\\nC. Amazon EC2 Auto Scaling 및 Application Load Balancer를 추가합니다.\\nD. Amazon ElastiCache 클러스터를 배포하여 자주 액세스하는 데이터를 저장합니다.\", \"A business runs an ecommerce application in a single VPC. A single web server and an Amazon RDS Multi-AZ database instance comprise the application stack.\\nTwice a month, the firm introduces new items. This results in a 400% increase in website traffic for a minimum of 72 hours. Users' browsers encounter poor response times and numerous timeout issues during product launches.\\nWhat should a solutions architect do to minimize response times and timeout failures while maintaining a minimal operational overhead?\\n\\nA.Increase the instance size of the web server.\\nB. Add an Application Load Balancer and an additional web server.\\nC. Add Amazon EC2 Auto Scaling and an Application Load Balancer.\\nD. Deploy an Amazon ElastiCache cluster to store frequently accessed data.\", \"C\"],\n[\"솔루션 설계자는 2단계 주문 프로세스 애플리케이션을 개발 중입니다. 첫 번째 단계는 동기식이며 사용자에게 최소한의 지연으로 반환해야 합니다. 두 번째 단계는 시간이 더 오래 걸리므로 별개의 구성 요소로 수행됩니다. 주문은 정확히 한 번만 원래 수령 순서대로 처리되어야 합니다.\\n솔루션 설계자는 이러한 구성 요소를 어떻게 통합합니까?\\n\\nA.Amazon SQS FIFO 대기열을 사용합니다.\\nB. Amazon SQS 표준 대기열과 함께 AWS Lambda 함수를 사용합니다.\\nC. SNS 주제를 생성하고 해당 주제에 대한 Amazon SQS FIFO 대기열을 구독합니다.\\nD. SNS 주제를 생성하고 해당 주제에 대한 Amazon SQS 표준 대기열을 구독합니다.\", \"A solutions architect is developing a two-step order process application. The first step is synchronous and must return with minimal delay to the user. Because the second stage is more time consuming, it will be done as a distinct component. Orders must be processed precisely once and in their original sequence of receipt.\\nHow are these components to be integrated by the solutions architect?\\n\\nA.Use Amazon SQS FIFO queues.\\nB. Use an AWS Lambda function along with Amazon SQS standard queues.\\nC. Create an SNS topic and subscribe an Amazon SQS FIFO queue to that topic.\\nD. Create an SNS topic and subscribe an Amazon SQS Standard queue to that topic.\", \"C. 사용자용 SNS, 주문 처리용 FIFO. 그러나 A가 답이라는 의견도 많음.\"],\n[\"한 비즈니스에서 AWS를 사용하여 Amazon S3 버킷에 저장된 기상 센서 데이터를 처리하는 애플리케이션을 운영하고 있습니다. 다양한 이유로 S3 버킷의 데이터를 처리하기 위해 3개의 배치 작업이 매시간 실행되도록 예약됩니다. 조직은 이벤트 기반 전략을 사용하여 세 가지 프로그램을 병렬로 실행하여 총 처리 시간을 최소화하고자 합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 대한 새 객체에 대한 S3 이벤트 알림을 활성화합니다. 처리를 위해 모든 응용 프로그램을 대기열에 등록합니다.\\nB. Amazon Simple Queue Service(Amazon SQS) 표준 대기열에 대한 새 객체에 대한 S3 이벤트 알림을 활성화합니다. 모든 응용 프로그램에 대한 추가 SQS 대기열을 만들고 처리를 위해 모든 응용 프로그램을 초기 대기열에 등록합니다.\\nC. 새 객체에 대한 S3 이벤트 알림을 활성화하여 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 분리합니다. 각 응용 프로그램에 대해 추가 SQS 대기열을 만들고 처리를 위해 초기 주제에 각 대기열을 구독합니다.\\nD. Amazon Simple Notification Service(Amazon SNS) 주제에 대한 새 객체에 대한 S3 이벤트 알림을 활성화합니다. 각 애플리케이션에 대한 Amazon Simple Queue Service(Amazon SQS) 대기열을 생성하고 처리할 주제에 대한 각 대기열을 구독합니다.\", \"A business is using AWS to operate an application that processes weather sensor data stored in an Amazon S3 bucket. Three batch tasks are scheduled to run hourly to process data in the S3 bucket for various reasons. The organization wishes to minimize total processing time by employing an event-based strategy to run the three programs in parallel.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Subscribe all applications to the queue for processing.\\nB. Enable S3 Event Notifications for new objects to an Amazon Simple Queue Service (Amazon SQS) standard queue. Create an additional SQS queue for all applications, and subscribe all applications to the initial queue for processing.\\nC. Enable S3 Event Notifications for new objects to separate Amazon Simple Queue Service (Amazon SQS) FIFO queues. Create an additional SQS queue for each application, and subscribe each queue to the initial topic for processing.\\nD. Enable S3 Event Notifications for new objects to an Amazon Simple Notification Service (Amazon SNS) topic. Create an Amazon Simple Queue Service (Amazon SQS) queue for each application, and subscribe each queue to the topic for processing.\", \"D\"],\n[\"단일 가용 영역에 있는 여러 Amazon EC2 인스턴스는 게임 회사에서 레이어 4 통신을 사용하여 플레이어와 연결하는 멀티플레이어 게임을 호스팅하는 데 사용됩니다. CTO(최고 기술 책임자)는 접근성이 높고 비용 효율적인 아키텍처를 원합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까? (2개를 선택하세요.)?\\n\\nA.EC2 인스턴스 수를 늘립니다.\\nB. EC2 인스턴스 수를 줄입니다.\\nC. EC2 인스턴스 앞에 Network Load Balancer를 구성합니다.\\nD. EC2 인스턴스 앞에 Application Load Balancer를 구성합니다.\\nE. 여러 가용 영역의 인스턴스를 자동으로 추가하거나 제거하도록 Auto Scaling 그룹을 구성합니다.\", \"Multiple Amazon EC2 instances in a single Availability Zone are used by a gaming firm to host a multiplayer game that connects with players using Layer 4 communication. The chief technology officer (CTO) desires a highly accessible and cost-effective architecture.\\nWhat actions should a solutions architect take to ensure that these criteria are met? (Select two.)?\\n\\nA.Increase the number of EC2 instances.\\nB. Decrease the number of EC2 instances.\\nC. Configure a Network Load Balancer in front of the EC2 instances.\\nD. Configure an Application Load Balancer in front of the EC2 instances.\\nE. Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically.\", \"C, E\"],\n[\"비즈니스는 Amazon S3에서 정적 웹 사이트를 실행합니다. 솔루션 설계자는 실수로 파일을 삭제한 경우에도 데이터를 복구할 수 있도록 보장해야 합니다.\\n이를 달성하려면 어떤 조치가 필요합니까?\\n\\nA.Amazon S3 버전 관리를 활성화합니다.\\nB. Amazon S3 Intelligent-Tiering을 활성화합니다.\\nC. Amazon S3 수명 주기 정책을 활성화합니다.\\nD. Amazon S3 교차 리전 복제를 활성화합니다.\", \"A business runs a static website on Amazon S3. A solutions architect must guarantee that data is recoverable in the event of an accidently deleted file.\\nWhich action is necessary to achieve this?\\n\\nA.Enable Amazon S3 versioning.\\nB. Enable Amazon S3 Intelligent-Tiering.\\nC. Enable an Amazon S3 lifecycle policy.\\nD. Enable Amazon S3 cross-Region replication.\", \"A\"],\n[\"솔루션 설계자는 회사 애플리케이션을 위한 고성능 기계 학습 기능을 갖춘 관리형 스토리지 솔루션을 개발해야 합니다. 이 애플리케이션은 AWS Fargate에서 호스팅되며 여기에 연결된 스토리지는 동시 파일 액세스를 지원하고 우수한 성능을 제공해야 합니다.\\n솔루션 설계자는 어떤 스토리지 선택을 권장해야 합니까?\\n\\nA.애플리케이션에 대한 Amazon S3 버킷을 생성하고 Fargate가 Amazon S3와 통신할 수 있도록 IAM 역할을 설정합니다.\\nB. Amazon FSx for Lustre 파일 공유를 생성하고 Fargate가 FSx for Lustre와 통신할 수 있도록 하는 IAM 역할을 설정합니다.\\nC. Amazon Elastic File System(Amazon EFS) 파일 공유를 생성하고 Fargate가 Amazon Elastic File System(Amazon EFS)과 통신할 수 있도록 하는 IAM 역할을 설정합니다.\\nD. 애플리케이션에 대한 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하고 Fargate가 Amazon Elastic Block Store(Amazon EBS)와 통신할 수 있도록 하는 IAM 역할을 설정합니다.\", \"A solutions architect must develop a managed storage solution with high-performance machine learning capability for a company's application. This application is hosted on AWS Fargate, and the storage attached to it must support concurrent file access and give good performance.\\nWhich storage choice should the architect of solutions recommend?\\n\\nA.Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3.\\nB. Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre.\\nC. Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon Elastic File System (Amazon EFS).\\nD. Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with Amazon Elastic Block Store (Amazon EBS).\", \"C\"],\n[\"한 회사에서 전 세계 도시의 온도, 습도 및 기압에 대한 데이터를 수집합니다. 매일 평균 500GB의 데이터가 각 스테이션에서 수집됩니다. 각 위치는 고속 인터넷 연결을 갖추고 있습니다. 회사의 일기 예보 도구는 지역에 중점을 두고 일일 데이터 분석을 수행합니다.\\n전 세계 모든 사이트에서 데이터를 수집하는 가장 빠른 방법은 무엇입니까?\\n\\nA.대상 버킷에서 Amazon S3 Transfer Acceleration을 활성화합니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 버킷에 직접 업로드합니다.\\nB. 가장 가까운 AWS 리전의 Amazon S3 버킷에 사이트 데이터를 업로드합니다. S3 교차 리전 복제를 사용하여 대상 버킷에 객체를 복사합니다.\\nC. 매일 AWS Snowball 작업을 예약하여 가장 가까운 AWS 리전으로 데이터를 전송합니다. S3 교차 리전 복제를 사용하여 대상 버킷에 객체를 복사합니다.\\nD. 가장 가까운 리전의 Amazon EC2 인스턴스에 데이터를 업로드합니다. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 하루에 한 번 EBS 스냅샷을 만들어 중앙 리전으로 복사합니다. 중앙 집중식 리전에서 EBS 볼륨을 복원하고 매일 데이터에 대한 분석을 실행합니다.\", \"A firm gathers data on temperature, humidity, and air pressure in cities across the world. Each day, an average of 500 GB of data is gathered each station. Each location is equipped with a high-speed internet connection. The company's weather forecasting tools are regionally focused and do daily data analysis.\\nWhat is the SPEEDIEST method for collecting data from all of these worldwide sites?\\n\\nA.Enable Amazon S3 Transfer Acceleration on the destination bucket. Use multipart uploads to directly upload site data to the destination bucket.\\nB. Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket.\\nC. Schedule AWS Snowball jobs daily to transfer data to the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket.\\nD. Upload the data to an Amazon EC2 instance in the closest Region. Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Once a day take an EBS snapshot and copy it to the centralized Region. Restore the EBS volume in the centralized Region and run an analysis on the data daily.\", \"A\"],\n[\"기업은 Amazon EC2 인스턴스를 사용하여 탄력적 IP 주소가 있는 퍼블릭 서브넷의 웹 서버를 호스팅합니다. EC2 인스턴스는 기본 보안 그룹에 할당됩니다. 모든 트래픽을 거부하도록 기본 네트워크 ACL(액세스 제어 목록)이 업데이트되었습니다. 솔루션 설계자는 포트 443을 통해 모든 위치에서 웹 서버에 액세스할 수 있도록 해야 합니다.\\n이 목표를 달성하는 절차의 순서는 무엇입니까? (2개를 선택하세요.)\\n\\nA.소스 0.0.0.0/0에서 TCP 포트 443을 허용하는 규칙으로 보안 그룹을 만듭니다.\\nB. TCP 포트 443을 대상 0.0.0.0/0으로 허용하는 규칙으로 보안 그룹을 만듭니다.\\nC. 소스 0.0.0.0/0에서 TCP 포트 443을 허용하도록 네트워크 ACL을 업데이트합니다.\\nD. 소스 0.0.0.0/0에서 대상 0.0.0.0/0으로 인바운드/아웃바운드 TCP 포트 443을 허용하도록 네트워크 ACL을 업데이트합니다.\\nE. 소스 0.0.0.0/0 및 아웃바운드 TCP 포트 32768-65535에서 대상 0.0.0.0/0으로 인바운드 TCP 포트 443을 허용하도록 네트워크 ACL을 업데이트합니다.\", \"A business uses an Amazon EC2 instance to host a web server on a public subnet with an Elastic IP address. The EC2 instance is assigned to the default security group. The default network access control list (ACL) has been updated to deny all traffic. A solutions architect must ensure that the web server is accessible from any location through port 443.\\nWhich sequence of procedures will achieve this objective? (Select two.)\\n\\nA.Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.\\nB. Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.\\nC. Update the network ACL to allow TCP port 443 from source 0.0.0.0/0.\\nD. Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0.\\nE. Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0.\", \"A, E\"],\n[\"한 기업이 3계층 사진 공유 플랫폼을 개발했습니다. 하나의 Amazon EC2 인스턴스에서 프런트 엔드 계층을 실행하고 다른 인스턴스에서 백엔드 계층을 실행하고 세 번째 인스턴스에서 MySQL 데이터베이스를 실행합니다. 솔루션 설계자는 고가용성 및 가능한 한 최소한의 애플리케이션 수정이 필요한 솔루션을 개발하는 책임을 맡았습니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon S3를 사용하여 프런트 엔드 계층을 호스팅하고 AWS Lambda 함수를 백엔드 계층에 사용합니다. 데이터베이스를 Amazon DynamoDB 테이블로 이동하고 Amazon S3를 사용하여 사용자의 이미지를 저장하고 제공합니다.\\nB. 프런트 엔드 및 백엔드 계층에 대해 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경을 사용합니다. 여러 읽기 전용 복제본이 있는 Amazon RDS 인스턴스로 데이터베이스를 이동하여 사용자의 이미지를 저장하고 제공합니다.\\nC. Amazon S3를 사용하여 백엔드 계층에 대한 Auto Scaling 그룹의 프런트 엔드 계층과 Amazon EC2 인스턴스 집합을 호스팅합니다. 데이터베이스를 메모리에 최적화된 인스턴스 유형으로 이동하여 사용자의 이미지를 저장하고 제공합니다.\\nD. 프런트 엔드 및 백엔드 계층에 대해 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경을 사용합니다. 다중 AZ 배포가 있는 Amazon RDS 인스턴스로 데이터베이스를 이동합니다. Amazon S3를 사용하여 사용자의 이미지를 저장하고 제공합니다.\", \"A business has developed a three-tiered picture sharing platform. It runs the front-end layer on one Amazon EC2 instance, the backend layer on another, and the MySQL database on a third. A solutions architect has been entrusted with the responsibility of developing a solution that is highly available and needs the fewest modifications to the application as possible.\\nWhich solution satisfies these criteria?\\n\\nA.Use Amazon S3 to host the front-end layer and AWS Lambda functions for the backend layer. Move the database to an Amazon DynamoDB table and use Amazon S3 to store and serve users' images.\\nB. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers. Move the database to an Amazon RDS instance with multiple read replicas to store and serve users' images.\\nC. Use Amazon S3 to host the front-end layer and a fleet of Amazon EC2 instances in an Auto Scaling group for the backend layer. Move the database to a memory optimized instance type to store and serve users' images.\\nD. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers. Move the database to an Amazon RDS instance with a Multi-AZ deployment. Use Amazon S3 to store and serve users' images.\", \"D. 최소한의 App 수정이므로 A에서 dynamoDB로 이전 불가능\"],\n[\"한 기업에서 다양한 가용 영역(AZ)에 분산된 다양한 프라이빗 서브넷과 AZ 중 하나에 위치한 하나의 퍼블릭 서브넷이 있는 가상 프라이빗 클라우드(VPC)를 개발했습니다. NAT 게이트웨이는 퍼블릭 서브넷에서 시작됩니다. 프라이빗 서브넷 내에서 NAT 게이트웨이를 사용하여 인터넷에 연결하는 상황이 있습니다. AZ 장애가 발생한 경우 조직은 모든 ​​인스턴스에 인터넷 연결 문제가 있는 것은 아니며 백업 계획이 준비되어 있는지 확인하려고 합니다.\\n솔루션 설계자에 따르면 가장 가용성이 높은 솔루션은 무엇입니까?\\n\\nA.동일한 AZ에 NAT 게이트웨이를 사용하여 새 퍼블릭 서브넷을 생성합니다. 두 NAT 게이트웨이 간에 트래픽을 분산합니다.\\nB. 새 퍼블릭 서브넷에 Amazon EC2 NAT 인스턴스를 생성합니다. NAT 게이트웨이와 NAT 인스턴스 간에 트래픽을 분산합니다.\\nC. 각 AZ에서 퍼블릭 서브넷을 생성하고 각 서브넷에서 NAT 게이트웨이를 시작합니다. 각 AZ의 프라이빗 서브넷에서 해당 NAT 게이트웨이로의 트래픽을 구성합니다.\\nD. 동일한 퍼블릭 서브넷에 Amazon EC2 NAT 인스턴스를 생성합니다. NAT 게이트웨이를 NAT 인스턴스로 교체하고 해당 인스턴스를 적절한 조정 정책이 있는 Auto Scaling 그룹과 연결합니다.\", \"A business has developed a virtual private cloud (VPC) with various private subnets distributed across different Availability Zones (AZs) and one public subnet located in one of the AZs. A NAT gateway is launched on the public subnet. Within private subnets, there are circumstances when a NAT gateway is used to connect to the internet. In the event of an AZ failure, the organization wants to verify that not all instances have internet connection difficulties and that a backup plan is prepared.\\nWhich solution, according to a solutions architect, is the MOST highly available?\\n\\nA.Create a new public subnet with a NAT gateway in the same AZ. Distribute the traffic between the two NAT gateways.\\nB. Create an Amazon EC2 NAT instance in a new public subnet. Distribute the traffic between the NAT gateway and the NAT instance.\\nC. Create public subnets in each AZ and launch a NAT gateway in each subnet. Configure the traffic from the private subnets in each AZ to the respective NAT gateway.\\nD. Create an Amazon EC2 NAT instance in the same public subnet. Replace the NAT gateway with the NAT instance and associate the instance with an Auto Scaling group with an appropriate scaling policy.\", \"C\"],\n[\"기업은 us-west-2 리전에 수많은 AWS 계정을 유지하고 앱을 배포합니다. 각 계정의 애플리케이션 로그는 Amazon S3 버킷에 보관됩니다. 조직은 단일 Amazon S3 버킷을 기반으로 중앙 집중식 로그 분석 시스템을 생성하려고 합니다. 로그는 us-west-2를 떠날 수 없으며 회사는 가능한 한 운영 비용을 최소화하기를 원합니다.\\n이 기준을 충족하고 가장 비용 효율적인 옵션은 무엇입니까?\\n\\nA.애플리케이션 S3 버킷 중 하나에서 중앙 집중식 S3 버킷으로 객체를 복사하는 S3 수명 주기 정책을 생성합니다.\\nB. S3 동일 지역 복제를 사용하여 S3 버킷의 로그를 us-west-2의 다른 S3 버킷으로 복제합니다. 로그 분석에 이 S3 버킷을 사용하십시오.\\nC. 매일 PutObject API 작업을 사용하여 버킷의 전체 콘텐츠를 us-west-2의 다른 S3 버킷에 복사하는 스크립트를 작성합니다. 로그 분석에 이 S3 버킷을 사용하십시오.\\nD. 로그가 S3 버킷으로 전달될 때마다 트리거되는 AWS Lambda 함수를 이러한 계정에 작성합니다(s3:ObjectCreated:* 이벤트). us-west-2의 다른 S3 버킷에 로그를 복사합니다. 로그 분석에 이 S3 버킷을 사용하십시오.\", \"A business maintains numerous AWS accounts and deploys apps in the us-west-2 Region. Each account's application logs are kept in Amazon S3 buckets. The organization wishes to create a centralized log analysis system based on a single Amazon S3 bucket. Logs cannot depart us-west-2, and the corporation want to incur the fewest possible operating costs.\\nWhich option satisfies these criteria and is the MOST cost-effective?\\n\\nA.Create an S3 Lifecycle policy that copies the objects from one of the application S3 buckets to the centralized S3 bucket.\\nB. Use S3 Same-Region Replication to replicate logs from the S3 buckets to another S3 bucket in us-west-2. Use this S3 bucket for log analysis.\\nC. Write a script that uses the PutObject API operation every day to copy the entire contents of the buckets to another S3 bucket in us-west-2. Use this S3 bucket for log analysis.\\nD. Write AWS Lambda functions in these accounts that are triggered every time logs are delivered to the S3 buckets (s3:ObjectCreated:* event). Copy the logs to another S3 bucket in us-west-2. Use this S3 bucket for log analysis.\", \"B\"],\n[\"기업이 온프레미스 앱을 Amazon Elastic Compute Cloud 인스턴스로 마이그레이션하고 있습니다. 그러나 다양한 컴퓨팅 요구 사항으로 인해 EC2 인스턴스는 지정된 가용 영역에서 항상 오전 8시에서 오후 5시 사이에 사용할 수 있어야 합니다.\\n비즈니스에서 애플리케이션을 실행하는 데 사용해야 하는 Amazon Elastic Compute Cloud 인스턴스는 무엇입니까?\\n\\nA.정기 예약 인스턴스\\nB. 온디맨드 인스턴스\\nC. 스팟 집합의 일부인 스팟 인스턴스\\nD. Auto Scaling 그룹의 EC2 인스턴스\", \"A business is migrating its on-premises apps to Amazon Elastic Compute Cloud instances. However, due to variable compute needs, EC2 instances must always be available for usage between the hours of 8 a.m. and 5 p.m. in designated Availability Zones.\\nWhich Amazon Elastic Compute Cloud instances should the business use to execute the applications?\\n\\nA.Scheduled Reserved Instances\\nB. On-Demand Instances\\nC. Spot Instances as part of a Spot Fleet\\nD. EC2 instances in an Auto Scaling group\", \"B. Scheduled Reserved Instances는 더 이상 지원되지 않으므로 A는 안됨.\"],\n[\"솔루션 설계자는 ECS 클러스터의 구성원인 Amazon EC2 인스턴스에서 작동하는 여러 Amazon Elastic Container Service(Amazon ECS) 작업 유형을 조정하는 솔루션을 개발하고 있습니다. 모든 작업의 ​​출력 및 상태 데이터를 저장해야 합니다. 각 작업은 약 10MB의 데이터를 출력하며 수백 개의 작업이 동시에 작동할 수 있습니다. 시스템은 빠른 속도로 읽고 쓸 수 있도록 조정되어야 합니다. 고대로\\n출력은 보존되고 제거되기 때문에 총 저장 공간은 1TB를 초과하지 않아야 합니다.\\n솔루션 설계자가 권장해야 하는 스토리지 옵션은 무엇입니까?\\n\\nA.모든 ECS 클러스터 인스턴스에서 액세스할 수 있는 Amazon DynamoDB 테이블.\\nB. 프로비저닝된 처리량 모드의 Amazon Elastic File System(Amazon EFS).\\nC. 버스팅 처리량 모드가 있는 Amazon Elastic File System(Amazon EFS) 파일 시스템.\\nD. ECS 클러스터 인스턴스에 탑재된 Amazon Elastic Block Store(Amazon EBS) 볼륨.\", \"A solutions architect is developing a solution that entails coordinating a number of Amazon Elastic Container Service (Amazon ECS) task types that are operating on Amazon EC2 instances that are members of an ECS cluster. All tasks' output and status data must be saved. Each job outputs around 10 MB of data, and hundreds of tasks may be operating concurrently. The system should be tuned for reading and writing at a fast rate of speed. As ancient\\nBecause outputs are preserved and removed, the total storage space should not exceed 1 TB.\\nWhich storage option should be recommended by the solutions architect?\\n\\nA.An Amazon DynamoDB table accessible by all ECS cluster instances.\\nB. An Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode.\\nC. An Amazon Elastic File System (Amazon EFS) file system with Bursting Throughput mode.\\nD. An Amazon Elastic Block Store (Amazon EBS) volume mounted to the ECS cluster instances.\", \"B. 버스팅 처리량 모드 = 기본모드\"],\n[\"솔루션 설계자는 고가용성 배스천 호스트 아키텍처를 설계해야 합니다. 솔루션은 단일 AWS 리전 내에서 강력해야 하며 유지 관리 노력이 거의 필요하지 않습니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.UDP 리스너를 사용하여 Auto Scaling 그룹에서 지원하는 Network Load Balancer를 생성합니다.\\nB. 파티션 배치 그룹의 인스턴스가 있는 스팟 집합에서 지원하는 Network Load Balancer를 생성합니다.\\nC. 다른 가용 영역의 기존 서버가 지원하는 Network Load Balancer를 대상으로 생성합니다.\\nD. 여러 가용 영역의 인스턴스를 대상으로 하여 Auto Scaling 그룹에서 지원하는 Network Load Balancer를 생성합니다.\", \"A solutions architect must design a bastion host architecture that is highly available. The solution must be robust inside a single AWS Region and need little maintenance effort.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Create a Network Load Balancer backed by an Auto Scaling group with a UDP listener.\\nB. Create a Network Load Balancer backed by a Spot Fleet with instances in a partition placement group.\\nC. Create a Network Load Balancer backed by the existing servers in different Availability Zones as the target.\\nD. Create a Network Load Balancer backed by an Auto Scaling group with instances in multiple Availability Zones as the target.\", \"D\"],\n[\"비즈니스의 CRM(고객 관계 관리) 애플리케이션은 Microsoft SQL Server를 실행하는 Amazon RDS 데이터베이스 인스턴스에 데이터를 저장합니다. 데이터베이스는 회사의 정보 기술 담당자가 관리합니다. 데이터베이스에는 기밀 정보가 포함됩니다. 조직은 IT 전문가가 데이터에 액세스할 수 없고 승인된 사람만 볼 수 있도록 보장하기를 원합니다.\\n솔루션 설계자는 데이터를 보호하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.Amazon RDS 관리형 키로 클라이언트 측 암호화를 사용합니다.\\nB. AWS Key Management Service(AWS KMS) 고객 관리형 키로 클라이언트 측 암호화를 사용합니다.\\nC. AWS Key Management Service(AWS KMS) 기본 암호화 키로 Amazon RDS 암호화를 사용합니다.\\nD. AWS Key Management Service(AWS KMS) 고객 관리형 키로 Amazon RDS 암호화를 사용합니다.\", \"A business's customer relationship management (CRM) application stores data on an Amazon RDS database instance running Microsoft SQL Server. The database is administered by the company's information technology personnel. The database includes confidential information. The organization want to guarantee that data is inaccessible to IT professionals and is only seen by authorized people.\\nWhat steps should a solutions architect take to safeguard data?\\n\\nA.Use client-side encryption with an Amazon RDS managed key.\\nB. Use client-side encryption with an AWS Key Management Service (AWS KMS) customer managed key.\\nC. Use Amazon RDS encryption with an AWS Key Management Service (AWS KMS) default encryption key.\\nD. Use Amazon RDS encryption with an AWS Key Management Service (AWS KMS) customer managed key.\", \"D\"],\n[\"Amazon Route 53 지연 시간 기반 라우팅은 회사에서 전 세계 고객을 위해 UDP 기반 애플리케이션으로 요청을 라우팅하는 데 사용하고 있습니다. 이 프로그램은 미국, 아시아 및 유럽에 있는 회사 자체 데이터 센터 내의 중복 서버에서 호스팅됩니다. 애플리케이션은 회사의 규정 준수 표준에 따라 온프레미스에서 호스팅되어야 합니다. 조직은 애플리케이션의 성능과 가용성을 향상하기를 원합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.3개의 AWS 리전에서 3개의 NLB(Network Load Balancer)를 구성하여 온프레미스 엔드포인트를 처리합니다. AWS Global Accelerator를 사용하여 액셀러레이터를 생성하고 NLB를 엔드포인트로 등록합니다. 가속기 DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다.\\nB. 3개의 AWS 리전에서 3개의 ALB(Application Load Balancer)를 구성하여 온프레미스 엔드포인트를 처리합니다. AWS Global Accelerator를 사용하여 액셀러레이터를 생성하고 ALB를 엔드포인트로 등록합니다. 가속기 DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다.\\nC. 3개의 AWS 리전에서 3개의 NLB(Network Load Balancer)를 구성하여 온프레미스 엔드포인트를 처리합니다. Route 53에서 3개의 NLB를 가리키는 지연 시간 기반 레코드를 생성하고 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다.\\nD. 3개의 AWS 리전에서 3개의 Application Load Balancer(ALB)를 구성하여 온프레미스 엔드포인트를 처리합니다. Route 53에서 3개의 ALB를 가리키는 지연 시간 기반 레코드를 생성하고 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS를 가리키는 CNAME을 사용하여 애플리케이션에 대한 액세스를 제공합니다.\", \"Amazon Route 53 latency-based routing is being used by a firm to route requests to their UDP-based application for customers worldwide. The program is hosted on redundant servers inside the company's own data centers in the United States, Asia, and Europe. The application must be hosted on-premises in accordance with the company's compliance standards. The organization want to enhance the application's performance and availability.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.\\nB. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.\\nC. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.\\nD. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.\", \"A\"],\n[\"한 기업이 대규모 멀티플레이어 온라인 게임을 개발 중입니다. 게임은 UDP를 통해 통신하므로 클라이언트와 백엔드가 짧은 대기 시간을 갖는 것이 중요합니다. 백엔드는 다양한 AWS 리전에서 확장될 수 있는 Amazon EC2 인스턴스에서 호스팅됩니다. 회사는 전 세계 소비자가 항상 게임에 액세스할 수 있도록 높은 수준의 게임 가용성을 요구합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon CloudFront를 배포하여 글로벌 트래픽을 지원합니다. 여러 리전의 EC2 인스턴스에 대한 액세스를 허용하도록 CloudFront를 오리진 그룹으로 구성합니다.\\nB. 한 지역에 Application Load Balancer를 배포하여 게임의 백엔드 인스턴스를 호스팅하는 각 지역의 EC2 인스턴스에 트래픽을 분산합니다.\\nC. Amazon CloudFront를 배포하여 오리진 액세스 ID(OAI)를 지원합니다. OAI를 각 리전의 EC2 인스턴스와 연결하여 글로벌 트래픽을 지원합니다.\\nD. 각 지역에 Network Load Balancer를 배포하여 트래픽을 분산합니다. AWS Global Accelerator를 사용하여 올바른 리전 엔드포인트로 트래픽을 라우팅하십시오.\", \"A business is developing a massively multiplayer online game. The game communicates through UDP, thus it is critical that the client and backend have a low latency. The backend is hosted on Amazon EC2 instances that may be scaled across various AWS Regions. The firm requires a high level of availability for the game in order for consumers worldwide to have access to it at all times.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Deploy Amazon CloudFront to support the global traffic. Configure CloudFront with an origin group to allow access to EC2 instances in multiple Regions.\\nB. Deploy an Application Load Balancer in one Region to distribute traffic to EC2 instances in each Region that hosts the game's backend instances.\\nC. Deploy Amazon CloudFront to support an origin access identity (OAI). Associate the OAI with EC2 instances in each Region to support global traffic.\\nD. Deploy a Network Load Balancer in each Region to distribute the traffic. Use AWS Global Accelerator to route traffic to the correct Regional endpoint.\", \"D\"],\n[\"비즈니스에서 회계 시스템을 온프레미스 데이터 센터에서 AWS 리전으로 이전하려고 합니다. 데이터 보안과 변경 불가능한 감사 로그에 우선 순위를 부여해야 합니다. 조직은 모든 ​​AWS 작업에 대해 규정 준수 감사를 수행해야 합니다. 조직에서 AWS CloudTrail을 활성화했지만 이러한 기준을 준수하는지 확인하려고 합니다.\\n솔루션 설계자는 CloudTrail을 보호하고 보호하기 위해 어떤 보호 장치와 보안 조치를 사용해야 합니까? (2개를 선택하세요.)\\n\\nA.CloudTrail 로그 파일 유효성 검사를 활성화합니다.\\nB. CloudTrail 처리 라이브러리를 설치합니다.\\nC. CloudTrail에서 Insights 이벤트 로깅을 활성화합니다.\\nD. 온프레미스 리소스에서 사용자 지정 로깅을 활성화합니다.\\nE. CloudTrail이 AWS KMS 관리형 암호화 키(SSE-KMS)와 함께 서버 측 암호화를 사용하도록 구성되었는지 여부를 모니터링하는 AWS Config 규칙을 생성합니다.\", \"A business wishes to relocate its accounting system from an on-premises data center to an AWS Region. Priority one should be given to data security and an unalterable audit log. The organization must conduct compliance audits on all AWS operations. Although the organization has activated AWS CloudTrail, it want to ensure that it complies with these criteria.\\nWhich safeguards and security measures should a solutions architect use to safeguard and secure CloudTrail? (Select two.)\\n\\nA.Enable CloudTrail log file validation.\\nB. Install the CloudTrail Processing Library.\\nC. Enable logging of Insights events in CloudTrail.\\nD. Enable custom logging from the on-premises resources.\\nE. Create an AWS Config rule to monitor whether CloudTrail is configured to use server-side encryption with AWS KMS managed encryption keys (SSE-KMS).\", \"A, E\"],\n[\"솔루션 설계자는 Amazon API Gateway와 함께 사용할 새로운 서비스를 개발 중입니다. 서비스의 요청 패턴은 초당 0에서 500까지 범위가 불규칙합니다. 백엔드 데이터베이스에 유지되어야 하는 전체 데이터 양은 이제 1GB 미만이며 향후 확장에 대해 예측할 수 없습니다. 간단한 키-값 쿼리를 사용하여 데이터를 쿼리할 수 있습니다.\\n이러한 요구 사항에 가장 적합한 AWS 서비스 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.AWS Fargate\\nB. AWS 람다\\nC. Amazon DynamoDB\\nD. Amazon EC2 Auto Scaling\\nE. MySQL 호환 Amazon Aurora\", \"A solutions architect is developing a new service to be used in conjunction with Amazon API Gateway. The service's request patterns will be erratic, ranging from zero to over 500 per second. The entire quantity of data that must be persisted in a backend database is now less than 1 GB, with unpredictability about future expansion. Simple key-value queries may be used to query data.\\nWhich AWS service combination would best suit these requirements? (Select two.)\\n\\nA.AWS Fargate\\nB. AWS Lambda\\nC. Amazon DynamoDB\\nD. Amazon EC2 Auto Scaling\\nE. MySQL-compatible Amazon Aurora\", \"B, C\"],\n[\"경영진은 모든 AWS VPC에서 IPv6을 허용하도록 선택했습니다. 일정 시간이 지나면 솔루션 설계자가 새 인스턴스를 생성하려고 시도하고 서브넷에 액세스 가능한 IP 주소 공간이 충분하지 않다는 오류가 발생합니다.\\n이를 해결하기 위한 솔루션 아키텍트의 역할은 무엇입니까?\\n\\nA.VPC 생성 시 IPv6만 사용했는지 확인합니다.\\nB. 범위가 더 넓은 새 IPv4 서브넷을 생성한 다음 인스턴스를 시작합니다.\\nC. 넓은 범위의 IPv6 전용 서브넷을 새로 생성한 후 인스턴스를 시작합니다.\\nD. IPv4 서브넷을 비활성화하고 모든 인스턴스를 IPv6으로만 마이그레이션합니다. 완료되면 인스턴스를 시작합니다.\", \"Management has chosen to allow IPv6 on all AWS VPCs. After a period of time, a solutions architect attempts to create a new instance and gets an error indicating that the subnet does not have enough accessible IP address space.\\nWhat is the solution architect's role in resolving this?\\n\\nA.Check to make sure that only IPv6 was used during the VPC creation.\\nB. Create a new IPv4 subnet with a larger range, and then launch the instance.\\nC. Create a new IPv6-only subnet with a large range, and then launch the instance.\\nD. Disable the IPv4 subnet and migrate all instances to IPv6 only. Once that is complete, launch the instance.\", \"B, C논란\"],\n[\"비즈니스는 물류 및 영업이라는 두 개의 AWS 계정과 함께 AWS Organizations를 사용합니다. Logistics 계정은 Amazon Redshift 클러스터의 운영을 담당합니다. Amazon EC2 인스턴스는 Sales 계정에 포함됩니다. Sales 계정에는 Logistics 계정이 소유한 Amazon Redshift 클러스터에 대한 액세스 권한이 필요합니다.\\n솔루션 설계자는 이 요구 사항을 달성하기 위해 가장 비용 효율적인 방법으로 무엇을 제안해야 합니까?\\n\\nA.물류 계정을 소유자로, 판매 계정을 참여자로 하여 VPC 공유를 설정하여 데이터를 전송합니다.\\nB. Logistics 계정에서 AWS Lambda 함수를 생성하여 Sales 계정의 Amazon EC2 인스턴스로 데이터를 전송합니다.\\nC. Amazon Redshift 클러스터의 스냅샷을 생성하고 스냅샷을 Sales 계정과 공유합니다. Sales 계정에서 Logistics 계정이 공유하는 스냅샷 ID를 사용하여 클러스터를 복원합니다.\\nD. COPY 명령을 실행하여 Amazon Redshift에서 Logistics 계정의 Amazon S3 버킷으로 데이터를 로드합니다. 판매 계정에 물류 계정의 S3 버킷에 액세스할 수 있는 권한을 부여합니다.\", \"A business uses AWS Organizations in conjunction with two AWS accounts: Logistics and Sales. The Logistics account is responsible for the operation of an Amazon Redshift cluster. Amazon EC2 instances are included in the Sales account. The Sales account requires access to the Amazon Redshift cluster owned by the Logistics account.\\nWhat should a solutions architect propose as the MOST cost-effective way to accomplish this requirement?\\n\\nA.Set up VPC sharing with the Logistics account as the owner and the Sales account as the participant to transfer the data.\\nB. Create an AWS Lambda function in the Logistics account to transfer data to the Amazon EC2 instances in the Sales account.\\nC. Create a snapshot of the Amazon Redshift cluster, and share the snapshot with the Sales account. In the Sales account, restore the cluster by using the snapshot ID that is shared by the Logistics account.\\nD. Run COPY commands to load data from Amazon Redshift into Amazon S3 buckets in the Logistics account. Grant permissions to the Sales account to access the S3 buckets of the Logistics account.\", \"C. 그러나 redshift 데이터공유 기능이 생겼다고 함.\"],\n[\"기업은 ALB(Application Load Balancer)를 사용하여 인터넷에 애플리케이션을 제공하고 있습니다. 조직은 애플리케이션 전체에서 비정상적인 트래픽 액세스 패턴을 식별합니다. 솔루션 설계자는 비즈니스에서 이러한 이상 현상을 이해하도록 지원하기 위해 인프라에 대한 가시성을 높여야 합니다.\\n이러한 요구 사항을 충족하는 가장 최적의 옵션은 무엇입니까?\\n\\nA.Amazon Athena에서 AWS CloudTrail 로그용 테이블을 생성합니다. 관련 정보에 대한 쿼리를 생성합니다.\\nB. Amazon S3에 대한 ALB 액세스 로깅을 활성화합니다. Amazon Athena에서 테이블을 생성하고 로그를 쿼리합니다.\\nC. Amazon S3에 대한 ALB 액세스 로깅을 활성화합니다. 텍스트 편집기에서 각 파일을 열고 각 행에서 관련 정보를 검색하십시오.\\nD. 전용 Amazon EC2 인스턴스에서 Amazon EMR을 사용하여 ALB에 직접 쿼리하여 트래픽 액세스 로그 정보를 얻습니다.\", \"A business is presenting their application to the internet using an Application Load Balancer (ALB). The organization identifies out-of-the-ordinary traffic access patterns across the application. A solutions architect must increase visibility into the infrastructure in order to assist the business in comprehending these anomalies.\\nWhat is the MOST OPTIMAL option that satisfies these requirements?\\n\\nA.Create a table in Amazon Athena for AWS CloudTrail logs. Create a query for the relevant information.\\nB. Enable ALB access logging to Amazon S3. Create a table in Amazon Athena, and query the logs.\\nC. Enable ALB access logging to Amazon S3. Open each file in a text editor, and search each line for the relevant information.\\nD. Use Amazon EMR on a dedicated Amazon EC2 instance to directly query the ALB to acquire traffic access log information.\", \"B\"],\n[\"비즈니스 운영 팀에는 버킷에 새 항목이 생성될 때 Amazon SQS 대기열에 알림을 보내도록 설정된 Amazon S3 버킷이 이미 있습니다. 또한 개발 팀은 새 개체가 생성될 때 알림을 받기를 원합니다. 운영 팀의 현재 워크플로를 유지해야 합니다.\\n이러한 기준을 충족하는 솔루션은 무엇입니까?\\n\\nA.다른 SQS 대기열을 만듭니다. 버킷의 S3 이벤트를 업데이트하여 새 객체가 생성될 때 새 대기열도 업데이트합니다.\\nB. Amazon S3만 대기열에 액세스하도록 허용하는 새 SQS 대기열을 생성합니다. 새 객체가 생성될 때 이 대기열을 업데이트하려면 Amazon S3를 업데이트하십시오.\\nC. 버킷 ​​업데이트를 위한 Amazon SNS 주제 및 SQS 대기열을 생성합니다. 새 주제에 이벤트를 보내도록 버킷을 업데이트합니다. Amazon SNS를 폴링하도록 두 대기열을 모두 업데이트합니다.\\nD. 버킷 업데이트를 위한 Amazon SNS 주제 및 SQS 대기열을 생성합니다. 새 주제에 이벤트를 보내도록 버킷을 업데이트합니다. 주제의 두 대기열에 대한 구독을 추가합니다.\", \"The operations team of a business already has an Amazon S3 bucket set to send notifications to an Amazon SQS queue when new items are generated in the bucket. Additionally, the development team want to get notifications when new objects are generated. The present workflow of the operations team must be maintained.\\nWhich solution would meet these criteria?\\n\\nA.Create another SQS queue. Update the S3 events in the bucket to also update the new queue when a new object is created.\\nB. Create a new SQS queue that only allows Amazon S3 to access the queue. Update Amazon S3 to update this queue when a new object is created.\\nC. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Updates both queues to poll Amazon SNS.\\nD. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic. Add subscriptions for both queues in the topic.\", \"D\"],\n[\"솔루션 설계자가 Amazon Linux 기반 HPC(고성능 컴퓨팅) 환경을 위한 스토리지를 만들고 있습니다. 워크로드는 공유 스토리지와 고성능 계산을 사용해야 하는 수많은 엔지니어링 도면을 저장하고 분석합니다.\\n어떤 스토리지 선택이 가장 좋습니까?\\n\\nA.Amazon Elastic File System(Amazon EFS)\\nB. Lustre용 Amazon FSx\\nC. Amazon EC2 인스턴스 스토어\\nD. Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS SSD(io1)\", \"A solutions architect is creating storage for an Amazon Linux-based high performance computing (HPC) environment. The workload saves and analyzes a huge number of engineering drawings, which necessitates the use of shared storage and high-performance computation.\\nWhich storage choice is the best?\\n\\nA.Amazon Elastic File System (Amazon EFS)\\nB. Amazon FSx for Lustre\\nC. Amazon EC2 instance store\\nD. Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1)\", \"B. HPC는 무조건 FSx Lustre\"],\n[\"한 기업이 Amazon Web Services(AWS)에서 공개 웹 애플리케이션을 구축할 계획입니다. 아키텍처는 Virtual Private Cloud(VPC) 내부에 포함되고 Elastic Load Balancer(ELB)로 보호되는 Amazon EC2 인스턴스로 구성됩니다. DNS는 타사 공급자가 관리합니다. 비즈니스의 솔루션 설계자는 대규모 DDoS 공격을 감지하고 방어하기 위한 솔루션을 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.계정에서 Amazon GuardDuty를 활성화합니다.\\nB. EC2 인스턴스에서 Amazon Inspector를 활성화합니다.\\nC. AWS Shield를 활성화하고 여기에 Amazon Route 53을 할당합니다.\\nD. AWS Shield Advanced를 활성화하고 ELB를 할당합니다.\", \"A business is planning to build a public-facing web application on Amazon Web Services (AWS). The architecture comprises of Amazon EC2 instances contained inside a Virtual Private Cloud (VPC) and protected by an Elastic Load Balancer (ELB). The DNS is managed by a third-party provider. The solutions architect of the business must offer a solution for detecting and defending against large-scale DDoS assaults.\\nWhich solution satisfies these criteria?\\n\\nA.Enable Amazon GuardDuty on the account.\\nB. Enable Amazon Inspector on the EC2 instances.\\nC. Enable AWS Shield and assign Amazon Route 53 to it.\\nD. Enable AWS Shield Advanced and assign the ELB to it.\", \"D\"],\n[\"비즈니스가 Amazon Web Services(AWS) 클라우드로 전환하고 있습니다. 이동할 초기 워크로드는 파일 서버입니다. 파일 공유는 SMB(서버 메시지 블록) 프로토콜을 통해 액세스할 수 있어야 합니다.\\n이 기준을 충족하는 AWS 관리형 서비스는 무엇입니까?\\n\\nA.Amazon Elastic Block Store(Amazon EBS)\\nB. 아마존 EC2\\nC. 아마존 FSx\\nD. 아마존 S3\", \"A business is shifting to the Amazon Web Services (AWS) Cloud. The initial workload to move is a file server. The file share must be accessible through the Server Message Block (SMB) protocol.\\nWhich AWS managed service satisfies these criteria?\\n\\nA.Amazon Elastic Block Store (Amazon EBS)\\nB. Amazon EC2\\nC. Amazon FSx\\nD. Amazon S3\", \"C\"],\n[\"기업에서 Fargate ECS 작업 시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS) 클러스터에 새 애플리케이션을 배포하고 있습니다. 회사는 실행 시 상당한 양의 트래픽을 수신하는 프로그램을 예상하여 CPU 및 메모리 사용을 모니터링하고 있습니다. 그러나 회사는 사용량이 감소함에 따라 비용 절감을 원합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon EC2 Auto Scaling을 사용하여 이전 트래픽 패턴을 기반으로 특정 기간에 확장합니다.\\nB. AWS Lambda 함수를 사용하여 Amazon CloudWatch 경보를 트리거하는 지표 위반을 기반으로 Amazon ECS를 확장합니다.\\nC. ECS 지표 위반이 Amazon CloudWatch 경보를 트리거할 때 확장하는 간단한 조정 정책과 함께 Amazon EC2 Auto Scaling을 사용합니다.\\nD. 대상 추적 정책과 함께 AWS Application Auto Scaling을 사용하여 ECS 지표 위반이 Amazon CloudWatch 경보를 트리거할 때 확장합니다.\", \"A business is deploying a new application on an Amazon Elastic Container Service (Amazon ECS) cluster, using the Fargate ECS task launch type. The firm is monitoring CPU and memory use in anticipation of the program receiving a significant volume of traffic upon launch. However, the corporation desires cost savings as usage declines.\\nWhat recommendations should a solutions architect make?\\n\\nA.Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.\\nB. Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm.\\nC. Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.\\nD. Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.\", \"D\"],\n[\"기업에 AWS에서 호스팅하는 웹 사이트가 있습니다. 데이터베이스 백엔드는 Amazon RDS for MySQL에서 호스팅되며 확장성 요구 사항을 수용하기 위해 기본 인스턴스와 5개의 읽기 전용 복제본으로 구성됩니다. 일관된 사용자 경험을 제공하려면 읽기 전용 복제본이 원본 인스턴스보다 1초 이상 늦어서는 안 됩니다.\\n웹사이트의 트래픽이 계속 증가함에 따라 사본이 피크 시간에 훨씬 뒤쳐져 검색 결과가 일치하지 않을 때 사용자 불만이 발생합니다. 솔루션 설계자의 목표는 애플리케이션의 코드 또는 운영 요구 사항을 거의 수정하지 않고 복제 대기 시간을 최소화하는 것입니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.데이터베이스를 Amazon Aurora MySQL로 마이그레이션합니다. MySQL 읽기 전용 복제본을 Aurora 복제본으로 교체하고 Aurora Auto Scaling 활성화\\nB. 데이터베이스 앞에 Amazon ElastiCache for Redis 클러스터를 배포합니다. 데이터베이스 읽기 끝점을 쿼리하기 전에 캐시를 확인하도록 웹 사이트를 수정합니다.\\nC. Amazon RDS에서 Amazon EC2 컴퓨팅 인스턴스에서 실행되는 MySQL로 데이터베이스를 마이그레이션합니다. 모든 복제본 노드에 대해 매우 큰 컴퓨팅 최적화 인스턴스를 선택합니다.\\nD. 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다. 처음에는 주문형 용량 확장이 활성화된 상태에서 필요한 처리량을 지원하기 위해 많은 수의 RCU(읽기 용량 단위)를 프로비저닝합니다.\", \"A business has an AWS-hosted website. The database backend is hosted on Amazon RDS for MySQL and consists of a main instance and five read replicas to accommodate scalability requirements. To provide a consistent user experience, read replicas should be no more than one second behind the original instance.\\n\\nA.the website's traffic continues to grow, the copies lag farther behind at peak moments, resulting in user complaints when searches return inconsistent results. A solutions architect's goal should be to minimize replication latency with little modifications to the application's code or operational requirements.\\nWhich solution satisfies these criteria?\\n\\nA.Migrate the database to Amazon Aurora MySQL. Replace the MySQL read replicas with Aurora Replicas and enable Aurora Auto Scaling\\nB. Deploy an Amazon ElastiCache for Redis cluster in front of the database. Modify the website to check the cache before querying the database read endpoints.\\nC. Migrate the database from Amazon RDS to MySQL running on Amazon EC2 compute instances. Choose very large compute optimized instances for all replica nodes.\\nD. Migrate the database to Amazon DynamoDB. Initially provision a large number of read capacity units (RCUs) to support the required throughput with on- demand capacity scaling enabled.\", \"A\"],\n[\"비즈니스에는 많은 AWS 리전에 설치된 애플리케이션을 사용하여 퍼블릭 고정 IP 주소를 노출하는 전 세계의 사용자가 있습니다. 사용자가 인터넷을 통해 프로그램을 사용할 때 성능 문제가 발생합니다.\\n솔루션 설계자는 인터넷 대기 시간을 줄이는 수단으로 무엇을 제안해야 합니까?\\n\\nA.AWS Global Accelerator를 설정하고 엔드포인트를 추가합니다.\\nB. 여러 리전에 AWS Direct Connect 위치를 설정합니다.\\nC. 애플리케이션에 액세스할 수 있도록 Amazon CloudFront 배포를 설정합니다.\\nD. 트래픽을 라우팅하도록 Amazon Route 53 지리 근접 라우팅 정책을 설정합니다.\", \"A business has users from all over the world using an application that is installed in many AWS Regions, exposing public static IP addresses. When users use the program through the internet, they encounter performance issues.\\nWhat should a solutions architect propose as a means of lowering internet latency?\\n\\nA.Set up AWS Global Accelerator and add endpoints.\\nB. Set up AWS Direct Connect locations in multiple Regions.\\nC. Set up an Amazon CloudFront distribution to access an application.\\nD. Set up an Amazon Route 53 geoproximity routing policy to route traffic.\", \"A\"],\n[\"비즈니스는 AWS에서 보고 솔루션을 개발해야 합니다. SQL 쿼리는 데이터 분석가가 데이터에 대해 실행할 수 있도록 솔루션에서 지원되어야 합니다. 데이터 분석가는 매일 10개 미만의 쿼리를 수행합니다. 회사는 매일 3GB의 새로운 데이터를 사내 관계형 데이터베이스에 추가합니다. 보고 작업을 수행하려면 이 데이터를 AWS로 보내야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 달성하기 위한 가장 저렴한 방법으로 무엇을 제안해야 합니까?\\n\\nA.AWS Database Migration Service(AWS DMS)를 사용하여 온프레미스 데이터베이스에서 Amazon S3로 데이터를 복제합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.\\nB. Amazon Kinesis Data Firehose 전송 스트림을 사용하여 데이터를 Amazon Elasticsearch Service(Amazon ES) 클러스터로 전송합니다. Amazon ES에서 쿼리를 실행합니다.\\nC. 온-프레미스 데이터베이스에서 데이터의 일일 복사본을 내보냅니다. AWS Storage Gateway 파일 게이트웨이를 사용하여 내보내기를 저장하고 Amazon S3에 복사합니다. Amazon EMR 클러스터를 사용하여 데이터를 쿼리합니다.\\nD. AWS Database Migration Service(AWS DMS)를 사용하여 온프레미스 데이터베이스에서 데이터를 복제하고 Amazon Redshift 클러스터에 로드합니다. Amazon Redshift 클러스터를 사용하여 데이터를 쿼리합니다.\", \"A business requires the development of a reporting solution on AWS. SQL queries must be supported by the solution for data analysts to execute on the data. Each day, the data analysts will do less than ten queries. Each day, the corporation adds 3 GB of fresh data to its on-premises relational database. This data must be sent to AWS in order for reporting chores to be performed.\\nWhat should a solutions architect propose as the CHEAPEST way to achieve these requirements?\\n\\nA.Use AWS Database Migration Service (AWS DMS) to replicate the data from the on-premises database into Amazon S3. Use Amazon Athena to query the data.\\nB. Use an Amazon Kinesis Data Firehose delivery stream to deliver the data into an Amazon Elasticsearch Service (Amazon ES) cluster. Run the queries in Amazon ES.\\nC. Export a daily copy of the data from the on-premises database. Use an AWS Storage Gateway file gateway to store and copy the export into Amazon S3. Use an Amazon EMR cluster to query the data.\\nD. Use AWS Database Migration Service (AWS DMS) to replicate the data from the on-premises database and load it into an Amazon Redshift cluster. Use the Amazon Redshift cluster to query the data.\", \"A\"],\n[\"기업은 Amazon S3 버킷을 사용하여 다양한 위치의 여러 부서에서 제출한 데이터를 저장하고 있습니다. 재무 관리자는 AWS Well-Architected 평가 중에 매월 10TB의 S3 Standard 스토리지 데이터가 청구되었음을 발견했습니다. 그러나 명령을 실행하여 Amazon S3용 AWS Management 콘솔에서 모든 파일과 폴더를 선택하면 총 크기가 5TB가 됩니다.\\n이러한 불일치의 잠재적인 이유는 무엇입니까? (2개를 선택하세요.)\\n\\nA.일부 파일은 중복 제거로 저장됩니다.\\nB. S3 버킷에 버전 관리가 활성화되어 있습니다.\\nC. 불완전한 S3 멀티파트 업로드가 있습니다.\\nD. S3 버커에는 AWS Key Management Service(AWS KMS)가 활성화되어 있습니다.\\nE. S3 버킷에 Intelligent-Tiering이 활성화되어 있습니다.\", \"A business is using an Amazon S3 bucket to store data that has been submitted by several departments from various locations. The finance manager finds that 10 TB of S3 Standard storage data has been charged each month during an AWS Well-Architected assessment. However, executing the command to select all files and folders in the AWS Management Console for Amazon S3 results in a total size of 5 TB.\\nWhat may be the potential reasons for this discrepancy? (Select two.)\\n\\nA.Some files are stored with deduplication.\\nB. The S3 bucket has versioning enabled.\\nC. There are incomplete S3 multipart uploads.\\nD. The S3 bucker has AWS Key Management Service (AWS KMS) enabled.\\nE. The S3 bucket has Intelligent-Tiering enabled.\", \"B, C\"],\n[\"AWS에서 비즈니스는 전자 상거래 웹 사이트를 만들고 있습니다. 이 웹 사이트는 Amazon Aurora MySQL 다중 AZ 배포에 MySQL 데이터베이스를 포함하는 3계층 설계로 구성되어 있습니다. 인터넷 애플리케이션은 고가용성이어야 하며 처음에는 3개의 가용 영역이 있는 AWS 리전에 배포됩니다. 프로그램은 겪고 있는 로드의 양을 나타내는 통계를 생성합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.예약된 조정이 있는 ALB 뒤에서 Amazon EC2 Auto Scaling을 사용하여 ALB(Application Load Balancer) 구성\\nB. 간단한 조정 정책을 사용하여 ALB 뒤에 Application Load Balancer(ALB) 및 Amazon EC2 Auto Scaling을 구성합니다.\\nC. NLB(Network Load Balancer)를 구성하고 NLB 뒤에서 Amazon EC2 Auto Scaling을 사용하여 스팟 집합을 시작합니다.\\nD. 대상 추적 조정 정책을 사용하여 ALB 뒤에서 Application Load Balancer(ALB) 및 Amazon EC2 Auto Scaling을 구성합니다.\", \"On AWS, a business is creating an ecommerce website. This website is constructed on a three-tier design that contains a MySQL database in an Amazon Aurora MySQL Multi-AZ deployment. The internet application must be highly available, and will be deployed in an AWS Region with three Availability Zones initially. The program generates a statistic that indicates the amount of load it is experiencing.\\nWhich solution satisfies these criteria?\\n\\nA.Configure an Application Load Balancer (ALB) with Amazon EC2 Auto Scaling behind the ALB with scheduled scaling\\nB. Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a simple scaling policy.\\nC. Configure a Network Load Balancer (NLB) and launch a Spot Fleet with Amazon EC2 Auto Scaling behind the NLB.\\nD. Configure an Application Load Balancer (ALB) and Amazon EC2 Auto Scaling behind the ALB with a target tracking scaling policy.\", \"D\"],\n[\"게임 회사는 AWS를 사용하여 브라우저 기반 애플리케이션을 호스팅합니다. 애플리케이션 사용자는 Amazon S3에 저장된 많은 양의 영화와 사진을 소비합니다. 이 자료는 모든 사용자에게 일관됩니다.\\n이 프로그램은 수백만 명의 사용자가 매일 이러한 미디어 파일에 액세스하면서 인기를 얻었습니다. 회사는 원본에 대한 부담을 최소화하면서 소비자에게 파일을 제공하기를 원합니다.\\n비용 효율성 측면에서 이러한 기준에 가장 적합한 옵션은 무엇입니까?\\n\\nA.웹 서버 앞에 AWS Global Accelerator 액셀러레이터를 배포합니다.\\nB. S3 버킷 앞에 Amazon CloudFront 웹 배포를 배포합니다.\\nC. 웹 서버 앞에 Amazon ElastiCache for Redis 인스턴스를 배포합니다.\\nD. 웹 서버 앞에 Amazon ElastiCache for Memcached 인스턴스를 배포합니다.\", \"A gaming firm uses AWS to host a browser-based application. The application's users consume a high volume of movies and photographs stored on Amazon S3. This material is consistent across all users.\\nThe program has grown in popularity, with millions of users accessing these media files on a daily basis. The firm want to provide files to consumers while minimizing strain on the origin.\\nWhich option best fits these criteria in terms of cost-effectiveness?\\n\\nA.Deploy an AWS Global Accelerator accelerator in front of the web servers.\\nB. Deploy an Amazon CloudFront web distribution in front of the S3 bucket.\\nC. Deploy an Amazon ElastiCache for Redis instance in front of the web servers.\\nD. Deploy an Amazon ElastiCache for Memcached instance in front of the web servers.\", \"B. CloudFront는 엣지 로케이션을 사용하여 콘텐츠를 캐시하는 반면 Global Accelerator는 엣지 로케이션을 사용하여 가장 가까운 리전 엔드포인트로 가는 최적의 경로를 찾습니다.\"],\n[\"비즈니스는 매일 데이터를 처리합니다. 프로세스의 출력은 Amazon S3 버킷에 보관되어 일주일 동안 매일 검사한 다음 임시 검사를 위해 즉시 사용할 수 있어야 합니다.\\n기존 구성에 대한 가장 비용 효율적인 대안은 무엇입니까?\\n\\nA.30일 후에 개체를 삭제하도록 수명 주기 정책을 구성합니다.\\nB. 30일 후에 객체를 Amazon S3 Glacier로 전환하도록 수명 주기 정책을 구성합니다.\\nC. 30일 후에 객체를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하도록 수명 주기 정책을 구성합니다.\\nD. 30일 후에 객체를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하도록 수명 주기 정책을 구성합니다.\", \"Every day, a business processes data. The processes' output is kept in an Amazon S3 bucket, examined daily for one week, and then must remain readily available for ad hoc examination.\\nWhich storage option is the MOST cost-effective alternative to the existing configuration?\\n\\nA.Configure a lifecycle policy to delete the objects after 30 days.\\nB. Configure a lifecycle policy to transition the objects to Amazon S3 Glacier after 30 days.\\nC. Configure a lifecycle policy to transition the objects to Amazon S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.\\nD. Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.\", \"C, D 논란\"],\n[\"비즈니스에서 애플리케이션을 개발 중입니다. 이 프로그램은 Amazon API Gateway를 통해 데이터를 수신하고 AWS Lambda 함수를 사용하여 Amazon Aurora PostgreSQL 데이터베이스에 저장합니다.\\n개념 증명 단계에서 회사는 데이터베이스에 로드해야 하는 많은 양의 데이터를 관리하기 위해 Lambda 할당량을 대폭 늘려야 합니다. 솔루션 설계자는 확장성을 최대화하고 설정 노력을 줄이는 새로운 설계에 대한 권장 사항을 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Lambda 함수 코드를 Amazon EC2 인스턴스에서 실행되는 Apache Tomcat 코드로 리팩터링합니다. 네이티브 JDBC(Java Database Connectivity) 드라이버를 사용하여 데이터베이스를 연결합니다.\\nB. 플랫폼을 Aurora에서 Amazon DynamoDB로 변경합니다. DynamoDB Accelerator(DAX) 클러스터를 프로비저닝합니다. DAX 클라이언트 SDK를 사용하여 DAX 클러스터에서 기존 DynamoDB API 호출을 가리킵니다.\\nC. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. 정보를 데이터베이스에 로드하도록 다른 기능을 구성하십시오. Amazon Simple Notification Service(Amazon SNS)를 사용하여 Lambda 함수를 통합합니다.\\nD. 두 개의 Lambda 함수를 설정합니다. 정보를 수신할 하나의 기능을 구성하십시오. 정보를 데이터베이스에 로드하도록 다른 기능을 구성하십시오. Amazon Simple Queue Service(Amazon SQS) 대기열을 사용하여 Lambda 함수를 통합합니다.\", \"A business is developing an application. The program receives data through Amazon API Gateway and stores it in an Amazon Aurora PostgreSQL database using an AWS Lambda function.\\nDuring the proof-of-concept stage, the firm must drastically raise the Lambda quotas to manage the large amounts of data that must be loaded into the database. A solutions architect must provide a recommendation for a new design that maximizes scalability and reduces setup effort.\\nWhich solution will satisfy these criteria?\\n\\nA.Refactor the Lambda function code to Apache Tomcat code that runs on Amazon EC2 instances. Connect the database by using native Java Database Connectivity (JDBC) drivers.\\nB. Change the platform from Aurora to Amazon DynamoDB. Provision a DynamoDB Accelerator (DAX) cluster. Use the DAX client SDK to point the existing DynamoDB API calls at the DAX cluster.\\nC. Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using Amazon Simple Notification Service (Amazon SNS).\\nD. Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue.\", \"D\"],\n[\"기업에서 온프레미스 MySQL 데이터베이스를 Amazon Web Services(AWS)로 마이그레이션하려고 합니다. 클라이언트 대면 애플리케이션에서 정기적으로 가져오면 데이터베이스에서 엄청난 양의 쓰기 작업이 발생합니다. 조직은 트래픽 양이 애플리케이션의 성능에 영향을 미칠 수 있다고 우려하고 있습니다.\\n솔루션 설계자는 AWS 아키텍처 설계에 어떻게 접근해야 합니까?\\n\\nA.프로비저닝된 IOPS SSD 스토리지로 Amazon RDS for MySQL DB 인스턴스를 프로비저닝합니다. Amazon CloudWatch를 사용하여 쓰기 작업 지표를 모니터링합니다. 필요한 경우 프로비저닝된 IOPS를 조정합니다.\\nB. 범용 SSD 스토리지가 있는 Amazon RDS for MySQL DB 인스턴스를 프로비저닝합니다. DB 인스턴스 앞에 Amazon ElastiCache 클러스터를 배치합니다. 대신 ElastiCache를 쿼리하도록 애플리케이션을 구성합니다.\\nC. 메모리 최적화 인스턴스 유형으로 Amazon DocumentDB(MongoDB 호환) 인스턴스를 프로비저닝합니다. 성능 관련 문제에 대해 Amazon CloudWatch를 모니터링합니다. 필요한 경우 인스턴스 클래스를 변경합니다.\\nD. 범용 성능 모드에서 Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝합니다. IOPS 병목 현상에 대해 Amazon CloudWatch를 모니터링합니다. 필요한 경우 프로비저닝된 처리량 성능 모드로 변경합니다.\", \"A business wishes to migrate its on-premises MySQL database to Amazon Web Services (AWS). Regular imports from a client-facing application result in a huge amount of write operations in the database. The organization is worried that the volume of traffic may be affecting the application's performance.\\nHow should a solutions architect approach the design of an AWS architecture?\\n\\nA.Provision an Amazon RDS for MySQL DB instance with Provisioned IOPS SSD storage. Monitor write operation metrics by using Amazon CloudWatch. Adjust the provisioned IOPS if necessary.\\nB. Provision an Amazon RDS for MySQL DB instance with General Purpose SSD storage. Place an Amazon ElastiCache cluster in front of the DB instance. Configure the application to query ElastiCache instead.\\nC. Provision an Amazon DocumentDB (with MongoDB compatibility) instance with a memory optimized instance type. Monitor Amazon CloudWatch for performance-related issues. Change the instance class if necessary.\\nD. Provision an Amazon Elastic File System (Amazon EFS) file system in General Purpose performance mode. Monitor Amazon CloudWatch for IOPS bottlenecks. Change to Provisioned Throughput performance mode if necessary.\", \"A\"],\n[\"한 회사에서 AWS를 사용하여 인스턴스 간에 짧은 지연 시간이 필요한 다중 인스턴스 애플리케이션을 만들고 있습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.클러스터 배치 그룹과 함께 Auto Scaling 그룹을 사용합니다.\\nB. 동일한 AWS 리전에서 단일 가용 영역이 있는 Auto Scaling 그룹을 사용합니다.\\nC. 동일한 AWS 리전에 여러 가용 영역이 있는 Auto Scaling 그룹을 사용합니다.\\nD. 여러 Amazon EC2 전용 호스트가 있는 Network Load Balancer를 대상으로 사용합니다.\", \"A firm is using AWS to create a multi-instance application that needs low latency between the instances.\\nWhat recommendations should a solutions architect make?\\n\\nA.Use an Auto Scaling group with a cluster placement group.\\nB. Use an Auto Scaling group with single Availability Zone in the same AWS Region.\\nC. Use an Auto Scaling group with multiple Availability Zones in the same AWS Region.\\nD. Use a Network Load Balancer with multiple Amazon EC2 Dedicated Hosts as the targets.\", \"A\"],\n[\"지난 15년 동안 기업은 온프레미스 데이터 센터에서 Oracle 관계형 데이터베이스를 사용하여 웹 애플리케이션을 운영해 왔습니다. 회사의 데이터베이스를 AWS로 마이그레이션해야 합니다. 기업은 애플리케이션의 코드를 수정하지 않고 운영 비용을 절감하기를 원합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스 서버를 Amazon RDS로 마이그레이션합니다.\\nB. Amazon EC2 인스턴스를 사용하여 데이터베이스 서버를 마이그레이션하고 운영합니다.\\nC. AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스 서버를 Amazon DynamoDB로 마이그레이션합니다.\\nD. AWS Snowball Edge Storage Optimized 디바이스를 사용하여 Oracle에서 Amazon Aurora로 데이터를 마이그레이션합니다.\", \"For the last 15 years, a corporation has been operating a web application using an Oracle relational database in an on-premises data center. The company's database must be migrated to AWS. The business wants to cut operating costs without modifying the application's code.\\nWhich solution satisfies these criteria?\\n\\nA.Use AWS Database Migration Service (AWS DMS) to migrate the database servers to Amazon RDS.\\nB. Use Amazon EC2 instances to migrate and operate the database servers.\\nC. Use AWS Database Migration Service (AWS DMS) to migrate the database servers to Amazon DynamoDB.\\nD. Use an AWS Snowball Edge Storage Optimized device to migrate the data from Oracle to Amazon Aurora.\", \"A\"],\n[\"개발 팀은 구성 파일에 Amazon RDS MySQL DB 인스턴스의 사용자 이름과 암호를 보관합니다. 구성 파일은 팀의 Amazon EC2 인스턴스 루트 디바이스 디스크에 일반 텍스트로 저장됩니다. 팀의 응용 프로그램이 데이터베이스에 연결해야 할 때 파일을 읽고 자격 증명이 코드에 로드됩니다. 팀은 프로그램만 해당 내용에 액세스할 수 있도록 구성 파일의 권한을 조정했습니다. 솔루션 설계자의 주요 책임은 더 나은 보안 시스템을 구축하는 것입니다.\\n이 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.구성 파일을 Amazon S3에 저장합니다. 구성 파일을 읽을 수 있는 액세스 권한을 애플리케이션에 부여합니다.\\nB. 데이터베이스 액세스 권한이 있는 IAM 역할을 생성합니다. 이 IAM 역할을 EC2 인스턴스에 연결합니다.\\nC. 데이터베이스 인스턴스에서 SSL 연결을 활성화합니다. 로그인할 때 SSL을 요구하도록 데이터베이스 사용자를 변경합니다.\\nD. 구성 파일을 EC2 인스턴스 스토어로 이동하고 인스턴스의 Amazon 머신 이미지(AMI)를 생성합니다. 이 AMI에서 새 인스턴스를 시작합니다.\", \"A development team keeps the user name and password for its Amazon RDS MySQL DB instance in a configuration file. The configuration file is saved in plaintext on the team's Amazon EC2 instance's root device disk. When the team's application needs to connect to the database, the file is read and the credentials are loaded into the code. The team adjusted the configuration file's permissions so that only the program may access its contents. A solution architect's primary responsibility is to build a better secure system.\\nWhat actions should the solutions architect do in order to satisfy this requirement?\\n\\nA.Store the configuration file in Amazon S3. Grant the application access to read the configuration file.\\nB. Create an IAM role with permission to access the database. Attach this IAM role to the EC2 instance.\\nC. Enable SSL connections on the database instance. Alter the database user to require SSL when logging in.\\nD. Move the configuration file to an EC2 instance store, and create an Amazon Machine Image (AMI) of the instance. Launch new instances from this AMI.\", \"B\"],\n[\"비즈니스 애플리케이션이 VPC 내부에 포함된 Amazon EC2 인스턴스에서 작동하고 있습니다. 항목을 저장하고 검색하려면 앱 중 하나가 Amazon S3 API에 요청해야 합니다. 회사의 보안 규정은 프로그램이 인터넷에 연결된 트래픽을 보내는 것을 금지합니다.\\n보안을 유지하면서 이러한 요구를 충족할 조치는 무엇입니까?\\n\\nA.S3 인터페이스 끝점을 구성합니다.\\nB. S3 게이트웨이 엔드포인트를 구성합니다.\\nC. 프라이빗 서브넷에 S3 버킷을 생성합니다.\\nD. EC2 인스턴스와 동일한 리전에 S3 버킷을 생성합니다.\", \"A business's application is operating on Amazon EC2 instances contained inside a VPC. One of the apps must make a request to the Amazon S3 API in order to store and retrieve items. The company's security regulations prohibit programs from sending any internet-bound traffic.\\nWhich course of action will satisfy these needs while still maintaining security?\\n\\nA.Configure an S3 interface endpoint.\\nB. Configure an S3 gateway endpoint.\\nC. Create an S3 bucket in a private subnet.\\nD. Create an S3 bucket in the same Region as the EC2 instance.\", \"B\"],\n[\"MySQL 데이터베이스는 기업의 주문 이행 서비스에서 사용됩니다. 데이터베이스는 많은 양의 동시 요청 및 트랜잭션을 처리할 수 있어야 합니다. 데이터베이스는 개발자에 의해 패치되고 조정됩니다. 이로 인해 새로운 제품 기능의 도입이 지연됩니다.\\n조직은 이 새로운 어려움을 해결하는 데 도움이 되도록 클라우드 기반 서비스를 사용하기를 원합니다. 이 솔루션은 개발자가 코드를 거의 또는 전혀 수정하지 않고 데이터베이스를 이동할 수 있도록 해야 하며 성능을 최대화해야 합니다.\\n이러한 요구 사항을 달성하려면 어떤 솔루션 설계자 서비스를 사용해야 합니까?\\n\\nA.아마존 오로라\\nB. Amazon DynamoDB\\nC. Amazon ElastiCache\\nD. Amazon EC2의 MySQL\", \"A MySQL database is used by a business's order fulfillment service. The database must be able to handle a high volume of concurrent requests and transactions. The database is patched and tuned by developers. This results in delays in the introduction of new product features.\\nThe organization wishes to use cloud-based services in order to assist it in addressing this new difficulty. The solution must enable developers to move the database with little or no modifications to the code and must maximize performance.\\nWhich solution architect service should be used to achieve these requirements?\\n\\nA.Amazon Aurora\\nB. Amazon DynamoDB\\nC. Amazon ElastiCache\\nD. MySQL on Amazon EC2\", \"A\"],\n[\"기업은 다중 지역 재해 복구를 위해 1초 RPO(복구 시점 목표) 및 1분 RTO(복구 시간 목표)로 관계형 데이터베이스를 만들어야 합니다.\\n어떤 AWS 솔루션이 이 작업을 수행할 수 있습니까?\\n\\nA.Amazon Aurora 글로벌 데이터베이스\\nB. Amazon DynamoDB 전역 테이블\\nC. 다중 AZ가 활성화된 MySQL용 Amazon RDS\\nD. 교차 리전 스냅샷 사본이 있는 MySQL용 Amazon RDS\", \"A corporation needs to create a relational database with a 1 second Recovery Point Objective (RPO) and a 1 minute Recovery Time Objective (RTO) for multi-region disaster recovery.\\nWhich AWS solution is capable of doing this?\\n\\nA.Amazon Aurora Global Database\\nB. Amazon DynamoDB global tables\\nC. Amazon RDS for MySQL with Multi-AZ enabled\\nD. Amazon RDS for MySQL with a cross-Region snapshot copy\", \"A\"],\n[\"솔루션 설계자는 새로운 정적 웹사이트의 구현을 설계하는 책임을 맡습니다. 솔루션은 비용 효율적이어야 하며 최소 99%의 가용성을 유지해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.버전 관리가 비활성화된 한 AWS 리전의 Amazon S3 버킷에 애플리케이션을 배포합니다.\\nB. 2개의 AWS 리전과 2개의 가용 영역에서 실행되는 Amazon EC2 인스턴스에 애플리케이션을 배포합니다.\\nC. 버전 관리 및 교차 리전 복제가 활성화된 Amazon S3 버킷에 애플리케이션을 배포합니다.\\nD. 하나의 AWS 리전과 하나의 가용 영역에서 실행되는 Amazon EC2 인스턴스에 애플리케이션을 배포합니다.\", \"A solutions architect is tasked with the responsibility of designing the implementation of a new static website. The solution must be cost effective and maintain a minimum of 99 percent availability.\\nWhich solution satisfies these criteria?\\n\\nA.Deploy the application to an Amazon S3 bucket in one AWS Region that has versioning disabled.\\nB. Deploy the application to Amazon EC2 instances that run in two AWS Regions and two Availability Zones.\\nC. Deploy the application to an Amazon S3 bucket that has versioning and cross-Region replication enabled.\\nD. Deploy the application to an Amazon EC2 instance that runs in one AWS Region and one Availability Zone.\", \"A. 단일 AZ S3만으로도 99% 가용성 유지 가능. 그러나 일반론적으로 C가 답이라는 의견 존재\"],\n[\"비즈니스에서 신용 카드 결제 처리를 위해 3계층 웹 애플리케이션을 운영하고 있습니다. 정적 웹 사이트는 프런트 엔드 사용자 인터페이스를 구성합니다. 애플리케이션 계층에는 긴 절차가 포함될 수 있습니다. MySQL은 데이터베이스 계층에서 사용됩니다.\\n현재 애플리케이션은 하나의 거대한 범용 Amazon EC2 머신에서 실행되고 있습니다. 솔루션 설계자는 웹 애플리케이션의 가용성을 최대화하기 위해 서비스를 분리해야 합니다.\\n다음 솔루션 중 가장 높은 수준의 가용성을 제공하는 솔루션은 무엇입니까?\\n\\nA.정적 자산을 Amazon CloudFront로 이동합니다. Auto Scaling 그룹의 EC2에 있는 애플리케이션을 그대로 둡니다. 데이터베이스를 Amazon RDS로 이동하여 다중 AZ를 배포합니다.\\nB. 정적 자산과 애플리케이션을 중간 규모 EC2 인스턴스로 이동합니다. 데이터베이스를 대규모 인스턴스에 그대로 둡니다. 두 인스턴스를 Auto Scaling 그룹에 배치합니다.\\nC. 정적 자산을 Amazon S3로 이동합니다. 동시성 제한이 설정된 AWS Lambda로 애플리케이션을 이동합니다. 온디맨드가 활성화된 Amazon DynamoDB로 데이터베이스를 이동합니다.\\nD. 정적 자산을 Amazon S3로 이동합니다. Auto Scaling이 활성화된 Amazon Elastic Container Service(Amazon ECS) 컨테이너로 애플리케이션을 이동합니다. 데이터베이스를 Amazon RDS로 이동하여 다중 AZ를 배포합니다.\", \"A business operates a three-tier web application for the purpose of processing credit card payments. Static websites comprise the front-end user interface. The application layer may include lengthy procedures. MySQL is used in the database layer.\\nCurrently, the application is running on a single huge general-purpose Amazon EC2 machine. A solutions architect must decouple the services in order to maximize the availability of the web application.\\nWhich of the following solutions would give the HIGHEST level of availability?\\n\\nA.Move static assets to Amazon CloudFront. Leave the application in EC2 in an Auto Scaling group. Move the database to Amazon RDS to deploy Multi-AZ.\\nB. Move static assets and the application into a medium EC2 instance. Leave the database on the large instance. Place both instances in an Auto Scaling group.\\nC. Move static assets to Amazon S3. Move the application to AWS Lambda with the concurrency limit set. Move the database to Amazon DynamoDB with on- demand enabled.\\nD. Move static assets to Amazon S3. Move the application to Amazon Elastic Container Service (Amazon ECS) containers with Auto Scaling enabled. Move the database to Amazon RDS to deploy Multi-AZ.\", \"D\"],\n[\"기업의 보안 팀은 네트워크 트래픽이 VPC Flow Logs에 기록되기를 원합니다. 로그는 90일 동안 자주 조회된 후 삭제됩니다.\\n가끔.\\n이러한 요구 사항을 충족하도록 로그를 사용자 지정할 때 솔루션 설계자는 무엇을 해야 합니까?\\n\\nA.Amazon CloudWatch를 대상으로 사용합니다. 만료일이 90일인 CloudWatch 로그 그룹을 설정합니다.\\nB. Amazon Kinesis를 대상으로 사용합니다. 항상 90일 동안 로그를 유지하도록 Kinesis 스트림을 구성합니다.\\nC. AWS CloudTrail을 대상으로 사용합니다. Amazon S3 버킷에 저장하도록 CloudTrail을 구성하고 S3 Intelligent-Tiering을 활성화합니다.\\nD. Amazon S3를 대상으로 사용합니다. S3 수명 주기 정책을 활성화하여 90일 후에 로그를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다.\", \"The security team of a corporation wants that network traffic be logged in VPC Flow Logs. The logs will be viewed often for 90 days and then deleted.\\noccasionally.\\nWhat should a solutions architect do when customizing the logs to satisfy these requirements?\\n\\nA.Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days.\\nB. Use Amazon Kinesis as the target. Configure the Kinesis stream to always retain the logs for 90 days.\\nC. Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent-Tiering.\\nD. Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days.\", \"A\"],\n[\"Amazon S3는 솔루션 설계자가 새로운 디지털 미디어 애플리케이션을 위한 스토리지 아키텍처를 개발하는 데 사용하고 있습니다. 미디어 파일은 가용 영역에 장애가 발생한 경우에도 견고해야 합니다. 특정 파일은 일상적으로 방문하는 반면 다른 파일은 드물게 예기치 않은 방식으로 봅니다. 솔루션 설계자는 미디어 파일을 저장하고 검색하는 비용을 최소화해야 합니다.\\n이러한 기준을 충족하는 스토리지 선택은 무엇입니까?\\n\\nA.S3 Standard\\nB. S3 Intelligent-Tiering\\nC. S3 Standard-Infrequent Access (S3 Standard-IA)\\nD. S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"Amazon S3 is being used by a solutions architect to develop the storage architecture for a new digital media application. The media files must be robust in the event of an Availability Zone failure. Certain files are routinely visited, while others are viewed infrequently and in an unexpected fashion. The architect of the solution must keep the expenses of storing and retrieving media files to a minimum.\\nWhich storage choice satisfies these criteria?\\n\\nA.S3 Standard\\nB. S3 Intelligent-Tiering\\nC. S3 Standard-Infrequent Access (S3 Standard-IA)\\nD. S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"B\"],\n[\"월별 보고서는 회사의 재무 애플리케이션에서 Amazon S3 버킷에 저장합니다. 재무 담당 부사장은 이러한 보고서에 대한 모든 액세스와 로그 파일에 대한 조정을 문서화하도록 지시했습니다.\\n솔루션 설계자는 이러한 요구 사항을 준수하기 위해 어떤 활동을 수행할 수 있습니까?\\n\\nA.읽기 및 쓰기 데이터 이벤트와 로그 파일 유효성 검사 옵션이 활성화된 보고서가 있는 버킷에서 S3 서버 액세스 로깅을 사용합니다.\\nB. 읽기 및 쓰기 관리 이벤트와 로그 파일 유효성 검사 옵션이 활성화된 보고서가 있는 버킷에서 S3 서버 액세스 로깅을 사용합니다.\\nC. AWS CloudTrail을 사용하여 새 추적을 생성합니다. 보고서가 포함된 S3 버킷에서 데이터 읽기 및 쓰기 이벤트를 기록하도록 추적을 구성합니다. 이러한 이벤트를 새 버킷에 기록하고 로그 파일 유효성 검사를 활성화합니다.\\nD. AWS CloudTrail을 사용하여 새 추적을 생성합니다. 보고서가 있는 S3 버킷에 대한 읽기 및 쓰기 관리 이벤트를 기록하도록 추적을 구성합니다. 이러한 이벤트를 새 버킷에 기록하고 로그 파일 유효성 검사를 활성화합니다.\", \"Monthly reports are stored in an Amazon S3 bucket by a company's financial application. The vice president of finance has directed that all access to these reports be documented, as well as any adjustments to the log files.\\nWhat activities can a solutions architect take to ensure compliance with these requirements?\\n\\nA.Use S3 server access logging on the bucket that houses the reports with the read and write data events and log file validation options enabled.\\nB. Use S3 server access logging on the bucket that houses the reports with the read and write management events and log file validation options enabled.\\nC. Use AWS CloudTrail to create a new trail. Configure the trail to log read and write data events on the S3 bucket that houses the reports. Log these events to a new bucket, and enable log file validation.\\nD. Use AWS CloudTrail to create a new trail. Configure the trail to log read and write management events on the S3 bucket that houses the reports. Log these events to a new bucket, and enable log file validation.\", \"C\"],\n[\"온라인 게임을 전문으로 하는 비즈니스는 전 세계적으로 매우 인기가 있을 것으로 예상되는 게임을 개발하고 있습니다. 솔루션 설계자는 각 참가자의 게임 데이터는 물론 세계 상위 25명의 플레이어 이름을 한 번에 캡처하고 표시할 수 있는 AWS 클라우드 아키텍처를 생성해야 합니다.\\n이러한 요구 사항을 충족하려면 어떤 AWS 데이터베이스 솔루션 및 구성을 사용해야 합니까?\\n\\nA.Amazon RDS for MySQL을 플레이어 활동의 데이터 저장소로 사용하십시오. 다중 AZ 지원을 위해 RDS DB 인스턴스를 구성합니다.\\nB. 플레이어 활동을 위한 데이터 저장소로 Amazon DynamoDB를 사용합니다. 플레이어 데이터에 대해 DynamoDB Accelerator(DAX)를 구성합니다.\\nC. 플레이어 활동을 위한 데이터 저장소로 Amazon DynamoDB를 사용합니다. 플레이어 데이터에 대해 필요한 각 AWS 리전에서 전역 테이블을 구성합니다.\\nD. Amazon RDS for MySQL을 플레이어 활동의 데이터 저장소로 사용합니다. 플레이어 근접성을 기반으로 필요한 각 AWS 리전에서 교차 리전 읽기 전용 복제본을 구성합니다.\", \"A business that specializes in online gaming is developing a game that is predicted to be very popular around the globe. A solutions architect must create an AWS Cloud architecture capable of capturing and presenting near-real-time game data for each participant, as well as the names of the world's top 25 players at any one moment.\\nWhich AWS database solution and configuration should be used to satisfy these requirements?\\n\\nA.Use Amazon RDS for MySQL as the data store for player activity. Configure the RDS DB instance for Multi-AZ support.\\nB. Use Amazon DynamoDB as the data store for player activity. Configure DynamoDB Accelerator (DAX) for the player data.\\nC. Use Amazon DynamoDB as the data store for player activity. Configure global tables in each required AWS Region for the player data.\\nD. Use Amazon RDS for MySQL as the data store for player activity. Configure cross-Region read replicas in each required AWS Region based on player proximity.\", \"C\"],\n[\"한 기업에서 사용자가 실시간 게임 통계에 참여할 수 있는 서버리스 웹 애플리케이션을 구축하고 있습니다. 게임에서 생성된 데이터는 라이브로 전송되어야 합니다. 비즈니스에는 사용자 데이터를 위한 강력하고 대기 시간이 짧은 데이터베이스 솔루션이 필요합니다. 회사는 응용 프로그램의 예상 사용자 기반에 대해 확신하지 못합니다. 모든 설계 고려 사항은 애플리케이션이 성장함에 따라 한 자릿수 밀리초 응답 속도를 보장해야 합니다.\\n이러한 요구 사항에 맞는 AWS 서비스 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.아마존 클라우드프론트\\nB. Amazon DynamoDB\\nC. 아마존 키네시스\\nD. 아마존 RDS\\nE. AWS 글로벌 액셀러레이터\", \"A business is building a serverless web application that will allow users to engage with real-time game stats. The data generated by the games must be transmitted live. The business need a robust, low-latency database solution for user data. The corporation is unsure about the application's anticipated user base. Any design considerations must ensure single-digit millisecond response rates as the application grows.\\nWhich AWS service combination will suit these requirements? (Select two.)\\n\\nA.Amazon CloudFront\\nB. Amazon DynamoDB\\nC. Amazon Kinesis\\nD. Amazon RDS\\nE. AWS Global Accelerator\", \"B, C\"],\n[\"솔루션 설계자는 사용자가 사진 컬렉션을 탐색하고 사용자 정의된 이미지를 요청할 수 있는 솔루션을 개발하고 있습니다. 이미지 사용자 지정을 위한 파라미터는 AWS API Gateway API에 대한 각 요청에 포함됩니다. 맞춤형 사진은 요청 시 생성되며 소비자는 이를 보거나 다운로드할 수 있는 링크를 받게 됩니다. 솔루션은 사진을 보고 수정하는 측면에서 매우 사용자 친화적이어야 합니다.\\n이러한 요구 사항을 충족하는 데 가장 비용 효율적인 접근 방식은 무엇입니까?\\n\\nA.Amazon EC2 인스턴스를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작합니다. 원본 이미지와 조작된 이미지를 Amazon S3에 저장합니다. EC2 인스턴스 앞에 Elastic Load Balancer를 구성합니다.\\nB. AWS Lambda를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작합니다. 원본 이미지와 조작된 이미지를 Amazon S3에 저장합니다. S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다.\\nC. AWS Lambda를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작합니다. 원본 이미지는 Amazon S3에 저장하고 조작된 이미지는 Amazon DynamoDB에 저장합니다. Amazon EC2 인스턴스 앞에 Elastic Load Balancer를 구성합니다.\\nD. Amazon EC2 인스턴스를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작합니다. 원본 이미지는 Amazon S3에 저장하고 조작된 이미지는 Amazon DynamoDB에 저장합니다. S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다.\", \"A solutions architect is developing a solution that will allow users to browse a collection of photos and make requests for customized images. Parameters for image customisation will be included in each request made to an AWS API Gateway API. The personalized picture will be created on demand, and consumers will get a link to see or download it. The solution must be very user-friendly in terms of viewing and modifying photos.\\nWhich approach is the MOST cost-effective in meeting these requirements?\\n\\nA.Use Amazon EC2 instances to manipulate the original image into the requested customizations. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances.\\nB. Use AWS Lambda to manipulate the original image to the requested customizations. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.\\nC. Use AWS Lambda to manipulate the original image to the requested customizations. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances.\\nD. Use Amazon EC2 instances to manipulate the original image into the requested customizations. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.\", \"B\"],\n[\"기업은 프라이빗 서브넷에서 Amazon EC2 인스턴스를 실행하고 패치 및 업그레이드를 받으려면 퍼블릭 웹사이트에 액세스해야 합니다. 조직은 다른 웹사이트가 EC2 인스턴스의 IP 주소를 보거나 연결을 시작하는 것을 원하지 않습니다.\\n솔루션 설계자는 이 목표를 어떻게 달성할 수 있습니까?\\n\\nA.사설 서브넷과 공용 사이트가 배포된 네트워크 간에 사이트 간 VPN 연결을 만듭니다.\\nB. 퍼블릭 서브넷에 NAT 게이트웨이를 생성합니다. NAT 게이트웨이를 통해 프라이빗 서브넷의 아웃바운드 트래픽을 라우팅합니다.\\nC. 배포된 EC2 인스턴스가 퍼블릭 웹 사이트의 IP 주소 범위에서만 액세스를 허용하는 프라이빗 서브넷에 대한 네트워크 ACL을 생성합니다.\\nD. 공개 웹사이트의 IP 주소 범위에서만 연결을 허용하는 보안 그룹을 만듭니다. 보안 그룹을 EC2 인스턴스에 연결합니다.\", \"A business runs an Amazon EC2 instance on a private subnet and requires access to a public website in order to get patches and upgrades. The organization does not want other websites to be able to see or start connections to the EC2 instance's IP address.\\nHow can a solutions architect accomplish this goal?\\n\\nA.Create a site-to-site VPN connection between the private subnet and the network in which the public site is deployed.\\nB. Create a NAT gateway in a public subnet. Route outbound traffic from the private subnet through the NAT gateway.\\nC. Create a network ACL for the private subnet where the EC2 instance deployed only allows access from the IP address range of the public website.\\nD. Create a security group that only allows connections from the IP address range of the public website. Attach the security group to the EC2 instance.\", \"B\"],\n[\"비즈니스는 AWS를 사용하여 웹 사이트를 호스팅합니다. 웹 사이트는 HTTP 및 HTTPS 트래픽을 독립적으로 관리하도록 구성된 ALB(Application Load Balancer)에 의해 보호됩니다.\\n회사는 HTTPS를 통해 모든 쿼리를 웹사이트로 라우팅하려고 합니다.\\n솔루션 설계자는 이 기준을 충족하기 위해 어떤 솔루션을 구현해야 합니까?\\n\\nA.HTTPS 트래픽만 허용하도록 ALB의 네트워크 ACL을 업데이트합니다.\\nB. URL의 HTTP를 HTTPS로 바꾸는 규칙을 만듭니다.\\nC. ALB에서 리스너 규칙을 생성하여 HTTP 트래픽을 HTTPS로 리디렉션합니다.\\nD. ALB를 SNI(서버 이름 표시)를 사용하도록 구성된 Network Load Balancer로 교체합니다.\", \"A business uses AWS to host its website. The website is protected by an Application Load Balancer (ALB) configured to manage HTTP and HTTPS traffic independently.\\nThe firm wishes to route all queries to the website through HTTPS.\\nWhat solution should a solutions architect implement to satisfy this criterion?\\n\\nA.Update the ALB's network ACL to accept only HTTPS traffic.\\nB. Create a rule that replaces the HTTP in the URL with HTTPS.\\nC. Create a listener rule on the ALB to redirect HTTP traffic to HTTPS.\\nD. Replace the ALB with a Network Load Balancer configured to use Server Name Indication (SNI).\", \"C\"],\n[\"기업은 ALB(Application Load Balancer)로 보호되는 Amazon EC2 인스턴스 집합을 사용하여 다국어 웹 사이트를 호스팅합니다. 이 설계는 현재 us-west-1 지역에서 작동하고 있지만 전 세계 다른 지역의 고객에게는 상당한 요청 지연이 있습니다.\\n웹사이트는 위치에 관계없이 사용자 쿼리에 빠르고 효과적으로 응답해야 합니다. 그러나 조직은 현재 인프라를 여러 지역에 복제하는 것을 원하지 않습니다.\\n솔루션 아키텍트가 이 작업을 어떻게 수행합니까?\\n\\nA.기존 아키텍처를 Amazon S3 버킷에서 제공하는 웹 사이트로 교체합니다. S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다.\\nB. ALB를 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. Accept-Language 요청 헤더를 기반으로 캐시만 캐시하도록 캐시 동작 설정을 설정합니다.\\nC. ALB를 통합으로 사용하여 Amazon API Gateway를 설정합니다. HTTP 통합 유형을 사용하도록 API Gateway를 구성합니다. API 캐시를 활성화하도록 API 게이트웨이 단계를 설정합니다.\\nD. 각 추가 리전에서 EC2 인스턴스를 시작하고 해당 리전의 캐시 서버 역할을 하도록 NGINX를 구성합니다. 모든 인스턴스와 ALB를 지리적 위치 라우팅 정책이 있는 Amazon Route 53 레코드 세트 뒤에 배치합니다.\", \"A business hosts a multilingual website using a fleet of Amazon EC2 instances protected by an Application Load Balancer (ALB). While this design is presently operational in the us-west-1 Region, it exhibits significant request delay for customers in other regions of the globe.\\nThe website must respond fast and effectively to user queries regardless of their location. The organization, however, does not want to duplicate the present infrastructure across numerous Regions.\\nHow is this to be accomplished by a solutions architect?\\n\\nA.Replace the existing architecture with a website served from an Amazon S3 bucket. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.\\nB. Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to only cache based on the Accept-Language request header.\\nC. Set up Amazon API Gateway with the ALB as an integration. Configure API Gateway to use an HTTP integration type. Set up an API Gateway stage to enable the API cache.\\nD. Launch an EC2 instance in each additional Region and configure NGINX to act as a cache server for that Region. Put all the instances plus the ALB behind an Amazon Route 53 record set with a geolocation routing policy.\", \"B\"],\n[\"AWS에서 비즈니스는 전자 상거래 웹 사이트의 프로토타입을 개발 중입니다. 이 웹 사이트는 Amazon Auto Scaling 사업부의 Application Load Balancer로 구동됩니다.\\n단일 AZ 모드로 구성된 웹 서버용 EC2 인스턴스 및 MySQL용 Amazon RDS 데이터베이스 인스턴스.\\n웹 사이트는 제품 카탈로그 검색을 수행하는 동안 반응이 느립니다. 제품 카탈로그는 회사가 제품을 저장하는 데 사용하는 MySQL 데이터베이스의 테이블 모음입니다.\\n정기적으로 업데이트되지 않습니다. 솔루션 설계자는 제품 카탈로그 검색이 발생할 때 데이터베이스 인스턴스의 CPU 사용량이 상당하다는 것을 확인했습니다.\\n솔루션 설계자는 제품 카탈로그 검색 중 웹사이트 성능을 최적화하기 위해 무엇을 제안해야 합니까?\\n\\nA.제품 카탈로그를 Amazon Redshift 데이터베이스로 마이그레이션합니다. COPY 명령을 사용하여 제품 카탈로그 테이블을 로드하십시오.\\nB. Redis용 Amazon ElastiCache 클러스터를 구현하여 제품 카탈로그를 캐시합니다. 캐시를 채우려면 지연 로딩을 사용하십시오.\\nC. Auto Scaling 그룹에 추가 조정 정책을 추가하여 데이터베이스 응답이 느릴 때 추가 EC2 인스턴스를 시작합니다.\\nD. DB 인스턴스에 대한 다중 AZ 구성을 켭니다. 데이터베이스로 전송되는 제품 카탈로그 쿼리를 조절하도록 EC2 인스턴스를 구성합니다.\", \"On AWS, a business is developing a prototype of an ecommerce website. The website is powered by an Application Load Balancer from Amazon's Auto Scaling division.\\nEC2 instances for web servers and an Amazon RDS for MySQL database instance configured in Single-AZ mode.\\nThe website is sluggish to react while doing product catalog searches. The product catalog is a collection of tables in the MySQL database that the firm uses to store its products.\\nnot regularly updated. A solutions architect has established that when product catalog searches occur, the CPU consumption on the database instance is significant.\\nWhat should the solutions architect propose to optimize the website's performance during product catalog searches?\\n\\nA.Migrate the product catalog to an Amazon Redshift database. Use the COPY command to load the product catalog tables.\\nB. Implement an Amazon ElastiCache for Redis cluster to cache the product catalog. Use lazy loading to populate the cache.\\nC. Add an additional scaling policy to the Auto Scaling group to launch additional EC2 instances when database response is slow.\\nD. Turn on the Multi-AZ configuration for the DB instance. Configure the EC2 instances to throttle the product catalog queries that are sent to the database.\", \"B\"],\n[\"한 기업이 내장된 자격 증명을 활용하여 Amazon RDS MySQL DB 인스턴스에서 데이터를 가져오는 맞춤형 애플리케이션을 개발했습니다. 경영진에 따르면 최소한의 개발 작업으로 애플리케이션의 보안을 강화해야 합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.AWS Key Management Service(AWS KMS) 고객 마스터 키(CMK)를 사용하여 키를 생성합니다. AWS KMS에서 데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. 자동 키 회전을 활성화합니다.\\nB. RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS Secrets Manager에 자격 증명을 저장합니다. Secrets Manager에서 데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. Secret Manager에서 자격 증명을 교체하는 AWS Lambda 함수를 생성합니다.\\nC. RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS Secrets Manager에 자격 증명을 저장합니다. Secrets Manager에서 데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. Secrets Manager를 사용하여 MySQL용 RDS 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명 교체 일정을 설정합니다.\\nD. RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS Systems Manager Parameter Store에 해당 자격 증명을 저장합니다. Parameter Store에서 데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. Parameter Store를 사용하여 MySQL용 RDS 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명 교체 일정을 설정합니다.\", \"A business has developed a bespoke application that utilizes embedded credentials to get data from an Amazon RDS MySQL DB instance. According to management, the application's security must be enhanced with the least amount of development work possible.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Use AWS Key Management Service (AWS KMS) customer master keys (CMKs) to create keys. Configure the application to load the database credentials from AWS KMS. Enable automatic key rotation.\\nB. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secret Manager.\\nC. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.\\nD. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store.\", \"C\"],\n[\"솔루션 설계자는 시장이 닫혀 있는 동안 금융 시장 성과를 분석하기 위한 시스템을 개발하고 있습니다. 매일 밤 시스템은 4시간 동안 연산 집약적인 작업을 연속적으로 수행합니다. 컴퓨팅 작업을 완료하는 데 필요한 시간은 일정해야 하며 한 번 시작되면 작업을 중지할 수 없습니다. 완공 후 시스템은 최소 1년 동안 운영될 예정이다.\\n시스템 비용을 낮추려면 어떤 Amazon EC2 인스턴스 유형을 사용해야 합니까?\\n\\nA.스팟 인스턴스\\nB. 온디맨드 인스턴스\\nC. 표준 예약 인스턴스\\nD. 정기 예약 인스턴스\", \"A solutions architect is developing a system for analyzing financial market performance while the markets are closed. Each night, the system will conduct a succession of compute-intensive operations for four hours. The time required to finish compute tasks is supposed to be constant, and once begun, jobs cannot be stopped. After completion, the system is scheduled to operate for at least one year.\\nWhich Amazon EC2 instance type should be utilized to lower the system's cost?\\n\\nA.Spot Instances\\nB. On-Demand Instances\\nC. Standard Reserved Instances\\nD. Scheduled Reserved Instances\", \"B. D는 더 이상 지원 X\"],\n[\"기업의 온프레미스 데이터 센터는 디렉터리 서비스 및 DNS와 같은 중요한 네트워크 서비스를 호스팅합니다. AWS Direct Connect는 데이터 센터를 AWS 클라우드(DX)에 연결합니다. 이러한 네트워크 서비스에 대한 지속적이고 신속하며 비용 효율적인 액세스가 필요한 추가 AWS 계정이 예상됩니다.\\n이러한 기준이 가능한 한 최소한의 운영 오버헤드를 충족하도록 하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.각각의 새 계정에서 DX 연결을 만드십시오. 네트워크 트래픽을 온프레미스 서버로 라우팅합니다.\\nB. 모든 필수 서비스에 대해 DX VPC에서 VPC 엔드포인트를 구성합니다. 네트워크 트래픽을 온프레미스 서버로 라우팅합니다.\\nC. 각각의 새 계정과 DX VPC 간에 VPN 연결을 생성합니다. 네트워크 트래픽을 온프레미스 서버로 라우팅합니다.\\nD. 계정 간에 AWS Transit Gateway를 구성합니다. DX를 전송 게이트웨이에 할당하고 네트워크 트래픽을 온프레미스 서버로 라우팅합니다.\", \"A business's on-premises data center hosts its critical network services, such as directory services and DNS. AWS Direct Connect connects the data center to the AWS Cloud (DX). Additional AWS accounts are anticipated, which will need continuous, rapid, and cost-effective access to these network services.\\nWhat measures should a solutions architect take to ensure that these criteria are met with the LEAST amount of operational overhead possible?\\n\\nA.Create a DX connection in each new account. Route the network traffic to the on-premises servers.\\nB. Configure VPC endpoints in the DX VPC for all required services. Route the network traffic to the on-premises servers.\\nC. Create a VPN connection between each new account and the DX VPC. Route the network traffic to the on-premises servers.\\nD. Configure AWS Transit Gateway between the accounts. Assign DX to the transit gateway and route network traffic to the on-premises servers.\", \"D\"],\n[\"기업에서 대용량 데이터를 저장하기 위한 새로운 애플리케이션을 개발 중입니다. 시간별 데이터 분석 및 수정은 여러 가용 영역에 분산된 많은 Amazon EC2 Linux 인스턴스에서 수행됩니다. 애플리케이션 팀은 필요한 공간이 다음 6개월 동안 계속 확장될 것으로 예상합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 애플리케이션 인스턴스에 EBS 볼륨을 탑재합니다.\\nB. Amazon Elastic File System(Amazon EFS) 파일 시스템에 데이터를 저장합니다. 애플리케이션 인스턴스에 파일 시스템을 마운트합니다.\\nC. Amazon S3 Glacier에 데이터를 저장합니다. 애플리케이션 인스턴스에 대한 액세스를 허용하도록 S3 Glacier 볼트 정책을 업데이트합니다.\\nD. 애플리케이션 인스턴스 간에 공유되는 Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS 볼륨에 데이터를 저장합니다.\", \"A business is developing a new application for storing a big volume of data. Hourly data analysis and modification will be performed by many Amazon EC2 Linux instances distributed across several Availability Zones. The application team anticipates that the required quantity of space will continue to expand over the following six months.\\nWhich course of action should a solutions architect pursue in order to meet these requirements?\\n\\nA.Store the data in an Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the application instances.\\nB. Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances.\\nC. Store the data in Amazon S3 Glacier. Update the S3 Glacier vault policy to allow access to the application instances.\\nD. Store the data in an Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS volume shared between the application instances.\", \"B\"],\n[\"솔루션 아키텍트는 AWS에서 호스팅될 새로운 애플리케이션을 위한 클라우드 아키텍처를 생성하는 책임이 있습니다. 처리할 작업의 수가 추가 및 제거된 애플리케이션 노드의 수를 결정하는 프로세스를 병렬화해야 합니다. 상태는 프로세서 프로그램에 의해 유지되지 않습니다. 솔루션 설계자는 애플리케이션이 느슨하게 연결되어 있고 작업 항목이 지속적으로 유지되도록 보장해야 합니다.\\n솔루션 설계자는 어떤 디자인을 사용해야 합니까?\\n\\nA.처리해야 하는 작업을 보낼 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI를 사용하는 시작 구성을 생성합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. CPU 사용량에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다.\\nB. 처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI를 사용하는 시작 구성을 생성합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. Auto Scaling 그룹의 scaling 정책을 설정하여 네트워크 사용량에 따라 노드를 추가 및 제거합니다.\\nC. 처리해야 하는 작업을 보관할 Amazon SQS 대기열을 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI를 사용하는 시작 템플릿을 생성합니다. 시작 템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SQS 대기열의 항목 수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다.\\nD. 처리해야 하는 작업을 보낼 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지(AMI)를 생성합니다. AMI를 사용하는 시작 템플릿을 생성합니다. 시작 템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. SNS 주제에 게시된 메시지 수에 따라 노드를 추가 및 제거하도록 Auto Scaling 그룹에 대한 조정 정책을 설정합니다.\", \"A solutions architect is tasked with the responsibility of creating the cloud architecture for a new application that will be hosted on AWS. The process should be parallelized, with the number of jobs to be handled dictating the number of application nodes added and removed. State is not maintained by the processor program. The solutions architect must guarantee that the application is loosely connected and that the task items are kept in a durable manner.\\nWhich design should the architect of solutions use?\\n\\nA.Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage.\\nB. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage.\\nC. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.\\nD. Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic.\", \"C. 시작 구성보다는 시작 템플릿 권장\"],\n[\"한 기업이 Amazon S3 버킷에 저장될 파일 공유 애플리케이션을 구축하고 있습니다. 회사는 Amazon CloudFront를 사용하여 모든 파일을 배포하려고 합니다. 회사는 파일이 S3 URL을 통해 직접 사용 가능한 것을 원하지 않습니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.각 S3 버킷에 대한 개별 정책을 작성하여 CloudFront 액세스에 대해서만 읽기 권한을 부여하십시오.\\nB. IAM 사용자를 생성합니다. 사용자에게 S3 버킷의 객체에 대한 읽기 권한을 부여합니다. CloudFront에 사용자를 할당합니다.\\nC. CloudFront 배포 ID를 보안 주체로 할당하고 대상 S3 버킷을 Amazon 리소스 이름(ARN)으로 할당하는 S3 버킷 정책을 작성합니다.\\nD. 원본 액세스 ID(OAI)를 생성합니다. CloudFront 배포에 OAI를 할당합니다. OAI만 읽기 권한을 갖도록 S3 버킷 권한을 구성합니다.\", \"A business is constructing a file-sharing application that will be stored in an Amazon S3 bucket. The firm want to distribute all files using Amazon CloudFront. The firm does not want for the files to be available directly via the S3 URL.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Write individual policies for each S3 bucket to grant read permission for only CloudFront access.\\nB. Create an IAM user. Grant the user read permission to objects in the S3 bucket. Assign the user to CloudFront.\\nC. Write an S3 bucket policy that assigns the CloudFront distribution ID as the Principal and assigns the target S3 bucket as the Amazon Resource Name (ARN).\\nD. Create an origin access identity (OAI). Assign the OAI to the CloudFront distribution. Configure the S3 bucket permissions so that only the OAI has read permission.\", \"D\"],\n[\"기업 내부의 수많은 비즈니스 프로세스는 파일 공유에 보관된 데이터에 액세스해야 합니다. 파일 공유는 SMB(서버 메시지 블록) 프로토콜을 사용하여 비즈니스 시스템에서 액세스합니다. 파일 공유 솔루션은 기업의 온프레미스 및 클라우드 환경 모두에서 사용할 수 있어야 합니다.\\n비즈니스에 필요한 서비스는 무엇입니까? (2개를 선택하세요.)\\n\\nA.Amazon Elastic Block Store(Amazon EBS)\\nB. Amazon Elastic File System(Amazon EFS)\\nC. Windows용 Amazon FSx\\nD. 아마존 S3\\nE. AWS Storage Gateway 파일 게이트웨이\", \"Numerous business processes inside a corporation need access to data kept in a file share. The file share will be accessed by business systems using the Server Message Block (SMB) protocol. The file sharing solution should be available from both the on-premises and cloud environments of the business.\\nWhich services are required by the business? (Select two.)\\n\\nA.Amazon Elastic Block Store (Amazon EBS)\\nB. Amazon Elastic File System (Amazon EFS)\\nC. Amazon FSx for Windows\\nD. Amazon S3\\nE. AWS Storage Gateway file gateway\", \"C, E\"],\n[\"기업은 Amazon EC2 인스턴스 집합을 활용하여 온프레미스 데이터 원본에서 데이터를 수집하고 있습니다. 데이터는 JSON 형식이며 최대 1MB/s의 속도로 수집될 수 있습니다. EC2 인스턴스가 다시 시작되면 전송 중이던 모든 데이터가 손실됩니다. 조직의 데이터 과학 팀은 가져온 데이터를 거의 실시간으로 쿼리하려고 합니다.\\n확장 가능하고 데이터 손실을 최소화하면서 실시간에 가까운 데이터 쿼리를 가능하게 하는 방법은 무엇입니까?\\n\\nA.Amazon Kinesis Data Streams에 데이터를 게시합니다. Kinesis Data Analytics를 사용하여 데이터를 쿼리합니다.\\nB. Amazon Redshift를 대상으로 하여 Amazon Kinesis Data Firehose에 데이터를 게시합니다. Amazon Redshift를 사용하여 데이터를 쿼리합니다.\\nC. 수집된 데이터를 EC2 인스턴스 스토어에 저장합니다. Amazon S3를 대상으로 하여 Amazon Kinesis Data Firehose에 데이터를 게시합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.\\nD. 수집된 데이터를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. Redis용 Amazon ElastiCache에 데이터를 게시합니다. Redis 채널을 구독하여 데이터를 쿼리하세요.\", \"A business is ingesting data from on-premises data sources utilizing a fleet of Amazon EC2 instances. The data is in JSON format and may be ingested at a rate of up to 1 MB/s. When an EC2 instance is restarted, any data that was in transit is lost. The data science team at the organization wishes to query imported data in near-real time.\\nWhich method enables near-real-time data querying while being scalable and causing the least amount of data loss?\\n\\nA.Publish data to Amazon Kinesis Data Streams. Use Kinesis Data Analytics to query the data.\\nB. Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.\\nC. Store ingested data in an EC2 instance store. Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data.\\nD. Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data.\", \"A\"],\n[\"기업은 테라바이트 규모의 .csv 파일에서 실행되고 수개월 분량의 데이터를 포함하는 기존의 사내 분석 솔루션에 의존합니다. 이전 프로그램은 증가하는 .csv 파일 크기에 대처할 수 없습니다. 매일 new.csv 파일이 수많은 데이터 소스에서 공통 온프레미스 스토리지 사이트로 업로드됩니다. 조직은 고객이 AWS 분석 기능에 익숙해지는 동안 기존 애플리케이션에 대한 지원을 유지하기를 원합니다. 이를 위해 솔루션 설계자는 all.csv 파일의 동기화된 사본 두 개를 온프레미스와 Amazon S3에 보관하려고 합니다.\\n솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\\n\\nA.AWS DataSync를 온프레미스에 배포합니다. 회사의 온프레미스 스토리지와 회사의 S3 버킷 간에 .csv 파일을 지속적으로 복제하도록 DataSync를 구성합니다.\\nB. 온프레미스 파일 게이트웨이를 배포합니다. .csv 파일을 파일 게이트웨이에 쓰도록 데이터 원본을 구성합니다. 레거시 분석 애플리케이션이 파일 게이트웨이를 가리키도록 합니다. 파일 게이트웨이는 .csv 파일을 Amazon S3에 복제해야 합니다.\\nC. 온프레미스 볼륨 게이트웨이를 배포합니다. .csv 파일을 볼륨 게이트웨이에 쓰도록 데이터 소스를 구성합니다. 레거시 분석 애플리케이션이 볼륨 게이트웨이를 가리키도록 합니다. 볼륨 게이트웨이는 데이터를 Amazon S3에 복제해야 합니다.\\nD. AWS DataSync를 온프레미스에 배포합니다. 온프레미스와 Amazon Elastic File System(Amazon EFS) 간에 .csv 파일을 지속적으로 복제하도록 DataSync를 구성합니다. Amazon Elastic File System(Amazon EFS)에서 회사의 S3 버킷으로 복제를 활성화합니다.\", \"A business relies on a traditional on-premises analytics solution that runs on terabytes of.csv files and contains months of data. The older program is unable to cope with the increasing size of.csv files. Daily, new.csv files are uploaded to a common on-premises storage site from numerous data sources. The organization want to maintain support for the traditional application while customers familiarize themselves with AWS analytics capabilities. To do this, the solutions architect want to keep two synchronized copies of all.csv files on-premises and on Amazon S3.\\nWhich solution should the architect of solutions recommend?\\n\\nA.Deploy AWS DataSync on-premises. Configure DataSync to continuously replicate the .csv files between the company's on-premises storage and the company's S3 bucket.\\nB. Deploy an on-premises file gateway. Configure data sources to write the .csv files to the file gateway. Point the legacy analytics application to the file gateway. The file gateway should replicate the .csv files to Amazon S3.\\nC. Deploy an on-premises volume gateway. Configure data sources to write the .csv files to the volume gateway. Point the legacy analytics application to the volume gateway. The volume gateway should replicate data to Amazon S3.\\nD. Deploy AWS DataSync on-premises. Configure DataSync to continuously replicate the .csv files between on-premises and Amazon Elastic File System (Amazon EFS). Enable replication from Amazon Elastic File System (Amazon EFS) to the company's S3 bucket.\", \"A. 그러나 B도 가능하다는 의견 존재\"],\n[\"한 기업이 3계층 애플리케이션을 Amazon Web Services로 이전하고 있습니다. 프로그램에는 MySQL 데이터베이스가 필요합니다. 이전에는 응용 프로그램 사용자가 새 항목을 추가하는 동안 프로그램의 느린 성능에 대해 불평했습니다. 이러한 성능 문제는 사용자가 업무 시간 동안 프로그램에서 다양한 실시간 보고서를 생성한 결과 발생했습니다.\\nAWS로 마이그레이션할 때 애플리케이션의 성능을 최적화하는 솔루션은 무엇입니까?\\n\\nA.프로비저닝된 용량이 있는 Amazon DynamoDB 테이블로 데이터를 가져옵니다. 보고서에 DynamoDB를 사용하도록 애플리케이션을 리팩터링합니다.\\nB. 컴퓨팅 최적화 Amazon EC2 인스턴스에 데이터베이스를 생성합니다. 컴퓨팅 리소스가 온프레미스 데이터베이스를 초과하는지 확인합니다.\\nC. 여러 읽기 전용 복제본이 있는 Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다. 보고서에 리더 엔드포인트를 사용하도록 애플리케이션을 구성합니다.\\nD. Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다. 클러스터의 백업 인스턴스를 보고서의 끝점으로 사용하도록 애플리케이션을 구성합니다.\", \"A business is transferring a three-tier application to Amazon Web Services. A MySQL database is required for the program. Previously, application users complained about the program's slow performance while adding new entries. These performance difficulties occurred as a result of users creating various real-time reports from the program during business hours.\\nWhich solution will optimize the application's performance when it is migrated to AWS?\\n\\nA.Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports.\\nB. Create the database on a compute optimized Amazon EC2 instance. Ensure compute resources exceed the on-premises database.\\nC. Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application to use the reader endpoint for reports.\\nD. Create an Amazon Aurora MySQL Multi-AZ DB cluster. Configure the application to use the backup instance of the cluster as an endpoint for the reports.\", \"C\"],\n[\"한 기업에 전 세계 영업 직원이 자주 사용하지 않는 사내 MySQL 데이터베이스가 있습니다. 영업 팀은 데이터베이스 다운타임이 거의 필요하지 않습니다. 데이터베이스 관리자는 앞으로 증가하는 사용자 트래픽 앞에서 인스턴스 유형을 지정하지 않고 이 데이터베이스를 AWS로 이동하려고 합니다.\\n어떤 솔루션 아키텍트 서비스를 권장해야 합니까?\\n\\nA.Amazon Aurora MySQL\\nB. MySQL용 Amazon Aurora 서버리스\\nC. Amazon Redshift 스펙트럼\\nD. MySQL용 Amazon RDS\", \"A corporation has an on-premises MySQL database that is used infrequently by the worldwide sales staff. The sales team needs little database downtime. A database administrator wishes to move this database to AWS without specifying an instance type in front of increased user traffic in the future.\\nWhich solution architect service should be recommended?\\n\\nA.Amazon Aurora MySQL\\nB. Amazon Aurora Serverless for MySQL\\nC. Amazon Redshift Spectrum\\nD. Amazon RDS for MySQL\", \"B\"],\n[\"기업은 소비자에게 가능한 한 최소한의 지연이 필요한 모바일 애플리케이션용 아키텍처를 개발하고 있습니다. 이 회사의 아키텍처는 Auto Scaling 그룹에서 작동하도록 구성된 Application Load Balancer를 통해 라우팅되는 Amazon EC2 인스턴스로 구성됩니다. Amazon EC2 인스턴스는 Amazon RDS와 통신합니다. 응용 프로그램의 베타 테스트에서 데이터를 읽는 동안 속도가 느려지는 것으로 나타났습니다. 그러나 데이터에 따르면 EC2 인스턴스가 초과하는 CPU 사용량 기준은 없습니다.\\n이 문제를 어떻게 해결할 수 있습니까?\\n\\nA.Auto Scaling 그룹에서 CPU 사용률 임계값을 줄입니다.\\nB. Application Load Balancer를 Network Load Balancer로 교체합니다.\\nC. RDS 인스턴스에 대한 읽기 전용 복제본을 추가하고 읽기 트래픽을 복제본으로 보냅니다.\\nD. 다중 AZ 지원을 RDS 인스턴스에 추가하고 읽기 트래픽을 새 EC2 인스턴스로 보냅니다.\", \"A corporation is developing an architecture for a mobile application that needs the least amount of delay possible for its consumers. The company's architecture is comprised of Amazon EC2 instances that are routed via an Application Load Balancer that is configured to operate in an Auto Scaling group. Amazon EC2 instances communicate with Amazon RDS. Beta testing of the application revealed a slowness while reading the data. However, the data suggest that no CPU usage criteria are exceeded by the EC2 instances.\\nHow can this problem be resolved?\\n\\nA.Reduce the threshold for CPU utilization in the Auto Scaling group.\\nB. Replace the Application Load Balancer with a Network Load Balancer.\\nC. Add read replicas for the RDS instances and direct read traffic to the replica.\\nD. Add Multi-AZ support to the RDS instances and direct read traffic to the new EC2 instance.\", \"C\"],\n[\"비즈니스의 애플리케이션 아키텍처는 2계층으로 되어 있으며 공용 서브넷과 사설 서브넷에 분산되어 있습니다. 퍼블릭 서브넷에는 웹 애플리케이션을 실행하는 Amazon EC2 인스턴스가 포함되어 있는 반면 프라이빗 서브넷에는 데이터베이스가 있습니다. 웹 애플리케이션 인스턴스와 데이터베이스는 모두 단일 가용 영역(AZ)에 포함됩니다.\\n솔루션 설계자는 이 아키텍처의 고가용성을 보장하기 위해 어떤 조치를 취해야 합니까? (2개를 선택하세요.)\\n\\nA.고가용성을 위해 동일한 AZ에 새 퍼블릭 및 프라이빗 서브넷을 생성합니다.\\nB. 여러 AZ에 걸쳐 Amazon EC2 Auto Scaling 그룹 및 Application Load Balancer를 생성합니다.\\nC. Application Load Balancer 뒤의 Auto Scaling 그룹에 기존 웹 애플리케이션 인스턴스를 추가합니다.\\nD. 새 AZ에 새 퍼블릭 및 프라이빗 서브넷을 생성합니다. 하나의 AZ에서 Amazon EC2를 사용하여 데이터베이스를 생성합니다.\\nE. 동일한 VPC에서 각각 새 AZ에 새 퍼블릭 및 프라이빗 서브넷을 생성합니다. 데이터베이스를 Amazon RDS 다중 AZ 배포로 마이그레이션합니다.\", \"A business's application architecture is two-tiered and distributed over public and private subnets. The public subnet contains Amazon EC2 instances that execute the web application, whereas the private subnet has a database. The web application instances and database are both contained inside a single Availability Zone (AZ).\\nWhich combination of measures should a solutions architect take to ensure this architecture's high availability? (Select two.)\\n\\nA.Create new public and private subnets in the same AZ for high availability.\\nB. Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs.\\nC. Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer.\\nD. Create new public and private subnets in a new AZ. Create a database using Amazon EC2 in one AZ.\\nE. Create new public and private subnets in the same VPC, each in a new AZ. Migrate the database to an Amazon RDS multi-AZ deployment.\", \"B, E\"],\n[\"기업은 Amazon S3를 온프레미스 데이터 세트의 보조 스토리지 위치로 활용하려고 합니다. 회사에서 이 사본에 액세스할 필요가 거의 없습니다. 스토리지 솔루션의 비용은 최소로 유지되어야 합니다.\\n이 기준을 충족하는 스토리지 옵션은 무엇입니까?\\n\\nA.S3 Standard\\nB. S3 Intelligent-Tiering\\nC. S3 Standard-Infrequent Access (S3 Standard-IA)\\nD. S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"A business want to utilize Amazon S3 as a supplementary storage location for its on-premises dataset. The business would seldom need access to this copy. The cost of the storage solution should be kept to a minimum.\\nWhich storage option satisfies these criteria?\\n\\nA.S3 Standard\\nB. S3 Intelligent-Tiering\\nC. S3 Standard-Infrequent Access (S3 Standard-IA)\\nD. S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"D\"],\n[\"팀의 모든 AWS 계정에서 특정 서비스 또는 활동에 대한 액세스를 제한하는 책임이 있는 보안 팀. AWS Organizations의 모든 계정은 거대한 조직의 일부입니다.\\n솔루션은 확장 가능해야 하며 권한은 중앙에서 관리되어야 합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.서비스 또는 작업에 대한 액세스를 제공하기 위해 ACL을 생성합니다.\\nB. 계정을 허용하는 보안 그룹을 생성하고 이를 사용자 그룹에 연결합니다.\\nC. 각 계정에 교차 계정 역할을 만들어 서비스 또는 작업에 대한 액세스를 거부합니다.\\nD. 루트 조직 단위에서 서비스 제어 정책을 만들어 서비스 또는 작업에 대한 액세스를 거부합니다.\", \"A security team that is responsible for restricting access to certain services or activities across all of the team's AWS accounts. All accounts in AWS Organizations are part of a huge organization.\\nThe solution must be scalable, and permissions must be managed centrally.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Create an ACL to provide access to the services or actions.\\nB. Create a security group to allow accounts and attach it to user groups.\\nC. Create cross-account roles in each account to deny access to the services or actions.\\nD. Create a service control policy in the root organizational unit to deny access to the services or actions.\", \"D\"],\n[\"비즈니스에는 타사 공급업체로부터 거의 실시간으로 데이터를 검색할 수 있는 REST 기반 인터페이스가 있는 응용 프로그램이 있습니다. 데이터를 수신한 후 프로그램은 추가 분석을 위해 분석하고 저장합니다. Amazon EC2 인스턴스는 애플리케이션을 호스팅하는 데 사용됩니다.\\n프로그램에 데이터를 전달할 때 타사 공급업체는 많은 503 서비스를 사용할 수 없음 오류를 확인했습니다. 데이터 볼륨이 증가하면 컴퓨팅 용량이 한계에 도달하고 애플리케이션이 모든 요청을 처리할 수 없게 됩니다.\\n확장성을 높이기 위해 솔루션 설계자는 어떤 설계를 옹호해야 합니까?\\n\\nA.Amazon Kinesis Data Streams를 사용하여 데이터를 수집합니다. AWS Lambda 함수를 사용하여 데이터를 처리합니다.\\nB. 기존 애플리케이션 위에 Amazon API Gateway를 사용합니다. 타사 공급업체에 대한 할당량 제한이 있는 사용 계획을 만듭니다.\\nC. Amazon Simple Notification Service(Amazon SNS)를 사용하여 데이터를 수집합니다. EC2 인스턴스를 Application Load Balancer 뒤에 있는 Auto Scaling 그룹에 넣습니다.\\nD. 애플리케이션을 컨테이너로 다시 패키징합니다. Auto Scaling 그룹과 함께 EC2 시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS)를 사용하여 애플리케이션을 배포합니다.\", \"A business has an application with a REST-based interface that enables near-real-time data retrieval from a third-party vendor. After receiving the data, the program analyzes and saves it for further analysis. Amazon EC2 instances are used to host the application.\\nWhen delivering data to the program, the third-party vendor saw many 503 Service Unavailable errors. When data volume increases, the compute capacity approaches its limit and the application becomes unable of processing all requests.\\nWhich design should a solutions architect advocate in order to achieve more scalability?\\n\\nA.Use Amazon Kinesis Data Streams to ingest the data. Process the data using AWS Lambda functions.\\nB. Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota limit for the third-party vendor.\\nC. Use Amazon Simple Notification Service (Amazon SNS) to ingest the data. Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer.\\nD. Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group.\", \"A, D 논란. B 소수의견\"],\n[\"한 비즈니스에서 상점 선반에 있는 품목의 야간 디지털 사진을 사용하여 재고 데이터를 분석하는 응용 프로그램을 개발했습니다. 애플리케이션은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에 배포되고 작업자 노드의 메타데이터 처리를 위해 Amazon S3 버킷에서 사진을 검색합니다. 솔루션 설계자는 작업자 노드가 각 그림을 처리하도록 보장해야 합니다.\\n솔루션 설계자는 가능한 가장 비용 효율적인 방식으로 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.EC2 스팟 인스턴스의 Auto Scaling 그룹을 대상 그룹으로 사용하는 작업자 노드에 대해 애플리케이션의 이미지 메타데이터를 두 번째 ALB로 직접 보냅니다.\\nB. Auto Scaling 그룹의 EC2 예약 인스턴스로 직접 전송하여 이미지 메타데이터를 처리합니다. 동적 조정 정책에서는 프런트 엔드 애플리케이션이 이미지를 가져오는 즉시 Auto Scaling 그룹의 평균 CPU 사용률에 대해 Amazon CloudWatch 지표를 사용합니다.\\nC. 프런트 엔드 애플리케이션이 이미지를 얻을 때 Amazon Simple Queue Service(Amazon SQS)에 메시지를 씁니다. 인스턴스 축소 보호 기능이 있는 Auto Scaling 그룹의 EC2 온디맨드 인스턴스와 정기적인 상태 확인을 통해 고정된 수의 인스턴스로 이미지를 처리합니다.\\nD. 애플리케이션이 이미지를 얻을 때 Amazon Simple Queue Service(Amazon SQS)에 메시지를 씁니다. 대기열의 현재 메시지 수에 대한 사용자 지정 Amazon CloudWatch 지표를 사용하여 인스턴스 축소 보호 및 동적 조정 정책이 있는 Auto Scaling 그룹의 EC2 스팟 인스턴스로 이미지를 처리합니다.\", \"A business has developed an application that analyzes inventory data by using overnight digital photographs of items on shop shelves. The application is deployed on Amazon EC2 instances behind an Application Load Balancer (ALB) and retrieves photos from an Amazon S3 bucket for metadata processing by worker nodes. A solutions architect must guarantee that worker nodes process each picture.\\nWhat actions should the solutions architect take to ensure that this need is met in the MOST cost-effective manner possible?\\n\\nA.Send the image metadata from the application directly to a second ALB for the worker nodes that use an Auto Scaling group of EC2 Spot Instances as the target group.\\nB. Process the image metadata by sending it directly to EC2 Reserved Instances in an Auto Scaling group. With a dynamic scaling policy, use an Amazon CloudWatch metric for average CPU utilization of the Auto Scaling group as soon as the front-end application obtains the images.\\nC. Write messages to Amazon Simple Queue Service (Amazon SQS) when the front-end application obtains an image. Process the images with EC2 On- Demand instances in an Auto Scaling group with instance scale-in protection and a fixed number of instances with periodic health checks.\\nD. Write messages to Amazon Simple Queue Service (Amazon SQS) when the application obtains an image. Process the images with EC2 Spot Instances in an Auto Scaling group with instance scale-in protection and a dynamic scaling policy using a custom Amazon CloudWatch metric for the current number of messages in the queue.\", \"D\"],\n[\"us-east-1 리전에서 회사에는 Development, Testing 및 Production으로 지정된 3개의 VPC가 있습니다. 3개의 가상 사설 클라우드는 온프레미스 데이터 센터에 연결되어야 하며 보안을 보장하고 리소스 공유를 피하기 위해 독립적이어야 합니다. 솔루션 설계자는 확장 가능하고 안전한 솔루션을 식별해야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.데이터 센터에 다시 연결할 각 VPC에 대해 AWS Direct Connect 연결 및 VPN 연결을 생성합니다.\\nB. 모든 VPC에서 프로덕션 VPC로 VPC 피어를 생성합니다. 프로덕션 VPC에서 데이터 센터로 다시 AWS Direct Connect 연결을 사용합니다.\\nC. 모든 VPC의 VPN 연결을 프로덕션 VPC의 VPN으로 연결합니다. 프로덕션 VPC에서 데이터 센터로 다시 VPN 연결을 사용합니다.\\nD. 네트워크라는 새 VPC를 생성합니다. 네트워크 VPC 내에서 데이터 센터에 대한 AWS Direct Connect 연결을 사용하여 AWS Transit Gateway를 생성합니다. 다른 모든 VPC를 네트워크 VPC에 연결합니다.\", \"In the us-east-1 Region, a corporation has three VPCs designated Development, Testing, and Production. The three virtual private clouds must be linked to an on-premises data center and are meant to be self-contained in order to ensure security and avoid resource sharing. A solutions architect must identify a solution that is both scalable and safe.\\nWhat recommendations should the solutions architect make?\\n\\nA.Create an AWS Direct Connect connection and a VPN connection for each VPC to connect back to the data center.\\nB. Create VPC peers from all the VPCs to the Production VPC. Use an AWS Direct Connect connection from the Production VPC back to the data center.\\nC. Connect VPN connections from all the VPCs to a VPN in the Production VPC. Use a VPN connection from the Production VPC back to the data center.\\nD. Create a new VPC called Network. Within the Network VPC, create an AWS Transit Gateway with an AWS Direct Connect connection back to the data center. Attach all the other VPCs to the Network VPC.\", \"D, A 논란\"],\n[\"기업은 애플리케이션을 위한 신뢰할 수 있는 아키텍처를 개발하기 위해 솔루션 설계자의 서비스를 유지했습니다. 애플리케이션은 단일 Amazon RDS 데이터베이스 인스턴스와 웹 서버를 실행하는 수동 배포 Amazon EC2 인스턴스 2개로 구성됩니다. 단일 가용 영역에는 모든 EC2 인스턴스가 포함됩니다.\\n직원이 최근에 데이터베이스 인스턴스를 제거하여 애플리케이션이 24시간 동안 오프라인 상태가 되었습니다. 회사는 환경의 일반적인 신뢰성에 관심이 있습니다.\\n솔루션 설계자는 애플리케이션의 인프라를 가능한 한 안정적으로 유지하기 위해 무엇을 해야 합니까?\\n\\nA.하나의 EC2 인스턴스를 삭제하고 다른 EC2 인스턴스에서 종료 방지를 활성화합니다. DB 인스턴스를 다중 AZ로 업데이트하고 삭제 방지를 활성화합니다.\\nB. DB 인스턴스를 다중 AZ로 업데이트하고 삭제 방지를 활성화합니다. EC2 인스턴스를 Application Load Balancer 뒤에 배치하고 여러 가용 영역에 걸쳐 EC2 Auto Scaling 그룹에서 실행합니다.\\nC. Amazon API Gateway 및 AWS Lambda 함수와 함께 추가 DB 인스턴스를 생성합니다. API Gateway를 통해 Lambda 함수를 호출하도록 애플리케이션을 구성합니다. Lambda 함수가 두 DB 인스턴스에 데이터를 쓰도록 합니다.\\nD. 여러 가용 영역에 여러 서브넷이 있는 EC2 Auto Scaling 그룹에 EC2 인스턴스를 배치합니다. 온디맨드 인스턴스 대신 스팟 인스턴스를 사용합니다. 인스턴스의 상태를 모니터링하도록 Amazon CloudWatch 경보를 설정합니다. DB 인스턴스를 다중 AZ로 업데이트하고 삭제 방지를 활성화합니다.\", \"A business has retained the services of a solutions architect to develop a dependable architecture for its application. The application is comprised of a single Amazon RDS database instance and two manually deployed Amazon EC2 instances running web servers. A single Availability Zone contains all of the EC2 instances.\\n\\nA.employee recently removed the database instance, resulting in the application being offline for 24 hours. The firm is concerned with the environment's general dependability.\\nWhat should the solutions architect do to ensure the application's infrastructure is as reliable as possible?\\n\\nA.Delete one EC2 instance and enable termination protection on the other EC2 instance. Update the DB instance to be Multi-AZ, and enable deletion protection.\\nB. Update the DB instance to be Multi-AZ, and enable deletion protection. Place the EC2 instances behind an Application Load Balancer, and run them in an EC2 Auto Scaling group across multiple Availability Zones.\\nC. Create an additional DB instance along with an Amazon API Gateway and an AWS Lambda function. Configure the application to invoke the Lambda function through API Gateway. Have the Lambda function write the data to the two DB instances.\\nD. Place the EC2 instances in an EC2 Auto Scaling group that has multiple subnets located in multiple Availability Zones. Use Spot Instances instead of On- Demand Instances. Set up Amazon CloudWatch alarms to monitor the health of the instances. Update the DB instance to be Multi-AZ, and enable deletion protection.\", \"B\"],\n[\"솔루션 설계자는 Amazon S3 버킷에 제출된 모든 항목의 암호화를 보장하기 위해 어떤 단계를 수행해야 합니까?\\n\\nA.PutObject에 s3:x-amz-acl 헤더 세트가 없는 경우 거부하도록 버킷 정책을 업데이트합니다.\\nB. PutObject에 private로 설정된 s3:x-amz-acl 헤더가 없는 경우 거부하도록 버킷 정책을 업데이트합니다.\\nC. PutObject에 aws:SecureTransport 헤더가 true로 설정되지 않은 경우 거부하도록 버킷 정책을 업데이트합니다.\\nD. PutObject에 x-amz-server-side-encryption 헤더 세트가 없는 경우 거부하도록 버킷 정책을 업데이트합니다.\", \"What steps should a solutions architect take to assure the encryption of all items submitted to an Amazon S3 bucket?\\n\\nA.Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set.\\nB. Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set to private.\\nC. Update the bucket policy to deny if the PutObject does not have an aws:SecureTransport header set to true.\\nD. Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set.\", \"D\"],\n[\"제조 비즈니스는 기계에 예측 유지보수를 구현하는 데 관심이 있습니다. 비즈니스는 실시간 데이터를 AWS로 전송할 수백 개의 IoT 센서를 배포할 것입니다. 솔루션 설계자는 각 장비에 대해 순서대로 이벤트를 수신하고 후속 처리를 위해 데이터가 보존되도록 보장하는 솔루션을 설계할 책임이 있습니다.\\n가장 효과적인 옵션은 무엇입니까?\\n\\nA.각 장비 자산에 대한 파티션이 있는 실시간 이벤트에 Amazon Kinesis Data Streams를 사용합니다. Amazon Kinesis Data Firehose를 사용하여 Amazon S3에 데이터를 저장합니다.\\nB. 각 장비 자산에 대한 샤드가 있는 실시간 이벤트에 Amazon Kinesis Data Streams를 사용합니다. Amazon Kinesis Data Firehose를 사용하여 Amazon Elastic Block Store(Amazon EBS)에 데이터를 저장합니다.\\nC. 각 장비 자산에 대해 하나의 대기열이 있는 실시간 이벤트에 Amazon SQS FIFO 대기열을 사용합니다. SQS 대기열에 대한 AWS Lambda 함수를 트리거하여 Amazon Elastic File System(Amazon EFS)에 데이터를 저장합니다.\\nD. 각 장비 자산에 대해 하나의 대기열이 있는 실시간 이벤트에 Amazon SQS 표준 대기열을 사용합니다. SQS 대기열에서 AWS Lambda 함수를 트리거하여 Amazon S3에 데이터를 저장합니다.\", \"A manufacturing business is interested in implementing predictive maintenance on its machines. The business will deploy hundreds of IoT sensors that will transmit real-time data to AWS. A solutions architect is entrusted with the responsibility of designing a solution that will receive events in an orderly fashion for each piece of equipment and will guarantee that data is preserved for subsequent processing.\\nWhich option is the MOST EFFECTIVE?\\n\\nA.Use Amazon Kinesis Data Streams for real-time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3.\\nB. Use Amazon Kinesis Data Streams for real-time events with a shard for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon Elastic Block Store (Amazon EBS).\\nC. Use an Amazon SQS FIFO queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function for the SQS queue to save data to Amazon Elastic File System (Amazon EFS).\\nD. Use an Amazon SQS standard queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3.\", \"A\"],\n[\"솔루션 설계자는 고객 대면 애플리케이션을 개발할 책임이 있습니다. 애플리케이션은 잘 정의된 액세스 패턴으로 일년 내내 다양한 ​​읽기 및 쓰기 횟수를 가질 것으로 예상됩니다. 데이터베이스 감사 및 확장성은 AWS 클라우드에서 제어해야 합니다. RPO(복구 시점 목표)는 5시간을 초과할 수 없습니다.\\n어떤 솔루션이 이 작업을 수행할 수 있습니까? (2개를 선택하세요.)\\n\\nA.Auto Scaling과 함께 Amazon DynamoDB를 사용하십시오. 온디맨드 백업 및 AWS CloudTrail을 사용합니다.\\nB. Auto Scaling과 함께 Amazon DynamoDB를 사용합니다. 온디맨드 백업과 Amazon DynamoDB 스트림을 사용합니다.\\nC. Amazon Redshift를 사용하여 동시성 확장을 구성합니다. 감사 로깅을 활성화합니다. 4시간마다 데이터베이스 스냅샷을 수행합니다.\\nD. 프로비저닝된 IOPS와 함께 Amazon RDS를 사용합니다. 데이터베이스 감사 매개변수를 활성화합니다. 5시간마다 데이터베이스 스냅샷을 수행합니다.\\nE. Auto Scaling과 함께 Amazon RDS를 사용합니다. 데이터베이스 감사 매개변수를 활성화합니다. 백업 보존 기간을 1일 이상으로 구성합니다.\", \"A solutions architect is tasked with the responsibility of developing a customer-facing application. The application is projected to have a varying number of reads and writes throughout the year, with well defined access patterns. Database auditing and scalability must be controlled in the AWS Cloud. The Recovery Point Objective (RPO) cannot exceed five hours.\\nWhich solutions are capable of doing this? (Select two.)\\n\\nA.Use Amazon DynamoDB with auto scaling. Use on-demand backups and AWS CloudTrail.\\nB. Use Amazon DynamoDB with auto scaling. Use on-demand backups and Amazon DynamoDB Streams.\\nC. Use Amazon Redshift Configure concurrency scaling. Enable audit logging. Perform database snapshots every 4 hours.\\nD. Use Amazon RDS with Provisioned IOPS. Enable the database auditing parameter. Perform database snapshots every 5 hours.\\nE. Use Amazon RDS with auto scaling. Enable the database auditing parameter. Configure the backup retention period to at least 1 day.\", \"A, E\"],\n[\"기업에서 필요에 따라 대량의 데이터를 일괄 처리하는 애플리케이션을 출시하고 있습니다. 워크로드는 Amazon EC2 인스턴스에서 실행됩니다. 네트워크 설계는 확장성이 매우 높아야 하며 동일한 기본 하드웨어를 가진 노드 그룹화를 피해야 합니다.\\n이러한 요구 사항에 적합한 네트워크 솔루션 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.배치 그룹에서 실행할 EC2 인스턴스에 대한 용량 예약을 생성합니다.\\nB. 분산 배치 그룹에서 EC2 인스턴스를 실행합니다.\\nC. 클러스터 배치 그룹에서 EC2 인스턴스를 실행합니다.\\nD. EC2 Auto Scaling 그룹에 EC2 인스턴스를 배치합니다.\\nE. 파티션 배치 그룹에서 EC2 인스턴스를 실행합니다.\", \"A business is launching an application that batch processes massive amounts of data as required. The workload will be run on Amazon EC2 instances. The network design must be extremely scalable and avoid groupings of nodes having the same underlying hardware.\\nWhich network solution combination will suit these requirements? (Select two.)\\n\\nA.Create Capacity Reservations for the EC2 instances to run in a placement group.\\nB. Run the EC2 instances in a spread placement group.\\nC. Run the EC2 instances in a cluster placement group.\\nD. Place the EC2 instances in an EC2 Auto Scaling group.\\nE. Run the EC2 instances in a partition placement group.\", \"B, D 랑 B, E 논란\"],\n[\"최근에 모놀리식 애플리케이션을 AWS로 이전했으며 현재 단일 Amazon EC2 머신에서 작동하고 있습니다. 애플리케이션 제한으로 인해 자동화된 확장을 사용하여 애플리케이션을 확장할 수 없습니다. CTO(최고 기술 책임자)는 기본 하드웨어가 손상될 가능성이 매우 낮은 상황에서 EC2 인스턴스를 복원하는 자동화된 방법을 원합니다.\\nEC2 인스턴스의 실현 가능한 가장 빠른 자동 복구를 가능하게 하는 것은 무엇입니까?\\n\\nA.EC2 인스턴스가 손상된 경우 복구를 트리거하는 Amazon CloudWatch 경보를 구성합니다.\\nB. EC2 인스턴스가 손상될 때 CTO에게 경고하는 SNS 메시지를 트리거하도록 Amazon CloudWatch 경보를 구성합니다.\\nC. EC2 인스턴스의 상태를 모니터링하도록 AWS CloudTrail을 구성하고 손상되면 인스턴스 복구를 트리거합니다.\\nD. EC2 인스턴스의 상태를 확인하고 EC2 인스턴스가 비정상인 경우 인스턴스 복구를 트리거하는 AWS Lambda 함수를 한 시간에 한 번씩 트리거하도록 Amazon EventBridge 이벤트를 구성합니다.\", \"Recently, we transferred a monolithic application to AWS and it is currently operating on a single Amazon EC2 machine. Due to application limits, automated scaling cannot be used to scale out the application. The chief technology officer (CTO) desires an automated method for restoring the EC2 instance in the very improbable event that the underlying hardware breaks.\\nWhat would enable the quickest feasible automated recovery of the EC2 instance?\\n\\nA.Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired.\\nB. Configure an Amazon CloudWatch alarm to trigger an SNS message that alerts the CTO when the EC2 instance is impaired.\\nC. Configure AWS CloudTrail to monitor the health of the EC2 instance, and if it becomes impaired, trigger instance recovery.\\nD. Configure an Amazon EventBridge event to trigger an AWS Lambda function once an hour that checks the health of the EC2 instance and triggers instance recovery if the EC2 instance is unhealthy.\", \"A\"],\n[\"내부적으로 기업은 미디어 및 애플리케이션 파일을 전달해야 합니다. 현재 사용자는 Active Directory를 통해 권한이 부여되고 Microsoft Windows 플랫폼을 통해 파일에 액세스할 수 있습니다. CEO는 이전과 동일한 사용자 권한을 유지하기를 원하지만 저장 용량 제한에 가까워지면 회사에서 절차를 개선하기를 원합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.기업 Amazon S3 버킷을 설정하고 모든 미디어 및 애플리케이션 파일을 이동합니다.\\nB. Windows 파일 서버용 Amazon FSx를 구성하고 모든 미디어 및 애플리케이션 파일을 이동합니다.\\nC. Amazon Elastic File System(Amazon EFS)을 구성하고 모든 미디어 및 애플리케이션 파일을 이동합니다.\\nD. Windows에서 Amazon EC2를 설정하고, 여러 Amazon Elastic Block Store(Amazon EBS) 볼륨을 연결하고, 모든 미디어 및 애플리케이션 파일을 이동합니다.\", \"Internally, a business must communicate media and application files. At the moment, users are authorized through Active Directory and have access to files via a Microsoft Windows platform. The chief executive officer wants to maintain the same user rights as before, but wishes for the corporation to enhance the procedure as it nears its storage capacity limit.\\nWhat recommendations should a solutions architect make?\\n\\nA.Set up a corporate Amazon S3 bucket and move all media and application files.\\nB. Configure Amazon FSx for Windows File Server and move all the media and application files.\\nC. Configure Amazon Elastic File System (Amazon EFS) and move all media and application files.\\nD. Set up Amazon EC2 on Windows, attach multiple Amazon Elastic Block Store (Amazon EBS) volumes, and move all media and application files.\", \"B\"],\n[\"한 기업에서 자율 주행 차량의 데이터를 광범위한 자동차 커뮤니티와 공유하려고 합니다. 데이터는 Amazon S3 버킷을 통해 액세스됩니다. 조직은 다른 AWS 고객이 이 데이터에 액세스할 수 있도록 하는 비용을 최소화하려고 합니다.\\n솔루션 설계자는 이 목표를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.버킷에 대한 S3 VPC 엔드포인트를 생성합니다.\\nB. S3 버킷을 요청자 지불 버킷으로 구성합니다.\\nC. S3 버킷 앞에 Amazon CloudFront 배포를 생성합니다.\\nD. BitTorrent 프로토콜을 사용해야만 파일에 액세스할 수 있습니다.\", \"A business wants to share data from self-driving vehicles with the broader automotive community. The data will be accessed through an Amazon S3 bucket. The organization want to keep the expense of making this data accessible to other AWS customers to a minimum.\\nWhat actions should a solutions architect take to achieve this objective?\\n\\nA.Create an S3 VPC endpoint for the bucket.\\nB. Configure the S3 bucket to be a Requester Pays bucket.\\nC. Create an Amazon CloudFront distribution in front of the S3 bucket.\\nD. Require that the files be accessible only with the use of the BitTorrent protocol.\", \"B. A라는 소수 의견 존재. 회사가 자체 및 고객에 대한 최소 요금을 원하면 A, 회사가 회사에 대한 요금을 줄이려면 B\"],\n[\"비즈니스는 AWS Lambda 함수를 사용하여 Amazon S3에서 데이터를 검색하고 해독합니다. 이러한 파일은 AWS Key Management Service(AWS KMS CMK)용 고객 마스터 키를 사용하여 암호화됩니다. 솔루션 설계자는 필요한 권한을 적절하게 설정하는 솔루션을 만들어야 합니다.\\n어떤 작업 조합이 이 작업을 수행합니까? (2개를 선택하세요.)\\n\\nA.kms:decrypt 권한을 Lambda 함수의 리소스 정책에 연결합니다.\\nB. KMS 키의 정책에서 Lambda IAM 역할에 대한 암호 해독 권한을 부여합니다.\\nC. KMS 키의 정책에서 Lambda 리소스 정책에 대한 암호 해독 권한을 부여합니다.\\nD. kms:decrypt 권한이 있는 새 IAM 정책을 생성하고 정책을 Lambda 함수에 연결합니다.\\nE. kms:decrypt 권한이 있는 새 IAM 역할을 생성하고 실행 역할을 Lambda 함수에 연결합니다.\", \"A business utilizes an AWS Lambda function to retrieve and decrypt data from Amazon S3. These files are encrypted using Customer Master Keys for AWS Key Management Service (AWS KMS CMKs). A solutions architect must create a solution that properly sets the needed permissions.\\nWhich action combination does this? (Select two.)\\n\\nA.Attach the kms:decrypt permission to the Lambda function's resource policy.\\nB. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy.\\nC. Grant the decrypt permission for the Lambda resource policy in the KMS key's policy.\\nD. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.\\nE. Create a new IAM role with the kms:decrypt permission and attach the execution role to the Lambda function.\", \"B, E\"],\n[\"기업은 온-프레미스 Windows Server에서 Microsoft.NET 응용 프로그램을 운영합니다. 이 프로그램은 Oracle Database Standard Edition 서버를 사용하여 데이터를 저장합니다. 이 회사는 AWS로 마이그레이션하는 과정에 있으며 프로세스 전반에 걸쳐 개발 수정 사항을 최소화하려고 합니다. Amazon Web Services 애플리케이션 환경은 매우 안정적이어야 합니다.\\n이러한 요구 사항을 달성하기 위해 조직은 어떤 단계를 함께 취해야 합니까? (2개를 선택하세요.)\\n\\nA..NET Core를 실행하는 AWS Lambda 함수를 사용하여 애플리케이션을 서버리스로 리팩터링합니다.\\nB. 다중 AZ 배포에서 .NET 플랫폼을 사용하여 AWS Elastic Beanstalk에서 애플리케이션을 다시 호스팅합니다.\\nC. Amazon Linux Amazon 머신 이미지(AMI)를 사용하여 Amazon EC2에서 실행되도록 애플리케이션을 다시 플랫폼화합니다.\\nD. AWS Database Migration Service(AWS DMS)를 사용하여 다중 AZ 배포에서 Oracle 데이터베이스에서 Amazon DynamoDB로 마이그레이션합니다.\\nE. AWS Database Migration Service(AWS DMS)를 사용하여 다중 AZ 배포에서 Oracle 데이터베이스에서 Amazon RDS의 Oracle로 마이그레이션합니다.\", \"A business operates a Microsoft.NET application on an on-premises Windows Server. The program makes use of an Oracle Database Standard Edition server to store data. The firm is in the process of migrating to AWS and want to minimize development modifications throughout the process. The Amazon Web Services application environment should be very reliable.\\nWhich steps should the organization take in combination to achieve these requirements? (Select two.)\\n\\nA.Refactor the application as serverless with AWS Lambda functions running .NET Core.\\nB. Rehost the application in AWS Elastic Beanstalk with the .NET platform in a Multi-AZ deployment.\\nC. Replatform the application to run on Amazon EC2 with the Amazon Linux Amazon Machine Image (AMI).\\nD. Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Amazon DynamoDB in a Multi-AZ deployment.\\nE. Use AWS Database Migration Service (AWS DMS) to migrate from the Oracle database to Oracle on Amazon RDS in a Multi-AZ deployment.\", \"B, E\"],\n[\"비즈니스는 자연 재해가 발생하기 쉬운 지역에 위치하여 데이터 센터 공급업체로부터 고르지 못한 서비스를 경험합니다. 조직은 AWS 클라우드로 완전히 이동할 준비가 되어 있지 않지만 온프레미스 데이터 센터에 장애가 발생할 경우 AWS에서 장애 조치 시나리오를 원합니다.\\n비즈니스는 제3자 제공업체에 연결되는 웹 서버를 운영합니다. AWS와 온프레미스에 저장된 데이터는 일관성이 있어야 합니다.\\n솔루션 아키텍트에 따르면 어떤 솔루션이 다운타임을 최소화해야 합니까?\\n\\nA.Amazon Route 53 장애 조치 레코드를 구성합니다. Auto Scaling 그룹의 Application Load Balancer 뒤에서 Amazon EC2 인스턴스에서 애플리케이션 서버를 실행합니다. Amazon S3에 데이터를 백업하기 위해 저장된 볼륨으로 AWS Storage Gateway를 설정합니다.\\nB. Amazon Route 53 장애 조치 레코드를 구성합니다. 스크립트에서 AWS CloudFormation 템플릿을 실행하여 Application Load Balancer 뒤에 Amazon EC2 인스턴스를 생성합니다. Amazon S3에 데이터를 백업하기 위해 저장된 볼륨으로 AWS Storage Gateway를 설정합니다.\\nC. Amazon Route 53 장애 조치 레코드를 구성합니다. VPC와 데이터 센터 간에 AWS Direct Connect 연결을 설정합니다. Auto Scaling 그룹의 Amazon EC2에서 애플리케이션 서버를 실행합니다. AWS Lambda 함수를 실행하여 AWS CloudFormation 템플릿을 실행하여 Application Load Balancer를 생성합니다.\\nD. Amazon Route 53 장애 조치 레코드를 구성합니다. AWS Lambda 함수를 실행하여 AWS CloudFormation 템플릿을 실행하여 두 개의 Amazon EC2 인스턴스를 시작합니다. Amazon S3에 데이터를 백업하기 위해 저장된 볼륨으로 AWS Storage Gateway를 설정합니다. VPC와 데이터 센터 간에 AWS Direct Connect 연결을 설정합니다.\", \"A business experiences uneven service from its data center supplier as a result of its location in a natural disaster-prone region. Although the organization is not ready to completely move to the AWS Cloud, it does desire a failover scenario on AWS in the event that the on-premises data center fails.\\nThe business operates web servers that link to third-party providers. The data stored on AWS and on-premises must be consistent.\\nWhich solution, according to a solutions architect, should have the LEAST amount of downtime?\\n\\nA.Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.\\nB. Configure an Amazon Route 53 failover record. Execute an AWS CloudFormation template from a script to create Amazon EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.\\nC. Configure an Amazon Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on Amazon EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer.\\nD. Configure an Amazon Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two Amazon EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. Set up an AWS Direct Connect connection between a VPC and the data center.\", \"A\"],\n[\"솔루션 설계자는 데이터의 대규모 일괄 처리를 처리할 응용 프로그램을 개발하고 있습니다. Amazon S3는 입력 데이터를 저장하는 데 사용되고 다른 S3 버킷은 출력 데이터를 유지하는 데 사용됩니다. 프로그램은 다른 Amazon EC2 인스턴스에 걸쳐 네트워크를 통해 데이터를 전송하여 데이터를 처리합니다.\\n솔루션 설계자는 데이터 전송의 총 비용을 최소화하기 위해 무엇을 해야 합니까?\\n\\nA.모든 EC2 인스턴스를 Auto Scaling 그룹에 배치합니다.\\nB. 모든 EC2 인스턴스를 동일한 AWS 리전에 배치합니다.\\nC. 모든 EC2 인스턴스를 동일한 가용 영역에 배치합니다.\\nD. 여러 가용 영역의 프라이빗 서브넷에 모든 EC2 인스턴스를 배치합니다.\", \"A solutions architect is developing an application that will handle large-scale batch processing of data. Amazon S3 will be used to store the input data, while another S3 bucket will be used to keep the output data. The program will handle the data by transferring it over the network across different Amazon EC2 instances.\\nWhat should the solutions architect do to minimize the total cost of data transfer?\\n\\nA.Place all the EC2 instances in an Auto Scaling group.\\nB. Place all the EC2 instances in the same AWS Region.\\nC. Place all the EC2 instances in the same Availability Zone.\\nD. Place all the EC2 instances in private subnets in multiple Availability Zones.\", \"C\"],\n[\"비즈니스에서 만들고 반환하는 패키지 애플리케이션은 사용자 요청에 대한 응답으로 일회용 텍스트 파일을 동적으로 생성하고 반환합니다. 이 회사는 이미 Amazon CloudFront를 사용하여 콘텐츠를 배포하고 있지만 데이터 전송 비용을 더욱 최소화하려고 합니다. 회사는 프로그램의 소스 코드를 편집할 수 없습니다.\\n솔루션 설계자는 비용을 절감하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.Lambda@Edge 를 사용 하여 사용자에게 전송되는 파일을 압축합니다.\\nB. 응답 시간을 줄이려면 Amazon S3 Transfer Acceleration을 활성화합니다.\\nC. CloudFront 배포에서 캐싱을 활성화하여 엣지에서 생성된 파일을 저장합니다.\\nD. Amazon S3 멀티파트 업로드를 사용하여 파일을 사용자에게 반환하기 전에 Amazon S3로 이동합니다.\", \"A packaged application created and returned by a business dynamically produces and returns single-use text files in response to user requests. The firm is already distributing content using Amazon CloudFront, but wants to further minimize data transmission costs. The firm is not permitted to edit the source code of the program.\\nWhat actions should a solutions architect do to save money?\\n\\nA.Use Lambda@Edge to compress the files as they are sent to users.\\nB. Enable Amazon S3 Transfer Acceleration to reduce the response times.\\nC. Enable caching on the CloudFront distribution to store generated files at the edge.\\nD. Use Amazon S3 multipart uploads to move the files to Amazon S3 before returning them to users.\", \"A\"],\n[\"현재 온프레미스에서 웹 사이트를 유지 관리하는 비즈니스에서 AWS 클라우드로 이전하려고 합니다. 웹 사이트는 단일 호스트 이름을 인터넷에 노출하지만 해당 기능을 URL 경로에 따라 고유한 온프레미스 서버 그룹으로 라우팅합니다. 서버 그룹은 지원하는 서비스의 요구 사항에 따라 개별적으로 조정됩니다. 회사의 온프레미스 네트워크는 AWS Direct Connect 링크를 통해 연결됩니다.\\n경로 기반 라우팅을 사용하여 트래픽이 적절한 서버 집합으로 전송되도록 하려면 솔루션 설계자가 무엇을 해야 합니까?\\n\\nA.모든 트래픽을 인터넷 게이트웨이로 라우팅합니다. 트래픽을 해당 경로를 지원하는 서버 그룹으로 라우팅하도록 인터넷 게이트웨이에서 패턴 일치 규칙을 구성합니다.\\nB. 각 서버 그룹에 대한 대상 그룹이 있는 네트워크 로드 밸런서(NLB)로 모든 트래픽을 라우팅합니다. NLB에서 패턴 일치 규칙을 사용하여 트래픽을 올바른 대상 그룹으로 라우팅합니다.\\nC. 모든 트래픽을 ALB(Application Load Balancer)로 라우팅합니다. ALB에서 경로 기반 라우팅을 구성하여 해당 경로를 지원하는 서버의 올바른 대상 그룹으로 트래픽을 라우팅합니다.\\nD. Amazon Route 53을 DNS 서버로 사용합니다. 해당 경로를 지원하는 서버 그룹에 대해 올바른 Elastic Load Balancer로 트래픽을 라우팅하도록 Route 53 경로 기반 별칭 레코드를 구성합니다.\", \"A business that now maintains a website on-premises want to move it to the AWS Cloud. Although the website exposes a single hostname to the internet, it routes its functionalities to distinct on-premises server groups dependent on the URL path. The server groups are individually scaled in accordance with the requirements of the services they support. The company's on-premises network is connected through an AWS Direct Connect link.\\nWhat should a solutions architect do to ensure that traffic is sent to the proper set of servers using path-based routing?\\n\\nA.Route all traffic to an internet gateway. Configure pattern matching rules at the internet gateway to route traffic to the group of servers supporting that path.\\nB. Route all traffic to a Network Load Balancer (NLB) with target groups for each group of servers. Use pattern matching rules at the NLB to route traffic to the correct target group.\\nC. Route all traffic to an Application Load Balancer (ALB). Configure path-based routing at the ALB to route traffic to the correct target group for the servers supporting that path.\\nD. Use Amazon Route 53 as the DNS server. Configure Route 53 path-based alias records to route traffic to the correct Elastic Load Balancer for the group of servers supporting that path.\", \"C\"],\n[\"기업은 수많은 웹사이트에서 조직화된 클릭스트림 데이터를 수집하고 일괄 처리를 사용하여 분석합니다. 회사는 매일 약 1KB 크기의 이벤트 레코드 1억 개를 받습니다. 매일 밤 조직은 비즈니스 분석가가 수집하는 Amazon Redshift로 데이터를 가져옵니다.\\n조직은 적시에 통찰력을 제공하기 위해 거의 실시간 데이터 처리로 전환하기를 원합니다. 솔루션은 가능한 한 최소한의 운영 오버헤드로 스트리밍 데이터를 처리해야 합니다.\\n비용 효율성 측면에서 이러한 목표를 가장 잘 충족하는 AWS 서비스 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.아마존 EC2\\nB. AWS 배치\\nC. Amazon Simple Queue Service(Amazon SQS)\\nD. Amazon Kinesis Data Firehose\\nE. Amazon Kinesis 데이터 분석\", \"A business collects organized clickstream data from numerous websites and analyzes it using batch processing. Each day, the firm gets 100 million event records, each of which is around 1 KB in size. Each night, the organization imports data onto Amazon Redshift, which business analysts ingest.\\nThe organization wishes to transition to near-real-time data processing in order to provide timely insights. The solution should process the streaming data with the least amount of operational overhead as feasible.\\nWhich AWS service combination best meets these objectives in terms of cost-effectiveness? (Select two.)\\n\\nA.Amazon EC2\\nB. AWS Batch\\nC. Amazon Simple Queue Service (Amazon SQS)\\nD. Amazon Kinesis Data Firehose\\nE. Amazon Kinesis Data Analytics\", \"D, E\"],\n[\"비즈니스에는 소프트웨어 엔지니어링 목적으로 AWS 계정이 있습니다. AWS Direct Connect 연결 쌍을 통해 AWS 계정은 회사의 온프레미스 데이터 센터에 액세스할 수 있습니다. 가상 사설 클라우드에서 시작되지 않은 모든 트래픽은 가상 사설 게이트웨이를 통해 라우팅됩니다.\\n개발 팀은 최근에 콘솔을 사용하여 AWS Lambda 함수를 구성했습니다. 개발 팀은 회사 데이터 센터 내부의 사설 서브넷에 있는 데이터베이스에 대한 기능에 대한 액세스를 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.적절한 보안 그룹이 있는 VPC에서 실행되도록 Lambda 함수를 구성합니다.\\nB. AWS에서 데이터 센터로 VPN 연결을 설정합니다. VPN을 통해 Lambda 함수의 트래픽을 라우팅합니다.\\nC. Lambda 함수가 Direct Connect를 통해 온프레미스 데이터 센터에 액세스할 수 있도록 VPC의 라우팅 테이블을 업데이트합니다.\\nD. 탄력적 IP 주소를 생성합니다. 탄력적 네트워크 인터페이스 없이 탄력적 IP 주소를 통해 트래픽을 보내도록 Lambda 함수를 구성합니다.\", \"A business has an AWS account for software engineering purposes. Through a pair of AWS Direct Connect connections, the AWS account gets access to the company's on-premises data center. All traffic that does not originate in a virtual private cloud is routed via the virtual private gateway.\\nA development team recently used the console to construct an AWS Lambda function. The development team must provide access to the function to a database that is located on a private subnet inside the company's data center.\\nWhich solution will satisfy these criteria?\\n\\nA.Configure the Lambda function to run in the VPC with the appropriate security group.\\nB. Set up a VPN connection from AWS to the data center. Route the traffic from the Lambda function through the VPN.\\nC. Update the route tables in the VPC to allow the Lambda function to access the on-premises data center through Direct Connect.\\nD. Create an Elastic IP address. Configure the Lambda function to send traffic through the Elastic IP address without an elastic network interface.\", \"C\"],\n[\"솔루션 설계자가 새로운 가상 사설 클라우드(VPC) 아키텍처를 개발하고 있습니다. 두 개의 퍼블릭 서브넷은 로드 밸런서용으로, 두 개의 프라이빗 서브넷은 웹 서버용으로, 두 개의 프라이빗 서브넷은 MySQL용으로 예약되어 있습니다. HTTPS는 웹 서버에서 사용하는 유일한 프로토콜입니다. 솔루션 설계자는 이전에 0.0.0.0/0에서 포트 443에 액세스할 수 있도록 로드 밸런서의 보안 그룹을 구성했습니다. 회사 정책에 따라 각 리소스에는 해당 기능을 수행하는 데 필요한 최소한의 액세스 권한이 있어야 합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 추가 구성 기술을 수행해야 합니까?\\n\\nA.웹 서버에 대한 보안 그룹을 생성하고 0.0.0.0/0에서 포트 443을 허용합니다. MySQL 서버용 보안 그룹을 생성하고 웹 서버 보안 그룹에 대해 포트 3306을 허용합니다.\\nB. 웹 서버에 대한 네트워크 ACL을 생성하고 0.0.0.0/0에서 포트 443을 허용합니다. MySQL 서버용 네트워크 ACL을 생성하고 웹 서버 보안 그룹에 대해 포트 3306을 허용합니다.\\nC. 웹 서버에 대한 보안 그룹을 생성하고 로드 밸런서에서 포트 443을 허용합니다. MySQL 서버용 보안 그룹을 생성하고 웹 서버 보안 그룹에 대해 포트 3306을 허용합니다.\\nD. 웹 서버에 대한 네트워크 ACL을 생성하고 로드 밸런서에서 포트 443을 허용합니다. MySQL 서버용 네트워크 ACL을 생성하고 웹 서버 보안 그룹에 대해 포트 3306을 허용합니다.\", \"A solutions architect is developing a new virtual private cloud (VPC) architecture. Two public subnets are reserved for the load balancer, two private subnets are reserved for web servers, and two private subnets are reserved for MySQL. HTTPS is the sole protocol used by the web servers. The solutions architect has previously configured the load balancer's security group to enable access to port 443 from 0.0.0.0/0. According to company policy, each resource must have the least amount of access necessary to accomplish its functions.\\nWhich extra configuration technique should the solutions architect do in order to satisfy these requirements?\\n\\nA.Create a security group for the web servers and allow port 443 from 0.0.0.0/0. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.\\nB. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.\\nC. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.\\nD. Create a network ACL for the web servers and allow port 443 from the load balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.\", \"C\"],\n[\"비즈니스에는 다양한 AWS 리전에서 실행 중인 여러 프로젝트가 있을 수 있습니다. 일반적으로 프로젝트에는 Application Load Balancer를 통해 라우팅되는 Amazon EC2 인스턴스로 구성된 3계층 아키텍처가 있습니다. 인스턴스는 Auto Scaling 그룹의 일부로 관리되며 Amazon Elastic File System(Amazon EFS) 스토리지와 Amazon Relational Database Service(Amazon RDS) 데이터베이스를 공유합니다. 특정 이니셔티브에는 여러 지역의 리소스가 필요합니다.\\n솔루션 설계자는 각 프로젝트와 관련된 특정 비용을 결정해야 합니다.\\n이 정보를 전달하는 데 최소한의 운영 노력이 필요한 방법은 무엇입니까?\\n\\nA.비용 탐색기를 사용하여 각 지역에 대해 일회성 쿼리를 수행하고 프로젝트별로 필터링하는 보고서를 만듭니다.\\nB. AWS Billing and Cost Management 세부 정보 페이지를 사용하여 프로젝트별 리소스의 실제 사용 비용을 확인합니다.\\nC. AWS Systems Manager를 사용하여 프로젝트별로 리소스를 그룹화하고 각 프로젝트의 리소스 및 비용을 모니터링합니다.\\nD. AWS Billing and Cost Management를 사용하여 비용 할당 태그를 활성화하고 프로젝트 태그를 기반으로 하는 보고서를 생성합니다.\", \"A business may have several projects running in various AWS Regions. Typically, the projects have a three-tier architecture comprised of Amazon EC2 instances that are routed via an Application Load Balancer. The instances are managed as part of an Auto Scaling group and share Amazon Elastic File System (Amazon EFS) storage and Amazon Relational Database Service (Amazon RDS) databases. Certain initiatives need resources from many regions.\\nA solutions architect must determine the specific expenses associated with each project.\\nWhich method requires the LEAST amount of operational effort to convey this information?\\n\\nA.Use Cost Explorer to perform one-time queries for each Region and create a report that filters by project.\\nB. Use the AWS Billing and Cost Management details page to see the actual usage costs of the resources by project.\\nC. Use AWS Systems Manager to group resources by project and monitor each project's resources and cost.\\nD. Use AWS Billing and Cost Management to activate cost allocation tags and create reports that are based on the project tags.\", \"D\"],\n[\"기업은 사람들이 서비스를 활용하는 방법에 대한 데이터를 수집, 처리 및 저장하기 위한 다양한 옵션을 평가하고 있습니다. 비즈니스 목표는 조직이 일반 SQL 쿼리를 사용하여 운영 통찰력을 쉽게 얻을 수 있도록 하는 분석 기능을 제공하는 것입니다. 솔루션은 액세스 가능성이 높고 데이터 계층의 ACID(Atomicity, Consistency, Isolation, and Durability) 요구 사항을 준수해야 합니다.\\n솔루션 아키텍트가 제안해야 하는 솔루션은 무엇입니까?\\n\\nA.Amazon Timestream 데이터베이스를 사용합니다.\\nB. 다중 AZ 설계에서 Amazon Neptune 데이터베이스를 사용합니다.\\nC. 다중 AZ 설계에서 MySQL용 완전 관리형 Amazon RDS 데이터베이스를 사용합니다.\\nD. Amazon Elastic Block Store(Amazon EBS) 처리량 최적화 HDD(st1) 스토리지를 사용하는 Amazon EC2 인스턴스에 PostgreSQL을 배포합니다.\", \"A business is evaluating various options for collecting, processing, and storing data about how people utilize their services. The business aim is to provide an analytics capability that enables the organization to easily acquire operational insights using regular SQL queries. The solution should be highly accessible and adhere to the data tier's Atomicity, Consistency, Isolation, and Durability (ACID) requirements.\\nWhich solution, if any, should a solutions architect suggest?\\n\\nA.Use an Amazon Timestream database.\\nB. Use an Amazon Neptune database in a Multi-AZ design.\\nC. Use a fully managed Amazon RDS for MySQL database in a Multi-AZ design.\\nD. Deploy PostgreSQL on an Amazon EC2 instance that uses Amazon Elastic Block Store (Amazon EBS) Throughput Optimized HDD (st1) storage.\", \"C\"],\n[\"비즈니스는 Amazon S3 버킷을 통해 us-east-1 리전에 정적 웹 사이트 콘텐츠를 저장합니다. 버킷의 콘텐츠는 이를 가리키는 Amazon CloudFront 오리진을 통해 액세스할 수 있습니다. 교차 리전 복제가 활성화되어 버킷을 ap-southeast-1 리전에 복제합니다. 관리 팀은 웹사이트의 가용성을 높일 수 있는 솔루션을 찾고 있습니다.\\n가용성 향상을 위해 솔루션 설계자는 어떤 활동을 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.두 버킷을 CloudFront 오리진에 추가합니다.\\nB. Amazon Route 53에서 장애 조치 라우팅을 구성합니다.\\nC. 복제본 버킷을 가리키는 Amazon Route 53에 레코드를 생성합니다.\\nD. ap-southeast-1 버킷을 가리키는 추가 CloudFront 오리진을 생성합니다.\\nE. us-east-1 버킷을 기본으로, ap-southeast-1 버킷을 보조로 사용하여 CloudFront 오리진 그룹을 설정합니다.\", \"A business stores its static website content in the us-east-1 Region through an Amazon S3 bucket. The bucket's content is made accessible through an Amazon CloudFront origin pointing to it. Cross-Region replication is enabled, which will replicate the bucket to the ap-southeast-1 Region. The management team is looking for a solution that would increase the website's availability.\\nWhich activities should a solutions architect perform in conjunction to enhance availability? (Select two.)\\n\\nA.Add both buckets to the CloudFront origin.\\nB. Configure failover routing in Amazon Route 53.\\nC. Create a record in Amazon Route 53 pointing to the replica bucket.\\nD. Create an additional CloudFront origin pointing to the ap-southeast-1 bucket.\\nE. Set up a CloudFront origin group with the us-east-1 bucket as the primary and the ap-southeast-1 bucket as the secondary.\", \"D, E\"],\n[\"한 기업이 온프레미스 데이터 센터에서 Amazon Web Services 클라우드로 2계층 애플리케이션을 이전했습니다. 데이터 계층은 12' Amazon Elastic Block Store(Amazon EBS) 범용 SSD 스토리지가 있는 Oracle용 다중 AZ Amazon RDS 구성입니다. 이 프로그램은 문서를 데이터베이스에서 평균 문서 크기가 6MB인 바이너리 빅 객체(BLOB)로 처리하고 저장하기 위한 것입니다.\\n데이터베이스는 시간이 지남에 따라 크기가 증가하여 성능이 저하되고 스토리지 비용이 증가합니다. 조직은 데이터베이스 성능을 높이고 가용성이 높고 강력한 솔루션이 필요합니다.\\n이러한 요구 사항을 충족하는 데 가장 비용 효율적인 접근 방식은 무엇입니까?\\n\\nA.RDS DB 인스턴스 크기를 줄입니다. 스토리지 용량을 24TiB로 늘립니다. 저장 유형을 마그네틱으로 변경합니다.\\nB. RDS DB 인스턴스 크기를 늘립니다. 스토리지 용량을 24TiB로 늘립니다. 스토리지 유형을 프로비저닝된 IOPS로 변경합니다.\\nC. Amazon S3 버킷을 생성합니다. S3 버킷에 문서를 저장하도록 애플리케이션을 업데이트합니다. 기존 데이터베이스에 개체 메타데이터를 저장합니다.\\nD. Amazon DynamoDB 테이블을 생성합니다. DynamoDB를 사용하도록 애플리케이션을 업데이트합니다. AWS Database Migration Service(AWS DMS)를 사용하여 Oracle 데이터베이스에서 DynamoDB로 데이터를 마이그레이션합니다.\", \"A business transferred a two-tier application from its on-premises data center to the Amazon Web Services Cloud. The data layer is a multi-AZ Amazon RDS for Oracle configuration with 12' of Amazon Elastic Block Store (Amazon EBS) general purpose SSD storage. The program is intended to process and store documents as binary big objects (blobs) with an average document size of 6 MB in the database.\\nThe database has increased in size over time, lowering performance and increasing storage costs. The organization wants to boost database performance and need a highly available and robust solution.\\nWhich approach will be the most cost-effective in meeting these requirements?\\n\\nA.Reduce the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Magnetic.\\nB. Increase the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Provisioned IOPS.\\nC. Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database.\\nD. Create an Amazon DynamoDB table. Update the application to use DynamoDB. Use AWS Database Migration Service (AWS DMS) to migrate data from the Oracle database to DynamoDB.\", \"C\"],\n[\"Amazon EC2 인스턴스에서 호스팅되는 비즈니스 웹 사이트는 Amazon S3에 저장된 분류된 데이터를 처리합니다. 조직은 보안 문제로 인해 EC2 리소스와 Amazon S3 간의 안전한 비공개 연결을 원합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.VPC 엔드포인트에서 액세스를 허용하도록 S3 버킷 정책을 설정합니다.\\nB. S3 버킷에 대한 읽기-쓰기 액세스 권한을 부여하도록 IAM 정책을 설정합니다.\\nC. NAT 게이트웨이를 설정하여 프라이빗 서브넷 외부의 리소스에 액세스합니다.\\nD. S3 버킷에 액세스하기 위한 액세스 키 ID와 보안 액세스 키를 설정합니다.\", \"The website of a business that is hosted on Amazon EC2 instances handles classified data that is stored in Amazon S3. The organization wants a private and secure connection between its EC2 resources and Amazon S3 due to security concerns.\\nWhich solution satisfies these criteria?\\n\\nA.Set up S3 bucket policies to allow access from a VPC endpoint.\\nB. Set up an IAM policy to grant read-write access to the S3 bucket.\\nC. Set up a NAT gateway to access resources outside the private subnet.\\nD. Set up an access key ID and a secret access key to access the S3 bucket.\", \"A\"],\n[\"비즈니스가 방금 전 세계적으로 확장되었으며 새로운 시장의 소비자가 해당 응용 프로그램을 사용할 수 있도록 하려고 합니다. 애플리케이션은 Application Load Balancer 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에 배포됩니다. 회사는 한 지역의 리소스에서 다른 지역으로 트래픽을 리디렉션할 수 있는 능력이 필요합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon Route 53 지연 시간 라우팅 정책을 구성합니다.\\nB. Amazon Route 53 지리적 위치 라우팅 정책을 구성합니다.\\nC. Amazon Route 53 지리 근접 라우팅 정책을 구성합니다.\\nD. Amazon Route 53 다중값 응답 라우팅 정책을 구성합니다.\", \"A business has just expanded worldwide and want to make its application available to consumers in those new markets. The application is deployed on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer. The firm need the capacity to redirect traffic from one region's resources to another.\\nWhat recommendations should a solutions architect make?\\n\\nA.Configure an Amazon Route 53 latency routing policy.\\nB. Configure an Amazon Route 53 geolocation routing policy.\\nC. Configure an Amazon Route 53 geoproximity routing policy.\\nD. Configure an Amazon Route 53 multivalue answer routing policy.\", \"C. 지리적 위치 라우팅 정책 – 사용자 위치를 기반으로 트래픽을 라우팅하려는 경우 사용합니다. 지리 근접 라우팅 정책 – 리소스 위치를 기반으로 트래픽을 라우팅하고 선택적으로 한 위치의 리소스에서 다른 위치의 리소스로 트래픽을 이동하려는 경우 사용합니다. \"],\n[\"기업은 애플리케이션에서 생성되는 방대한 양의 스트리밍 데이터를 소비하고 관리해야 합니다. 애플리케이션은 Amazon EC2 인스턴스에 배포되고 기본 파라미터로 설정된 Amazon Kinesis Data Streams와 통신합니다. 애플리케이션은 비즈니스 인텔리전스(BI) 분석을 위해 격일로 Amazon S3 버킷에 데이터를 사용하고 게시합니다. 비즈니스는 Amazon S3가 애플리케이션에서 Kinesis Data Streams로 전송한 모든 데이터를 가져오지 않는다는 점에 주목합니다.\\n솔루션 아키텍트가 이 문제를 해결하기 위해 취해야 할 가장 좋은 조치는 무엇입니까?\\n\\nA.데이터 보존 기간을 수정하여 Kinesis Data Streams 기본 설정을 업데이트합니다.\\nB. Kinesis Producer Library(KPL)를 사용하여 Kinesis Data Streams로 데이터를 전송하도록 애플리케이션을 업데이트합니다.\\nC. Kinesis Data Streams로 전송되는 데이터의 처리량을 처리하도록 Kinesis 샤드 수를 업데이트합니다.\\nD. S3 버킷 내에서 S3 버전 관리를 켜서 S3 버킷에서 수집되는 모든 객체의 모든 버전을 보존합니다.\", \"A business must consume and manage massive volumes of streaming data generated by its application. The application is deployed on Amazon EC2 instances and communicates with Amazon Kinesis Data Streams, which is setup with default parameters. The application consumes and publishes data to an Amazon S3 bucket every other day for business intelligence (BI) analysis. The business notes that Amazon S3 is not getting all of the data sent to Kinesis Data Streams by the application.\\nWhat is the best course of action for a solutions architect to take in order to tackle this issue?\\n\\nA.Update the Kinesis Data Streams default settings by modifying the data retention period.\\nB. Update the application to use the Kinesis Producer Library (KPL) to send the data to Kinesis Data Streams.\\nC. Update the number of Kinesis shards to handle the throughput of the data that is sent to Kinesis Data Streams.\\nD. Turn on S3 Versioning within the S3 bucket to preserve every version of every object that is ingested in the S3 bucket.\", \"A\"],\n[\"한 기업이 보험 견적을 처리할 목적으로 AWS에서 웹 애플리케이션을 개발하고 있습니다. 이 프로그램을 통해 사용자는 견적을 찾을 수 있습니다. 견적은 견적 유형에 따라 분류되어야 하며 24시간 이내에 응답해야 하며 그렇지 않으면 손실될 위험이 있습니다. 솔루션은 구현 및 유지 관리가 간단해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.견적 유형을 기반으로 여러 Amazon Kinesis 데이터 스트림을 생성합니다. 메시지를 적절한 데이터 스트림으로 보내도록 웹 애플리케이션을 구성합니다. Kinesis 클라이언트 라이브러리(KCL)를 사용하여 자체 데이터 스트림에서 메시지를 풀링하도록 애플리케이션 서버의 각 백엔드 그룹을 구성합니다.\\nB. 여러 Amazon Simple Notification Service(Amazon SNS) 주제를 생성하고 견적 유형에 따라 Amazon SQS 대기열을 자체 SNS 주제에 등록합니다. SNS 주제 대기열에 메시지를 게시하도록 웹 애플리케이션을 구성합니다. 자체 SQS 대기열을 작동하도록 각 백엔드 애플리케이션 서버를 구성하십시오.\\nC. 단일 Amazon Simple Notification Service(Amazon SNS) 주제를 생성하고 SNS 주제에 대한 Amazon SQS 대기열을 구독합니다. 견적 유형에 따라 적절한 SQS 대기열에 메시지를 게시하도록 SNS 메시지 필터링을 구성합니다. 자체 SQS 대기열을 작동하도록 각 백엔드 애플리케이션 서버를 구성하십시오.\\nD. 견적 유형에 따라 Amazon Kinesis Data Firehose 전송 스트림을 여러 개 생성하여 Amazon Elasticsearch Service(Amazon ES) 클러스터에 데이터 스트림을 전송합니다. 메시지를 적절한 배달 스트림으로 보내도록 웹 응용 프로그램을 구성합니다. Amazon ES에서 메시지를 검색하고 그에 따라 처리하도록 애플리케이션 서버의 각 백엔드 그룹을 구성합니다.\", \"A business is developing a web application on AWS for the purpose of processing insurance quotations. The program will allow users to seek quotations. Quotes must be classified according to quotation type and must be answered to within 24 hours or risk being lost. The solution should be straightforward to implement and maintain.\\nWhich solution satisfies these criteria?\\n\\nA.Create multiple Amazon Kinesis data streams based on the quote type. Configure the web application to send messages to the proper data stream. Configure each backend group of application servers to pool messages from its own data stream using the Kinesis Client Library (KCL).\\nB. Create multiple Amazon Simple Notification Service (Amazon SNS) topics and register Amazon SQS queues to their own SNS topic based on the quote type. Configure the web application to publish messages to the SNS topic queue. Configure each backend application server to work its own SQS queue.\\nC. Create a single Amazon Simple Notification Service (Amazon SNS) topic and subscribe the Amazon SQS queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to work its own SQS queue.\\nD. Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon Elasticsearch Service (Amazon ES) cluster. Configure the web application to send messages to the proper delivery stream. Configure each backend group of application servers to search for the messages from Amazon ES and process them accordingly.\", \"C\"],\n[\"한 기업이 Amazon EC2 인스턴스의 가상 사설 클라우드에서 작동할 새로운 애플리케이션을 개발 중입니다. 이 프로그램은 Amazon S3에 데이터를 저장하고 Amazon DynamoDB를 사용하여 데이터에 액세스합니다. 회사는 규정 준수 문제로 인해 EC2 인스턴스와 다른 AWS 서비스 간의 통신이 공용 인터넷을 통해 이동하는 것을 금지합니다.\\n솔루션 아키텍트는 이 기준을 충족하기 위해 무엇을 할 수 있습니까?\\n\\nA.Amazon S3 및 DynamoDB에 대한 게이트웨이 VPC 엔드포인트를 구성합니다.\\nB. Amazon S3 및 DynamoDB에 대한 인터페이스 VPC 엔드포인트를 구성합니다.\\nC. Amazon S3에 대한 게이트웨이 VPC 엔드포인트를 구성합니다. DynamoDB에 대한 인터페이스 VPC 엔드포인트를 구성합니다.\\nD. DynamoDB에 대한 게이트웨이 VPC 엔드포인트를 구성합니다. Amazon S3에 대한 인터페이스 VPC 엔드포인트를 구성합니다.\", \"A business is developing a new application that will operate in a virtual private cloud on Amazon EC2 instances. The program stores data in Amazon S3 and accesses it using Amazon DynamoDB. The corporation forbids any communication between EC2 instances and other AWS services from traveling over the public internet for compliance concerns.\\nWhat can a solution architect do to satisfy this criterion?\\n\\nA.Configure gateway VPC endpoints to Amazon S3 and DynamoDB.\\nB. Configure interface VPC endpoints to Amazon S3 and DynamoDB.\\nC. Configure a gateway VPC endpoint to Amazon S3. Configure an interface VPC endpoint to DynamoDB.\\nD. Configure a gateway VPC endpoint to DynamoDB. Configure an interface VPC endpoint to Amazon S3.\", \"A\"],\n[\"비즈니스에서 새 AWS 계정을 만들었습니다. 계정이 새로 설정되었으며 기본 설정이 변경되지 않았습니다. 조직은 AWS 계정 루트 사용자의 보안에 대해 걱정하고 있습니다.\\n루트 사용자를 보호하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.일일 관리 작업을 위한 IAM 사용자를 생성합니다. 루트 사용자를 비활성화합니다.\\nB. 일일 관리 작업을 위한 IAM 사용자를 생성합니다. 루트 사용자에 대해 다단계 인증을 활성화합니다.\\nC. 루트 사용자에 대한 액세스 키를 생성합니다. AWS Management 콘솔 대신 일일 관리 작업에 액세스 키를 사용합니다.\\nD. 최상위 솔루션 설계자에게 루트 사용자 자격 증명을 제공합니다. 솔루션 설계자가 일상적인 관리 작업에 루트 사용자를 사용하도록 합니다.\", \"A business has created a new AWS account. The account is freshly established, and no changes to the default settings have been made. The organization is worried about the AWS account root user's security.\\nWhat measures should be taken to safeguard the root user?\\n\\nA.Create IAM users for daily administrative tasks. Disable the root user.\\nB. Create IAM users for daily administrative tasks. Enable multi-factor authentication on the root user.\\nC. Generate an access key for the root user. Use the access key for daily administration tasks instead of the AWS Management Console.\\nD. Provide the root user credentials to the most senior solutions architect. Have the solutions architect use the root user for daily administration tasks.\", \"B\"],\n[\"조직은 2개의 프라이빗 서브넷에 있는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 솔루션 설계자의 목표는 응용 프로그램을 공용 인터넷을 통해 가능한 한 쉽게 액세스할 수 있도록 하는 것입니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.로드 밸런서를 생성하고 프라이빗 인스턴스와 동일한 가용 영역에서 2개의 퍼블릭 서브넷을 연결합니다. 로드 밸런서에 프라이빗 인스턴스를 추가합니다.\\nB. 로드 밸런서를 생성하고 프라이빗 인스턴스와 동일한 가용 영역에서 2개의 프라이빗 서브넷을 연결합니다. 로드 밸런서에 프라이빗 인스턴스를 추가합니다.\\nC. 프라이빗 서브넷에서 인스턴스의 Amazon 머신 이미지(AMI)를 생성하고 퍼블릭 서브넷에서 복원합니다. 로드 밸런서를 생성하고 퍼블릭 인스턴스와 동일한 가용 영역에서 두 개의 퍼블릭 서브넷을 연결합니다.\\nD. 프라이빗 서브넷에서 인스턴스의 Amazon 머신 이미지(AMI)를 생성하고 퍼블릭 서브넷에서 복원합니다. 로드 밸런서를 생성하고 퍼블릭 인스턴스와 동일한 가용 영역에서 2개의 프라이빗 서브넷을 연결합니다.\", \"An organization hosts an application on Amazon EC2 instances on two private subnets. A solutions architect's goal is to make the application as easily accessible as possible over the public internet.\\nWhat recommendations should the solutions architect make?\\n\\nA.Create a load balancer and associate two public subnets from the same Availability Zones as the private instances. Add the private instances to the load balancer.\\nB. Create a load balancer and associate two private subnets from the same Availability Zones as the private instances. Add the private instances to the load balancer.\\nC. Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two public subnets from the same Availability Zones as the public instances.\\nD. Create an Amazon Machine Image (AMI) of the instances in the private subnet and restore in the public subnet. Create a load balancer and associate two private subnets from the same Availability Zones as the public instances.\", \"A\"],\n[\"기업의 HTTP 애플리케이션은 NLB(Network Load Balancer)로 보호됩니다. NLB의 대상 그룹은 웹 서비스를 실행하는 수많은 EC2 인스턴스가 있는 Amazon EC2 Auto Scaling 그룹을 사용하도록 설정됩니다.\\n회사는 응용 프로그램의 HTTP 오류가 NLB에서 감지되지 않는 것으로 확인합니다. 이러한 문제는 웹 서비스의 EC2 인스턴스를 수동으로 다시 시작해야 합니다. 조직은 맞춤형 스크립트나 코드를 작성하지 않고도 애플리케이션의 가용성을 높일 수 있는 방법이 필요합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.회사 응용 프로그램의 URL을 제공하여 NLB에서 HTTP 상태 확인을 활성화합니다.\\nB. EC2 인스턴스에 cron 작업을 추가하여 1분에 한 번씩 로컬 애플리케이션의 로그를 확인합니다. HTTP 오류가 감지되면 애플리케이션이 다시 시작됩니다.\\nC. NLB를 Application Load Balancer로 교체합니다. 회사 애플리케이션의 URL을 제공하여 HTTP 상태 확인을 활성화합니다. 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 구성합니다.\\nD. NLB에 대한 UnhealthyHostCount 지표를 모니터링하는 Amazon CloudWatch 경보를 생성합니다. 경보가 ALARM 상태일 때 비정상 인스턴스를 교체하도록 Auto Scaling 작업을 구성합니다.\", \"The HTTP application of a business is protected by a Network Load Balancer (NLB). The target group of the NLB is set to use an Amazon EC2 Auto Scaling group with numerous EC2 instances running the web service.\\nThe firm sees that the application's HTTP faults are not being detected by the NLB. These problems need a manual restart of the web service's EC2 instances. The organization need a way to increase the application's availability without having to write bespoke scripts or code.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Enable HTTP health checks on the NLB, supplying the URL of the company's application.\\nB. Add a cron job to the EC2 instances to check the local application's logs once each minute. If HTTP errors are detected, the application will restart.\\nC. Replace the NLB with an Application Load Balancer. Enable HTTP health checks by supplying the URL of the company's application. Configure an Auto Scaling action to replace unhealthy instances.\\nD. Create an Amazon CloudWatch alarm that monitors the UnhealthyHostCount metric for the NLB. Configure an Auto Scaling action to replace unhealthy instances when the alarm is in the ALARM state.\", \"C. NLB도 상태 확인은 L7에서 할 수 있음.\"],\n[\"AWS에서 기업은 다중 계층 웹 애플리케이션을 운영하고 있습니다. 애플리케이션의 데이터베이스 계층은 Amazon Aurora MySQL을 기반으로 합니다. 애플리케이션 및 데이터베이스 계층은 us-east-1 지역에 있습니다. 정기적으로 Aurora DB 클러스터를 확인하는 데이터베이스 관리자는 읽기 트래픽이 간헐적으로 급증하면 읽기 전용 복제본의 CPU 사용량이 높아져 애플리케이션의 읽기 지연 시간이 증가한다는 사실을 알게 됩니다.\\n솔루션 설계자는 애플리케이션의 읽기 확장성을 높이려면 어떻게 해야 합니까?\\n\\nA.Aurora DB 클러스터를 재부팅합니다.\\nB. 교차 리전 읽기 전용 복제본 생성\\nC. 읽기 전용 복제본의 인스턴스 클래스를 늘립니다.\\nD. 읽기 전용 복제본에 대해 Aurora Auto Scaling을 구성합니다.\", \"On AWS, a business is operating a multi-tier web application. The application's database layer is powered by Amazon Aurora MySQL. The application and database layers are located in the region us-east-1. A database administrator who checks the Aurora DB cluster on a regular basis notices that an occasional surge in read traffic results in high CPU use on the read replica, increasing the application's read latency.\\nWhat should a solutions architect do to increase the read scalability of their application?\\n\\nA.Reboot the Aurora DB cluster.\\nB. Create a cross-Region read replica\\nC. Increase the instance class of the read replica.\\nD. Configure Aurora Auto Scaling for the read replica.\", \"D\"],\n[\"한 비즈니스에서 1PB의 온프레미스 이미지 리포지토리를 AWS로 이전하려고 합니다. 사진은 서버리스 웹 애플리케이션에서 활용됩니다. 드물게 사용되지만 즉시 액세스할 수 있어야 합니다. 또한 사진을 저장하는 동안 암호화해야 하며 실수로 삭제되는 것을 방지해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.클라이언트 측 암호화를 구현하고 이미지를 Amazon S3 Glacier 볼트에 저장합니다. 실수로 삭제되지 않도록 볼트 잠금을 설정하십시오.\\nB. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스의 Amazon S3 버킷에 이미지를 저장합니다. S3 버킷에서 버전 관리, 기본 암호화 및 MFA 삭제를 활성화합니다.\\nC. Windows 파일 서버 파일 공유용 Amazon FSx에 이미지를 저장합니다. AWS Key Management Service(AWS KMS) 고객 마스터 키(CMK)를 사용하여 파일 공유의 이미지를 암호화하도록 Amazon FSx 파일 공유를 구성합니다. 실수로 삭제되는 것을 방지하려면 이미지에 NTFS 권한 집합을 사용하십시오.\\nD. Infrequent Access 스토리지 클래스의 Amazon Elastic File System(Amazon EFS) 파일 공유에 이미지를 저장합니다. AWS Key Management Service(AWS KMS) 고객 마스터 키(CMK)를 사용하여 파일 공유의 이미지를 암호화하도록 EFS 파일 공유를 구성합니다. 실수로 삭제되는 것을 방지하려면 이미지에 NFS 권한 집합을 사용하십시오.\", \"A business wishes to relocate its on-premises image repository of 1 PB to AWS. The photos will be utilized by a serverless web application. Although they will be used infrequently, they must be promptly accessible. Additionally, the photos must be encrypted while storage and prevented from being deleted accidentally.\\nWhich solution satisfies these criteria?\\n\\nA.Implement client-side encryption and store the images in an Amazon S3 Glacier vault. Set a vault lock to prevent accidental deletion.\\nB. Store the images in an Amazon S3 bucket in the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Enable versioning, default encryption, and MFA Delete on the S3 bucket.\\nC. Store the images in an Amazon FSx for Windows File Server file share. Configure the Amazon FSx file share to use an AWS Key Management Service (AWS KMS) customer master key (CMK) to encrypt the images in the file share. Use NTFS permission sets on the images to prevent accidental deletion.\\nD. Store the Images in an Amazon Elastic File System (Amazon EFS) file share in the Infrequent Access storage class. Configure the EFS file share to use an AWS Key Management Service (AWS KMS) customer master key (CMK) to encrypt the images in the file share. Use NFS permission sets on the images to prevent accidental deletion.\", \"B\"],\n[\"비즈니스에는 Amazon RDS for MySQL을 데이터베이스로 사용하는 여러 앱이 있습니다. 최근에 조직은 새로운 사용자 지정 보고 응용 프로그램이 데이터베이스의 쿼리 수를 늘렸다는 것을 깨달았습니다. 이로 인해 성능이 저하됩니다.\\n솔루션 설계자는 가능한 가장 적은 수의 애플리케이션 수정으로 이 문제를 어떻게 해결할 수 있습니까?\\n\\nA.다중 AZ를 사용하여 보조 DB 인스턴스를 추가합니다.\\nB. Amazon RDS에서 read replica 및 다중 AZ를 설정합니다.\\nC. Amazon RDS에 대기 복제본 및 다중 AZ를 설정합니다.\\nD. Amazon RDS에서 캐싱을 사용하여 전체 성능을 개선합니다.\", \"A business has a number of apps that make use of Amazon RDS for MySQL as the database. Recently, the organization realized that a new custom reporting application had increased the database's query count. This results in a decrease in performance.\\nHow could a solutions architect address this problem with the fewest number of application modifications possible?\\n\\nA.Add a secondary DB instance using Multi-AZ.\\nB. Set up a read replica and Multi-AZ on Amazon RDS.\\nC. Set up a standby replica and Multi-AZ on Amazon RDS.\\nD. Use caching on Amazon RDS to improve the overall performance.\", \"B\"],\n[\"한 회사가 컨테이너를 활용하여 AWS에서 웹 애플리케이션을 개발하고 있습니다. 어느 순간에 조직은 웹 애플리케이션의 세 가지 인스턴스를 실행해야 합니다. 증가하는 수요를 따라잡으려면 애플리케이션을 확장할 수 있어야 합니다. 경영진은 비용에 민감하지만 애플리케이션에 대한 접근성이 높아야 한다는 데 동의합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Fargate 시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 원하는 개수의 3개 작업으로 ECS 서비스를 생성합니다.\\nB. 하나의 가용 영역에 3개의 컨테이너 인스턴스가 있는 Amazon EC2 시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 각 컨테이너 인스턴스에 대해 하나의 작업을 배치합니다.\\nC. 세 개의 서로 다른 가용 영역에 하나의 컨테이너 인스턴스가 있는 Fargate 시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 원하는 개수의 3개 작업으로 ECS 서비스를 생성합니다.\\nD. 두 개의 서로 다른 가용 영역에 하나의 컨테이너 인스턴스가 있는 Amazon EC2 시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 하나의 컨테이너 인스턴스에 두 개의 작업을 배치하고 나머지 컨테이너 인스턴스에 하나의 작업을 배치합니다.\", \"A firm is developing a web application on AWS utilizing containers. At any one moment, the organization needs three instances of the web application to be running. The application must be scalable in order to keep up with demand increases. While management is cost-conscious, they agree that the application should be highly accessible.\\nWhat recommendations should a solutions architect make?\\n\\nA.Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.\\nB. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with three container instances in one Availability Zone. Create a task definition for the web application. Place one task for each container instance.\\nC. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Fargate launch type with one container instance in three different Availability Zones. Create a task definition for the web application. Create an ECS service with a desired count of three tasks.\\nD. Create an Amazon Elastic Container Service (Amazon ECS) cluster using the Amazon EC2 launch type with one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance and one task on the remaining container instance.\", \"A\"],\n[\"기업은 온프레미스 데이터베이스 서버를 위한 복원력 있는 백업 스토리지 솔루션이 필요하며, 신속한 복구를 위해 온프레미스 앱이 이러한 백업에 액세스할 수 있도록 보장해야 합니다. 회사는 이러한 백업을 AWS 스토리지 서비스에 저장합니다. 솔루션 설계자는 가능한 최소한의 운영 오버헤드로 솔루션을 개발할 책임이 있습니다.\\n솔루션 아키텍트가 구현해야 하는 솔루션은 무엇입니까?\\n\\nA.AWS Storage Gateway 파일 게이트웨이를 온프레미스에 배포하고 Amazon S3 버킷과 연결합니다.\\nB. 데이터베이스를 AWS Storage Gateway 볼륨 게이트웨이에 백업하고 Amazon S3 API를 사용하여 액세스합니다.\\nC. 데이터베이스 백업 파일을 Amazon EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 전송합니다.\\nD. 데이터베이스를 AWS Snowball 디바이스에 직접 백업하고 수명 주기 규칙을 사용하여 데이터를 Amazon S3 Glacier Deep Archive로 이동합니다.\", \"A business needs a resilient backup storage solution for its on-premises database servers, while also guaranteeing that on-premises apps have access to these backups for rapid recovery. The corporation will store these backups on AWS storage services. A solutions architect is responsible for developing a solution with the least amount of operational overhead possible.\\nWhich solution should be implemented by the solutions architect?\\n\\nA.Deploy an AWS Storage Gateway file gateway on-premises and associate it with an Amazon S3 bucket.\\nB. Back up the databases to an AWS Storage Gateway volume gateway and access it using the Amazon S3 API.\\nC. Transfer the database backup files to an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance.\\nD. Back up the database directly to an AWS Snowball device and use lifecycle rules to move the data to Amazon S3 Glacier Deep Archive.\", \"A\"],\n[\"AWS Organizations를 사용하면 기업에서 다양한 부서의 많은 AWS 계정을 관리할 수 있습니다. 관리 계정에는 프로젝트 보고서가 저장되는 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 대한 액세스를 AWS Organizations 계정이 있는 사람들로 제한하려고 합니다.\\nFEASTEST 운영 오버헤드로 이러한 기준을 충족하는 방법은 무엇입니까?\\n\\nA.S3 버킷 정책에 조직 ID에 대한 참조와 함께 aws:PrincipalOrgID 전역 조건 키를 추가합니다.\\nB. 각 부서에 대한 조직 단위(OU)를 만듭니다. aws:PrincipalOrgPaths 전역 조건 키를 S3 버킷 정책에 추가합니다.\\nC. AWS CloudTrail을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. 그에 따라 S3 버킷 정책을 업데이트합니다.\\nD. S3 버킷에 액세스해야 하는 각 사용자에 태그를 지정합니다. aws:PrincipalTag 전역 조건 키를 S3 버킷 정책에 추가합니다.\", \"AWS Organizations enables a business to manage many AWS accounts for various departments. The management account has an Amazon S3 bucket where project reports are stored. The corporation wishes to restrict access to this S3 bucket to people with AWS Organizations accounts.\\nWhich method satisfies these criteria with the FEASTEST operational overhead?\\n\\nA.Add the aws:PrincipalOrgID global condition key with a reference to the organization ID to the S3 bucket policy.\\nB. Create an organizational unit (OU) for each department. Add the aws:PrincipalOrgPaths global condition key to the S3 bucket policy.\\nC. Use AWS CloudTrail to monitor the CreateAccount, InviteAccountToOrganization, LeaveOrganization, and RemoveAccountFromOrganization events. Update the S3 bucket policy accordingly.\\nD. Tag each user that needs access to the S3 bucket. Add the aws:PrincipalTag global condition key to the S3 bucket policy.\", \"A\"],\n[\"기업은 Amazon S3를 활용하여 민감한 사용자 데이터를 저장하려고 합니다. 내부 보안 규정 준수 요구 사항에 따라 데이터를 Amazon S3로 보내기 전에 암호화해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.고객이 제공한 암호화 키를 사용한 서버 측 암호화\\nB. Amazon S3 관리형 암호화 키를 사용한 클라이언트 측 암호화\\nC. AWS key Management Service(AWS KMS)에 저장된 키를 사용한 서버 측 암호화\\nD. AWS Key Management Service(AWS KMS)에 저장된 마스터 키로 클라이언트 측 암호화\", \"A business intends to utilize Amazon S3 to store sensitive user data. Internal security compliance requirements demand that data be encrypted prior to being sent to Amazon S3.\\nWhat recommendations should a solutions architect make to meet these requirements?\\n\\nA.Server-side encryption with customer-provided encryption keys\\nB. Client-side encryption with Amazon S3 managed encryption keys\\nC. Server-side encryption with keys stored in AWS key Management Service (AWS KMS)\\nD. Client-side encryption with a master key stored in AWS Key Management Service (AWS KMS)\", \"D\"],\n[\"기업은 인공 지능 및 기계 학습(AI/ML) 연구를 수행하는 고객에게 데이터 세트를 제공합니다. 데이터 세트는 us-east-1 리전의 Amazon S3 버킷에서 호스팅되는 형식이 지정된 거대한 파일입니다. 기업은 소비자가 특정 데이터 세트에 대한 액세스 권한을 구매할 수 있는 웹 애플리케이션을 실행합니다. 여러 Amazon EC2 인스턴스를 사용하여 웹 애플리케이션을 호스팅한 다음 Application Load Balancer를 통해 라우팅합니다. 구매 후 구매자는 파일에 대한 액세스 권한을 부여하는 S3 서명 URL을 받습니다.\\n고객은 북미와 유럽 전역에 있습니다. 조직은 성능을 유지하거나 개선하면서 데이터 전송 비용을 낮추기를 원합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.기존 S3 버킷에서 S3 Transfer Acceleration을 구성합니다. 고객 요청을 S3 Transfer Acceleration 엔드포인트로 안내합니다. 액세스 제어를 위해 S3 서명 URL을 계속 사용합니다.\\nB. 기존 S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 배포합니다. 고객 요청을 CloudFront URL로 안내합니다. 액세스 제어를 위해 CloudFront 서명된 URL로 전환합니다.\\nC. 버킷 ​​간 S3 교차 리전 복제를 사용하여 eu-central-1 리전에 두 번째 S3 버킷을 설정합니다. 가장 가까운 지역으로 고객 요청을 안내합니다. 액세스 제어를 위해 S3 서명 URL을 계속 사용합니다.\\nD. 최종 사용자에게 데이터 세트를 스트리밍할 수 있도록 웹 애플리케이션을 수정합니다. 기존 S3 버킷에서 데이터를 읽도록 웹 애플리케이션을 구성합니다. 애플리케이션에서 직접 액세스 제어를 구현합니다.\", \"A business offers datasets to clients doing artificial intelligence and machine learning (AI/ML) research. The datasets are huge, formatted files that are hosted in a bucket on Amazon S3 in the us-east-1 Region. The business runs a web application via which consumers may buy access to a certain dataset. Multiple Amazon EC2 instances are used to host the web application, which is then routed via an Application Load Balancer. Following a purchase, buyers get an S3-signed URL granting access to the files.\\nCustomers are located across North America and Europe. The organization wishes to lower the cost of data transfers while maintaining or improving performance.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Configure S3 Transfer Acceleration on the existing S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint. Continue to use S3 signed URLs for access control.\\nB. Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin. Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control.\\nC. Set up a second S3 bucket in the eu-central-1 Region with S3 Cross-Region Replication between the buckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control.\\nD. Modify the web application to enable streaming of the datasets to end users. Configure the web application to read the data from the existing S3 bucket. Implement access control directly in the application.\", \"B. 그러나 CloudFront는 30GB까지만 지원하므로, 데이터 세트가 방대하다면 비용이 더 들더라도 A\"],\n[\"솔루션 설계자는 대용량 전자 상거래 온라인 애플리케이션을 위한 데이터베이스 솔루션 설계를 담당합니다. 고객 프로필 및 장바구니 정보는 데이터베이스에 저장됩니다. 데이터베이스는 최고 수준에서 초당 수백만 개의 쿼리를 처리하고 밀리초 단위로 응답할 수 있어야 합니다. 데이터베이스 노후화 및 확장성과 관련된 운영 오버헤드는 최소로 유지되어야 합니다.\\n솔루션 아키텍트가 추천해야 하는 데이터베이스 솔루션은 무엇입니까?\\n\\nA.아마존 오로라\\nB. Amazon DynamoDB\\nC. 아마존 RDS\\nD. 아마존 레드시프트\", \"A solutions architect is tasked with the responsibility of designing a database solution for a high-volume ecommerce online application. Customer profiles and shopping cart information are stored in the database. The database must be able to handle several million queries per second at its peak and respond in milliseconds. The operational overhead associated with database aging and scalability must be kept to a minimum.\\nWhich database solution should be recommended by the solutions architect?\\n\\nA.Amazon Aurora\\nB. Amazon DynamoDB\\nC. Amazon RDS\\nD. Amazon Redshift\", \"B\"],\n[\"보안 문제를 위해 기업에는 프라이빗 서브넷에 구성된 많은 Amazon EC2 인스턴스가 있습니다. 이러한 인스턴스는 Amazon S3에서 대량의 데이터를 자주 읽고 쓰는 애플리케이션을 실행하는 데 사용됩니다. 현재 서브넷 라우팅은 NAT 게이트웨이를 통해 모든 트래픽을 인터넷으로 라우팅합니다. 조직은 Amazon S3 또는 공용 인터넷과 인터페이스할 수 있는 애플리케이션의 용량을 유지하면서 전체 비용을 줄이기를 원합니다.\\n솔루션 설계자는 비용을 절감하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.추가 NAT 게이트웨이를 생성합니다. NAT 게이트웨이로 라우팅하도록 라우팅 테이블을 업데이트합니다. S3 트래픽을 허용하도록 네트워크 ACL을 업데이트합니다.\\nB. 인터넷 게이트웨이를 생성합니다. 인터넷 게이트웨이로 트래픽을 라우팅하도록 라우팅 테이블을 업데이트합니다. S3 트래픽을 허용하도록 네트워크 ACL을 업데이트합니다.\\nC. Amazon S3용 VPC 엔드포인트를 생성합니다. 끝점 정책을 끝점에 연결합니다. 트래픽을 VPC 엔드포인트로 보내도록 라우팅 테이블을 업데이트합니다.\\nD. VPC 외부에서 AWS Lambda 함수를 생성하여 S3 요청을 처리합니다. IAM 정책을 EC2 인스턴스에 연결하여 Lambda 함수를 호출할 수 있도록 합니다.\", \"For security concerns, a business has many Amazon EC2 instances configured in a private subnet. These instances are used to run applications that frequently read and write huge volumes of data to and from Amazon S3. At the moment, subnet routing routes all traffic to the internet via a NAT gateway. The organization wishes to reduce overall costs while maintaining the application's capacity to interface with Amazon S3 or the public internet.\\nWhat actions should a solutions architect do to save costs?\\n\\nA.Create an additional NAT gateway. Update the route table to route to the NAT gateway. Update the network ACL to allow S3 traffic.\\nB. Create an internet gateway. Update the route table to route traffic to the internet gateway. Update the network ACL to allow S3 traffic.\\nC. Create a VPC endpoint for Amazon S3. Attach an endpoint policy to the endpoint. Update the route table to direct traffic to the VPC endpoint.\\nD. Create an AWS Lambda function outside of the VPC to handle S3 requests. Attach an IAM policy to the EC2 instances, allowing them to invoke the Lambda function.\", \"C\"],\n[\"한 비즈니스에서 단일 AWS 리전에 배포할 새 웹 애플리케이션을 개발 중입니다. Amazon EC2 인스턴스와 Amazon RDS 데이터베이스 인스턴스를 사용할 애플리케이션에는 2계층 설계가 필요합니다. 솔루션 설계자는 모든 구성 요소에 쉽게 액세스할 수 있는 방식으로 응용 프로그램의 아키텍처를 계획해야 합니다.\\n이러한 요구 사항을 충족하는 데 가장 비용 효율적인 접근 방식은 무엇입니까?\\n\\nA.추가 리전에 EC2 인스턴스를 배포합니다. 다중 AZ 옵션이 활성화된 DB 인스턴스를 생성합니다.\\nB. 동일한 리전 및 동일한 가용 영역에 모든 EC2 인스턴스를 배포합니다. 다중 AZ 옵션이 활성화된 DB 인스턴스를 생성합니다.\\nC. 동일한 리전 내의 2개 이상의 가용 영역에 EC2 인스턴스를 배포합니다. 단일 가용 영역에 DB 인스턴스를 생성합니다.\\nD. 동일한 리전 내의 2개 이상의 가용 영역에 EC2 인스턴스를 배포합니다. 다중 AZ 옵션이 활성화된 DB 인스턴스를 생성합니다.\", \"A business is developing a new web application that will be deployed in a single AWS Region. A two-tier design is required for the application, which will use Amazon EC2 instances and an Amazon RDS database instance. A solutions architect must plan the application's architecture in such a way that all components are highly accessible.\\nWhich approach will be the most cost-effective in meeting these requirements?\\n\\nA.Deploy EC2 instances in an additional Region. Create a DB instance with the Multi-AZ option activated.\\nB. Deploy all EC2 instances in the same Region and the same Availability Zone. Create a DB instance with the Multi-AZ option activated.\\nC. Deploy EC2 instances across at least two Availability Zones within the same Region. Create a DB instance in a single Availability Zone.\\nD. Deploy EC2 instances across at least two Availability Zones within the same Region. Create a DB instance with the Multi-AZ option activated.\", \"D\"],\n[\"한 기업이 Amazon EC 인스턴스에서 실행되고 다음 기능을 수행하는 맞춤형 애플리케이션을 개발했습니다.\\nג€¢ Amazon S3에서 많은 양의 데이터 읽기\\nג€¢ 다단계 분석 수행\\nג€¢ 결과를 Amazon DynamoDB에 기록\\n다단계 분석 중에 프로그램은 엄청난 수의 큰 임시 파일을 생성합니다. 프로시저의 성능은 임시 저장소의 성능에 따라 다릅니다.\\n임시 파일을 저장하는 가장 빠른 방법은 무엇입니까?\\n\\nA.스토리지용 Transfer Acceleration이 포함된 여러 Amazon S3 버킷.\\nB. 프로비저닝된 IOPS 및 EBS 최적화 기능이 있는 여러 Amazon Elastic Block Store(Amazon EBS) 드라이브.\\nC. 네트워크 파일 시스템 버전 4.1(NFSv4.1) 프로토콜을 사용하는 여러 Amazon Elastic File System(Amazon EFS) 볼륨.\\nD. 소프트웨어 RAID 0이 있는 여러 인스턴스 저장소 볼륨.\", \"A business has developed a bespoke application that runs on an Amazon EC instance and performs the following functions:\\nג€¢ Reads a large amount of data from Amazon S3\\nג€¢ Performs a multi-stage analysis\\nג€¢ Writes the results to Amazon DynamoDB\\nDuring the multi-stage analysis, the program creates a huge number of big temporary files. The performance of the procedure is dependent on the performance of the temporary storage.\\nWhat would be the quickest method of storing temporary files?\\n\\nA.Multiple Amazon S3 buckets with Transfer Acceleration for storage.\\nB. Multiple Amazon Elastic Block Store (Amazon EBS) drives with Provisioned IOPS and EBS optimization.\\nC. Multiple Amazon Elastic File System (Amazon EFS) volumes using the Network File System version 4.1 (NFSv4.1) protocol.\\nD. Multiple instance store volumes with software RAID 0.\", \"D\"],\n[\"사내 구축형 비즈니스에는 Microsoft Windows 공유 파일 저장소가 필요한 상당한 규모의 Microsoft SharePoint 구현이 있습니다. 조직은 이 워크로드를 AWS 클라우드로 마이그레이션하고 다른 스토리지 솔루션을 평가하는 것을 고려하고 있습니다. 저장소 솔루션은 가용성이 높아야 하며 Active Directory와 결합된 액세스 제어 기능이 있어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon EFS Amazon Elastic File System(Amazon EFS) 스토리지를 구성하고 인증을 위해 Active Directory 도메인을 설정합니다.\\nB. 2개의 가용 영역에 있는 AWS Storage Gateway 파일 게이트웨이에 SMB 파일 공유를 생성합니다.\\nC. Amazon S3 버킷을 생성하고 볼륨으로 탑재하도록 Microsoft Windows Server를 구성합니다.\\nD. AWS에서 Windows 파일 서버용 Amazon FSx 파일 시스템을 생성하고 인증을 위해 Active Directory 도메인을 설정합니다.\", \"On-premises, a business has a sizable Microsoft SharePoint implementation that needs Microsoft Windows shared file storage. The organization is contemplating migrating this workload to AWS Cloud and evaluating other storage solutions. The storage solution must be highly available and have access control coupled with Active Directory.\\nWhich solution will meet these criteria?\\n\\nA.Configure Amazon EFS Amazon Elastic File System (Amazon EFS) storage and set the Active Directory domain for authentication.\\nB. Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones.\\nC. Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume.\\nD. Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication.\", \"D\"],\n[\"회사는 AWS 클라우드를 사용하여 다계층 공개 웹 애플리케이션을 호스팅합니다. Amazon EC2 인스턴스는 웹 애플리케이션을 호스팅하고 Amazon RDS는 데이터베이스를 호스팅합니다. 회사는 다가오는 휴일 주말 동안 매출이 크게 증가할 것으로 예상합니다. 솔루션 설계자는 웹 애플리케이션의 성능을 2분 이하의 단위로 분석하기 위한 솔루션을 제공해야 합니다.\\n이 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon CloudWatch 로그를 Amazon Redshift로 보냅니다. Amazon QuickSight를 사용하여 추가 분석을 수행하십시오.\\nB. 모든 EC2 인스턴스에 대한 세부 모니터링을 활성화합니다. Amazon CloudWatch 지표를 사용하여 추가 분석을 수행합니다.\\nC. Amazon CloudWatch Logs에서 EC2 로그를 가져오는 AWS Lambda 함수를 생성합니다. Amazon CloudWatch 지표를 사용하여 추가 분석을 수행합니다.\\nD. EC2 로그를 Amazon S3로 보냅니다. Amazon Redshift를 사용하여 S3 버킷에서 로그를 가져와 Amazon QuickSight로 추가 분석을 위해 원시 데이터를 처리합니다.\", \"A firm uses the AWS Cloud to host its multi-tiered public web application. Amazon EC2 instances host the web application, while Amazon RDS hosts the database. The firm anticipates a significant boost in revenues during the forthcoming holiday weekend. A solutions architect must provide a solution for analyzing the web application's performance with a granularity of no more than two minutes.\\nWhat actions should the solutions architect do in order to satisfy this requirement?\\n\\nA.Send Amazon CloudWatch logs to Amazon Redshift. Use Amazon QuickSight to perform further analysis.\\nB. Enable detailed monitoring on all EC2 instances. Use Amazon CloudWatch metrics to perform further analysis.\\nC. Create an AWS Lambda function to fetch EC2 logs from Amazon CloudWatch Logs. Use Amazon CloudWatch metrics to perform further analysis.\\nD. Send EC2 logs to Amazon S3. Use Amazon Redshift to fetch logs from the S3 bucket to process raw data for further analysis with Amazon QuickSight.\", \"B. CloudWatch는 5분마다 분석하지만, 세부 모니터링 활성화 시 1분마다 분석 가능.\"],\n[\"기업은 AWS를 사용하여 제품 정보 웹 사이트를 호스팅합니다. 현재 접근 방식은 Application Load Balancer 뒤의 Auto Scaling 그룹에 수많은 Amazon EC2 인스턴스를 배포합니다. 또한 웹 사이트는 특수 DNS 이름을 사용하고 전용 SSL 인증서를 사용하여 HTTPS를 통해서만 상호 작용합니다. 회사는 새로운 제품을 출시하는 과정에 있으며 전 세계의 사람들이 새 웹사이트에서 가능한 최고의 경험을 즐길 수 있도록 하고자 합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon CloudFront를 사용하도록 애플리케이션을 재설계합니다.\\nB. AWS Elastic Beanstalk를 사용하도록 애플리케이션을 재설계합니다.\\nC. Network Load Balancer를 사용하도록 애플리케이션을 재설계합니다.\\nD. Amazon S3 정적 웹 사이트 호스팅을 사용하도록 애플리케이션을 재설계합니다.\", \"A corporation uses AWS to host its product information websites. The present approach deploys numerous Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer. Additionally, the website utilizes a special DNS name and interacts over HTTPS only using a dedicated SSL certificate. The firm is in the process of launching a new product and wants to ensure that people from all over the globe enjoy the greatest experience possible on the new website.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Redesign the application to use Amazon CloudFront.\\nB. Redesign the application to use AWS Elastic Beanstalk.\\nC. Redesign the application to use a Network Load Balancer.\\nD. Redesign the application to use Amazon S3 static website hosting.\", \"A\"],\n[\"비즈니스에 Amazon Elastic File System(Amazon EFS)에 데이터를 저장하는 애플리케이션이 있습니다. 파일 크기는 1GB 이상이며 제작 후 처음 며칠 동안 자주 방문합니다. 애플리케이션 데이터는 Linux 서버 클러스터에 분산됩니다. 회사는 애플리케이션의 스토리지 비용을 낮추기를 원합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.Amazon FSx를 구현하고 각 서버에 네트워크 드라이브를 탑재합니다.\\nB. Amazon Elastic File System(Amazon EFS)에서 파일을 이동하고 각 Amazon EC2 인스턴스에 로컬로 저장합니다.\\nC. 7일 후에 파일을 EFS IA(Infrequent Access) 스토리지 클래스로 이동하도록 수명 주기 정책을 구성합니다.\\nD. S3 수명 주기 정책이 활성화된 Amazon S3로 파일을 이동합니다. S3 버킷 탑재를 지원하도록 애플리케이션을 다시 작성합니다.\", \"A business has an application that stores data in Amazon Elastic File System (Amazon EFS). The files are 1 GB or bigger in size and are often visited during the first several days after production. The data for the application is distributed over a cluster of Linux servers. The corporation wishes to lower the application's storage expenses.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Implement Amazon FSx and mount the network drive on each server.\\nB. Move the files from Amazon Elastic File System (Amazon EFS) and store them locally on each Amazon EC2 instance.\\nC. Configure a Lifecycle policy to move the files to the EFS Infrequent Access (IA) storage class after 7 days.\\nD. Move the files to Amazon S3 with S3 lifecycle policies enabled. Rewrite the application to support mounting the S3 bucket.\", \"C\"],\n[\"최근 한 기업에서 메시지 처리 시스템을 AWS로 이전했습니다. 시스템은 Amazon EC2 인스턴스의 ActiveMQ 대기열로 메시지를 수락합니다. Amazon EC2에서 실행되는 소비자 애플리케이션은 메시지를 처리합니다. 소비자 애플리케이션은 메시지를 처리하고 결과를 Amazon EC2 MySQL 데이터베이스에 씁니다. 조직은 운영 복잡성이 거의 없는 접근성이 높은 애플리케이션을 원합니다.\\n가장 신뢰할 수 있는 아키텍처는 무엇입니까?\\n\\nA.다른 가용 영역에 두 번째 ActiveMQ 서버를 추가합니다. 다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.\\nB. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다. MySQL 데이터베이스를 다른 가용 영역에 복제합니다.\\nC. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다. 다중 AZ가 활성화된 MySQL용 Amazon RDS를 사용합니다.\\nD. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다. 두 가용 영역에 걸쳐 소비자 EC2 인스턴스에 대한 Auto Scaling 그룹을 추가합니다. 다중 AZ가 활성화된 MySQL용 Amazon RDS를 사용합니다.\", \"Recently, a business moved a message processing system to AWS. The system accepts messages into an Amazon EC2 instance's ActiveMQ queue. A consumer application running on Amazon EC2 processes the messages. The consumer application processes the messages and writes the results to an Amazon EC2 MySQL database. The organization wants a highly accessible application with little operational complexity.\\nWhich architecture is the MOST RELIABLE?\\n\\nA.Add a second ActiveMQ server to another Availability Zone. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.\\nB. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone.\\nC. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi-AZ enabled.\\nD. Use Amazon MQ with active/standby brokers configured across two Availability Zones. Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones. Use Amazon RDS for MySQL with Multi-AZ enabled.\", \"D\"],\n[\"최근 한 기업에서 전 세계 사용자 기반에 정보를 제공하기 위해 웹사이트를 만들었습니다. 이 회사는 Amazon CloudFront 및 Amazon EC2 인스턴스를 오리진으로 사용하여 정적 자료를 저장하고 소비자에게 빠르게 전달하고자 합니다.\\n솔루션 설계자는 애플리케이션의 고가용성을 어떻게 극대화해야 합니까?\\n\\nA.CloudFront에 Lambda@Edge 를 사용 합니다.\\nB. CloudFront에 Amazon S3 Transfer Acceleration을 사용합니다.\\nC. 다른 가용 영역에 다른 EC2 인스턴스를 오리진 그룹의 일부로 구성합니다.\\nD. 동일한 가용 영역에서 원본 서버 클러스터의 일부로 다른 EC2 인스턴스를 구성합니다.\", \"Recently, a corporation created its website in order to deliver information to its worldwide user base. The firm wishes to store and speed the delivery of static material to its consumers via the usage of Amazon CloudFront and an Amazon EC2 instance as the origin.\\nHow should a solutions architect maximize an application's high availability?\\n\\nA.Use Lambda@Edge for CloudFront.\\nB. Use Amazon S3 Transfer Acceleration for CloudFront.\\nC. Configure another EC2 instance in a different Availability Zone as part of the origin group.\\nD. Configure another EC2 instance as part of the origin server cluster in the same Availability Zone.\", \"C\"],\n[\"솔루션 설계자는 2계층 온라인 애플리케이션 구축을 담당합니다. 애플리케이션은 퍼블릭 서브넷의 Amazon EC2에서 호스팅되는 프런트 엔드 웹 계층으로 구성됩니다. 데이터베이스 계층은 Amazon EC2의 프라이빗 서브넷에서 작동하는 Microsoft SQL Server 인스턴스로 구성됩니다. 조직은 보안을 매우 중요하게 생각합니다.\\n이 경우 보안 그룹을 어떻게 구성해야 합니까? (2개를 선택하세요.)\\n\\nA.0.0.0.0/0에서 포트 443의 인바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다.\\nB. 0.0.0.0/0에서 포트 443의 아웃바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다.\\nC. 웹 계층의 보안 그룹으로부터 포트 1433의 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다.\\nD. 데이터베이스 계층의 보안 그룹을 구성하여 포트 443 및 1433의 아웃바운드 트래픽을 웹 계층의 보안 그룹으로 보냅니다.\\nE. 웹 계층의 보안 그룹에서 포트 443 및 1433의 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다.\", \"A solutions architect is tasked with the responsibility of building a two-tier online application. The application is composed of a front-end web layer that is hosted on Amazon EC2 on public subnets. The database layer is comprised of Microsoft SQL Server instances operating in a private subnet on Amazon EC2. The organization places a high premium on security.\\nIn this case, how should security groups be configured? (Select two.)\\n\\nA.Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0.\\nB. Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0.\\nC. Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier.\\nD. Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier.\\nE. Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier.\", \"A, C\"],\n[\"AWS 호스팅 애플리케이션에 성능 문제가 있으며 애플리케이션 공급업체는 추가 문제 해결을 위해 로그 파일을 분석하려고 합니다. 로그 파일의 크기는 10GB이며 Amazon S3에서 호스팅됩니다. 짧은 기간 동안 애플리케이션 소유자는 공급업체가 로그 파일에 액세스할 수 있도록 합니다.\\n이를 수행하는 가장 안전한 방법은 무엇입니까?\\n\\nA.S3 객체에 대한 공개 읽기를 활성화하고 공급업체에 대한 링크를 제공합니다.\\nB. 파일을 Amazon WorkDocs에 업로드하고 공개 링크를 공급업체와 공유합니다.\\nC. 미리 서명된 URL을 생성하고 만료되기 전에 공급업체가 로그 파일을 다운로드하도록 합니다.\\nD. 공급업체가 S3 버킷 및 애플리케이션에 대한 액세스 권한을 제공할 IAM 사용자를 생성합니다. 다단계 인증을 시행합니다.\", \"AWS-hosted application is having performance issues, and the application vendor want to analyze the log file in order to troubleshoot further. The log file is 10 GB in size and is hosted on Amazon S3. For a short period, the application owner will make the log file accessible to the vendor.\\nWhat is the MOST SECURE method of doing this?\\n\\nA.Enable public read on the S3 object and provide the link to the vendor.\\nB. Upload the file to Amazon WorkDocs and share the public link with the vendor.\\nC. Generate a presigned URL and have the vendor download the log file before it expires.\\nD. Create an IAM user for the vendor to provide access to the S3 bucket and the application. Enforce multi-factor authentication.\", \"C\"],\n[\"서비스 소비에 대한 승차 공유 회사의 과거 데이터가 구성됩니다. Amazon S3 csv 데이터 파일 데이터 분석가는 이 데이터에 대해 SQL 쿼리를 실행해야 합니다.\\n솔루션 설계자는 쿼리의 비용 효율성을 극대화하는 솔루션을 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon EMR 클러스터를 생성합니다. 데이터를 로드합니다. 쿼리를 수행합니다.\\nB. Amazon Redshift 클러스터를 생성합니다. 데이터를 가져옵니다. 쿼리를 수행합니다.\\nC. Amazon Aurora PostgreSQL DB 클러스터를 생성합니다. 데이터를 가져옵니다. 쿼리를 수행합니다.\\nD. Amazon Athena 데이터베이스를 생성합니다. Amazon S3의 데이터를 연결합니다. 쿼리를 수행합니다.\", \"A ride-hailing company's historical data on service consumption is organized. Amazon S3 csv data files A data analyst must run SQL queries on this data.\\nA solutions architect must offer a solution that maximizes the query's cost-effectiveness.\\nWhich solution satisfies these criteria?\\n\\nA.Create an Amazon EMR cluster. Load the data. Perform the queries.\\nB. Create an Amazon Redshift cluster. Import the data. Perform the queries.\\nC. Create an Amazon Aurora PostgreSQL DB cluster. Import the data. Perform the queries.\\nD. Create an Amazon Athena database. Associate the data in Amazon S3. Perform the queries.\", \"D. Athena는 S3에 저장된 로그 데이터를 분석하는 데 널리 사용\"],\n[\"솔루션 설계자는 애플리케이션을 위한 새로운 Amazon CloudFront 배포를 개발하는 책임을 맡습니다. 사용자가 제공한 특정 정보는 민감한 정보로 간주됩니다. 이 프로그램은 HTTPS를 사용하지만 추가 보호 계층이 필요합니다. 민감한 데이터는 전체 애플리케이션 스택에서 보호되어야 하며 액세스는 특정 앱으로 제한되어야 합니다.\\n솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.CloudFront 서명된 URL 구성\\nB. CloudFront 서명 쿠키를 구성합니다.\\nC. CloudFront 필드 수준 암호화 프로필을 구성합니다.\\nD. CloudFront를 구성하고 오리진 프로토콜 정책 설정을 HTTPS로 설정합니다. 뷰어 프로토콜 Pokey 전용입니다.\", \"A solutions architect is tasked with the responsibility of developing a new Amazon CloudFront distribution for an application. Certain information given by users is considered sensitive. Although the program employs HTTPS, it requires an additional layer of protection. Sensitive data should be safeguarded throughout the whole application stack, and access to it should be limited to specific apps.\\nWhich course of action should be taken by the solutions architect?\\n\\nA.Configure a CloudFront signed URL\\nB. Configure a CloudFront signed cookie.\\nC. Configure a CloudFront field-level encryption profile.\\nD. Configure a CloudFront and set the Origin Protocol Policy setting to HTTPS. Only for the Viewer Protocol Pokey.\", \"C\"],\n[\"웹 애플리케이션은 Application Load Balancer를 통해 라우팅되는 Amazon EC2 인스턴스에서 호스팅됩니다. 사용자는 과거 날씨 데이터를 사용하여 맞춤형 보고서를 작성할 수 있습니다. 보고서를 생성하는 데 최대 5분이 소요될 수 있습니다. 이러한 긴 쿼리는 시스템에서 사용 가능한 수신 연결의 상당 부분을 사용하여 시스템을 다른 사용자가 사용할 수 없도록 만듭니다.\\n솔루션 설계자는 시스템의 응답성을 어떻게 높일 수 있습니까?\\n\\nA.Amazon SQS를 AWS Lambda와 함께 사용하여 보고서를 생성합니다.\\nB. Application Load Balancer의 유휴 시간 제한을 5분으로 늘립니다.\\nC. 요청 제한 시간을 5분으로 늘리기 위해 클라이언트 측 애플리케이션 코드를 업데이트합니다.\\nD. 보고서를 Amazon S3에 게시하고 Amazon CloudFront를 사용하여 사용자에게 다운로드합니다.\", \"A web application is hosted on Amazon EC2 instances, which are routed through an Application Load Balancer. Users may construct bespoke reports using historical weather data. A report may take up to five minutes to generate. These lengthy queries use a significant portion of the system's available incoming connections, rendering the system unusable to other users.\\nHow can a solutions architect increase the responsiveness of a system?\\n\\nA.Use Amazon SQS with AWS Lambda to generate reports.\\nB. Increase the idle timeout on the Application Load Balancer to 5 minutes.\\nC. Update the client-side application code to increase its request timeout to 5 minutes.\\nD. Publish the reports to Amazon S3 and use Amazon CloudFront for downloading to the user.\", \"A\"],\n[\"비즈니스에서 현재 온프레미스에 정적 웹 사이트를 유지 관리하고 있으며 이를 AWS로 이전하려고 합니다. 전 세계 방문자의 경우 웹 사이트가 가능한 한 빨리 로드되어야 합니다. 또한 비즈니스는 가장 비용 효율적인 옵션을 찾습니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.웹사이트 콘텐츠를 Amazon S3 버킷에 복사합니다. 정적 웹 페이지 콘텐츠를 제공하도록 버킷을 구성합니다. S3 버킷을 여러 AWS 리전에 복제합니다.\\nB. 웹사이트 콘텐츠를 Amazon S3 버킷에 복사합니다. 정적 웹 페이지 콘텐츠를 제공하도록 버킷을 구성합니다. S3 버킷을 오리진으로 사용하여 Amazon CloudFront를 구성합니다.\\nC. 웹 사이트 콘텐츠를 Apache HTTP Server를 실행하는 Amazon EBS 지원 Amazon EC2 인스턴스에 복사합니다. 가장 가까운 오리진을 선택하도록 Amazon Route 53 지리적 위치 라우팅 정책을 구성합니다.\\nD. 여러 AWS 리전에서 Apache HTTP Server를 실행하는 여러 Amazon EBS 지원 Amazon EC2 인스턴스에 웹 사이트 콘텐츠를 복사합니다. 가장 가까운 오리진을 선택하도록 Amazon CloudFront 지리적 위치 라우팅 정책을 구성합니다.\", \"A business currently maintains a static website on-premises and want to transfer it to AWS. For visitors worldwide, the website should load as rapidly as possible. Additionally, the business seeks the most cost-effective option.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions.\\nB. Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin.\\nC. Copy the website content to an Amazon EBS-backed Amazon EC2 instance running Apache HTTP Server. Configure Amazon Route 53 geolocation routing policies to select the closest origin.\\nD. Copy the website content to multiple Amazon EBS-backed Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions. Configure Amazon CloudFront geolocation routing policies to select the closest origin.\", \"B\"],\n[\"한 기업에서 보안 문제에 대해 연결된 수백만 대의 장치를 분석하고 결과를 Amazon S3 버킷에 기록하는 애플리케이션을 개발했습니다. 조직은 매주 약 70GB의 데이터를 생성하고 기업은 기록 보고를 위해 3년 동안의 데이터를 보관해야 합니다. 조직은 복잡한 분석 쿼리 및 조인을 수행하여 가능한 최단 시간에 Amazon S3의 데이터를 분석, 집계 및 향상해야 합니다. Amazon QuickSight 대시보드에 집계된 데이터 세트가 표시됩니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.AWS Glue에서 ETL 작업을 생성하고 실행하여 Amazon S3의 데이터를 처리하고 Amazon Redshift로 로드합니다. Amazon Redshift에서 집계 쿼리를 수행합니다.\\nB. S3 PutObject 이벤트 트리거를 기반으로 하는 AWS Lambda 함수를 사용하여 증분 변경 사항을 Amazon DynamoDB에 복사합니다. DynamoDB에서 집계 쿼리를 수행합니다.\\nC. S3 PutObject 이벤트 트리거를 기반으로 하는 AWS Lambda 함수를 사용하여 증분 변경 사항을 Amazon Aurora MySQL에 복사합니다. Aurora MySQL에서 집계 쿼리를 수행합니다.\\nD. AWS Glue를 사용하여 Amazon S3의 데이터를 카탈로그화합니다. Amazon Athena를 사용하여 카탈로그된 테이블에서 집계 쿼리를 수행합니다. Amazon S3에서 직접 데이터를 쿼리합니다.\", \"A business has developed an application that analyzes millions of connected devices for security concerns and records the results to an Amazon S3 bucket. Each week, the organization generates around 70 GB of data, and the corporation must retain three years of data for historical reporting. The organization must analyze, aggregate, and enhance data from Amazon S3 in the shortest period of time possible by conducting complicated analytical queries and joins. On an Amazon QuickSight dashboard, the aggregated dataset is shown.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Create and run an ETL job in AWS Glue to process the data from Amazon S3 and load it into Amazon Redshift. Perform the aggregation queries on Amazon Redshift.\\nB. Use AWS Lambda functions based on S3 PutObject event triggers to copy the incremental changes to Amazon DynamoDB. Perform the aggregation queries on DynamoDB.\\nC. Use AWS Lambda functions based on S3 PutObject event triggers to copy the incremental changes to Amazon Aurora MySQL. Perform the aggregation queries on Aurora MySQL.\\nD. Use AWS Glue to catalog the data in Amazon S3. Perform the aggregation queries on the cataloged tables by using Amazon Athena. Query the data directly from Amazon S3.\", \"A. Redshift는 TB이상의 복잡한 쿼리에 사용. Athena는 간단한 쿼리에 사용.\"],\n[\"한 회사는 eu-east-1 지역 내 3개의 고유한 가상 사설 클라우드(VPC)에서 많은 비즈니스 앱을 실행합니다. 애플리케이션은 VPC에서 서로 상호 작용할 수 있어야 합니다. 또한 앱은 단일 온프레미스 데이터 센터에서 실행되는 지연 시간에 민감한 애플리케이션에 매일 수백 테라바이트의 데이터를 보낼 수 있어야 합니다.\\n솔루션 설계자의 주요 책임은 가능한 비용 효율적인 네트워크 연결 솔루션을 구축하는 것입니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.데이터 센터에서 AWS로 3개의 AWS Site-to-Site VPN 연결을 구성합니다. 각 VPC에 대해 하나의 VPN 연결을 구성하여 연결을 설정합니다.\\nB. 각 VPC에서 타사 가상 네트워크 어플라이언스를 시작합니다. 데이터 센터와 각 가상 어플라이언스 간에 IPsec VPN 터널을 설정합니다.\\nC. 데이터 센터에서 us-east-1의 Direct Connect 게이트웨이로 3개의 AWS Direct Connect 연결을 설정합니다. Direct Connect 연결 중 하나를 사용하도록 각 VPC를 구성하여 연결을 설정합니다.\\nD. 데이터 센터에서 AWS로 하나의 AWS Direct Connect 연결을 설정합니다. 전송 게이트웨이를 생성하고 각 VPC를 전송 게이트웨이에 연결합니다. Direct Connect 연결과 전송 게이트웨이 간의 연결을 설정합니다.\", \"A firm runs many business apps in three distinct virtual private clouds (VPCs) inside the eu-east-1 Region. Applications must be able to interact with one another across VPCs. Additionally, the apps must be capable of sending hundreds of terabytes of data daily to a latency-sensitive application running in a single on-premises data center.\\nA solutions architect's primary responsibility is to build a network connection solution that is as cost-effective as possible.\\nWhich solution satisfies these criteria?\\n\\nA.Configure three AWS Site-to-Site VPN connections from the data center to AWS. Establish connectivity by configuring one VPN connection for each VPC.\\nB. Launch a third-party virtual network appliance in each VPC. Establish an IPsec VPN tunnel between the data center and each virtual appliance.\\nC. Set up three AWS Direct Connect connections from the data center to a Direct Connect gateway in us-east-1. Establish connectivity by configuring each VPC to use one of the Direct Connect connections.\\nD. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.\", \"D\"],\n[\"매일 12:00에 웹 사이트는 트래픽이 급증하는 웹 애플리케이션을 호스팅합니다. 사람들은 매일 새로운 이미지와 자료를 제출하지만 시간 초과에 대해 불평했습니다. 설계는 Amazon EC2 Auto Scaling 그룹을 활용하며 사용자 지정 애플리케이션은 사용자 쿼리에 응답하기 전에 시작하는 데 평균 1분이 걸립니다.\\n솔루션 설계자는 변화하는 트래픽 패턴에 적응하기 위해 아키텍처를 어떻게 재구성해야 합니까?\\n\\nA.느린 시작 구성으로 Network Load Balancer를 구성합니다.\\nB. 직접 요청을 서버로 오프로드하도록 Redis용 AWS ElastiCache를 구성합니다.\\nC. 인스턴스 준비 조건으로 Auto Scaling 단계 조정 정책을 구성합니다.\\nD. Application Load Balancer를 오리진으로 사용하도록 Amazon CloudFront를 구성합니다.\", \"Each day at 12:00, a website hosts a web application that gets a spike of traffic. Daily, people submit fresh images and material, but have complained about timeouts. The design makes advantage of Amazon EC2 Auto Scaling groups, and the custom application takes an average of one minute to start up before responding to user queries.\\nHow should a solutions architect reimagine the architecture in order to adapt to shifting traffic patterns?\\n\\nA.Configure a Network Load Balancer with a slow start configuration.\\nB. Configure AWS ElastiCache for Redis to offload direct requests to the servers.\\nC. Configure an Auto Scaling step scaling policy with an instance warmup condition.\\nD. Configure Amazon CloudFront to use an Application Load Balancer as the origin.\", \"C\"],\n[\"한 기업에서 Amazon EC2 인스턴스 운영 체제 버전, 패치 적용 및 설치된 애플리케이션에 대한 정보를 통합하기 위해 새로운 감사 시스템을 구현했습니다. 솔루션 설계자는 EC2 Auto Scaling 그룹을 통해 프로비저닝된 모든 인스턴스가 시작 및 종료 시 감사 보고서를 감사 시스템에 올바르게 전달하도록 보장해야 합니다.\\n어떤 방법이 이러한 목표를 가장 효과적으로 달성합니까?\\n\\nA.예약된 AWS Lambda 함수를 사용하고 모든 EC2 인스턴스에서 원격으로 스크립트를 실행하여 데이터를 감사 시스템으로 보냅니다.\\nB. EC2 Auto Scaling 수명 주기 후크를 사용하여 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 보내는 사용자 지정 스크립트를 실행합니다.\\nC. EC2 Auto Scaling 시작 구성을 사용하여 사용자 데이터를 통해 사용자 지정 스크립트를 실행하여 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 보냅니다.\\nD. 인스턴스 운영 체제에서 사용자 정의 스크립트를 실행하여 감사 시스템에 데이터를 보냅니다. 인스턴스 시작 및 종료 시 EC2 Auto Scaling 그룹에서 실행할 스크립트를 구성합니다.\", \"A corporation has implemented a new auditing system to consolidate information about Amazon EC2 instance operating system versions, patching, and installed applications. A solutions architect must guarantee that all instances provisioned through EC2 Auto Scaling groups correctly deliver audit reports to the auditing system at startup and shutdown.\\nWhich method accomplishes these objectives the MOST EFFECTIVELY?\\n\\nA.Use a scheduled AWS Lambda function and run a script remotely on all EC2 instances to send data to the audit system.\\nB. Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.\\nC. Use an EC2 Auto Scaling launch configuration to run a custom script through user data to send data to the audit system when instances are launched and terminated.\\nD. Run a custom script on the instance operating system to send data to the audit system. Configure the script to be executed by the EC2 Auto Scaling group when the instance starts and is terminated.\", \"B\"],\n[\"솔루션 설계자는 조직의 온프레미스 인프라를 Amazon Web Services로 마이그레이션하기 위한 새로운 하이브리드 아키텍처를 개발하고 있습니다. 조직은 지속적으로 짧은 지연 시간으로 AWS 리전에 대한 액세스 가능성이 높은 연결을 찾고 있습니다. 이 회사는 비용 절감에 관심을 갖고 있으며 주요 연결이 끊어지는 경우 느린 트래픽을 견딜 준비가 되어 있습니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 연결이 실패하는 경우 백업으로 VPN 연결을 프로비저닝합니다.\\nB. 개인 연결을 위해 지역에 VPN 터널 연결을 프로비저닝합니다. 개인 연결을 위해 두 번째 VPN 터널을 프로비저닝하고 기본 VPN 연결이 실패할 경우 백업으로 제공합니다.\\nC. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 연결이 실패하는 경우 백업과 동일한 리전에 두 번째 Direct Connect 연결을 프로비저닝합니다.\\nD. 리전에 대한 AWS Direct Connect 연결을 프로비저닝합니다. AWS CLI에서 Direct Connect 장애 조치 속성을 사용하여 기본 Direct Connect 연결이 실패할 경우 백업 연결을 자동으로 생성합니다.\", \"A solutions architect is developing a new hybrid architecture to migrate an organization's on-premises infrastructure to Amazon Web Services. The organization seeks a highly accessible connection to an AWS Region with constant low latency. The firm is concerned with cost containment and is ready to endure slower traffic in the event that the main connection breaks.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Provision an AWS Direct Connect connection to a Region. Provision a VPN connection as a backup if the primary Direct Connect connection fails.\\nB. Provision a VPN tunnel connection to a Region for private connectivity. Provision a second VPN tunnel for private connectivity and as a backup if the primary VPN connection fails.\\nC. Provision an AWS Direct Connect connection to a Region. Provision a second Direct Connect connection to the same Region as a backup if the primary Direct Connect connection fails.\\nD. Provision an AWS Direct Connect connection to a Region. Use the Direct Connect failover attribute from the AWS CLI to automatically create a backup connection if the primary Direct Connect connection fails.\", \"A\"],\n[\"한 기업이 NoSQL 데이터베이스 클러스터를 Amazon EC2로 이전하고 있습니다. 데이터베이스는 최소 3개의 복사본을 유지하기 위해 데이터를 자동으로 복제합니다. 서버의 I/O 처리량이 가장 중요합니다.\\n솔루션 설계자는 마이그레이션을 위해 어떤 종류의 인스턴스를 제안해야 합니까?\\n\\nA.인스턴스 스토어가 있는 스토리지 최적화 인스턴스\\nB. Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 버스트 가능한 범용 인스턴스\\nC. Amazon Elastic Block Store(Amazon EBS) 최적화가 활성화된 메모리 최적화 인스턴스\\nD. Amazon Elastic Block Store(Amazon EBS) 최적화가 활성화된 컴퓨팅 최적화 인스턴스\", \"A business is transferring a cluster of NoSQL databases to Amazon EC2. The database duplicates data automatically in order to retain at least three copies of it. The servers' I/O throughput is of the utmost importance.\\nWhat sort of instance should a solutions architect propose for the migration?\\n\\nA.Storage optimized instances with instance store\\nB. Burstable general purpose instances with an Amazon Elastic Block Store (Amazon EBS) volume\\nC. Memory optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled\\nD. Compute optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled\", \"A\"],\n[\"미디어 회사는 응용 프로그램을 사용하여 웹 사이트에서 사용자 클릭을 모니터링하고 분석을 수행하여 거의 실시간으로 제안을 제공합니다. 이 프로그램은 웹사이트에서 데이터를 수집하고 이를 Amazon RDS 데이터베이스 인스턴스로 전송하는 Amazon EC2 인스턴스의 힐(Heel of Amazon EC2)로 구현됩니다. 다른 Amazon EC2 인스턴스 집합은 데이터베이스의 변경 사항을 지속적으로 모니터링하고 제안을 생성하기 위해 SQL 쿼리를 수행하는 프로그램을 호스팅합니다. 경영진은 인프라를 분리하기 위해 인프라를 재고하도록 명령했습니다. 솔루션은 데이터 분석가가 데이터 분석 목적으로만 SQL을 작성하도록 보장해야 합니다. 배포 중에 데이터가 손실될 가능성은 없습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon Kinesis Data Streams를 사용하여 웹 사이트 Kinesis Data Firehose에서 데이터를 캡처하여 Amazon S3에 데이터를 유지하고 Amazon Athena를 사용하여 데이터를 쿼리합니다.\\nB. Amazon Kinesis Data Streams를 사용하여 웹 사이트에서 데이터를 캡처합니다. Kinesis Data Analytics는 데이터를 쿼리하고 Kinesis Data Firehose는 Amazon S3에서 데이터를 유지합니다.\\nC. Amazon Simple Queue Service(Amazon SQS)를 사용하여 웹 사이트에서 데이터를 캡처하고, EC2 인스턴스 집합을 유지하고, Auto Scaling 그룹 구성에서 더 큰 인스턴스 유형으로 변경합니다.\\nD. Amazon Simple Notification Service(Amazon SNS)를 사용하여 웹 사이트에서 데이터를 수신하고 쿼리를 실행하고 데이터를 유지하는 AWS Lambda 함수에 메시지를 프록시합니다. 데이터를 유지하려면 Amazon RDS를 Amazon Aurora Serverless로 변경하십시오.\", \"A media firm uses an application to monitor user clicks on its websites and do analytics in order to deliver near-real-time suggestions. The program is implemented as a Heel of Amazon EC2 instances that collect data from websites and transfer it to an Amazon RDS database instance. Another fleet of Amazon EC2 instances hosts the piece of the program that is constantly monitoring the database for changes and performing SQL queries to generate suggestions. Management has ordered a rethink of the infrastructure in order to decouple it. The solution must guarantee that data analysts write SQL only for the purpose of data analysis. There is no possibility of data loss during the deployment.\\nWhat recommendations should a solutions architect make?\\n\\nA.Use Amazon Kinesis Data Streams to capture the data from the websites Kinesis Data Firehose to persist the data on Amazon S3, and Amazon Athena to query the data.\\nB. Use Amazon Kinesis Data Streams to capture the data from the websites. Kinesis Data Analytics to query the data, and Kinesis Data Firehose to persist the data on Amazon S3.\\nC. Use Amazon Simple Queue Service (Amazon SQS) to capture the data from the websites, keep the fleet of EC2 instances, and change to a bigger instance type in the Auto Scaling group configuration.\\nD. Use Amazon Simple Notification Service (Amazon SNS) to receive data from the websites and proxy the messages to AWS Lambda functions that execute the queries and persist the data. Change Amazon RDS to Amazon Aurora Serverless to persist the data.\", \"B. Athena는 배치 분석을 위한 것이며, 거의 실시간 분석을 위해 Kinesis Data Analytics를 활용\"],\n[\"한 비즈니스에서 사용자가 위치에 체크인하고 점수를 매기고 경험에 대한 의견을 제공할 수 있는 응용 프로그램을 개발했습니다. 애플리케이션은 성공적이며 월간 사용자 기반이 빠르게 증가하고 있습니다.\\nCTO는 단일 Amazon RDS for MySQL 인스턴스가 읽기 요청으로 인한 리소스 고갈과 관련된 경고를 생성했기 때문에 현재 인프라를 지원하는 데이터베이스가 다음 달 추가 수요를 관리할 수 없을 것이라고 우려하고 있습니다.\\n솔루션 설계자는 데이터베이스 계층에서 서비스 중단을 피하기 위해 필요한 코드 수정을 최소화하기 위해 무엇을 제안할 수 있습니까?\\n\\nA.RDS 읽기 전용 복제본을 생성하고 읽기 전용 트래픽을 읽기 전용 복제본 엔드포인트로 리디렉션합니다. 다중 AZ 배포를 활성화합니다.\\nB. Amazon EMR 클러스터를 생성하고 복제 계수가 3인 HDFS(Hadoop Distributed File System)로 데이터를 마이그레이션합니다.\\nC. Amazon ElastiCache 클러스터를 생성하고 모든 읽기 전용 트래픽을 클러스터로 리디렉션합니다. 3개의 가용 영역에 배포할 클러스터를 설정합니다.\\nD. Amazon DynamoDB 테이블을 생성하여 RDS 인스턴스를 교체하고 모든 읽기 전용 트래픽을 DynamoDB 테이블로 리디렉션합니다. DynamoDB Accelerator를 활성화하여 기본 테이블에서 트래픽을 오프로드합니다.\", \"A business developed an application that enables users to check in at locations, score them, and provide opinions about their experiences. The application is a success, with a monthly user base that is rapidly growing.\\nThe chief technology officer is concerned that the database that powers the present infrastructure will be unable to manage the additional demand the following month, since the single Amazon RDS for MySQL instance has generated alerts linked to resource depletion due to read requests.\\nWhat can a solutions architect propose to minimize code modifications required to avoid service interruptions at the database layer?\\n\\nA.Create RDS read replicas and redirect read-only traffic to the read replica endpoints. Enable a Multi-AZ deployment.\\nB. Create an Amazon EMR cluster and migrate the data to a Hadoop Distributed File System (HDFS) with a replication factor of 3.\\nC. Create an Amazon ElastiCache cluster and redirect all read-only traffic to the cluster. Set up the cluster to be deployed in three Availability Zones.\\nD. Create an Amazon DynamoDB table to replace the RDS instance and redirect all read-only traffic to the DynamoDB table. Enable DynamoDB Accelerator to offload traffic from the main table.\", \"A\"],\n[\"의료 기관은 환자 기록을 극도로 기밀로 유지합니다. 규정 준수를 위해서는 여러 복사본을 별개의 위치에 저장해야 합니다. 각 기록은 7년 동안 보관해야 합니다. 이 회사는 처음 30일 동안은 즉시 문서를 제공하고 그 이후에는 요청 후 4시간 이내에 문서를 제공하도록 요구하는 정부 기관과 서비스 수준 계약(SLA)을 체결했습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.교차 리전 복제가 활성화된 Amazon S3를 사용합니다. 30일 후 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier로 전환합니다.\\nB. CORS(교차 출처 리소스 공유)가 활성화된 Amazon S3를 사용합니다. 30일 후에 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier로 전환합니다.\\nC. 교차 리전 복제가 활성화된 Amazon S3를 사용합니다. 30일 후 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier Deep Achieve로 전환합니다.\\nD. 교차 출처 리소스 공유(CORS)가 활성화된 Amazon S3를 사용합니다. 30일 후 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier Deep Archive로 전환합니다.\", \"A healthcare organization maintains extremely confidential patient records. Compliance necessitates the storage of several copies in distinct places. Each record must be retained for a period of seven years. The corporation has a service level agreement (SLA) with government agencies that requires documents to be provided instantly for the first 30 days and then within four hours of a request after that.\\nWhat recommendations should a solutions architect make?\\n\\nA.Use Amazon S3 with cross-Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier using lifecycle policy.\\nB. Use Amazon S3 with cross-origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier using a lifecycle policy.\\nC. Use Amazon S3 with cross-Region replication enabled. After 30 days, transition the data to Amazon S3 Glacier Deep Achieve using a lifecycle policy.\\nD. Use Amazon S3 with cross-origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier Deep Archive using a lifecycle policy.\", \"A\"],\n[\"온프레미스에서 비즈니스는 건강 기록을 관리합니다. 회사는 이러한 문서를 영구적으로 보관하고, 저장 후 변경 사항을 비활성화하고, 모든 수준에서 세부적으로 액세스를 감사해야 합니다. CTO(최고 기술 책임자)는 현재 모든 애플리케이션에서 수백만 개의 데이터를 사용하지 않고 있고 현재 인프라의 용량이 부족하기 때문에 걱정하고 있습니다. 최고 기술 책임자(CTO)는 솔루션 설계자에게 오래된 데이터를 마이그레이션하고 향후 기록을 지원하기 위한 솔루션을 구축하도록 요청했습니다.\\n이러한 요구 사항을 충족하기 위해 어떤 솔루션 설계자 서비스를 권장할 수 있습니까?\\n\\nA.AWS DataSync를 사용하여 기존 데이터를 AWS로 이동합니다. Amazon S3를 사용하여 기존 데이터와 새 데이터를 저장합니다. Amazon S3 객체 잠금을 활성화하고 데이터 이벤트로 AWS CloudTrail을 활성화합니다.\\nB. AWS Storage Gateway를 사용하여 기존 데이터를 AWS로 이동합니다. Amazon S3를 사용하여 기존 데이터와 새 데이터를 저장합니다. Amazon S3 객체 잠금을 활성화하고 관리 이벤트로 AWS CloudTrail을 활성화합니다.\\nC. AWS DataSync를 사용하여 기존 데이터를 AWS로 이동합니다. Amazon S3를 사용하여 기존 데이터와 새 데이터를 저장합니다. Amazon S3 객체 잠금을 활성화하고 관리 이벤트로 AWS CloudTrail을 활성화합니다.\\nD. AWS Storage Gateway를 사용하여 기존 데이터를 AWS로 이동합니다. Amazon Elastic Block Store(Amazon EBS)를 사용하여 기존 데이터와 새 데이터를 저장합니다. Amazon S3 객체 잠금을 활성화하고 Amazon S3 서버 액세스 로깅을 활성화합니다.\", \"On-premises, a business manages health records. The firm must retain these documents in perpetuity, disable any alterations made to them after they are saved, and audit access at all levels granularly. The chief technology officer (CTO) is worried because millions of data are currently unused by any application and the present infrastructure is running out of capacity. The Chief Technology Officer has asked that a solutions architect build a solution for migrating old data and supporting future records.\\nWhich solutions architect services may be recommended to suit these requirements?\\n\\nA.Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with data events.\\nB. Use AWS Storage Gateway to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.\\nC. Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.\\nD. Use AWS Storage Gateway to move existing data to AWS. Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data. Enable Amazon S3 object lock and enable Amazon S3 server access logging.\", \"A. cloudtrail은 기본적으로 관리 이벤트 활성화 되어 있음.\"],\n[\"비즈니스는 AWS에서 애플리케이션을 호스팅합니다. 애플리케이션은 Elastic Load Balancer 및 Amazon DynamoDB 데이터베이스 뒤의 Amazon EC2 인스턴스에서 호스팅됩니다. 조직은 애플리케이션이 다운타임을 최소화하면서 다른 AWS 리전으로 이동할 수 있도록 보장해야 합니다.\\n이러한 기준이 가능한 최소 가동 중지 시간을 충족하도록 하려면 솔루션 설계자가 무엇을 해야 합니까?\\n\\nA.재해 복구 지역에 Auto Scaling 그룹과 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 새 재해 복구 지역의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다.\\nB. AWS CloudFormation 템플릿을 생성하여 필요할 때 실행할 EC2 인스턴스, 로드 밸런서 및 DynamoDB 테이블을 생성합니다. 새 재해 복구 지역의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다.\\nC. AWS CloudFormation 템플릿을 생성하여 EC2 인스턴스를 생성하고 필요할 때 실행할 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 새 재해 복구 지역의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다.\\nD. 재해 복구 지역에 Auto Scaling 그룹 및 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다. 트리거할 Amazon CloudWatch 경보와 재해 복구 로드 밸런서를 가리키는 Amazon Route 53을 업데이트하는 AWS Lambda 함수를 생성합니다.\", \"A business hosts their application on AWS. The application is hosted on Amazon EC2 instances behind an Elastic Load Balancer and an Amazon DynamoDB database. The organization needs to guarantee that the application may be moved to another AWS Region with the least amount of downtime possible.\\nWhat should a solutions architect do to ensure that these criteria are met with the MINIMUM possible downtime?\\n\\nA.Create an Auto Scaling group and a load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.\\nB. Create an AWS CloudFormation template to create EC2 instances, load balancers, and DynamoDB tables to be executed when needed. Configure DNS failover to point to the new disaster recovery Region's load balancer.\\nC. Create an AWS CloudFormation template to create EC2 instances and a load balancer to be executed when needed. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.\\nD. Create an Auto Scaling group and load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm to trigger and AWS Lambda function that updates Amazon Route 53 pointing to the disaster recovery load balancer.\", \"A\"],\n[\"솔루션 설계자는 Amazon API Gateway를 사용하여 고객의 요청을 수락하는 새로운 API를 개발하고 있습니다. 요청 트래픽은 매우 다양합니다. 요청을 한 번도 받지 않고 여러 시간이 지나갈 수 있습니다. 비동기식 데이터 처리가 발생하지만 요청이 이루어진 후 몇 초 이내에 완료되어야 합니다.\\n솔루션 설계자는 요구 사항을 효율적으로 충족하기 위해 어떤 컴퓨팅 서비스를 호출하도록 API에 지시해야 합니까?\\n\\nA.AWS Glue 작업\\nB. AWS Lambda 함수\\nC. Amazon Elastic Kubernetes Service(Amazon EKS)에서 호스팅되는 컨테이너화된 서비스\\nD. Amazon EC2와 함께 Amazon ECS에서 호스팅되는 컨테이너화된 서비스\", \"A solutions architect is developing a new API that will accept requests from customers using Amazon API Gateway. Request traffic varies significantly; many hours may pass without getting a single request. Asynchronous data processing will occur, but should be finished within a few seconds of a request being made.\\nWhich compute service should the solutions architect instruct the API to call in order to meet the requirements efficiently?\\n\\nA.An AWS Glue job\\nB. An AWS Lambda function\\nC. A containerized service hosted in Amazon Elastic Kubernetes Service (Amazon EKS)\\nD. A containerized service hosted in Amazon ECS with Amazon EC2\", \"B. 요청이 15분이상 걸린다면 D\"],\n[\"솔루션 설계자는 애플리케이션 개발을 담당합니다. 애플리케이션은 VPC 내부의 여러 가용 영역에 분산된 Amazon EC2 인스턴스에 배포됩니다.\\nAmazon EC2 인스턴스는 민감한 데이터가 포함된 대용량 파일에 정기적으로 액세스합니다. 이러한 파일은 Amazon S3 버킷에서 처리됩니다. 솔루션 설계자의 네트워크 설계는 데이터 전송 비용을 줄이기 위해 최적화되어야 합니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.VPC에서 Amazon S3용 게이트웨이 엔드포인트를 생성합니다. 프라이빗 서브넷에 대한 라우팅 테이블에서 게이트웨이 엔드포인트에 대한 항목을 추가합니다.\\nB. 퍼블릭 서브넷에 단일 NAT 게이트웨이를 생성합니다. 프라이빗 서브넷의 라우팅 테이블에서 NAT 게이트웨이를 가리키는 기본 경로를 추가합니다.\\nC. VPC에서 Amazon S3용 AWS PrivateLink 인터페이스 엔드포인트를 생성합니다. 프라이빗 서브넷의 라우팅 테이블에서 인터페이스 엔드포인트에 대한 항목을 추가합니다.\\nD. 퍼블릭 서브넷의 각 가용 영역에 대해 하나의 NAT 게이트웨이를 생성합니다. 프라이빗 서브넷의 각 라우팅 테이블에서 동일한 가용 영역의 NAT 게이트웨이를 가리키는 기본 경로를 추가합니다.\", \"A solutions architect is responsible for the development of an application. The application will be deployed on Amazon EC2 instances distributed across several Availability Zones inside a VPC.\\nThe Amazon EC2 instances will regularly access huge files containing sensitive data. These files are processed in Amazon S3 buckets. The solutions architect's network design must be optimized to reduce data transmission expenses.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Create a gateway endpoint for Amazon S3 in the VPC. In the route tables for the private subnets, add an entry for the gateway endpoint.\\nB. Create a single NAT gateway in a public subnet. In the route tables for the private subnets, add a default route that points to the NAT gateway.\\nC. Create an AWS PrivateLink interface endpoint for Amazon S3 in the VPC. In the route tables for the private subnets, add an entry for the interface endpoint.\\nD. Create one NAT gateway for each Availability Zone in public subnets. In each of the route tables for the private subnets, add a default route that points to the NAT gateway in the same Availability Zone.\", \"A\"],\n[\"Amazon S3 버킷에서 기업은 60TB의 프로덕션 수준 데이터를 저장하고 있습니다. 솔루션 설계자는 분기별 감사 요구 사항을 준수하기 위해 해당 데이터를 온프레미스로 가져올 책임이 있습니다. 이 데이터 내보내기는 전송 중에 암호화되어야 합니다. 이 회사는 AWS와 온프레미스 데이터 센터 간에 저대역폭 네트워크 연결을 사용합니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.데이터 전송을 위한 복제 기간이 90일인 AWS Migration Hub를 배포합니다.\\nB. AWS에 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. 90일 복제 창을 활성화하여 데이터를 전송합니다.\\nC. 수명 주기 정책이 활성화된 Amazon Elastic File System(Amazon EFS)을 AWS에 배포합니다. 데이터를 전송하는 데 사용합니다.\\nD. AWS Snowball 콘솔에서 내보내기 작업 요청을 완료한 후 온프레미스 데이터 센터에 AWS Snowball 디바이스를 배포합니다.\", \"In an Amazon S3 bucket, a business is storing 60 TB of production-level data. A solutions architect is responsible for bringing that data on-premises in order to comply with quarterly audit requirements. This data export must be encrypted in transit. The corporation uses a low-bandwidth network connection between AWS and its on-premises data center.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Deploy AWS Migration Hub with 90-day replication windows for data transfer.\\nB. Deploy an AWS Storage Gateway volume gateway on AWS. Enable a 90-day replication window to transfer the data.\\nC. Deploy Amazon Elastic File System (Amazon EFS), with lifecycle policies enabled, on AWS. Use it to transfer the data.\\nD. Deploy an AWS Snowball device in the on-premises data center after completing an export job request in the AWS Snowball console.\", \"D\"],\n[\"기업은 최대 스토리지 요구 사항이 200GB인 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 응용 프로그램은 거의 사용되지 않으며 아침과 저녁이 가장 바쁜 시간입니다. 디스크 I/O는 다양하지만 최대 3,000 IOPS에 도달합니다. 회사의 최고 재무 책임자(CFO)는 비용이 걱정되어 솔루션 설계자에게 성능 저하 없이 가장 비용 효율적인 스토리지 선택에 대한 권장 사항을 요청했습니다.\\n솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\\n\\nA.Amazon Elastic Block Store(Amazon EBS) 콜드 HDD(sc1)\\nB. Amazon Elastic Block Store(Amazon EBS) 범용 SSD(gp2)\\nC. Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS SSD(io1)\\nD. Amazon Elastic Block Store(Amazon EBS) 처리량 최적화 HDD(st1)\", \"A business runs an application on an Amazon EC2 instance with a maximum storage requirement of 200 GB. The application is utilized rarely, with mornings and evenings being the busiest times. Disk I/O varies but reaches a maximum of 3,000 IOPS. The company's chief financial officer is worried about expenses and has requested a recommendation from a solutions architect for the most cost-effective storage choice that does not compromise performance.\\nWhich solution should the architect of solutions recommend?\\n\\nA.Amazon Elastic Block Store (Amazon EBS) Cold HDD (sc1)\\nB. Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2)\\nC. Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1)\\nD. Amazon Elastic Block Store (Amazon EBS) Throughput Optimized HDD (st1)\", \"B. HDD는 최대 500IOPS. \"],\n[\"기업에서 Amazon RDS DB 인스턴스에 보관된 외부 감사자와 법의학 회계 데이터를 공유하려고 합니다. 감사자는 자체 Amazon Web Services(AWS) 계정을 갖고 있으며 데이터베이스 사본을 요구합니다.\\n조직은 안전한 방식으로 감사자와 데이터베이스를 어떻게 공유해야 합니까?\\n\\nA.데이터베이스의 읽기 전용 복제본을 만들고 감사자 액세스 권한을 부여하도록 IAM 표준 데이터베이스 인증을 구성합니다.\\nB. 데이터베이스의 스냅샷을 Amazon S3에 복사하고 감사자에게 IAM 역할을 할당하여 해당 버킷의 객체에 대한 액세스 권한을 부여합니다.\\nC. 데이터베이스 콘텐츠를 텍스트 파일로 내보내고 Amazon S3에 파일을 저장하고 해당 버킷에 대한 액세스 권한이 있는 감사자를 위한 새 IAM 사용자를 생성합니다.\\nD. 데이터베이스의 암호화된 스냅샷을 만들고, 스냅샷을 공유하고, AWS Key Management Service(AWS KMS) 암호화 키에 대한 액세스를 허용합니다.\", \"A business wishes to share forensic accounting data with an external auditor that is kept in an Amazon RDS DB instance. The auditor has its own Amazon Web Services (AWS) account and demands a copy of the database.\\nHow should the organization share the database with the auditor in a secure manner?\\n\\nA.Create a read replica of the database and configure IAM standard database authentication to grant the auditor access.\\nB. Copy a snapshot of the database to Amazon S3 and assign an IAM role to the auditor to grant access to the object in that bucket.\\nC. Export the database contents to text files, store the files in Amazon S3, and create a new IAM user for the auditor with access to that bucket.\\nD. Make an encrypted snapshot of the database, share the snapshot, and allow access to the AWS Key Management Service (AWS KMS) encryption key.\", \"D\"],\n[\"비즈니스는 재해 발생 시 복구할 수 있도록 데이터를 AWS에 복제하려고 합니다. 오늘날 시스템 관리자는 데이터를 NFS 공유로 전송하는 프로그램을 가지고 있습니다.\\n처리 문제를 해결하려면 프로그램 관리자가 개별 백업 파일을 신속하게 검색해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.온프레미스 NFS 공유 대신 Amazon S3 버킷에 데이터를 복사하도록 스크립트를 수정합니다.\\nB. 온프레미스 NFS 공유 대신 Amazon S3 Glacier 아카이브에 데이터를 복사하도록 스크립트를 수정합니다.\\nC. 온프레미스 NFS 공유 대신 Amazon Elastic File System(Amazon EFS) 볼륨에 데이터를 복사하도록 스크립트를 수정합니다.\\nD. 온프레미스 NFS 공유 대신 AWS Storage Gateway for File Gateway 가상 어플라이언스에 데이터를 복사하도록 스크립트를 수정합니다.\", \"A business want to duplicate its data to AWS in order to be able to recover in the case of a catastrophe. A system administrator nowadays has programs that transfer data to an NFS share.\\nIndividual backup files must be retrieved quickly by program administrators in order to address processing issues.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Modify the script to copy data to an Amazon S3 bucket instead of the on-premises NFS share.\\nB. Modify the script to copy data to an Amazon S3 Glacier Archive instead of the on-premises NFS share.\\nC. Modify the script to copy data to an Amazon Elastic File System (Amazon EFS) volume instead of the on-premises NFS share.\\nD. Modify the script to copy data to an AWS Storage Gateway for File Gateway virtual appliance instead of the on-premises NFS share.\", \"D\"],\n[\"비즈니스 웹 사이트는 단일 AWS 리전에서 Amazon EC2 인스턴스의 Auto Scaling 그룹에서 제공합니다. 웹 사이트에는 데이터베이스가 필요하지 않습니다.\\n비즈니스가 성장하고 있으며 기술 팀은 웹사이트를 두 번째 지역으로 확장합니다. 회사는 확장 및 재해 복구를 허용하기 위해 두 지역에 트래픽을 분산하려고 합니다. 솔루션은 웹사이트가 감염된 지역의 방문자에게 서비스를 제공하지 않아야 합니다.\\n이러한 요구 사항을 준수하기 위해 기업은 어떤 정책 또는 리소스를 구현해야 합니까?\\n\\nA.Amazon Route 53 단순 라우팅 정책\\nB. Amazon Route 53 다중값 응답 라우팅 정책\\nC. 두 리전의 EC2 인스턴스 ID를 지정하는 대상 그룹이 있는 한 리전의 Application Load Balancer\\nD. 두 리전의 EC2 인스턴스 IP 주소를 지정하는 대상 그룹이 있는 한 리전의 Application Load Balancer\", \"The website of a business is served by an Auto Scaling group of Amazon EC2 instances in a single AWS Region. A database is not required for the website.\\nThe business is growing, and the technical team expands the website to a second Region. The firm want to spread traffic across the two Regions in order to allow expansion and catastrophe recovery. The solution should avoid serving visitors from regions where the website is infected.\\nWhich policy or resource should the business implement in order to comply with these requirements?\\n\\nA.An Amazon Route 53 simple routing policy\\nB. An Amazon Route 53 multivalue answer routing policy\\nC. An Application Load Balancer in one Region with a target group that specifies the EC2 instance IDs from both Regions\\nD. An Application Load Balancer in one Region with a target group that specifies the IP addresses of the EC2 instances from both Regions\", \"B\"],\n[\"기업에 온프레미스 SQL 데이터베이스를 사용하여 데이터를 저장하는 전자상거래 애플리케이션이 있습니다. 조직은 이 데이터베이스를 Amazon Web Services(AWS)로 이동하기로 선택했습니다.\\n그러나 마이그레이션의 일부로 조직은 빈번한 읽기 요청에 대해 밀리초 미만의 응답 시간을 달성하고자 합니다.\\n솔루션 설계자는 성능이 중요하며 데이터베이스 읽기 중에 반환되는 소량의 오래된 데이터가 허용된다는 것을 이해합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon RDS 읽기 전용 복제본을 구축합니다.\\nB. 데이터베이스를 더 큰 인스턴스 유형으로 구축합니다.\\nC. Amazon ElastiCache를 사용하여 데이터베이스 캐시를 구축합니다.\\nD. Amazon Elasticsearch Service(Amazon ES)를 사용하여 데이터베이스 캐시를 구축합니다.\", \"A business has an ecommerce application that uses an on-premises SQL database to store data. The organization has chosen to move this database to Amazon Web Services (AWS).\\nHowever, as part of the migration, the organization wishes to achieve response times of less than a millisecond for frequent read requests.\\nA solutions architect understands that performance is critical and that a tiny amount of stale data returned during database reads is acceptable.\\nWhat recommendations should the solutions architect make?\\n\\nA.Build Amazon RDS read replicas.\\nB. Build the database as a larger instance type.\\nC. Build a database cache using Amazon ElastiCache.\\nD. Build a database cache using Amazon Elasticsearch Service (Amazon ES).\", \"C\"],\n[\"기업은 민감한 사용자 데이터를 Amazon S3 버킷에 보관합니다. 조직은 VPC 내부에서 작동하는 Amazon EC2 인스턴스로 구성된 애플리케이션 계층에서 이 버킷에 대한 액세스를 보호하기를 원합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 함께 사용해야 합니까? (2개를 선택하세요.)\\n\\nA.VPC 내에서 Amazon S3용 VPC 게이트웨이 엔드포인트를 구성합니다.\\nB. S3 버킷의 객체를 퍼블릭으로 만들기 위한 버킷 정책을 생성합니다.\\nC. VPC에서 실행되는 애플리케이션 계층으로만 액세스를 제한하는 버킷 정책을 생성합니다.\\nD. S3 액세스 정책으로 IAM 사용자를 생성하고 IAM 자격 증명을 EC2 인스턴스에 복사합니다.\\nE. NAT 인스턴스를 생성하고 EC2 인스턴스가 NAT 인스턴스를 사용하여 S3 버킷에 액세스하도록 합니다.\", \"A business keeps sensitive user data in an Amazon S3 bucket. The organization wishes to safeguard access to this bucket from the application layer, which is comprised of Amazon EC2 instances operating inside a VPC.\\nWhich actions should a solutions architect use in conjunction to achieve this? (Select two.)\\n\\nA.Configure a VPC gateway endpoint for Amazon S3 within the VPC.\\nB. Create a bucket policy to make the objects in the S3 bucket public.\\nC. Create a bucket policy that limits access to only the application tier running in the VPC.\\nD. Create an IAM user with an S3 access policy and copy the IAM credentials to the EC2 instance.\\nE. Create a NAT instance and have the EC2 instances use the NAT instance to access the S3 bucket.\", \"A, C\"],\n[\"한 기업에서 고객이 웹사이트에 이미지를 제출할 수 있도록 하는 모바일 애플리케이션을 개발합니다. 응용 프로그램에는 MFA(다단계 인증)가 포함된 보안 로그인 프로세스가 필요합니다. 회사는 솔루션을 구성하고 유지 관리하는 데 필요한 시간을 최소화하기를 원합니다.\\n솔루션 설계자에 따르면 이러한 요구 사항을 충족하려면 어떤 솔루션을 권장해야 합니까?\\n\\nA.SMS 기반 MFA와 함께 Amazon Cognito 자격 증명을 사용합니다.\\nB. 모든 사용자에 대해 MFA를 요구하도록 IAM 정책을 편집합니다.\\nC. MFA가 필요한 기업 Active Directory에 대해 IAM을 연합합니다.\\nD. Amazon API Gateway를 사용하고 사진에 대해 서버 측 암호화(SSE)를 요구합니다.\", \"A business develops a mobile application that enables clients to submit images to a website. The application requires a secure login process that includes multi-factor authentication (MFA). The firm want to minimize the time required to construct and maintain the solution.\\nWhich solution, according to a solutions architect, should be recommended to satisfy these requirements?\\n\\nA.Use Amazon Cognito Identity with SMS-based MFA.\\nB. Edit IAM policies to require MFA for all users.\\nC. Federate IAM against the corporate Active Directory that requires MFA.\\nD. Use Amazon API Gateway and require server-side encryption (SSE) for photos.\", \"A\"],\n[\"수년 동안 응용 프로그램에는 개발 환경(DEV)과 프로덕션 환경(PROD)이 필요했습니다. DEV 인스턴스는 정규 업무 시간 동안 하루 10시간 동안 사용할 수 있는 반면 PROD 인스턴스는 하루 24시간 동안 사용할 수 있습니다. 솔루션 설계자는 비용을 줄이기 위해 컴퓨팅 인스턴스 구매 전략을 결정해야 합니다.\\n다음 중 가장 비용 효율적인 솔루션은 무엇입니까?\\n\\nA.스팟 인스턴스가 있는 DEV 및 온디맨드 인스턴스가 있는 PROD\\nB. 온디맨드 인스턴스가 있는 DEV 및 스팟 인스턴스가 있는 PROD\\nC. 정기 예약 인스턴스가 있는 DEV 및 예약 인스턴스가 있는 PROD\\nD. 온디맨드 인스턴스가 있는 DEV 및 정기 예약 인스턴스가 있는 PROD\", \"For many years, an application needs a development environment (DEV) and a production environment (PROD). DEV instances will be available for 10 hours per day during regular business hours, whereas PROD instances will be available 24 hours per day. A solutions architect must decide on a strategy for purchasing compute instances in order to reduce expenses.\\nWhich of the following is the MOST cost-effective solution?\\n\\nA.DEV with Spot Instances and PROD with On-Demand Instances\\nB. DEV with On-Demand Instances and PROD with Spot Instances\\nC. DEV with Scheduled Reserved Instances and PROD with Reserved Instances\\nD. DEV with On-Demand Instances and PROD with Scheduled Reserved Instances\", \"C\"],\n[\"기업은 성능을 최적화하기 위해 다계층 애플리케이션을 온프레미스에서 AWS 클라우드로 마이그레이션하려고 합니다. 프로그램은 RESTful 서비스를 사용하여 서로 연결하는 수준으로 나뉩니다. 계층이 과부하되면 트랜잭션이 삭제됩니다. 솔루션 설계자는 이러한 문제를 해결하고 애플리케이션을 현대화하는 솔루션 개발을 담당합니다.\\n어떤 솔루션이 이러한 매개변수를 충족하고 운영 효율성 측면에서 가장 최적입니까?\\n\\nA.Amazon API Gateway를 사용하고 애플리케이션 계층으로 AWS Lambda 함수에 대한 트랜잭션을 지시합니다. Amazon Simple Queue Service(Amazon SQS)를 애플리케이션 서비스 간의 통신 계층으로 사용합니다.\\nB. Amazon CloudWatch 지표를 사용하여 애플리케이션 성능 기록을 분석하여 성능 장애 동안 서버의 최대 사용률을 결정합니다. 최대 요구 사항을 충족하도록 애플리케이션 서버의 Amazon EC2 인스턴스 크기를 늘립니다.\\nC. Amazon Simple Notification Service(Amazon SNS)를 사용하여 Auto Scaling 그룹의 Amazon EC2에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch를 사용하여 SNS 대기열 길이를 모니터링하고 필요에 따라 확장 및 축소합니다.\\nD. Amazon Simple Queue Service(Amazon SQS)를 사용하여 Auto Scaling 그룹의 Amazon EC2에서 실행되는 애플리케이션 서버 간의 메시징을 처리합니다. Amazon CloudWatch를 사용하여 SQS 대기열 길이를 모니터링하고 통신 오류가 감지되면 확장합니다.\", \"A business want to migrate a multi-tiered application from on-premises to the AWS Cloud in order to optimize its performance. The program is divided into levels that connect with one another using RESTful services. When a tier gets overloaded, transactions are dropped. A solutions architect is responsible for developing a solution that addresses these concerns and modernizes the application.\\nWhich solution satisfies these parameters and is the MOST OPTIMAL in terms of operational efficiency?\\n\\nA.Use Amazon API Gateway and direct transactions to the AWS Lambda functions as the application layer. Use Amazon Simple Queue Service (Amazon SQS) as the communication layer between application services.\\nB. Use Amazon CloudWatch metrics to analyze the application performance history to determine the server's peak utilization during the performance failures. Increase the size of the application server's Amazon EC2 instances to meet the peak requirements.\\nC. Use Amazon Simple Notification Service (Amazon SNS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SNS queue length and scale up and down as required.\\nD. Use Amazon Simple Queue Service (Amazon SQS) to handle the messaging between application servers running on Amazon EC2 in an Auto Scaling group. Use Amazon CloudWatch to monitor the SQS queue length and scale up when communication failures are detected.\", \"A\"],\n[\"전자 상거래 웹 사이트는 Auto Scaling 그룹의 Application Load Balancer(ALB)에서 관리하는 Amazon EC2 인스턴스에서 호스팅됩니다. 사이트는 동적 IP 주소를 사용하는 승인되지 않은 외부 시스템의 상당한 양의 요청으로 인해 성능 문제를 겪고 있습니다. 보안팀은 웹사이트에서 DDoS 공격 가능성을 우려하고 있습니다. 회사는 합법적인 사용자에게 가능한 한 최소한의 악영향을 미치는 방식으로 무단 인바운드 요청을 금지해야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon Inspector를 배포하고 ALB와 연결합니다.\\nB. AWS WAF를 배포하고 이를 ALB와 연결하고 속도 제한 규칙을 구성합니다.\\nC. 들어오는 트래픽을 차단하기 위해 ALB와 연결된 네트워크 ACL에 규칙을 배포합니다.\\nD. GuardDuty를 구성할 때 Amazon GuardDuty를 배포하고 속도 제한 보호를 활성화합니다.\", \"An ecommerce website is hosted on Amazon EC2 instances that are managed by an Application Load Balancer (ALB) in an Auto Scaling group. The site is experiencing performance difficulties as a result of a significant volume of requests from unauthorized external systems using dynamic IP addresses. The security team is concerned about the possibility of DDoS assaults on the website. The firm must prohibit unauthorized inbound requests in a manner that has the fewest possible adverse effects on legal users.\\nWhat recommendations should a solutions architect make?\\n\\nA.Deploy Amazon Inspector and associate it with the ALB.\\nB. Deploy AWS WAF, associate it with the ALB, and configure a rate-limiting rule.\\nC. Deploy rules to the network ACLs associated with the ALB to block the incoming traffic.\\nD. Deploy Amazon GuardDuty and enable rate-limiting protection when configuring GuardDuty.\", \"B\"],\n[\"그룹이 Amazon S3 버킷에서 항목을 나열하고 제거하려면 권한이 필요합니다. 버킷에 대한 액세스를 제공하기 위해 관리자는 다음 IAM 정책을 개발하여 그룹에 적용했습니다. 그룹은 버킷에서 항목을 제거할 수 없습니다. 조직은 액세스와 관련하여 최소 권한 원칙을 준수합니다.\\nhttps://i.imgur.com/csLL7w5l.png\\n버킷 액세스를 수정하기 위해 솔루션 설계자가 정책에 어떤 문장을 포함해야 합니까?\\n\\nA. https://i.imgur.com/t8KnAJ5l.png\\nB.  https://i.imgur.com/xwPIgOml.png\\nC.  https://i.imgur.com/QTz0Q9zl.png\\nD.  https://i.imgur.com/8UbpkVOl.png\", \"Permissions are required for a group to list and remove things from an Amazon S3 bucket. To provide access to the bucket, an administrator developed the following IAM policy and applied it to the group. The group does not have the ability to remove items from the bucket. The organization adheres to the principle of least privilege when it comes to access.\\nWhich sentence in the policy should a solutions architect include to rectify bucket access?\", \"D\"],\n[\"한 기업이 가상 서버 기반 워크로드를 AWS로 이전하는 것을 고려하고 있습니다. 회사는 응용 프로그램 서버에 의해 백업되는 인터넷의 로드 밸런서를 활용합니다. 패치는 인터넷 호스팅 리포지토리를 사용하여 애플리케이션 서버에 적용됩니다.\\n솔루션 설계자는 퍼블릭 서브넷 호스팅을 위해 어떤 서비스를 제안해야 합니까? (2개를 선택하세요.)\\n\\nA.NAT 게이트웨이\\nB. Amazon RDS DB 인스턴스\\nC. 애플리케이션 로드 밸런서\\nD. Amazon EC2 애플리케이션 서버\\nE. Amazon Elastic File System(Amazon EFS) 볼륨\", \"A business is considering moving its virtual server-based workloads to AWS. The corporation utilizes load balancers on the internet that are backed up by application servers. Patches are applied to the application servers using an internet-hosted repository.\\nWhich services should a solution architect propose for public subnet hosting? (Select two.)\\n\\nA.NAT gateway\\nB. Amazon RDS DB instances\\nC. Application Load Balancers\\nD. Amazon EC2 application servers\\nE. Amazon Elastic File System (Amazon EFS) volumes\", \"A, C\"],\n[\"비즈니스는 Amazon ECS를 사용하여 애플리케이션을 실행합니다. 프로그램은 원본 사진의 크기를 조정한 다음 Amazon S3 API를 사용하여 조정된 사진을 Amazon S3에 저장합니다.\\n솔루션 설계자는 애플리케이션에 Amazon S3에 대한 액세스 권한이 부여되도록 어떻게 보장할 수 있습니까?\\n\\nA.Amazon ECS에서 읽기/쓰기 액세스를 허용하도록 AWS IAM에서 S3 역할을 업데이트한 다음 컨테이너를 다시 시작합니다.\\nB. S3 권한이 있는 IAM 역할을 생성한 다음 해당 역할을 작업 정의에서 taskRoleArn으로 지정합니다.\\nC. Amazon ECS에서 Amazon S3로의 액세스를 허용하는 보안 그룹을 생성하고 ECS 클러스터에서 사용하는 시작 구성을 업데이트합니다.\\nD. S3 권한이 있는 IAM 사용자를 생성한 다음 이 계정으로 로그인한 상태에서 ECS 클러스터에 대한 Amazon EC2 인스턴스를 다시 시작합니다.\", \"A business uses Amazon ECS to execute an application. The program resizes an original picture and then uses the Amazon S3 API to store the scaled photos in Amazon S3.\\nHow can a solutions architect guarantee that an application is granted access to Amazon S3?\\n\\nA.Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container.\\nB. Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.\\nC. Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster.\\nD. Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account.\", \"B\"],\n[\"애플리케이션이 공급업체 호스팅 서비스에 요청합니다. 판매자는 호출 단위로 요금을 청구합니다. 재무 부서는 청구서를 확인하기 위해 서비스에 대한 호출 횟수에 대한 정보가 필요합니다.\\n솔루션 설계자는 애플리케이션 변경 없이 호출 수를 안정적으로 기록할 수 있는 시스템을 어떻게 개발할 수 있습니까?\\n\\nA.인터넷 게이트웨이를 통해 서비스를 호출합니다.\\nB. Amazon Simple Queue Service(Amazon SQS) 대기열을 사용하여 서비스에서 애플리케이션을 분리합니다.\\nC. 서비스에 대한 호출 수를 계산하는 사용자 지정 Amazon CloudWatch 지표를 게시합니다.\\nD. VPC 피어링 연결을 통해 서비스를 호출합니다.\", \"An application makes a request to a vendor-hosted service. The seller charges on a per-call basis. The finance department need information on the number of calls made to the service in order to verify the billing bills.\\nHow can a solutions architect develop a system that can reliably record the number of calls without needing application changes?\\n\\nA.Call the service through an internet gateway.\\nB. Decouple the application from the service with an Amazon Simple Queue Service (Amazon SQS) queue.\\nC. Publish a custom Amazon CloudWatch metric that counts calls to the service.\\nD. Call the service through a VPC peering connection.\", \"C\"],\n[\"한 회사에서 AWS를 사용하여 인기 있는 게임 플랫폼을 강화합니다. 이 프로그램은 사용자 경험을 저하시키고 특정 플레이어에게 불공정한 우위를 제공할 수 있으므로 대기 시간에 민감합니다. 애플리케이션은 모든 AWS 리전에서 사용할 수 있습니다. ALB(Application Load Balancer) 뒤에 있는 Auto Scaling 그룹의 구성원으로 구성된 Amazon EC2 인스턴스에서 호스팅됩니다. 솔루션 설계자는 애플리케이션의 상태를 모니터링하고 트래픽을 정상 엔드포인트로 리디렉션하는 시스템을 포함해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Global Accelerator에서 액셀러레이터를 구성합니다. 애플리케이션이 수신 대기하는 포트에 대한 리스너를 추가하고 이를 각 리전의 리전 엔드포인트에 연결합니다. ALB를 엔드포인트로 추가하십시오.\\nB. Amazon CloudFront 배포를 생성하고 ALB를 오리진 서버로 지정합니다. 원본 캐시 헤더를 사용하도록 캐시 동작을 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화하십시오.\\nC. Amazon CloudFront 배포를 생성하고 Amazon S3를 오리진 서버로 지정합니다. 원본 캐시 헤더를 사용하도록 캐시 동작을 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화하십시오.\\nD. 애플리케이션의 데이터 저장소 역할을 하도록 Amazon DynamoDB 데이터베이스를 구성합니다. DynamoDB Accelerator(DAX) 클러스터를 생성하여 애플리케이션 데이터를 호스팅하는 DynamoDB의 인메모리 캐시 역할을 합니다.\", \"기업은 Auto Scaling 그룹에서 제공한 Amazon EC2 인스턴스에 대한 요구 사항을 재평가해야 합니다. 현재 Auto Scaling 그룹은 2개의 가용 영역에서 2개 이상, 4개 이하의 인스턴스를 실행하도록 설정되어 있습니다. 솔루션 설계자는 Amazon CloudWatch 분석을 평가하고 모든 EC2 인스턴스의 CPU 사용량이 일관되게 낮다는 것을 발견했습니다.\\n솔루션 설계자는 애플리케이션에서 내결함성을 유지하면서 사용을 개선하기 위해 무엇을 제안해야 합니까?\\n\\nA.일부 EC2 인스턴스를 제거하여 나머지 인스턴스의 활용도를 높입니다.\\nB. CPU 사용률이 낮은 인스턴스의 Amazon Elastic Block Store(Amazon EBS) 용량을 늘립니다.\\nC. Auto Scaling 그룹 조정 정책을 수정하여 더 높은 CPU 사용률 지표를 기반으로 축소 및 축소합니다.\\nD. 더 작은 인스턴스 유형을 사용하는 새로운 시작 구성을 생성합니다. 기존 Auto Scaling 그룹을 업데이트합니다.\", \"A\"],\n[\"비즈니스는 여러 AWS 리전에 걸쳐 있는 두 VPC의 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 인스턴스는 인터넷을 통해 서로 상호 작용합니다. 보안 팀은 인스턴스 간에 인터넷을 통해 통신이 발생하지 않도록 하려고 합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.NAT 게이트웨이를 생성하고 EC2 인스턴스 서브넷의 라우팅 테이블을 업데이트합니다.\\nB. VPC 엔드포인트를 생성하고 EC2 인스턴스 서브넷의 라우팅 테이블을 업데이트합니다.\\nC. VPN 연결을 생성하고 EC2 인스턴스 서브넷의 라우팅 테이블을 업데이트합니다.\\nD. VPC 피어링 연결을 생성하고 EC2 인스턴스 서브넷의 라우팅 테이블을 업데이트합니다.\", \"A business hosts an application on Amazon EC2 instances in two VPCs spread across several AWS Regions. The instances interact with one another over the internet. The security team want to guarantee that no communication occurs over the internet between the instances.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Create a NAT gateway and update the route table of the EC2 instances' subnet.\\nB. Create a VPC endpoint and update the route table of the EC2 instances' subnet.\\nC. Create a VPN connection and update the route table of the EC2 instances' subnet.\\nD. Create a VPC peering connection and update the route table of the EC2 instances' subnet.\", \"D\"],\n[\"기업은 AWS Lambda 및 Amazon API Gateway에서 공개적으로 사용 가능한 서버리스 애플리케이션을 운영하고 있습니다. 최근 봇넷의 가짜 요청으로 인해 애플리케이션의 트래픽이 크게 증가했습니다.\\n권한 없는 사용자가 요청을 제출하지 못하도록 솔루션 설계자는 어떤 조치를 취해야 합니까? (2개를 선택하세요.)\\n\\nA.정품 사용자에게만 공유되는 API 키로 사용 계획을 작성하십시오.\\nB. 사기성 IP 주소의 요청을 무시하도록 Lambda 함수 내에 로직을 통합합니다.\\nC. AWS WAF 규칙을 구현하여 악의적인 요청을 대상으로 하고 이를 필터링하는 작업을 트리거합니다.\\nD. 기존 공개 API를 비공개 API로 변환합니다. DNS 레코드를 업데이트하여 사용자를 새 API 엔드포인트로 리디렉션합니다.\\nE. API 액세스를 시도하는 각 사용자에 대해 IAM 역할을 생성합니다. 사용자는 API 호출 시 역할을 맡게 됩니다.\", \"A business is operating a publicly available serverless application on AWS Lambda and Amazon API Gateway. Recently, the application's traffic increased significantly as a result of bogus requests from botnets.\\nWhich actions should a solutions architect take to prevent unauthorized users from submitting requests? (Select two.)\\n\\nA.Create a usage plan with an API key that is shared with genuine users only.\\nB. Integrate logic within the Lambda function to ignore the requests from fraudulent IP addresses.\\nC. Implement an AWS WAF rule to target malicious requests and trigger actions to filter them out.\\nD. Convert the existing public API to a private API. Update the DNS records to redirect users to the new API endpoint.\\nE. Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call.\", \"A, C\"],\n[\"기업에서 us-east-l 리전의 Amazon RDS for Oracle 다중 AZ DB 인스턴스를 통해 us-east-l 리전의 Amazon RDS for Oracle 다중 AZ DB 인스턴스로 온프레미스 Oracle 데이터베이스를 마이그레이션했습니다. 솔루션 설계자는 us-east-1 지역에서 데이터베이스에 액세스할 수 없는 경우 us-west-2 지역에 데이터베이스를 제공하는 재해 복구 계획을 만들고 있습니다. 아키텍처는 데이터베이스가 us-west-2 리전에서 최대 2시간 이내에 제공되도록 보장해야 하며 최대 데이터 손실 창은 3시간입니다.\\n이러한 조건은 어떻게 충족되어야 합니까?\\n\\nA.DB 인스턴스를 편집하고 us-west-2에서 읽기 전용 복제본을 생성합니다. 재해 복구 환경을 활성화해야 하는 경우 us-west-2에서 읽기 전용 복제본을 마스터로 승격합니다.\\nB. 다중 지역 옵션을 선택하여 us-west-2에서 대기 인스턴스를 프로비저닝합니다. 재해 복구 환경을 생성해야 하는 경우 대기 인스턴스가 us-west-2의 마스터로 자동 승격됩니다.\\nC. 데이터베이스 인스턴스의 자동 스냅샷을 만들어 3시간마다 us-west-2에 복사합니다. 재해 복구 환경을 활성화해야 하는 경우 최신 스냅샷을 복원하여 us-west-2의 다른 데이터베이스 인스턴스를 프로비저닝합니다.\\nD. 여러 AWS 리전에서 멀티마스터 읽기/쓰기 인스턴스를 생성합니다. us-east-1 및 us-west-2에서 VPC를 선택하여 배포합니다. 재해 복구 환경을 활성화할 필요가 없도록 us-west-2의 마스터 읽기/쓰기 인스턴스를 사용 가능한 상태로 유지하십시오.\", \"A corporation has migrated an on-premises Oracle database to an Amazon RDS for Oracle Multi-AZ DB instance in the us-east-l Region through an Amazon RDS for Oracle Multi-AZ DB instance in the us-east-l Region. A solutions architect is creating a disaster recovery plan that will provide the database in the us-west-2 Region in the event that the database becomes inaccessible in the us-east-1 Region. The architecture must guarantee that the database is supplied within a maximum of two hours in the us-west-2 Region, with a maximum data loss window of three hours.\\nHow are these stipulations to be met?\\n\\nA.Edit the DB instance and create a read replica in us-west-2. Promote the read replica to master in us-west-2 in case the disaster recovery environment needs to be activated.\\nB. Select the multi-Region option to provision a standby instance in us-west-2. The standby instance will be automatically promoted to master in us-west-2 in case the disaster recovery environment needs to be created.\\nC. Take automated snapshots of the database instance and copy them to us-west-2 every 3 hours. Restore the latest snapshot to provision another database instance in us-west-2 in case the disaster recovery environment needs to be activated.\\nD. Create a multimaster read/write instances across multiple AWS Regions. Select VPCs in us-east-1 and us-west-2 to make that deployment. Keep the master read/write instance in us-west-2 available to avoid having to activate a disaster recovery environment.\", \"A. B도 가능하다는 의견 존재\"],\n[\"기업은 단일 VPC 아래 다양한 가용 영역에 분산된 여러 Amazon EC2 인스턴스를 사용하여 미디어 샵을 운영합니다. 조직은 모든 ​​EC2 인스턴스에서 데이터를 공유하기 위한 고성능 솔루션이 필요하지만 데이터를 VPC 내부에 유지하기를 원합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon S3 버킷을 생성하고 각 인스턴스의 애플리케이션에서 서비스 API를 호출합니다.\\nB. Amazon S3 버킷을 생성하고 모든 인스턴스가 탑재된 볼륨으로 액세스하도록 구성합니다.\\nC. Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성하고 모든 인스턴스에 탑재합니다.\\nD. Amazon Elastic File System(Amazon EFS) 파일 시스템을 구성하고 모든 인스턴스에 탑재합니다.\", \"A business operates a media shop using several Amazon EC2 instances dispersed across various Availability Zones under a single VPC. The organization need a high-performance solution for data sharing across all EC2 instances, but wishes to retain data inside the VPC.\\nWhat recommendations should a solutions architect make?\\n\\nA.Create an Amazon S3 bucket and call the service APIs from each instance's application.\\nB. Create an Amazon S3 bucket and configure all instances to access it as a mounted volume.\\nC. Configure an Amazon Elastic Block Store (Amazon EBS) volume and mount it across all instances.\\nD. Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances.\", \"D\"],\n[\"한 기업은 현재 운영 중인 두 개의 NAT 인스턴스가 기업의 애플리케이션에 필요한 트래픽을 처리할 수 없을 것이라고 우려하고 있습니다. 솔루션 설계자는 고가용성, 내결함성 및 자체 확장 시스템을 개발하려고 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.두 개의 NAT 인스턴스를 제거하고 동일한 가용 영역에 있는 두 개의 NAT 게이트웨이로 교체합니다.\\nB. 다른 가용 영역의 NAT 인스턴스에 대해 Network Load Balancer와 함께 Auto Scaling 그룹을 사용합니다.\\nC. 두 개의 NAT 인스턴스를 제거하고 서로 다른 가용 영역에 있는 두 개의 NAT 게이트웨이로 교체합니다.\\nD. 두 NAT 인스턴스를 서로 다른 가용 영역의 스팟 인스턴스로 교체하고 Network Load Balancer를 배포합니다.\", \"A business is worried that the two NAT instances now in operation would be unable to handle the traffic required for the business's application. A solutions architect wishes to develop a highly available, fault-tolerant, and self-scaling system.\\nWhat recommendations should the solutions architect make?\\n\\nA.Remove the two NAT instances and replace them with two NAT gateways in the same Availability Zone.\\nB. Use Auto Scaling groups with Network Load Balancers for the NAT instances in different Availability Zones.\\nC. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.\\nD. Replace the two NAT instances with Spot Instances in different Availability Zones and deploy a Network Load Balancer.\", \"C\"],\n[\"기업은 뉴스 정보를 호스팅할 목적으로 다계층 웹 응용 프로그램을 유지 관리합니다. 애플리케이션은 Application Load Balancer를 통해 라우팅되는 Amazon EC2 인스턴스에 배포됩니다. 인스턴스는 Amazon EC2 Auto Scaling 그룹을 통해 다양한 가용 영역에 분산되고 Amazon Aurora 데이터베이스를 사용합니다. 솔루션 설계자는 요청 속도의 빈번한 급증에 대한 애플리케이션의 저항을 강화해야 합니다.\\n솔루션 아키텍트가 구현해야 하는 아키텍처는 무엇입니까? (2개를 선택하세요.)\\n\\nA.AWS Shield를 추가합니다.\\nB. Aurora 복제본을 추가합니다.\\nC. AWS Direct Connect를 추가합니다.\\nD. AWS Global Accelerator를 추가합니다.\\nE. Application Load Balancer 앞에 Amazon CloudFront 배포를 추가합니다.\", \"A business maintains a multi-tiered web application for the purpose of hosting news information. The application is deployed on Amazon EC2 instances that are routed via an Application Load Balancer. The instances are distributed across various Availability Zones through an Amazon EC2 Auto Scaling group and use an Amazon Aurora database. A solution architect must strengthen the application's resistance to frequent spikes in request rates.\\nWhich architecture should be implemented by the solutions architect? (Select two.)\\n\\nA.Add AWS Shield.\\nB. Add Aurora Replica.\\nC. Add AWS Direct Connect.\\nD. Add AWS Global Accelerator.\\nE. Add an Amazon CloudFront distribution in front of the Application Load Balancer.\", \"B, E\"],\n[\"한 회사가 컨테이너를 활용하여 AWS에서 웹 애플리케이션을 개발하고 있습니다. 어느 순간에 조직은 웹 애플리케이션의 세 가지 인스턴스를 실행해야 합니다. 애플리케이션은 수요 증가에 발맞추기 위해 가용성과 확장성이 높아야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Fargate 시작 유형을 사용하여 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 원하는 개수의 3개 작업이 있는 ECS 서비스를 생성합니다.\\nB. Amazon EC2 시작 유형을 사용하여 하나의 가용 영역에 3개의 컨테이너 인스턴스가 있는 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 각 컨테이너 인스턴스에 대해 하나의 작업을 배치합니다.\\nC. AWS Fargate 시작 유형을 사용하여 3개의 서로 다른 가용 영역에 3개의 컨테이너 인스턴스가 있는 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 원하는 개수의 3개 작업이 있는 ECS 서비스를 생성합니다.\\nD. Amazon EC2 시작 유형을 사용하여 두 개의 서로 다른 가용 영역에 하나의 컨테이너 인스턴스가 있는 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 웹 응용 프로그램에 대한 작업 정의를 만듭니다. 하나의 컨테이너 인스턴스에 두 개의 작업을 배치합니다. 나머지 컨테이너 인스턴스에 하나의 작업을 배치합니다.\", \"A firm is developing a web application on AWS utilizing containers. At any one moment, the organization needs three instances of the web application to be running. The application must be highly available and scalable in order to keep up with demand increases.\\nWhich solution satisfies these criteria?\\n\\nA.Use the AWS Fargate launch type to create an Amazon Elastic Container Service (Amazon ECS) cluster. Create a task definition for the web application. Create an ECS service that has a desired count of three tasks.\\nB. Use the Amazon EC2 launch type to create an Amazon Elastic Container Service (Amazon ECS) cluster that has three container instances in one Availability Zone. Create a task definition for the web application. Place one task for each container instance.\\nC. Use the AWS Fargate launch type to create an Amazon Elastic Container Service (Amazon ECS) cluster that has three container instances in three different Availability Zones. Create a task definition for the web application. Create an ECS service that has a desired count of three tasks.\\nD. Use the Amazon EC2 launch type to create an Amazon Elastic Container Service (Amazon ECS) cluster that has one container instance in two different Availability Zones. Create a task definition for the web application. Place two tasks on one container instance. Place one task on the remaining container instance.\", \"A. Fargate는 기본적으로 여러 AZ에 분산되어있음.\"],\n[\"비즈니스에서는 Amazon S3 버킷에 있는 항목의 모든 버전을 보존해야 합니다. 처음 30일 동안 현재 개체 버전을 자주 방문합니다. 그 후에는 거의 액세스되지 않으며 5분 이내에 검색할 수 있어야 합니다. 이전 개체 버전은 무기한 유지해야 하며 거의 볼 수 없으며 일주일 이내에 복구될 수 있습니다. 모든 저장 옵션은 접근이 용이하고 내구성이 있어야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하는 가장 비용 효율적인 방법으로 무엇을 제안해야 합니까?\\n\\nA.30일 후에 현재 객체 버전을 S3 Standard 스토리지에서 S3 Glacier로 이동하고 1일 후에 이전 객체 버전을 S3 Glacier로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성합니다.\\nB. 30일 후에 현재 객체 버전을 S3 Standard 스토리지에서 S3 Glacier로 이동하고 1일 후에 이전 객체 버전을 S3 Glacier Deep Archive로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성합니다.\\nC. 30일 후에 현재 객체 버전을 S3 Standard 스토리지에서 S3 Standard-infrequent Access(S3 Standard-IA)로 이동하고 1일 후에 이전 객체 버전을 S3 Glacier Deep Archive로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성합니다.\\nD. 30일 후에 현재 객체 버전을 S3 표준 스토리지에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 이동하고 1일 후에 이전 객체 버전을 S3 Glacier Deep Archive로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성합니다.\", \"A business demands the retention of all versions of items in its Amazon S3 bucket. During the first 30 days, current object versions will be often visited; afterwards, they will be seldom accessed and must be retrievable within 5 minutes. Previous object versions must be retained indefinitely, will be viewed seldom, and may be recovered within a week. All storage options must be very accessible and durable.\\nWhat should a solutions architect propose as the MOST cost-effective method of meeting these requirements?\\n\\nA.Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier after 1 day.\\nB. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day.\\nC. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Standard-infrequent Access (S3 Standard-IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day.\\nD. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day.\", \"B\"],\n[\"기업은 Auto Scaling 그룹에서 제공한 Amazon EC2 인스턴스에 대한 요구 사항을 재평가해야 합니다. 현재 Auto Scaling 그룹은 2개의 가용 영역에서 2개 이상, 4개 이하의 인스턴스를 실행하도록 설정되어 있습니다. 솔루션 설계자는 Amazon CloudWatch 분석을 평가하고 모든 EC2 인스턴스의 CPU 사용량이 일관되게 낮다는 것을 발견했습니다.\\n솔루션 설계자는 애플리케이션에서 내결함성을 유지하면서 사용을 개선하기 위해 무엇을 제안해야 합니까?\\n\\nA.일부 EC2 인스턴스를 제거하여 나머지 인스턴스의 활용도를 높입니다.\\nB. CPU 사용률이 낮은 인스턴스의 Amazon Elastic Block Store(Amazon EBS) 용량을 늘립니다.\\nC. Auto Scaling 그룹 조정 정책을 수정하여 더 높은 CPU 사용률 지표를 기반으로 축소 및 축소합니다.\\nD. 더 작은 인스턴스 유형을 사용하는 새로운 시작 구성을 생성합니다. 기존 Auto Scaling 그룹을 업데이트합니다.\", \"A business must reassess its requirements for the Amazon EC2 instances it has supplied in an Auto Scaling group. At the moment, the Auto Scaling group is set to run no less than two instances and no more than four instances across two Availability Zones. A solutions architect evaluated Amazon CloudWatch analytics and discovered that CPU usage for all EC2 instances is consistently low.\\nWhat should the solutions architect propose to improve usage while maintaining fault tolerance in the application?\\n\\nA.Remove some EC2 instances to increase the utilization of remaining instances.\\nB. Increase the Amazon Elastic Block Store (Amazon EBS) capacity of instances with less CPU utilization.\\nC. Modify the Auto Scaling group scaling policy to scale in and out based on a higher CPU utilization metric.\\nD. Create a new launch configuration that uses smaller instance types. Update the existing Auto Scaling group.\", \"D\"],\n[\"한 회사에서 Application Load Balancer를 사용하여 3개의 AWS 리전에 애플리케이션을 설치하고 있습니다. 이러한 리전에 트래픽을 분산하기 위해 Amazon Route 53이 활용됩니다.\\n솔루션 설계자는 가능한 최고의 성능을 얻기 위해 어떤 Route 53 구성을 사용해야 합니까?\\n\\nA.대기 시간 정책을 사용하여 A 레코드를 생성합니다.\\nB. 지리적 위치 정책으로 A 레코드를 생성합니다.\\nC. 장애 조치 정책으로 CNAME 레코드를 생성합니다.\\nD. 지리 근접성 정책으로 CNAME 레코드를 생성합니다.\", \"A firm is installing an application in three AWS Regions utilizing an Application Load Balancer. To distribute traffic across these Regions, Amazon Route 53 will be utilized.\\nWhich Route 53 configuration should a solutions architect employ to get the highest possible performance?\\n\\nA.Create an A record with a latency policy.\\nB. Create an A record with a geolocation policy.\\nC. Create a CNAME record with a failover policy.\\nD. Create a CNAME record with a geoproximity policy.\", \"A\"],\n[\"기업은 30일 이내에 데이터 센터에서 AWS 클라우드로 20TB의 데이터를 이동해야 합니다. 조직의 네트워크 용량은 15Mbps로 제한되며 70%를 초과할 수 없습니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.AWS Snowball을 사용합니다.\\nB. AWS DataSync를 사용합니다.\\nC. 보안 VPN 연결을 사용합니다.\\nD. Amazon S3 Transfer Acceleration을 사용합니다.\", \"Within 30 days, a corporation must move 20 TB of data from a data center to the AWS Cloud. The network capacity of the organization is restricted to 15 Mbps and cannot exceed 70% use.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Use AWS Snowball.\\nB. Use AWS DataSync.\\nC. Use a secure VPN connection.\\nD. Use Amazon S3 Transfer Acceleration.\", \"A\"],\n[\"AWS 클라우드에서 기업은 다계층 전자 상거래 웹 애플리케이션을 운영하고 있습니다. Amazon EC2 인스턴스는 웹 애플리케이션을 호스팅하는 데 사용됩니다. 데이터베이스 계층은 다중 AZ 환경에서 작성기 및 판독기와 함께 배포되는 Amazon Aurora MySQL DB 클러스터에서 호스팅됩니다. 데이터베이스 계층의 새로운 요구 사항은 인스턴스 장애 조치를 통해 지속적인 쓰기 가용성을 제공하기 위해 애플리케이션에 서비스를 제공하는 것입니다.\\n이 새로운 요구 사항을 준수하기 위해 솔루션 설계자는 무엇을 해야 합니까?\\n\\nA.다중 쓰기를 위해 DB 클러스터에 새 AWS 리전을 추가합니다.\\nB. 작성자와 동일한 가용 영역에 새 리더를 추가합니다.\\nC. 데이터베이스 계층을 Aurora 다중 마스터 클러스터로 마이그레이션합니다.\\nD. 병렬 쿼리가 활성화된 Aurora DB 클러스터로 데이터베이스 계층을 마이그레이션합니다.\", \"In the AWS Cloud, a business is operating a multi-tier ecommerce web application. Amazon EC2 instances are used to host the web application. The database layer is hosted on an Amazon Aurora MySQL DB cluster that is deployed with a writer and a reader in a Multi-AZ environment. The database tier's new need is to service the application in order to provide continuous write availability through instance failover.\\nWhat is a solutions architect to do in order to comply with this new requirement?\\n\\nA.Add a new AWS Region to the DB cluster for multiple writes.\\nB. Add a new reader in the same Availability Zone as the writer.\\nC. Migrate the database tier to an Aurora multi-master cluster.\\nD. Migrate the database tier to an Aurora DB cluster with parallel query enabled.\", \"C\"],\n[\"조직은 VPC의 프라이빗 서브넷에 있는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. EC2 인스턴스는 Auto Scaling 그룹에 구성되며 Elastic Load Balancer(ELB)를 통해 Elastic Load Balancer에 연결됩니다. 아웃바운드 인터넷 연결을 위해 EC2 인스턴스는 NAT 게이트웨이를 사용합니다. 반면 EC2 인스턴스는 소프트웨어 업데이트를 받기 위해 공용 인터넷에 액세스할 수 없습니다.\\n이 문제의 근본적인 이유는 무엇입니까? (2개를 선택하세요.)\\n\\nA.ELB가 적절한 상태 확인으로 구성되지 않았습니다.\\nB. VPC의 라우팅 테이블이 잘못 구성되었습니다.\\nC. EC2 인스턴스는 탄력적 IP 주소와 연결되어 있지 않습니다.\\nD. NAT 게이트웨이에 연결된 보안 그룹이 잘못 구성되었습니다.\\nE. EC2 인스턴스에 연결된 보안 그룹의 아웃바운드 규칙이 잘못 구성되었습니다.\", \"An organization hosts an application on Amazon EC2 instances in a private subnet of a VPC. The EC2 instances are configured in an Auto Scaling group and are connected to an Elastic Load Balancer through an Elastic Load Balancer (ELB). For outbound internet connectivity, the EC2 instances make use of a NAT gateway. EC2 instances, on the other hand, are unable to access to the public internet in order to get software updates.\\nWhat might be the underlying reasons of this problem? (Select two.)\\n\\nA.The ELB is not configured with a proper health check.\\nB. The route tables in the VPC are configured incorrectly.\\nC. The EC2 instances are not associated with an Elastic IP address.\\nD. The security group attached to the NAT gateway is configured incorrectly.\\nE. The outbound rules on the security group attached to the EC2 instances are configured incorrectly.\", \"B, E. NAT Gateway는 보안 그룹 지원 안함\"],\n[\"기업은 프로덕션 워크로드를 데이터 센터에서 클라우드로 마이그레이션할 때 AWS 클라우드 리소스에 대한 액세스에 대해 엄격한 보안 제어를 적용하려고 합니다.\\n회사의 경영진은 모든 이용자가 직책과 책임에 따라 권리를 획득하기를 원합니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 방법은 무엇입니까?\\n\\nA.AWS Single Sign-On 배포를 생성합니다. 사내 Active Directory에 연결하여 회사 전체의 사용자 및 권한을 중앙에서 관리합니다.\\nB. 각 직무에 대한 IAM 역할을 생성합니다. 각 직원이 AWS Management 콘솔에서 sts:AssumeRole 작업을 호출하여 직무를 수행하도록 요구합니다.\\nC. 각 직원에 대한 개별 IAM 사용자 계정을 생성합니다. 각 직무에 대한 IAM 정책을 생성하고 직무 역할에 따라 모든 IAM 사용자에게 정책을 연결합니다.\\nD. 각 직원에 대한 개별 IAM 사용자 계정을 생성합니다. 각 직무에 대한 IAM 정책을 생성합니다. IAM 그룹을 생성하고 각 그룹에 연결된 정책을 연결합니다. 직무 역할에 따라 IAM 사용자를 그룹에 할당합니다.\", \"A corporation wishes to impose stringent security controls on access to AWS Cloud resources as it migrates production workloads from its data centers to the cloud.\\nThe company's management desires that all users obtain rights according with their employment titles and responsibilities.\\nWhich method satisfies these criteria with the LEAST amount of operational overhead?\\n\\nA.Create an AWS Single Sign-On deployment. Connect to the on-premises Active Directory to centrally manage users and permissions across the company.\\nB. Create an IAM role for each job function. Require each employee to call the sts:AssumeRole action in the AWS Management Console to perform their job role.\\nC. Create individual IAM user accounts for each employee. Create an IAM policy for each job function, and attach the policy to all IAM users based on their job role.\\nD. Create individual IAM user accounts for each employee. Create IAM policies for each job function. Create IAM groups, and attach associated policies to each group. Assign the IAM users to a group based on their job role.\", \"A\"],\n[\"비즈니스 요구 사항에 따라 1주일 동안 진행되는 이벤트에 대해 특정 AWS 리전 내 지정된 3개의 가용 영역에서 Amazon EC2 용량이 보장됩니다.\\n조직은 EC2 용량을 유지하기 위해 무엇을 해야 합니까?\\n\\nA.필요한 리전을 지정하는 예약 인스턴스를 구매합니다.\\nB. 필요한 지역을 지정하는 온디맨드 용량 예약을 생성합니다.\\nC. 필요한 지역과 3개의 가용 영역을 지정하는 예약 인스턴스를 구매합니다.\\nD. 필요한 지역과 3개의 가용 영역을 지정하는 온디맨드 용량 예약을 생성합니다.\", \"A business need guaranteed Amazon EC2 capacity in three specified Availability Zones inside a certain AWS Region for a one-week-long event.\\nWhat should the organization do to ensure EC2 capacity is maintained?\\n\\nA.Purchase Reserved Instances that specify the Region needed.\\nB. Create an On-Demand Capacity Reservation that specifies the Region needed.\\nC. Purchase Reserved Instances that specify the Region and three Availability Zones needed.\\nD. Create an On-Demand Capacity Reservation that specifies the Region and three Availability Zones needed.\", \"D\"],\n[\"온라인 교육 제공업체가 AWS 클라우드로 전환하고 있습니다. 회사의 학생 기록은 PostgreSQL 데이터베이스에 저장됩니다. 조직에는 여러 AWS 리전에서 데이터를 항상 사용 가능하고 액세스할 수 있도록 하는 솔루션이 필요합니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 방법은 무엇입니까?\\n\\nA.PostgreSQL 데이터베이스를 Amazon EC2 인스턴스의 PostgreSQL 클러스터로 마이그레이션합니다.\\nB. 다중 AZ 기능이 켜진 상태에서 PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스로 마이그레이션합니다.\\nC. PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스로 마이그레이션합니다. 다른 리전에 읽기 전용 복제본을 생성합니다.\\nD. PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스로 마이그레이션합니다. 다른 리전에 복사할 DB 스냅샷을 설정합니다.\", \"A provider of online education is transitioning to the AWS Cloud. The company's student records are stored in a PostgreSQL database. The organization need a solution that ensures its data is always available and accessible across several AWS Regions.\\nWhich method satisfies these criteria with the LEAST amount of operational overhead?\\n\\nA.Migrate the PostgreSQL database to a PostgreSQL cluster on Amazon EC2 instances.\\nB. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance with the Multi-AZ feature turned on.\\nC. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.\\nD. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Set up DB snapshots to be copied to another Region.\", \"C\"],\n[\"솔루션 설계자는 Microsoft Windows Server에서 실행되는 온프레미스 데이터 센터의 기존 문서 관리 프로그램을 개선하고 있습니다.\\n이 프로그램은 네트워크 파일 공유를 광범위하게 사용하여 엄청난 수의 파일을 저장합니다. CIO는 온프레미스 스토리지를 AWS로 마이그레이션하여 온프레미스 데이터 센터의 설치 공간과 스토리지 비용을 줄이려고 합니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.AWS Storage Gateway 파일 게이트웨이를 설정합니다.\\nB. Amazon Elastic File System(Amazon EFS) 설정\\nC. AWS Storage Gateway를 볼륨 게이트웨이로 설정\\nD. Amazon Elastic Block Store(Amazon EBS) 볼륨을 설정합니다.\", \"A solutions architect is improving an on-premises data center's old document management program running on Microsoft Windows Server.\\nThe program makes extensive use of a network file sharing to store a huge number of files. The chief information officer wants to lower the footprint of on-premises data centers and storage expenses by migrating on-premises storage to AWS.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Set up an AWS Storage Gateway file gateway.\\nB. Set up Amazon Elastic File System (Amazon EFS)\\nC. Set up AWS Storage Gateway as a volume gateway\\nD. Set up an Amazon Elastic Block Store (Amazon EBS) volume.\", \"A. File gateway : 표준 스토리지 프로토콜. SMB, NFS를 통해 S3 엑세스 제공. Volume Gateway : iSCSI를 통한 블록 스토리지 볼륨 제공, 백업을 EBS스냅샷으로 제공\"],\n[\"기업은 현재 하드웨어 보안 모듈(HSM)에 대칭 암호화 키를 보관합니다. 솔루션 설계자는 AWS로의 키 관리 마이그레이션을 위한 솔루션 설계를 담당합니다. 고객 제공 키의 사용과 마찬가지로 키 순환이 지원되어야 합니다.\\n이러한 요구 사항을 준수하려면 중요한 재료를 어디에 보관해야 합니까?\\n\\nA.아마존 S3\\nB. AWS Secrets Manager\\nC. AWS Systems Manager 파라미터 스토어\\nD. AWS 키 관리 서비스(AWS KMS)\", \"A business keeps symmetric encryption keys in a hardware security module at the moment (HSM). A solutions architect is responsible for designing a solution for key management migration to AWS. Key rotation should be supported, as should the usage of customer-supplied keys.\\nWhere should critical material be housed to ensure compliance with these requirements?\\n\\nA.Amazon S3\\nB. AWS Secrets Manager\\nC. AWS Systems Manager Parameter store\\nD. AWS Key Management Service (AWS KMS)\", \"D, B 논란. KMS는 암호화 키 생성 및 관리. Secret Manager는 자격 증명, 비밀번호 저장\"],\n[\"제품 데이터 애플리케이션을 사용하면 회사 본사의 사용자가 제품 정보를 볼 수 있습니다. 제품 데이터는 Amazon RDS에서 호스팅하는 MySQL 데이터베이스 인스턴스에 저장됩니다. 운영 팀은 애플리케이션에서 성능 지연을 발견했으며 읽기 및 쓰기 트래픽을 분할하려고 합니다. 솔루션 설계자는 애플리케이션의 성능을 최적화하기 위해 빠르게 작업해야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.기존 데이터베이스를 다중 AZ 배포로 변경합니다. 기본 가용 영역에서 읽기 요청을 제공합니다.\\nB. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 보조 가용 영역에서 읽기 요청을 제공합니다.\\nC. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 컴퓨팅 및 스토리지 리소스의 절반을 원본 데이터베이스로 사용하여 읽기 전용 복제본을 구성합니다.\\nD. 데이터베이스에 대한 읽기 전용 복제본을 생성합니다. 원본 데이터베이스와 동일한 컴퓨팅 및 스토리지 리소스로 읽기 전용 복제본을 구성합니다.\", \"A product data application enables users at a company's headquarters to view product information. The product data is saved in a MySQL database instance hosted by Amazon RDS. The operations team has found a performance delay in the application and want to split read and write traffic. A solutions architect must work fast to optimize an application's performance.\\nWhat recommendations should the solutions architect make?\\n\\nA.Change the existing database to a Multi-AZ deployment. Serve the read requests from the primary Availability Zone.\\nB. Change the existing database to a Multi-AZ deployment. Serve the read requests from the secondary Availability Zone.\\nC. Create read replicas for the database. Configure the read replicas with half of the compute and storage resources as the source database.\\nD. Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.\", \"D\"],\n[\"기업은 인터넷 연결 애플리케이션 로드 밸런서(ALB) 뒤의 가상 사설 클라우드(VPC)에서 API를 구현했습니다. 두 번째 계정에서는 API를 클라이언트로 사용하는 애플리케이션이 NAT 게이트웨이 뒤의 프라이빗 서브넷에 설치됩니다. 클라이언트 애플리케이션에 대한 요청 수가 증가하면 NAT 게이트웨이 비용이 예상을 초과합니다. ALB는 솔루션 설계자가 내부적으로 설정했습니다.\\n어떤 아키텍처 개선이 가장 낮은 NAT 게이트웨이 비용으로 이어집니까? (2개를 선택하세요.)\\n\\nA.두 VPC 간에 VPC 피어링 연결을 구성합니다. 비공개 주소를 사용하여 API에 액세스합니다.\\nB. 두 VPC 간에 AWS Direct Connect 연결을 구성합니다. 비공개 주소를 사용하여 API에 액세스합니다.\\nC. API에 대한 ClassicLink 연결을 클라이언트 VPC에 구성합니다. ClassicLink 주소를 사용하여 API에 액세스합니다.\\nD. API에 대한 PrivateLink 연결을 클라이언트 VPC로 구성합니다. PrivateLink 주소를 사용하여 API에 액세스합니다.\\nE. 두 계정 간에 AWS Resource Access Manager 연결을 구성합니다. 비공개 주소를 사용하여 API에 액세스합니다.\", \"A business has implemented an API in a Virtual Private Cloud (VPC) behind an internet-facing Application Load Balancer (ALB). In a second account, an application that uses the API as a client is installed in private subnets behind a NAT gateway. When the number of requests to the client application increases, the NAT gateway expenses exceed expectations. The ALB has been set to be internal by a solutions architect.\\nWhich architectural improvements will result in the lowest NAT gateway costs? (Select two.)\\n\\nA.Configure a VPC peering connection between the two VPCs. Access the API using the private address.\\nB. Configure an AWS Direct Connect connection between the two VPCs. Access the API using the private address.\\nC. Configure a ClassicLink connection for the API into the client VPC. Access the API using the ClassicLink address.\\nD. Configure a PrivateLink connection for the API into the client VPC. Access the API using the PrivateLink address.\\nE. Configure an AWS Resource Access Manager connection between the two accounts. Access the API using the private address.\", \"A, D\"],\n[\"최근 한 기업이 프라이빗 서브넷의 Amazon EC2에 Linux 기반 애플리케이션 인스턴스를 구축하고 VPC의 퍼블릭 서브넷에 있는 Amazon EC2 인스턴스에 Linux 기반 배스천 호스트를 구축했습니다. 솔루션 설계자는 회사의 인터넷 연결을 통해 온프레미스 네트워크에서 배스천 호스트 및 애플리케이션 서버로의 연결을 설정해야 합니다. 솔루션 설계자는 모든 EC2 인스턴스의 보안 그룹이 이 액세스를 허용하는지 확인해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (2개를 선택하세요.)\\n\\nA.배스천 호스트의 현재 보안 그룹을 애플리케이션 인스턴스의 인바운드 액세스만 허용하는 보안 그룹으로 교체합니다.\\nB. 배스천 호스트의 현재 보안 그룹을 회사의 사설 IP 범위에서만 인바운드 액세스를 허용하는 보안 그룹으로 교체합니다.\\nC. 배스천 호스트의 현재 보안 그룹을 회사의 공용 IP 범위에서만 인바운드 액세스를 허용하는 보안 그룹으로 교체합니다.\\nD. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 사설 IP 주소에서만 인바운드 SSH 액세스를 허용하는 보안 그룹으로 교체합니다.\\nE. 애플리케이션 인스턴스의 현재 보안 그룹을 배스천 호스트의 공용 IP 주소에서만 인바운드 SSH 액세스를 허용하는 보안 그룹으로 교체합니다.\", \"Recently, a corporation built Linux-based application instances on Amazon EC2 in a private subnet and a Linux-based bastion host on an Amazon EC2 instance in a VPC's public subnet. A solutions architect must establish connections from the on-premises network to the bastion host and application servers through the company's internet connection. The solutions architect must ensure that all EC2 instances' security groups permit this access.\\nWhich measures should the solutions architect do in combination to satisfy these requirements? (Select two.)\\n\\nA.Replace the current security group of the bastion host with one that only allows inbound access from the application instances.\\nB. Replace the current security group of the bastion host with one that only allows inbound access from the internal IP range for the company.\\nC. Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company.\\nD. Replace the current security group of the application instances with one that allows inbound SSH access from only the private IP address of the bastion host.\\nE. Replace the current security group of the application instances with one that allows inbound SSH access from only the public IP address of the bastion host.\", \"C, D\"],\n[\"회사의 보안 정책에 따라 AWS 계정의 모든 AWS API 활동은 정기적으로 추적 및 감사됩니다. 회사는 AWS Organizations를 사용하는 모든 기존 및 향후 AWS 계정에서 AWS CloudTrail을 활성화해야 합니다.\\n다음 중 가장 안전한 솔루션은 무엇입니까?\\n\\nA.조직의 루트에서 CloudTrail만 활성화하도록 허용하는 SCP(서비스 제어 정책)를 정의하고 연결합니다.\\nB. 필요에 따라 조직의 관리 계정에 IAM 그룹을 생성합니다. 사용자가 CloudTrail을 비활성화하지 못하도록 하는 IAM 정책을 정의하고 그룹에 연결합니다.\\nC. 계정을 조직 단위(OU)로 구성합니다. 조직의 루트에서 사용자가 CloudTrail을 비활성화하지 못하도록 하는 SCP(서비스 제어 정책)를 정의하고 연결합니다.\\nD. 조직의 루트 아래에 있는 모든 기존 계정을 추가합니다. 사용자가 CloudTrail을 비활성화하지 못하도록 하는 서비스 제어 정책(SCP)을 정의하고 모든 계정에 연결합니다.\", \"A company's security policy mandates that all AWS API activity in its AWS accounts be tracked and audited on a regular basis. The firm must activate AWS CloudTrail on all existing and future AWS accounts that use AWS Organizations.\\nWhich of the following solutions is the MOST SECURE?\\n\\nA.At the organization's root, define and attach a service control policy (SCP) that permits enabling CloudTrail only.\\nB. Create IAM groups in the organization's management account as needed. Define and attach an IAM policy to the groups that prevents users from disabling CloudTrail.\\nC. Organize accounts into organizational units (OUs). At the organization's root, define and attach a service control policy (SCP) that prevents users from disabling CloudTrail.\\nD. Add all existing accounts under the organization's root. Define and attach a service control policy (SCP) to every account that prevents users from disabling CloudTrail.\", \"C\"],\n[\"솔루션 설계자는 다양한 가용 영역에 분산된 웹 애플리케이션을 위한 공유 스토리지 솔루션을 구축하는 책임이 있습니다. 웹 애플리케이션은 자동으로 조정되는 Amazon EC2 인스턴스에서 호스팅됩니다. 회사는 정기적으로 정보를 업데이트할 계획입니다. 솔루션은 수정되는 즉시 업데이트된 자료를 제공하는 데 있어 매우 일관성이 있어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까? (2개를 선택하세요.)\\n\\nA.개별 EC2 인스턴스에 탑재된 AWS Storage Gateway 볼륨 게이트웨이 iSCSI(Internet Small Computer Systems Interface) 블록 스토리지를 사용합니다.\\nB. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 개별 EC2 인스턴스에 EFS 파일 시스템을 탑재합니다.\\nC. 공유 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. 개별 EC2 인스턴스에 EBS 볼륨을 탑재합니다.\\nD. AWS DataSync를 사용하여 Auto Scaling 그룹의 EC2 호스트 간에 데이터의 지속적인 동기화를 수행합니다.\\nE. 웹 콘텐츠를 저장할 Amazon S3 버킷을 생성합니다. Cache-Control 헤더의 메타데이터를 no-cache로 설정합니다. Amazon CloudFront를 사용하여 콘텐츠를 제공합니다.\", \"A solutions architect is tasked with the responsibility of building a shared storage solution for a web application that is distributed across various Availability Zones. The web application is hosted on Amazon EC2 instances that are automatically scaled. The firm intends to update the information on a regular basis. The solution must be very consistent in providing the updated material as soon as it is modified.\\nWhich solutions satisfy these criteria? (Select two.)\\n\\nA.Use AWS Storage Gateway Volume Gateway Internet Small Computer Systems Interface (iSCSI) block storage that is mounted to the individual EC2 instances.\\nB. Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on the individual EC2 instances.\\nC. Create a shared Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on the individual EC2 instances.\\nD. Use AWS DataSync to perform continuous synchronization of data between EC2 hosts in the Auto Scaling group.\\nE. Create an Amazon S3 bucket to store the web content. Set the metadata for the Cache-Control header to no-cache. Use Amazon CloudFront to deliver the content.\", \"B, D. B, E라는 의견도 있는데 AWS설명에 따르면 B,D가 맞는 듯. AWS DataSync는 , 자동화, 온프레미스 스토리지 시스템 간 및 AWS 스토리지 서비스 간 데이터 이동 및 복제 가속화 DataSync는 (...) amazon EFS 파일 시스템 간에 데이터를 복사할 수 있습니다.\"],\n[\"AWS에서 기업은 느슨하게 연결된 마이크로서비스 모음으로 온라인 마켓플레이스 애플리케이션을 개발하려고 합니다. 클라이언트가 새 주문을 하면 두 개의 마이크로서비스가 이 애플리케이션에서 동시에 이벤트를 처리해야 합니다. 이메일 마이크로서비스를 통해 확인 이메일이 전송되고 OrderProcessing 마이크로서비스가 주문 배송 절차를 시작합니다. 클라이언트가 주문을 취소하면 OrderCancellation 및 Email 마이크로서비스가 취소를 동시에 처리해야 합니다.\\n솔루션 설계자는 Amazon Simple Queue Service(Amazon SQS)와 Amazon Simple Notification Service(Amazon SNS)를 사용하여 마이크로서비스 간의 통신을 구축하려고 합니다.\\n솔루션 설계자는 솔루션을 설계하는 동안 어떤 접근 방식을 사용해야 합니까?\\n\\nA.단일 SQS 대기열을 만들고 여기에 주문 이벤트를 게시합니다. 그런 다음 이메일 OrderProcessing 및 OrderCancellation 마이크로서비스는 대기열의 메시지를 사용할 수 있습니다.\\nB. 각 마이크로 서비스에 대해 3개의 SNS 주제를 생성합니다. 세 가지 주제에 주문 이벤트를 게시합니다. 각 이메일 OrderProcessing 및 OrderCancellation 마이크로서비스를 자체 주제에 구독합니다.\\nC. SNS 주제를 생성하고 이에 대한 주문 이벤트를 게시합니다. 이메일 OrderProcessing 및 OrderCancellation 마이크로서비스에 대해 3개의 SQS 대기열을 만듭니다. 메시지 필터링을 사용하여 모든 SQS 대기열을 SNS 주제에 구독합니다.\\nD. 두 개의 SQS 대기열을 만들고 동시에 두 대기열에 주문 이벤트를 게시합니다. 하나의 대기열은 Email 및 OrderProcessing 마이크로서비스를 위한 것입니다. 두 번째 대기열은 Email 및 OrderCancellation 마이크로서비스용입니다.\", \"On AWS, a business want to develop an online marketplace application as a collection of loosely linked microservices. When a client places a new order, two microservices should process the event concurrently in this application. A confirmation email will be sent via the Email microservice, and the OrderProcessing microservice will initiate the order delivery procedure. When a client cancels an order, the OrderCancellation and Email microservices should process the cancellation concurrently.\\nA solutions architect want to build the communications between microservices using Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS).\\nWhat approach should the solutions architect use while designing the solution?\\n\\nA.Create a single SQS queue and publish order events to it. The Email OrderProcessing and OrderCancellation microservices can then consume messages of the queue.\\nB. Create three SNS topics for each microservice. Publish order events to the three topics. Subscribe each of the Email OrderProcessing and OrderCancellation microservices to its own topic.\\nC. Create an SNS topic and publish order events to it. Create three SQS queues for the Email OrderProcessing and OrderCancellation microservices. Subscribe all SQS queues to the SNS topic with message filtering.\\nD. Create two SQS queues and publish order events to both queues simultaneously. One queue is for the Email and OrderProcessing microservices. The second queue is for the Email and OrderCancellation microservices.\", \"C\"],\n[\"한 기업이 Amazon DynamoDB 데이터베이스에서 읽고 쓸 웹사이트를 개발 중입니다. 웹사이트의 트래픽은 주중 업무 시간에 최고조에 달하고 야간 및 주말에 감소한다는 점에서 예측 가능합니다. 솔루션 설계자는 비용 효율적이고 수요를 처리할 수 있는 솔루션을 만들어야 합니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.DynamoDB Accelerator(DAX)를 활성화하여 데이터를 캐시합니다.\\nB. DynamoDB 데이터베이스에 대해 다중 AZ 복제를 활성화합니다.\\nC. 테이블을 생성할 때 DynamoDB Auto Scaling을 활성화합니다.\\nD. 테이블을 생성할 때 DynamoDB 온디맨드 용량 할당을 활성화합니다.\", \"A business is developing a website that will read from and write to an Amazon DynamoDB database. The website's traffic is predictable in that it peaks during business hours on weekdays and falls overnight and on weekends. A solutions architect must create a solution that is both cost efficient and capable of handling the demand.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Enable DynamoDB Accelerator (DAX) to cache the data.\\nB. Enable Multi-AZ replication for the DynamoDB database.\\nC. Enable DynamoDB auto scaling when creating the tables.\\nD. Enable DynamoDB On-Demand capacity allocation when creating the tables.\", \"C. DAX는 읽기 집약적일 때 효율적.\"],\n[\"기업은 온프레미스 데이터 센터를 통해 정적 웹사이트를 유지 관리합니다. 회사에는 모든 트래픽을 관리하는 많은 서버가 있지만 바쁜 날에는 서비스가 중단되고 웹 사이트에 액세스할 수 없는 경우가 있습니다. 이 회사는 전 세계적으로 발자취를 남기기를 원하며 온라인 트래픽을 3배로 늘릴 계획입니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.웹 사이트 콘텐츠를 Amazon S3로 마이그레이션하고 Amazon CloudFront에서 웹 사이트를 호스팅합니다.\\nB. 여러 AWS 리전에서 퍼블릭 탄력적 IP 주소를 사용하여 웹 사이트 콘텐츠를 Amazon EC2 인스턴스로 마이그레이션합니다.\\nC. 웹 사이트 콘텐츠를 Amazon EC2 인스턴스로 마이그레이션하고 부하가 증가함에 따라 수직으로 확장합니다.\\nD. Amazon Route 53을 사용하여 전 세계적으로 존재하는 각 AWS 리전의 여러 Amazon CloudFront 배포에 로드를 분산합니다.\", \"A business maintains a static website through its on-premises data center. Although the firm has many servers that manage all of its traffic, services are sometimes disrupted and the website goes inaccessible on busy days. The corporation wants to have a worldwide footprint and intends to treble its online traffic.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Migrate the website content to Amazon S3 and host the website on Amazon CloudFront.\\nB. Migrate the website content to Amazon EC2 instances with public Elastic IP addresses in multiple AWS Regions.\\nC. Migrate the website content to Amazon EC2 instances and vertically scale as the load increases.\\nD. Use Amazon Route 53 to distribute the loads across multiple Amazon CloudFront distributions for each AWS Region that exists globally.\", \"A\"],\n[\"기업의 웹 사이트는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 호스팅됩니다. 웹 사이트에는 동적 정보와 정적 정보가 결합되어 있습니다. 전 세계의 사용자들이 웹사이트의 속도 저하에 대해 불평하고 있습니다.\\n전 세계 사용자의 웹사이트 성능이 향상되는 일련의 활동은 무엇입니까?\\n\\nA.Amazon CloudFront 배포를 생성하고 ALB를 오리진으로 구성합니다. 그런 다음 CloudFront 배포를 가리키도록 Amazon Route 53 레코드를 업데이트합니다.\\nB. ALB에 대한 지연 시간 기반 Amazon Route 53 레코드를 생성합니다. 그런 다음 더 큰 인스턴스 크기로 새 EC2 인스턴스를 시작하고 해당 인스턴스를 ALB에 등록합니다.\\nC. 사용자에게 더 가까운 다른 리전에서 동일한 웹 애플리케이션을 호스팅하는 새로운 EC2 인스턴스를 시작합니다. 그런 다음 교차 리전 VPC 피어링을 사용하여 동일한 ALB에 인스턴스를 등록합니다.\\nD. 사용자와 가장 가까운 리전의 Amazon S3 버킷에서 웹 사이트를 호스팅하고 ALB 및 EC2 인스턴스를 삭제합니다. 그런 다음 S3 버킷을 가리키도록 Amazon Route 53 레코드를 업데이트합니다.\", \"The website of a business is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). There is a combination of dynamic and static information on the website. Users from all around the world are complaining about the website's slowness.\\nWhich set of activities will result in an increase in website performance for global users?\\n\\nA.Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution.\\nB. Create a latency-based Amazon Route 53 record for the ALB. Then launch new EC2 instances with larger instance sizes and register the instances with the ALB.\\nC. Launch new EC2 instances hosting the same web application in different Regions closer to the users. Then register instances with the same ALB using cross- Region VPC peering.\\nD. Host the website in an Amazon S3 bucket in the Regions closest to the users and delete the ALB and EC2 instances. Then update an Amazon Route 53 record to point to the S3 buckets.\", \"A\"],\n[\"비즈니스에 가끔 사용되는 웹 응용 프로그램이 있습니다. 매월 초에는 사용량이 급증하고, 매주 초에는 약간의 사용량이 급증하고, 한 주 내내 예상치 못한 사용량이 급증합니다. 이 프로그램은 데이터 센터 내부에 있는 웹 서버와 MySQL 데이터베이스 서버로 구성됩니다. 이 회사는 애플리케이션을 AWS 클라우드로 마이그레이션하고 데이터베이스 조정이 필요하지 않은 저렴한 데이터베이스 플랫폼을 선택해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Amazon DynamoDB\\nB. MySQL용 Amazon RDS\\nC. MySQL 호환 Amazon Aurora Serverless\\nD. Auto Scaling 그룹의 Amazon EC2에 배포된 MySQL\", \"A business has a web application that receives occasional use. Each month, there is a spike in use at the beginning, a minor spike at the start of each week, and an unexpected spike throughout the week. The program is made up of a web server and a MySQL database server that are both located inside the data center. The firm want to migrate the application to the AWS Cloud and needs to choose an affordable database platform that does not need database adjustments.\\nWhich solution will satisfy these criteria?\\n\\nA.Amazon DynamoDB\\nB. Amazon RDS for MySQL\\nC. MySQL-compatible Amazon Aurora Serverless\\nD. MySQL deployed on Amazon EC2 in an Auto Scaling group\", \"C\"],\n[\"한 비즈니스에서 고객이 Amazon S3에 작은 파일을 업로드할 수 있는 애플리케이션을 개발 중입니다. 사용자가 파일을 업로드한 후 1회 기본 처리를 거쳐 데이터를 변경하고 추가 분석을 위해 JSON 형식으로 저장합니다.\\n각 파일은 업로드 즉시 처리되어야 합니다. 수요가 변동될 것입니다. 어떤 날에는 사람들이 비정상적으로 많은 양의 파일을 업로드합니다. 다른 날에는 사람들이 적은 수의 파일을 업로드하거나 전혀 업로드하지 않습니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 방법은 무엇입니까?\\n\\nA.Amazon S3에서 텍스트 파일을 읽도록 Amazon EMR을 구성합니다. 처리 스크립트를 실행하여 데이터를 변환합니다. 결과 JSON 파일을 Amazon Aurora DB 클러스터에 저장합니다.\\nB. 이벤트 알림을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내도록 Amazon S3를 구성합니다. Amazon EC2 인스턴스를 사용하여 대기열에서 읽고 데이터를 처리합니다. 결과 JSON 파일을 Amazon DynamoDB에 저장합니다.\\nC. 이벤트 알림을 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내도록 Amazon S3를 구성합니다. AWS Lambda 함수를 사용하여 대기열에서 읽고 데이터를 처리합니다. 결과 JSON 파일을 Amazon DynamoDB에 저장합니다.\\nD. 새 파일이 업로드될 때 Amazon Kinesis Data Streams에 이벤트를 보내도록 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. AWS Lambda 함수를 사용하여 스트림에서 이벤트를 소비하고 데이터를 처리합니다. 결과 JSON 파일을 Amazon Aurora DB 클러스터에 저장합니다.\", \"A business is developing an application that will allow customers to upload tiny files to Amazon S3. After a user uploads a file, it undergoes one-time basic processing to change the data and store it in JSON format for further analysis.\\nEach file must be handled immediately upon upload. Demand will fluctuate. On some days, people will upload an unusually large amount of files. On other days, people will upload a small number of files or none at all.\\nWhich method satisfies these criteria with the LEAST amount of operational overhead?\\n\\nA.Configure Amazon EMR to read text files from Amazon S3. Run processing scripts to transform the data. Store the resulting JSON file in an Amazon Aurora DB cluster.\\nB. Configure Amazon S3 to send an event notification to an Amazon Simple Queue Service (Amazon SQS) queue. Use Amazon EC2 instances to read from the queue and process the data. Store the resulting JSON file in Amazon DynamoDB.\\nC. Configure Amazon S3 to send an event notification to an Amazon Simple Queue Service (Amazon SQS) queue. Use an AWS Lambda function to read from the queue and process the data. Store the resulting JSON file in Amazon DynamoDB.\\nD. Configure Amazon EventBridge (Amazon CloudWatch Events) to send an event to Amazon Kinesis Data Streams when a new file is uploaded. Use an AWS Lambda function to consume the event from the stream and process the data. Store the resulting JSON file in Amazon Aurora DB cluster.\", \"C\"],\n[\"기업에서 마이크로서비스 애플리케이션을 구축했습니다. Amazon API Gateway와 통합된 클라이언트 대면 API 및 Amazon EC2 인스턴스에 배포된 여러 내부 서비스를 사용하여 사용자 쿼리를 처리합니다. API는 예상치 못한 트래픽 급증을 처리하도록 구축되었지만 내부 서비스가 과부하 상태가 되어 일시적으로 서비스를 사용할 수 없게 될 수 있습니다. 솔루션 설계자는 내부 서비스를 사용할 수 없거나 응답하지 않을 때 실수를 최소화하는 보다 신뢰할 수 있는 솔루션을 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.트래픽이 급증할 때 AWS Auto Scaling을 사용하여 내부 서비스를 확장합니다.\\nB. 다른 가용 영역을 사용하여 내부 서비스를 호스팅합니다. 내부 서비스가 응답하지 않을 때 시스템 관리자에게 알림을 보냅니다.\\nC. Elastic Load Balancer를 사용하여 내부 서비스 간에 트래픽을 분산합니다. 내부 서비스에 대한 트래픽을 모니터링하도록 Amazon CloudWatch 지표를 구성합니다.\\nD. Amazon Simple Queue Service(Amazon SQS)를 사용하여 도착하는 사용자 요청을 저장합니다. 처리를 위해 대기열에서 요청을 검색하도록 내부 서비스를 변경합니다.\", \"A business has built a microservices application. It processes user queries using a client-facing API integrated with Amazon API Gateway and several internal services deployed on Amazon EC2 instances. Although the API is built to handle unforeseen traffic spikes, internal services may become overloaded and unavailable for a brief period during surges. A solutions architect must provide a more dependable solution that minimizes mistakes when internal services become unavailable or unresponsive.\\nWhich solution satisfies these criteria?\\n\\nA.Use AWS Auto Scaling to scale up internal services when there is a surge in traffic.\\nB. Use different Availability Zones to host internal services. Send a notification to a system administrator when an internal service becomes unresponsive.\\nC. Use an Elastic Load Balancer to distribute the traffic between internal services. Configure Amazon CloudWatch metrics to monitor traffic to internal services.\\nD. Use Amazon Simple Queue Service (Amazon SQS) to store user requests as they arrive. Change the internal services to retrieve the requests from the queue for processing.\", \"D\"],\n[\"기업에서 온프레미스 HPC(고성능 컴퓨팅) 애플리케이션과 데이터를 AWS 클라우드로 전송하려고 합니다. 온프레미스 스토리지는 계층화되어 있으며 주기적인 실행 중에 프로그램을 지원하는 핫 고성능 병렬 스토리지와 애플리케이션이 활발히 작동하지 않는 동안 데이터를 저장하는 보다 비용 효율적인 콜드 스토리지가 있습니다.\\n솔루션 설계자는 애플리케이션의 스토리지 요구 사항을 충족하기 위해 어떤 솔루션 조합을 제안해야 합니까? (2개를 선택하세요.)\\n\\nA.콜드 데이터 스토리지를 위한 Amazon S3\\nB. 콜드 데이터 스토리지를 위한 Amazon Elastic File System(Amazon EFS)\\nC. 고성능 병렬 스토리지를 위한 Amazon S3\\nD. 고성능 병렬 스토리지를 위한 Lustre용 Amazon FSx\\nE. 고성능 병렬 스토리지를 위한 Windows용 Amazon FSx\", \"A business wishes to transfer an on-premises high performance computing (HPC) application and data to the AWS Cloud. On-premises storage is tiered, with hot high-performance parallel storage supporting the program during periodic runs and more cost-effective cold storage storing data while the application is not actively operating.\\nWhich solution combination should a solutions architect propose to meet the application's storage requirements? (Select two.)\\n\\nA.Amazon S3 for cold data storage\\nB. Amazon Elastic File System (Amazon EFS) for cold data storage\\nC. Amazon S3 for high-performance parallel storage\\nD. Amazon FSx for Lustre for high-performance parallel storage\\nE. Amazon FSx for Windows for high-performance parallel storage\", \"A, D\"],\n[\"비즈니스는 IPv6 주소가 장착된 Amazon EC2 인스턴스에서 앱을 호스팅합니다. 인터넷을 통해 앱은 다른 외부 응용 프로그램과 통신을 시작해야 합니다. 그러나 회사의 보안 정책에 따라 외부 서비스는 EC2 인스턴스에 대한 연결을 시작할 수 없습니다.\\n솔루션 설계자는 이 문제에 대한 해결책으로 무엇을 제안해야 합니까?\\n\\nA.NAT 게이트웨이를 생성하고 서브넷의 라우팅 테이블의 대상으로 만듭니다.\\nB. 인터넷 게이트웨이를 만들고 서브넷의 라우팅 테이블의 대상으로 만듭니다.\\nC. 가상 프라이빗 게이트웨이를 생성하고 서브넷의 라우팅 테이블의 대상으로 만듭니다.\\nD. 송신 전용 인터넷 게이트웨이를 생성하고 서브넷 라우팅 테이블의 대상으로 만듭니다.\", \"A business hosts apps on Amazon EC2 instances equipped with IPv6 addresses. Through the internet, the apps must begin communications with other external applications. However, according to the company's security policy, no external service is permitted to start a connection to the EC2 instances.\\nWhat should a solutions architect suggest as a remedy to this problem?\\n\\nA.Create a NAT gateway and make it the destination of the subnet's route table.\\nB. Create an internet gateway and make it the destination of the subnet's route table.\\nC. Create a virtual private gateway and make it the destination of the subnet's route table.\\nD. Create an egress-only internet gateway and make it the destination of the subnet's route table.\", \"D. NAT Gateway는 IPv4전용. IPv6은 주소가 넘쳐나기 때문에 NAT같은거 사용 안하고 무조건 공용IP.\"],\n[\"솔루션 설계자는 미션 크리티컬 온라인 애플리케이션 개발을 담당합니다. Application Load Balancer를 통해 관계형 데이터베이스에 연결된 Amazon EC2 인스턴스로 구성됩니다. 데이터베이스는 가용성이 높아야 하고 내결함성이 있어야 합니다.\\n어떤 데이터베이스 구현이 이러한 기준을 충족할 수 있습니까? (2개를 선택하세요.)\\n\\nA.아마존 레드시프트\\nB. Amazon DynamoDB\\nC. MySQL용 Amazon RDS\\nD. MySQL 호환 Amazon Aurora 다중 AZ\\nE. SQL Server Standard Edition 다중 AZ용 Amazon RDS\", \"A solutions architect is tasked with the responsibility of developing a mission-critical online application. It will be comprised of Amazon EC2 instances connected to a relational database through an Application Load Balancer. The database should have a high degree of availability and should be fault tolerant.\\nWhich database implementations will be able to fulfill these criteria? (Select two.)\\n\\nA.Amazon Redshift\\nB. Amazon DynamoDB\\nC. Amazon RDS for MySQL\\nD. MySQL-compatible Amazon Aurora Multi-AZ\\nE. Amazon RDS for SQL Server Standard Edition Multi-AZ\", \"D, E\"],\n[\"한 기업이 콘텐츠 관리 시스템과 인터페이스할 웹 애플리케이션을 개발 중입니다. 콘텐츠 관리 시스템은 ALB(Application Load Balancer)를 통해 라우팅되는 Amazon EC2 인스턴스에서 호스팅됩니다. EC2 인스턴스는 Auto Scaling 그룹의 여러 가용 영역에 분산되어 있습니다. 콘텐츠 관리 시스템의 사용자는 파일, 블로그 및 기타 웹 사이트 자산을 지속적으로 추가 및 수정하고 있습니다.\\n솔루션 설계자는 가능한 최소 지연 시간으로 모든 EC2 인스턴스가 현재 웹 사이트 콘텐츠를 교환할 수 있도록 하는 솔루션을 설계해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Auto Scaling 그룹 수명 주기 정책에서 EC2 사용자 데이터를 업데이트하여 가장 최근에 시작된 EC2 인스턴스에서 웹 사이트 자산을 복사합니다. 최신 EC2 인스턴스에서만 웹 사이트 자산을 변경하도록 ALB를 구성합니다.\\nB. 웹 사이트 자산을 Amazon Elastic File System(Amazon EFS) 파일 시스템에 복사합니다. EFS 파일 시스템을 로컬로 탑재하도록 각 EC2 인스턴스를 구성합니다. EFS 파일 시스템에 저장된 웹 사이트 자산을 참조하도록 웹 사이트 호스팅 응용 프로그램을 구성합니다.\\nC. 웹사이트 자산을 Amazon S3 버킷에 복사합니다. 각 EC2 인스턴스가 S3 버킷에서 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 웹 사이트 자산을 다운로드하는지 확인합니다. 파일을 최신 상태로 유지하려면 1시간에 한 번씩 S3 sync 명령을 실행합니다.\\nD. 웹사이트 자산으로 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 복원합니다. 새 EC2 인스턴스가 시작될 때 EBS 스냅샷을 보조 EBS 볼륨으로 연결합니다. 보조 EBS 볼륨에 저장된 웹사이트 자산을 참조하도록 웹사이트 호스팅 애플리케이션을 구성합니다.\", \"A business is developing a web application that will interface with a content management system. The content management system is hosted on Amazon EC2 instances, which are routed via an Application Load Balancer (ALB). The EC2 instances are distributed across several Availability Zones in an Auto Scaling group. The content management system's users are continually adding and modifying files, blogs, and other website assets.\\nA solutions architect must design a solution that enables all EC2 instances to exchange current website content with the least amount of lag time feasible.\\nWhich solution satisfies these criteria?\\n\\nA.Update the EC2 user data in the Auto Scaling group lifecycle policy to copy the website assets from the EC2 instance that was launched most recently. Configure the ALB to make changes to the website assets only in the newest EC2 instance.\\nB. Copy the website assets to an Amazon Elastic File System (Amazon EFS) file system. Configure each EC2 instance to mount the EFS file system locally. Configure the website hosting application to reference the website assets that are stored in the EFS file system.\\nC. Copy the website assets to an Amazon S3 bucket. Ensure that each EC2 instance downloads the website assets from the S3 bucket to the attached Amazon Elastic Block Store (Amazon EBS) volume. Run the S3 sync command once each hour to keep files up to date.\\nD. Restore an Amazon Elastic Block Store (Amazon EBS) snapshot with the website assets. Attach the EBS snapshot as a secondary EBS volume when a new EC2 instance is launched. Configure the website hosting application to reference the website assets that are stored in the secondary EBS volume.\", \"B\"],\n[\"단일 AWS 계정을 통해 기업은 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터에서 인터넷 연결 컨테이너화된 웹 애플리케이션을 호스팅할 수 있습니다.\\nEKS 클러스터는 VPC의 프라이빗 서브넷 내부에 있습니다. EKS 클러스터는 공용 네트워크의 배스천 서버를 통해 시스템 관리자가 액세스합니다.\\n회사의 새로운 보안 정책은 배스천 호스트의 사용을 금지합니다. 또한 조직은 EKS 클러스터에 대한 인터넷 액세스를 금지해야 합니다.\\n비용 효율성 측면에서 이러한 기준에 가장 적합한 옵션은 무엇입니까?\\n\\nA.AWS Direct Connect 연결을 설정합니다.\\nB. Transit Gateway를 생성합니다.\\nC. VPN 연결을 설정합니다.\\nD. AWS Storage Gateway를 사용합니다.\", \"A single AWS account allows a business to host its internet-facing containerized web application on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.\\nThe EKS cluster is located inside a VPC's private subnet. The EKS cluster is accessed by system administrators through a bastion server on a public network.\\nThe company's new security policy prohibits the usage of bastion hosts. Additionally, the organization must prohibit internet access to the EKS cluster.\\nWhich option best fits these criteria in terms of cost-effectiveness?\\n\\nA.Set up an AWS Direct Connect connection.\\nB. Create a transit gateway.\\nC. Establish a VPN connection.\\nD. Use AWS Storage Gateway.\", \"C\"],\n[\"비즈니스에는 완료하는 데 많은 수의 Amazon EC2 인스턴스를 사용해야 하는 매우 동적인 배치 처리 작업이 있습니다. 작업은 본질적으로 상태 비저장입니다. 즉, 손상을 입히지 않고 언제든지 시작 및 중지할 수 있으며 일반적으로 완료하는 데 최대 60분이 걸립니다. 조직은 솔루션 설계자를 고용하여 작업 요구 사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 개발했습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.EC2 스팟 인스턴스를 구현합니다.\\nB. EC2 예약 인스턴스 구매.\\nC. EC2 온디맨드 인스턴스를 구현합니다.\\nD. AWS Lambda에서 처리를 구현합니다.\", \"A business has a highly dynamic batch processing operation that requires the utilization of a large number of Amazon EC2 instances to finish. The work is stateless in nature, meaning it may be started and stopped at any moment without causing any damage, and normally takes up to 60 minutes to finish. The organization has engaged a solutions architect to develop a scalable and cost-effective solution that satisfies the job's needs.\\nWhat recommendations should the solutions architect make?\\n\\nA.Implement EC2 Spot Instances.\\nB. Purchase EC2 Reserved Instances.\\nC. Implement EC2 On-Demand Instances.\\nD. Implement the processing on AWS Lambda.\", \"A\"],\n[\"기업에는 공유 Amazon RDS MySQL 다중 AZ 데이터베이스 인스턴스에 정기적으로 액세스해야 하는 여러 웹 서버가 있습니다. 조직은 웹 서버가 데이터베이스에 연결할 수 있는 안전한 수단을 요구하는 동시에 사용자 자격 증명을 정기적으로 교체해야 하는 보안 요구 사항을 준수해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Secrets Manager에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 AWS Secrets Manager에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.\\nB. AWS Systems Manager OpsCenter에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 OpsCenter에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.\\nC. 안전한 Amazon S3 버킷에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버가 자격 증명을 검색하고 데이터베이스에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.\\nD. 웹 서버 파일 시스템에서 AWS Key Management Service(AWS KMS)로 암호화된 파일에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버는 파일을 해독하고 데이터베이스에 액세스할 수 있어야 합니다.\", \"A business has multiple web servers that regularly need access to a shared Amazon RDS MySQL Multi-AZ database instance. The organization requires a safe means for web servers to connect to the database while also adhering to a security requirement that user credentials be rotated on a regular basis.\\nWhich solution satisfies these criteria?\\n\\nA.Store the database user credentials in AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager.\\nB. Store the database user credentials in AWS Systems Manager OpsCenter. Grant the necessary IAM permissions to allow the web servers to access OpsCenter.\\nC. Store the database user credentials in a secure Amazon S3 bucket. Grant the necessary IAM permissions to allow the web servers to retrieve credentials and access the database.\\nD. Store the database user credentials in files encrypted with AWS Key Management Service (AWS KMS) on the web server file system. The web server should be able to decrypt the files and access the database.\", \"A\"],\n[\"한 기업에서 미션 크리티컬 데이터 세트를 Amazon S3로 마이그레이션하는 것을 고려하고 있습니다. 현재 솔루션 아키텍처는 버전 관리가 활성화된 us-east-1 리전의 단일 S3 버킷에 데이터 세트를 저장합니다. 회사의 재해 복구 전략에 따르면 모든 데이터는 다양한 AWS 리전에 복제됩니다.\\n솔루션 설계자는 S3 솔루션을 어떻게 설계해야 합니까?\\n\\nA.다른 리전에서 추가 S3 버킷을 생성하고 교차 리전 복제를 구성합니다.\\nB. 다른 리전에서 추가 S3 버킷을 생성하고 교차 출처 리소스 공유(CORS)를 구성합니다.\\nC. 다른 리전에서 버전 관리를 사용하여 추가 S3 버킷을 생성하고 리전 간 복제를 구성합니다.\\nD. 다른 리전에서 버전 관리가 포함된 추가 S3 버킷을 생성하고 CORS(교차 출처 리소스)를 구성합니다.\", \"A corporation is considering migrating a mission-critical dataset to Amazon S3. The present solution architecture stores the dataset in a single S3 bucket in the us-east-1 Region with versioning enabled. According to the company's disaster recovery strategy, all data is replicated across various AWS Regions.\\nHow should the S3 solution be designed by a solutions architect?\\n\\nA.Create an additional S3 bucket in another Region and configure cross-Region replication.\\nB. Create an additional S3 bucket in another Region and configure cross-origin resource sharing (CORS).\\nC. Create an additional S3 bucket with versioning in another Region and configure cross-Region replication.\\nD. Create an additional S3 bucket with versioning in another Region and configure cross-origin resource (CORS).\", \"C\"],\n[\"솔루션 아키텍트는 AWS에 배포되는 새로운 애플리케이션을 위한 클라우드 아키텍처 개발을 담당합니다. 응용 프로그램 사용자는 대화식으로 파일을 다운로드하고 업로드할 수 있습니다. 90일 이상 된 파일은 최신 파일보다 방문 빈도가 낮지만 모든 파일에 즉시 액세스할 수 있어야 합니다. 솔루션 설계자는 애플리케이션이 페타바이트 규모의 데이터를 안전하게 저장할 수 있도록 확장되도록 보장해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon S3 Standard에 파일을 저장합니다. 90일이 지난 객체를 S3 Glacier로 이동하는 S3 수명 주기 정책을 생성합니다.\\nB. Amazon S3 Standard에 파일을 저장합니다. 90일 이상 지난 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동하는 S3 수명 주기 정책을 생성합니다.\\nC. Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일을 저장합니다. 볼륨의 스냅샷을 예약합니다. 스냅샷을 사용하여 90일 이상 지난 데이터를 보관하십시오.\\nD. RAID 스트라이프 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일을 저장합니다. 볼륨의 스냅샷을 예약합니다. 스냅샷을 사용하여 90일 이상 지난 데이터를 보관하십시오.\", \"A solutions architect is tasked with the responsibility of developing the cloud architecture for a new application being deployed on AWS. The application's users will be able to download and upload files interactively. Over 90-day-old files will be visited less often than fresher ones, but all files must be promptly accessible. The solutions architect must guarantee that the application scales to securely store petabytes of data.\\nWhich solution satisfies these criteria?\\n\\nA.Store the files in Amazon S3 Standard. Create an S3 Lifecycle policy that moves objects that are more than 90 days old to S3 Glacier.\\nB. Store the files in Amazon S3 Standard. Create an S3 Lifecycle policy that moves objects that are more than 90 days old to S3 Standard-Infrequent Access (S3 Standard-IA).\\nC. Store the files in Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data that is more than 90 days old.\\nD. Store the files in RAID-striped Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data that is more than 90 days old.\", \"B\"],\n[\"전자 상거래 회사의 솔루션 설계자는 애플리케이션 로그 데이터를 Amazon S3에 백업하려고 합니다. 솔루션 설계자는 얼마나 자주 또는 어떤 로그에 액세스할지 모릅니다. 조직은 적절한 S3 스토리지 클래스를 사용하여 비용을 절감하고자 합니다.\\n이러한 요구 사항을 충족하려면 어떤 S3 스토리지 유형을 사용해야 합니까?\\n\\nA.S3 빙하\\nB. S3 지능형 계층화\\nC. S3 Standard-Infrequent Access(S3 Standard-IA)\\nD. S3 One Zone-Infrequent Access(S3 One Zone-IA)\", \"An ecommerce company's solutions architect want to back up application log data to Amazon S3. The solutions architect has no idea how often or which logs will be accessed. The organization wishes to save expenses by using the suitable S3 storage class.\\nWhich S3 storage type should be used to satisfy these requirements?\\n\\nA.S3 Glacier\\nB. S3 Intelligent-Tiering\\nC. S3 Standard-Infrequent Access (S3 Standard-IA)\\nD. S3 One Zone-Infrequent Access (S3 One Zone-IA)\", \"B\"],\n[\"비즈니스는 VPC 내의 프라이빗 서브넷에 포함된 Amazon EC2 인스턴스에서 애플리케이션을 운영합니다. 인스턴스는 동일한 AWS 리전의 Amazon S3 버킷에 저장된 데이터에 액세스할 수 있습니다. S3 버킷에 액세스하기 위해 VPC는 ​​퍼블릭 서브넷의 NAT 게이트웨이로 구성됩니다. 조직은 보안이나 이중화를 희생하지 않고 NAT 게이트웨이를 교체하여 비용을 절감하고자 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.NAT 게이트웨이를 NAT 인스턴스로 교체하십시오.\\nB. NAT 게이트웨이를 인터넷 게이트웨이로 교체합니다.\\nC. NAT 게이트웨이를 게이트웨이 VPC 엔드포인트로 교체합니다.\\nD. NAT 게이트웨이를 AWS Direct Connect 연결로 교체합니다.\", \"A business operates an application on Amazon EC2 instances contained inside a private subnet within a VPC. The instances have access to data stored in the same AWS Region's Amazon S3 bucket. To access the S3 bucket, the VPC comprises a NAT gateway on a public subnet. The organization wishes to save money by replacing the NAT gateway without sacrificing security or redundancy.\\nWhich solution satisfies these criteria?\\n\\nA.Replace the NAT gateway with a NAT instance.\\nB. Replace the NAT gateway with an internet gateway.\\nC. Replace the NAT gateway with a gateway VPC endpoint.\\nD. Replace the NAT gateway with an AWS Direct Connect connection.\", \"C\"],\n[\"전 세계 이벤트의 주최자는 일일 보고서를 온라인에 정적 HTML 페이지로 게시하려고 합니다. 페이지는 전 세계 방문자로부터 수백만 건의 조회수를 얻을 것으로 예상됩니다. 파일은 Amazon S3의 버킷에 저장됩니다. 솔루션 설계자는 효율적이고 효과적인 솔루션을 설계할 책임이 있습니다.\\n이를 위해 솔루션 아키텍트는 어떻게 해야 합니까?\\n\\nA.파일에 대해 미리 서명된 URL을 생성합니다.\\nB. 모든 리전에 교차 리전 복제를 사용합니다.\\nC. Amazon Route 53의 지리 근접성 기능을 사용합니다.\\nD. S3 버킷을 오리진으로 하여 Amazon CloudFront를 사용합니다.\", \"The organizers of a worldwide event want to publish daily reports as static HTML pages online. The pages are anticipated to get millions of views from visitors worldwide. The files are stored in a bucket on Amazon S3. A solutions architect has been tasked with the responsibility of designing a solution that is both efficient and effective.\\nHow should the solutions architect go in order to do this?\\n\\nA.Generate presigned URLs for the files.\\nB. Use cross-Region replication to all Regions.\\nC. Use the geoproximity feature of Amazon Route 53.\\nD. Use Amazon CloudFront with the S3 bucket as its origin.\", \"D\"],\n[\"전자상거래 회사는 제3자 지불 제공자를 통한 지불을 처리할 애플리케이션을 개발 중입니다. 결제 제공자는 결제를 요청하는 서버의 공인 IP 주소에 대한 액세스를 명시적으로 허용해야 합니다. 그러나 회사의 보안 규정은 모든 서버를 공용 인터넷에 직접 연결하는 것을 금지합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.탄력적 IP 주소를 프로비저닝합니다. 프라이빗 서브넷의 Amazon EC2 인스턴스에서 애플리케이션 서버를 호스팅합니다. 애플리케이션 서버에 공용 IP 주소를 할당하십시오.\\nB. 퍼블릭 서브넷에 NAT 게이트웨이를 생성합니다. 프라이빗 서브넷의 Amazon EC2 인스턴스에서 애플리케이션 서버를 호스팅합니다. NAT 게이트웨이를 통해 결제 요청을 라우팅합니다.\\nC. 애플리케이션 로드 밸런서(ALB)를 배포합니다. 프라이빗 서브넷의 Amazon EC2 인스턴스에서 애플리케이션 서버를 호스팅합니다. ALB를 통해 결제 요청을 라우팅합니다.\\nD. 결제 서비스에 대한 AWS Client VPN 연결을 설정합니다. 프라이빗 서브넷의 Amazon EC2 인스턴스에서 애플리케이션 서버를 호스팅합니다. VPN을 통해 결제 요청을 라우팅합니다.\", \"An ecommerce firm is developing an application that will handle payments through a third-party payment provider. The payment provider must expressly permit access to the public IP address of the server making the payment request. However, the company's security regulations prohibit the direct connection of any server to the public internet.\\nWhich solution will satisfy these criteria?\\n\\nA.Provision an Elastic IP address. Host the application servers on Amazon EC2 instances in a private subnet. Assign the public IP address to the application servers.\\nB. Create a NAT gateway in a public subnet. Host the application servers on Amazon EC2 instances in a private subnet. Route payment requests through the NAT gateway.\\nC. Deploy an Application Load Balancer (ALB). Host the application servers on Amazon EC2 instances in a private subnet. Route the payment requests through the ALB.\\nD. Set up an AWS Client VPN connection to the payment service. Host the application servers on Amazon EC2 instances in a private subnet. Route the payment requests through the VPN.\", \"B\"],\n[\"기업은 Amazon S3를 사용하여 AWS 자격 증명이 없는 고객을 선택하기 위해 파일을 제공합니다. 이러한 사용자는 일정 기간 동안 액세스 권한을 부여받아야 합니다.\\n솔루션 설계자는 이러한 기준을 안전하게 충족하기 위해 어떤 단계를 수행해야 합니까?\\n\\nA.Amazon S3 버킷에 대한 공개 액세스를 활성화합니다.\\nB. 사용자와 공유할 미리 서명된 URL을 생성합니다.\\nC. AWS KMS를 사용하여 파일을 암호화하고 사용자에게 키를 제공합니다.\\nD. 사용자에게 GetObject 권한을 부여할 IAM 역할을 생성하고 할당합니다.\", \"A business uses Amazon S3 to provide files to select customers who do not have AWS credentials. These users must be granted access for a certain period of time.\\nWhat steps should a solutions architect take to ensure that these criteria are met securely?\\n\\nA.Enable public access on an Amazon S3 bucket.\\nB. Generate a presigned URL to share with the users.\\nC. Encrypt files using AWS KMS and provide keys to the users.\\nD. Create and assign IAM roles that will grant GetObject permissions to the users.\", \"B. URL에 시간 제한 기능 설정 가능\"],\n[\"기업은 다양한 AWS 리전에 분산된 수많은 Amazon EC2 인스턴스를 활용하여 Amazon Web Services(AWS)에서 웹 애플리케이션을 실행하려고 합니다. 애플리케이션 콘텐츠가 지역별로 다르기 때문에 클라이언트 요청은 해당 클라이언트 위치에 대한 콘텐츠를 호스팅하는 서버로 보내야 합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.지연 시간 라우팅 정책으로 Amazon Route 53을 구성합니다.\\nB. 가중치 기반 라우팅 정책으로 Amazon Route 53을 구성합니다.\\nC. 지리적 위치 라우팅 정책으로 Amazon Route 53을 구성합니다.\\nD. 다중값 응답 라우팅 정책으로 Amazon Route 53 구성\", \"A business wishes to run its web application on Amazon Web Services (AWS) utilizing numerous Amazon EC2 instances spread across various AWS Regions. Due to the fact that the application content will be region-specific, client requests must be directed to the server that hosts the content for that client location.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Configure Amazon Route 53 with a latency routing policy.\\nB. Configure Amazon Route 53 with a weighted routing policy.\\nC. Configure Amazon Route 53 with a geolocation routing policy.\\nD. Configure Amazon Route 53 with a multivalue answer routing policy\", \"C\"],\n[\"솔루션 설계자는 사용자가 사용자 정의 도메인 이름을 통해 액세스하는 정적 단일 페이지 애플리케이션을 위한 저지연 솔루션을 설계하는 책임을 맡습니다. 서버리스, 전송 중 암호화 및 비용 효율성은 모두 솔루션의 요구 사항입니다.\\n솔루션 아키텍트는 어떤 AWS 서비스와 기능을 함께 사용해야 합니까? (2개를 선택하세요.)\\n\\nA.아마존 S3\\nB. 아마존 EC2\\nC. AWS Fargate\\nD. 아마존 클라우드프론트\\nE. 탄력적 로드 밸런서\", \"A solutions architect is tasked with the responsibility of designing a low-latency solution for a static single-page application that users access through a custom domain name. Serverless, encrypted in transit, and cost-effective are all requirements for the solution.\\nWhich AWS services and functionalities should the solutions architect utilize in combination? (Select two.)\\n\\nA.Amazon S3\\nB. Amazon EC2\\nC. AWS Fargate\\nD. Amazon CloudFront\\nE. Elastic Load Balancer\", \"A, D\"],\n[\"솔루션 설계자는 많은 Amazon EC2 인스턴스가 모든 EC2 인스턴스가 동시에 액세스할 수 있는 미션 크리티컬 데이터에 대한 단일 데이터 소스를 공유할 수 있도록 하는 네트워크를 생성해야 합니다. 솔루션은 확장성이 뛰어나고 설치가 간편해야 하며 NFS 표준을 준수해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 각 가용 영역에서 탑재 대상을 구성합니다. 각 인스턴스를 적절한 탑재 대상에 연결합니다.\\nB. 추가 EC2 인스턴스를 생성하고 파일 서버로 구성합니다. 인스턴스 간 통신을 허용하는 보안 그룹을 생성하여 추가 인스턴스에 적용합니다.\\nC. 적절한 권한이 있는 Amazon S3 버킷을 생성합니다. S3 버킷에 올바른 권한을 부여하는 역할을 AWS IAM에서 생성합니다. 데이터에 액세스해야 하는 EC2 인스턴스에 역할을 연결합니다.\\nD. 적절한 권한이 있는 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성합니다. EBS 볼륨에 올바른 권한을 부여하는 역할을 AWS IAM에서 생성합니다. 데이터에 액세스해야 하는 EC2 인스턴스에 역할을 연결합니다.\", \"A solutions architect must create a network that enables many Amazon EC2 instances to share a single data source for mission-critical data that all EC2 instances may access concurrently. The solution must be highly scalable, simple to install, and compliant with the NFS standard.\\nWhich solution satisfies these criteria?\\n\\nA.Create an Amazon Elastic File System (Amazon EFS) file system. Configure a mount target in each Availability Zone. Attach each instance to the appropriate mount target.\\nB. Create an additional EC2 instance and configure it as a file server. Create a security group that allows communication between the Instances and apply that to the additional instance.\\nC. Create an Amazon S3 bucket with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the S3 bucket. Attach the role to the EC2 Instances that need access to the data.\\nD. Create an Amazon Elastic Block Store (Amazon EBS) volume with the appropriate permissions. Create a role in AWS IAM that grants the correct permissions to the EBS volume. Attach the role to the EC2 instances that need access to the data.\", \"A\"],\n[\"비즈니스는 Amazon API Gateway API를 사용하여 호출되는 Amazon Web Services Lambda 함수에 애플리케이션을 설치합니다. 고객 데이터는 Lambda 함수를 사용하여 Amazon Aurora MySQL 데이터베이스에 저장됩니다. 기업이 데이터베이스를 업데이트하면 Lambda 함수는 업그레이드가 완료될 때까지 데이터베이스 연결을 설정할 수 없습니다. 결과적으로 일부 이벤트에 대해 클라이언트 데이터가 캡처되지 않습니다.\\n솔루션 설계자는 데이터베이스 업데이트 중에 생성된 고객 데이터를 안전하게 유지 관리하는 솔루션을 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Lambda 함수와 데이터베이스 사이에 위치하도록 Amazon RDS 프록시를 프로비저닝합니다. RDS 프록시에 연결하도록 Lambda 함수를 구성합니다.\\nB. Lambda 함수의 실행 시간을 최대로 늘립니다. 데이터베이스에 고객 데이터를 저장하는 코드에서 재시도 메커니즘을 만듭니다.\\nC. 고객 데이터를 Lambda 로컬 스토리지에 유지합니다. 고객 데이터를 데이터베이스에 저장하기 위해 로컬 스토리지를 스캔하도록 새로운 Lambda 함수를 구성합니다.\\nD. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 고객 데이터를 저장합니다. 대기열을 폴링하고 고객 데이터를 데이터베이스에 저장하는 새 Lambda 함수를 생성합니다.\", \"A business installs an application on Amazon Web Services Lambda functions that are called using the Amazon API Gateway API. Customer data is stored in an Amazon Aurora MySQL database using Lambda functions. When a corporation updates its database, Lambda functions are prevented from establishing database connections until the upgrade is complete. As a consequence, client data is not captured for some events.\\nA solutions architect must provide a solution that securely maintains customer data generated during database updates.\\nWhich solution will satisfy these criteria?\\n\\nA.Provision an Amazon RDS proxy to sit between the Lambda functions and the database. Configure the Lambda functions to connect to the RDS proxy.\\nB. Increase the run time of the Lambda functions to the maximum. Create a retry mechanism in the code that stores the customer data in the database.\\nC. Persist the customer data to Lambda local storage. Configure new Lambda functions to scan the local storage to save the customer data to the database.\\nD. Store the customer data in an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Create a new Lambda function that polls the queue and stores the customer data in the database.\", \"D\"],\n[\"전자 상거래 회사는 Amazon RDS 기반 웹 애플리케이션의 성능이 저하되었음을 깨달았습니다. 성능 저하의 원인은 비즈니스 분석가가 시작한 읽기 전용 SQL 쿼리의 양이 증가했기 때문입니다. 솔루션 설계자는 현재 웹 애플리케이션을 최소한으로 수정하여 문제를 해결해야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.데이터를 Amazon DynamoDB로 내보내고 비즈니스 분석가가 쿼리를 실행하도록 합니다.\\nB. 데이터를 Amazon ElastiCache에 로드하고 비즈니스 분석가가 쿼리를 실행하도록 합니다.\\nC. 기본 데이터베이스의 읽기 전용 복제본을 만들고 비즈니스 분석가가 쿼리를 실행하도록 합니다.\\nD. 데이터를 Amazon Redshift 클러스터에 복사하고 비즈니스 분석가가 쿼리를 실행하도록 합니다.\", \"An ecommerce firm realized that the performance of their Amazon RDS-based web application had degraded. The reduction in performance is being ascribed to an increase in the amount of read-only SQL queries initiated by business analysts. A solutions architect must resolve the issue with the least amount of modification to the current web application.\\nWhat recommendations should the solutions architect make?\\n\\nA.Export the data to Amazon DynamoDB and have the business analysts run their queries.\\nB. Load the data into Amazon ElastiCache and have the business analysts run their queries.\\nC. Create a read replica of the primary database and have the business analysts run their queries.\\nD. Copy the data into an Amazon Redshift cluster and have the business analysts run their queries.\", \"C\"],\n[\"솔루션 설계자는 모놀리식 애플리케이션을 마이크로서비스 A와 마이크로서비스 B의 두 마이크로서비스로 리팩토링하고 있습니다. 마이크로서비스\\n\\nA.중앙 Amazon Simple Queue Service(Amazon SQS) 대기열에서 마이크로서비스 B가 사용할 메시지를 대기열에 넣습니다. Microservice B가 4번의 시도 후에도 메시지를 처리할 수 없으면 대기열에서 메시지를 철회하고 추후 연구를 위해 보관해야 합니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.SQS 배달 못한 편지 대기열을 만듭니다. 마이크로 서비스 B는 메시지를 받고 네 번 처리에 실패한 후 해당 큐에 실패한 메시지를 추가합니다.\\nB. SQS 배달 못한 편지 대기열을 만듭니다. 메시지가 네 번 수신된 후 배달 못한 편지 대기열로 메시지를 배달하도록 기본 SQS 대기열을 구성합니다.\\nC. 실패한 메시지에 대한 SQS 대기열을 만듭니다. 마이크로 서비스 A는 마이크로 서비스 B가 메시지를 받고 네 번 처리에 실패한 후 해당 큐에 실패한 메시지를 추가합니다.\\nD. 실패한 메시지에 대한 SQS 대기열을 만듭니다. 원본 메시지가 네 번 수신된 후 기본 SQS 대기열에서 메시지를 가져오도록 실패한 메시지에 대한 SQS 대기열을 구성합니다.\", \"A solutions architect is refactoring a monolithic application into two microservices: Microservice A and Microservice B.\\nMicroservice A queues messages for consumption by Microservice B in a central Amazon Simple Queue Service (Amazon SQS) queue. When Microservice B is unable to process a message after four attempts, the message must be withdrawn from the queue and archived for later study.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Create an SQS dead-letter queue. Microservice B adds failed messages to that queue after it receives and fails to process the message four times.\\nB. Create an SQS dead-letter queue. Configure the main SQS queue to deliver messages to the dead-letter queue after the message has been received four times.\\nC. Create an SQS queue for failed messages. Microservice A adds failed messages to that queue after Microservice B receives and fails to process the message four times.\\nD. Create an SQS queue for failed messages. Configure the SQS queue for failed messages to pull messages from the main SQS queue after the original message has been received four times.\", \"B. A가 가능하다는 의견도 있음.\"],\n[\"Amazon EC2는 기업에서 빅 데이터 분석 워크로드를 호스팅하는 데 사용됩니다. 매일 밤 이러한 가변 워크로드가 실행되며 다음 날 업무 시작 전에 완료하는 것이 중요합니다. 솔루션 설계자는 가능한 가장 비용 효율적인 솔루션을 개발할 책임이 있습니다.\\n어떤 접근 방식이 이 작업을 수행할 가능성이 가장 높습니까?\\n\\nA.스팟 플릿\\nB. 스팟 인스턴스\\nC. 예약 인스턴스\\nD. 온디맨드 인스턴스\", \"Amazon EC2 is being used by a business to host its big data analytics workloads. Each night, these variable workloads run, and it is vital that they be completed before the start of business the following day. A solutions architect has been assigned with the responsibility of developing the MOST cost-effective solution possible.\\nWhich approach is most likely to do this?\\n\\nA.Spot Fleet\\nB. Spot Instances\\nC. Reserved Instances\\nD. On-Demand Instances\", \"A. 스팟 집합은 EMR과 같은 많은 AWS 서비스에서 일괄 처리에 사용됩니다. 또한 최대 6시간 동안 종료되지 않도록 설정할 수 있습니다. aws에 따르면 스팟 집합은 스팟 인스턴스 및 선택적으로 온디맨드 인스턴스의 모음 또는 집합입니다.\"],\n[\"기업은 AWS 리전을 온프레미스 인프라의 백업 사이트로 활용하고자 합니다. 조직에는 이제 10테라바이트의 데이터가 포함되어 있으며 사내 데이터 센터에는 초당 1기가비트의 인터넷 연결이 있습니다. 솔루션 설계자는 조직에서 암호화되지 않은 연결을 사용하지 않고 72시간 내에 기존 데이터를 AWS로 마이그레이션할 수 있는 전략을 고안해야 합니다.\\n건축가는 어떤 선택을 해야 할까요?\\n\\nA.FTP를 사용하여 초기 10TB의 데이터를 AWS로 보냅니다.\\nB. AWS Snowball을 사용하여 초기 10TB의 데이터를 AWS로 보냅니다.\\nC. Amazon VPC와 회사 데이터 센터 간에 VPN 연결을 설정합니다.\\nD. Amazon VPC와 회사 데이터 센터 간에 AWS Direct Connect 연결을 설정합니다.\", \"A business want to utilize an AWS Region as a backup site for its on-premises infrastructure. The organization now contains ten terabytes of data and the on-premise data center has a one gigabit per second internet connection. A solutions architect must devise a strategy that enables the organization to migrate its existing data to AWS in 72 hours without utilizing an unencrypted connection.\\nWhich option should the architect choose?\\n\\nA.Send the initial 10 TB of data to AWS using FTP.\\nB. Send the initial 10 TB of data to AWS using AWS Snowball.\\nC. Establish a VPN connection between Amazon VPC and the company's data center.\\nD. Establish an AWS Direct Connect connection between Amazon VPC and the company's data center.\", \"C\"],\n[\"한 팀에서 Amazon S3 버킷으로의 새 항목 업로드를 모니터링하는 애플리케이션을 개발했습니다. 업로드하면 AWS Lambda 함수가 객체 정보를 Amazon DynamoDB 테이블과 Amazon RDS에서 호스팅하는 PostgreSQL 데이터베이스로 보냅니다.\\n다음 중 고가용성을 달성하기 위해 팀에서 수행해야 하는 작업은 무엇입니까?\\n\\nA.S3 버킷에서 교차 리전 복제를 활성화합니다.\\nB. 애플리케이션이 배포된 각 가용 영역에 대해 Lambda 함수를 생성합니다.\\nC. RDS for PostgreSQL 데이터베이스에서 다중 AZ를 활성화합니다.\\nD. DynamoDB 테이블에 대한 DynamoDB 스트림을 생성합니다.\", \"A team has developed an application that monitors the upload of new items to an Amazon S3 bucket. The uploads cause an AWS Lambda function to send object information to an Amazon DynamoDB table and a PostgreSQL database hosted by Amazon RDS.\\nWhich of the following actions should the team do to achieve high availability?\\n\\nA.Enable Cross-Region Replication in the S3 bucket.\\nB. Create a Lambda function for each Availability Zone the application is deployed in.\\nC. Enable Multi-AZ on the RDS for PostgreSQL database.\\nD. Create a DynamoDB stream for the DynamoDB table.\", \"C\"],\n[\"기업은 일괄 처리를 사용하여 많은 웹사이트에서 클릭스트림 데이터를 수집하고 분석합니다. 데이터는 매일 밤 Amazon Redshift로 가져온 다음 비즈니스 분석가가 사용합니다. 조직은 적시에 통찰력을 제공하기 위해 거의 실시간 데이터 처리로 전환하기를 원합니다. 솔루션은 스트리밍 데이터를 효율적으로 그리고 낮은 운영 오버헤드로 처리해야 합니다.\\n이 솔루션에 가장 비용 효율적인 AWS 서비스 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.아마존 EC2\\nB. AWS 람다\\nC. Amazon Kinesis 데이터 스트림\\nD. Amazon Kinesis Data Firehose\\nE. Amazon Kinesis 데이터 분석\", \"A business collects and analyzes clickstream data from many websites using batch processing. The data is imported into Amazon Redshift on a nightly basis and is then consumed by business analysts. The organization wishes to transition to near-real-time data processing in order to provide timely insights. The solution should handle streaming data efficiently and with low operational overhead.\\nWhich AWS service combination is the MOST cost-effective for this solution? (Select two.)\\n\\nA.Amazon EC2\\nB. AWS Lambda\\nC. Amazon Kinesis Data Streams\\nD. Amazon Kinesis Data Firehose\\nE. Amazon Kinesis Data Analytics\", \"C, E 또는 D,E 또는 C, D 논란\"],\n[\"한 기업이 최근 3계층 애플리케이션을 가상 사설 클라우드(VPC)로 이전하는 것을 검토하고 있습니다. 보안 팀은 애플리케이션 계층 간의 Amazon EC2 보안 그룹에 대한 출입 규칙에 최소 권한 개념이 적용되지 않는 것을 감지했습니다.\\n솔루션 설계자는 이 상황을 바로잡기 위해 어떤 조치를 취해야 합니까?\\n\\nA.인스턴스 ID를 원본 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.\\nB. 보안 그룹 ID를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.\\nC. VPC CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.\\nD. 서브넷 CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.\", \"A business is examining a recent transfer of a three-tier application to a virtual private cloud (VPC). The security team detects that the concept of least privilege is not being applied to the entrance and egress rules for Amazon EC2 security groups between application layers.\\nWhat actions should a solutions architect take to rectify this situation?\\n\\nA.Create security group rules using the instance ID as the source or destination.\\nB. Create security group rules using the security group ID as the source or destination.\\nC. Create security group rules using the VPC CIDR blocks as the source or destination.\\nD. Create security group rules using the subnet CIDR blocks as the source or destination.\", \"B\"],\n[\"라이브 영상 스트리밍을 제공하는 기업으로 실시간 데이터를 캡처하여 디스크에 최적화된 데이터베이스 시스템에 저장합니다. 조직은 예상보다 낮은 처리량을 경험하고 있으며 데이터 복제를 통해 더 빠르고 고가용성을 제공하는 인메모리 데이터베이스 스토리지 솔루션을 찾고 있습니다.\\n솔루션 아키텍트가 추천해야 하는 데이터베이스는 무엇입니까?\\n\\nA.MySQL용 Amazon RDS\\nB. PostgreSQL용 Amazon RDS.\\nC. Redis용 Amazon ElastiCache\\nD. Memcached용 Amazon ElastiCache\", \"A corporation that provides live video streaming captures and saves real-time data in a disk-optimized database system. The organization is experiencing lower-than-expected throughput and is looking for an in-memory database storage solution that is speedier and delivers high availability via data replication.\\nWhich database should be recommended by a solutions architect?\\n\\nA.Amazon RDS for MySQL\\nB. Amazon RDS for PostgreSQL.\\nC. Amazon ElastiCache for Redis\\nD. Amazon ElastiCache for Memcached\", \"C. Memcached는 복제 X\"],\n[\"VPC-A의 Amazon EC2 인스턴스에서 작동하는 웹 애플리케이션은 VPC-B의 다른 Amazon EC2 인스턴스에 있는 파일에 액세스해야 합니다. 둘 다 별개입니다. AWS 자격 증명. 네트워크 관리자는 VPC-A에서 VPC-B의 EC2 인스턴스로 안전하게 액세스할 수 있는 솔루션을 구축해야 합니다. 단일 실패 지점이나 대역폭 문제가 없어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.VPC-A와 VPC-B 간에 VPC 피어링 연결을 설정합니다.\\nB. VPC-B에서 실행되는 EC2 인스턴스에 대한 VPC 게이트웨이 엔드포인트를 설정합니다.\\nC. 가상 프라이빗 게이트웨이를 VPC-B에 연결하고 VPC-A에서 라우팅을 활성화합니다.\\nD. VPC-B에서 실행되는 EC2 인스턴스용 프라이빗 가상 인터페이스(VIF)를 생성하고 VPC-B에서 적절한 경로를 추가합니다.\", \"A web application operating on an Amazon EC2 instance in VPC-A requires access to files located on another Amazon EC2 instance in VPC-B. Both are distinct. AWS credentials. The network administrator must build a solution that enables safe access from VPC-A to an EC2 instance in VPC-B. There should be no single point of failure or issues about bandwidth.\\nWhich solution will satisfy these criteria?\\n\\nA.Set up a VPC peering connection between VPC-A and VPC-B.\\nB. Set up VPC gateway endpoints for the EC2 instance running in VPC-B.\\nC. Attach a virtual private gateway to VPC-B and enable routing from VPC-A.\\nD. Create a private virtual interface (VIF) for the EC2 instance running in VPC-B and add appropriate routes from VPC-B.\", \"A\"],\n[\"한 비즈니스에서 Amazon RDS MySQL 데이터베이스를 사용하는 애플리케이션을 제공하고 있습니다. 데이터베이스는 가동 중지 시간을 최소화하면서 가용 영역 및 AWS 리전에서 고가용성을 유지하도록 설계해야 합니다.\\n솔루션 설계자가 이 요구 사항을 충족하는 가장 좋은 방법은 무엇입니까?\\n\\nA.RDS MySQL 다중 AZ DB 인스턴스를 설정합니다. 적절한 백업 창을 구성합니다.\\nB. RDS MySQL 다중 AZ DB 인스턴스를 설정합니다. 다른 리전에서 읽기 전용 복제본을 구성합니다.\\nC. RDS MySQL 단일 AZ DB 인스턴스를 설정합니다. 다른 리전에서 읽기 전용 복제본을 구성합니다.\\nD. RDS MySQL 단일 AZ DB 인스턴스를 설정합니다. 자동화된 스냅샷을 하나 이상의 다른 리전에 복사합니다.\", \"A business is offering an application that makes use of an Amazon RDS MySQL database. The database must be designed in such a way that it maintains high availability across Availability Zones and AWS Regions with the least amount of downtime possible.\\nWhat is the best way for a solutions architect to fulfill this requirement?\\n\\nA.Set up an RDS MySQL Multi-AZ DB instance. Configure an appropriate backup window.\\nB. Set up an RDS MySQL Multi-AZ DB instance. Configure a read replica in a different Region.\\nC. Set up an RDS MySQL Single-AZ DB instance. Configure a read replica in a different Region.\\nD. Set up an RDS MySQL Single-AZ DB instance. Copy automated snapshots to at least one other Region.\", \"B\"],\n[\"Amazon EC2에서는 비즈니스 애플리케이션이 호스팅되고 Amazon S3에서 보안 객체 스토리지를 제공합니다. 최고 정보 보안 책임자에 따르면 두 서비스 간의 애플리케이션 통신은 공용 인터넷을 통해 전달되어서는 안 됩니다.\\n솔루션 설계자는 규정 준수를 위해 어떤 기능을 사용해야 합니까?\\n\\nA.AWS 키 관리 서비스(AWS KMS)\\nB. VPC 엔드포인트\\n다. 사설 서브넷\\nD. 가상 사설 게이트웨이\", \"On Amazon EC2, a business application is hosted and secured object storage is provided by Amazon S3. According to the chief information security officer, no application communication between the two services should pass over the public internet.\\nWhich capabilities should the solution architect use to ensure compliance?\\n\\nA.AWS Key Management Service (AWS KMS)\\nB. VPC endpoint\\nC. Private subnet\\nD. Virtual private gateway\", \"B\"],\n[\"솔루션 설계자는 공급업체에서 Docker 컨테이너 이미지로 제공하는 애플리케이션의 아키텍처를 설계하는 일을 담당합니다. 컨테이너에는 50GB의 임시 파일 스토리지가 필요합니다. 서버리스 인프라가 필요합니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 방법은 무엇입니까?\\n\\nA.50GB 이상의 공간이 있는 Amazon S3 탑재 볼륨이 있는 Docker 컨테이너 이미지를 사용하는 AWS Lambda 함수를 생성합니다.\\nB. 50GB 이상의 공간이 있는 Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 Docker 컨테이너 이미지를 사용하는 AWS Lambda 함수를 생성합니다.\\nC. AWS Fargate 시작 유형을 사용하는 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. Amazon Elastic File System(Amazon EFS) 볼륨으로 컨테이너 이미지에 대한 작업 정의를 생성합니다. 해당 작업 정의로 서비스를 만듭니다.\\nD. 50GB 이상의 공간이 있는 Amazon Elastic Block Store(Amazon EBS) 볼륨과 함께 Amazon EC2 시작 유형을 사용하는 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다. 컨테이너 이미지에 대한 작업 정의를 만듭니다. 해당 작업 정의로 서비스를 만듭니다.\", \"A solutions architect is responsible for designing the architecture of an application that is delivered as a Docker container image by a vendor. The container requires 50 GB of temporary file storage. Serverless infrastructure is required.\\nWhich method satisfies these criteria with the LEAST amount of operational overhead?\\n\\nA.Create an AWS Lambda function that uses the Docker container image with an Amazon S3 mounted volume that has more than 50 GB of space.\\nB. Create an AWS Lambda function that uses the Docker container image with an Amazon Elastic Block Store (Amazon EBS) volume that has more than 50 GB of space.\\nC. Create an Amazon Elastic Container Service (Amazon ECS) cluster that uses the AWS Fargate launch type. Create a task definition for the container image with an Amazon Elastic File System (Amazon EFS) volume. Create a service with that task definition.\\nD. Create an Amazon Elastic Container Service (Amazon ECS) cluster that uses the Amazon EC2 launch type with an Amazon Elastic Block Store (Amazon EBS) volume that has more than 50 GB of space. Create a task definition for the container image. Create a service with that task definition.\", \"C\"],\n[\"회사에 Lambda 함수와 동일한 AWS 계정에서 호스팅되는 Amazon S3 버킷에 대한 읽기 액세스 권한이 필요한 AWS Lambda 함수가 있습니다.\\n가능한 가장 안전한 방법으로 이러한 기준을 충족하는 솔루션은 무엇입니까?\\n\\nA.S3 버킷에 대한 읽기 액세스 권한을 부여하는 S3 버킷 정책을 적용합니다.\\nB. Lambda 함수에 IAM 역할을 적용합니다. 역할에 IAM 정책을 적용하여 S3 버킷에 대한 읽기 액세스 권한을 부여합니다.\\nC. Lambda 함수의 코드에 액세스 키와 비밀 키를 포함하여 S3 버킷에 대한 읽기 액세스에 필요한 IAM 권한을 부여합니다.\\nD. Lambda 함수에 IAM 역할을 적용합니다. 역할에 IAM 정책을 적용하여 계정의 모든 S3 버킷에 대한 읽기 액세스 권한을 부여합니다.\", \"A corporation has an AWS Lambda function that requires read access to an Amazon S3 bucket hosted in the same AWS account as the Lambda function.\\nWhich solution satisfies these criteria the SAFEST way possible?\\n\\nA.Apply an S3 bucket policy that grants read access to the S3 bucket.\\nB. Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to the S3 bucket.\\nC. Embed an access key and a secret key in the Lambda function's code to grant the required IAM permissions for read access to the S3 bucket.\\nD. Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to all S3 buckets in the account.\", \"B\"],\n[\"비즈니스는 Amazon Aurora MySQL DB 클러스터에 데이터를 저장하는 다중 계층 웹 애플리케이션을 실행합니다. Amazon EC2 인스턴스는 애플리케이션 계층을 호스팅하는 데 사용됩니다. 회사의 정보 기술 보안 정책은 데이터베이스 자격 증명을 암호화하고 14일마다 변경할 것을 요구합니다.\\n가능한 한 최소한의 운영 작업으로 이러한 요구를 충족시키기 위해 솔루션 설계자는 무엇을 해야 합니까?\\n\\nA.새 AWS Key Management Service(AWS KMS) 암호화 키를 생성합니다. AWS Secrets Manager를 사용하여 적절한 자격 증명과 함께 KMS 키를 사용하는 새 암호를 생성합니다. 비밀을 Aurora DB 클러스터와 연결합니다. 14일의 사용자 지정 순환 기간을 구성합니다.\\nB. AWS Systems Manager Parameter Store에서 두 개의 매개변수를 생성합니다. 하나는 문자열 매개변수로 사용자 이름을 위한 것이고 다른 하나는 암호로 SecureString 유형을 사용하는 것입니다. 암호 파라미터에 대해 AWS Key Management Service(AWS KMS) 암호화를 선택하고 애플리케이션 계층에서 이러한 파라미터를 로드합니다. 14일마다 암호를 교체하는 AWS Lambda 함수를 구현합니다.\\nC. AWS Key Management Service(AWS KMS) 암호화 Amazon Elastic File System(Amazon EFS) 파일 시스템에 자격 증명이 포함된 파일을 저장합니다. 애플리케이션 계층의 모든 EC2 인스턴스에 EFS 파일 시스템을 탑재합니다. 응용 프로그램이 파일을 읽고 수퍼유저만 파일을 수정할 수 있도록 파일 시스템의 파일에 대한 액세스를 제한합니다. 14일마다 Aurora에서 키를 교체하고 새 자격 증명을 파일에 쓰는 AWS Lambda 함수를 구현합니다.\\nD. 애플리케이션이 자격 증명을 로드하는 데 사용하는 AWS Key Management Service(AWS KMS) 암호화 Amazon S3 버킷에 자격 증명이 포함된 파일을 저장합니다. 파일을 정기적으로 응용 프로그램에 다운로드하여 올바른 자격 증명이 사용되는지 확인하십시오. 14일마다 Aurora 자격 증명을 교체하고 이러한 자격 증명을 S3 버킷의 파일에 업로드하는 AWS Lambda 함수를 구현합니다.\", \"A business runs a multi-tier web application that stores data on an Amazon Aurora MySQL DB cluster. Amazon EC2 instances are used to host the application tier. The company's information technology security policies require that database credentials be encrypted and changed every 14 days.\\nWhat should a solutions architect do in order to satisfy this demand with the LEAST amount of operational work possible?\\n\\nA.Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.\\nB. Create two parameters in AWS Systems Manager Parameter Store: one for the user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days.\\nC. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all EC2 instances of the application tier. Restrict the access to the file on the file system so that the application can read the file and that only super users can modify the file. Implement an AWS Lambda function that rotates the key in Aurora every 14 days and writes new credentials into the file.\\nD. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon S3 bucket that the application uses to load the credentials. Download the file to the application regularly to ensure that the correct credentials are used. Implement an AWS Lambda function that rotates the Aurora credentials every 14 days and uploads these credentials to the file in the S3 bucket.\", \"A\"],\n[\"기업은 수많은 Application Load Balancer로 보호되는 웹사이트를 운영하고 있습니다. 회사는 여러 국가에서 자료에 대한 다양한 배포 권한을 가지고 있습니다. 솔루션 아키텍트는 배포 권한을 침해하지 않고 적절한 자료가 사용자에게 제공되는지 확인해야 합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 구성을 사용해야 합니까?\\n\\nA.AWS WAF로 Amazon CloudFront를 구성합니다.\\nB. AWS WAF로 Application Load Balancer를 구성합니다.\\nC. 지리적 위치 정책으로 Amazon Route 53을 구성합니다.\\nD. 지리 근접 라우팅 정책으로 Amazon Route 53을 구성합니다.\", \"A business operates a website that is protected by numerous Application Load Balancers. The corporation has a variety of distribution rights to its material in several countries. A solutions architect must verify that the proper material is given to users without infringing on distribution rights.\\nWhich configuration should the solution architect use in order to satisfy these requirements?\\n\\nA.Configure Amazon CloudFront with AWS WAF.\\nB. Configure Application Load Balancers with AWS WAF.\\nC. Configure Amazon Route 53 with a geolocation policy.\\nD. Configure Amazon Route 53 with a geoproximity routing policy.\", \"C\"],\n[\"사용자가 Amazon EC2 인스턴스와 연결된 IAM 역할 목록을 요청합니다. 사용자는 로그인 인터페이스를 통해 EC2 인스턴스에 액세스할 수 있지만 IAM 권한은 없습니다.\\n.솔루션 아키텍트가 이 데이터를 검색하는 방법은 무엇입니까?\\n\\nA.다음 EC2 명령을 실행합니다. curl http://169.254.169.254/latest/meta-data/iam/info\\nB. 다음 EC2 명령을 실행합니다. curl http://169.254.169.254/latest/user-data/iam/info\\nC. 다음 EC2 명령을 실행합니다. http://169.254.169.254/latest/dynamic/instance-identity/\\nD. 다음 AWS CLI 명령을 실행합니다. aws iam get-instance-profile --instance-profile-name ExampleInstanceProfile\", \"A user requests a list of the IAM roles associated with their Amazon EC2 instance. The user has access to the EC2 instance through the login interface but does not have IAM rights.\\n.How might a solutions architect go about retrieving this data?\\n\\nA.Run the following EC2 command: curl http://169.254.169.254/latest/meta-data/iam/info\\nB. Run the following EC2 command: curl http://169.254.169.254/latest/user-data/iam/info\\nC. Run the following EC2 command: http://169.254.169.254/latest/dynamic/instance-identity/\\nD. Run the following AWS CLI command: aws iam get-instance-profile --instance-profile-name ExampleInstanceProfile\", \"A\"],\n[\"상품에 대한 수요가 증가함에 따라 사업이 확장되고 있습니다. 트래픽이 증가하면 회사의 현재 구매 애플리케이션이 느려집니다. 애플리케이션은 동기식 트랜잭션을 사용하는 3계층 모놀리스이며 때때로 애플리케이션 계층에서 병목 현상이 발생합니다. 솔루션 설계자는 트래픽 흐름의 급증을 허용하면서 애플리케이션 응답 시간 요구 사항을 충족하는 솔루션을 구축해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.더 큰 Amazon EC2 인스턴스 크기를 사용하여 애플리케이션 인스턴스를 수직으로 확장합니다.\\nB. AWS에 Oracle RAC를 도입하여 애플리케이션의 지속성 계층을 수평으로 확장합니다.\\nC. Auto Scaling 그룹과 Application Load Balancer를 사용하여 웹 및 애플리케이션 계층을 수평으로 확장합니다.\\nD. 비동기식 AWS Lambda 호출과 함께 Amazon Simple Queue Service(Amazon SQS)를 사용하여 애플리케이션과 데이터 계층을 분리합니다.\", \"A business is expanding as demand for its goods increases. When traffic increases, the company's current purchase application is sluggish. The application is a three-layer monolith that employs synchronous transactions and sometimes has bottlenecks at the application tier. A solutions architect must build a solution that satisfies application response time requirements while allowing for surges in traffic flow.\\nWhich solution will satisfy these criteria?\\n\\nA.Vertically scale the application instance using a larger Amazon EC2 instance size.\\nB. Scale the application's persistence layer horizontally by introducing Oracle RAC on AWS.\\nC. Scale the web and application tiers horizontally using Auto Scaling groups and an Application Load Balancer.\\nD. Decouple the application and data tiers using Amazon Simple Queue Service (Amazon SQS) with asynchronous AWS Lambda calls.\", \"C\"],\n[\"솔루션 설계자는 새 AWS 계정을 설정했으며 계정에 대한 루트 사용자 액세스를 보호할 책임이 있습니다.\\n어떤 조치가 이 작업을 수행합니까? (2개를 선택하세요.)\\n\\nA.루트 사용자가 강력한 암호를 사용하는지 확인하십시오.\\nB. 루트 사용자에 대한 다단계 인증을 활성화합니다.\\nC. 암호화된 Amazon S3 버킷에 루트 사용자 액세스 키를 저장합니다.\\nD. 관리 권한이 포함된 그룹에 루트 사용자를 추가합니다.\\nE. 인라인 정책 문서를 사용하여 루트 사용자에게 필요한 권한을 적용합니다.\", \"A solutions architect has established a new AWS account and is responsible for securing root user access to the account.\\nWhich action(s) will do this? (Select two.)\\n\\nA.Ensure the root user uses a strong password.\\nB. Enable multi-factor authentication to the root user.\\nC. Store root user access keys in an encrypted Amazon S3 bucket.\\nD. Add the root user to a group containing administrative permissions.\\nE. Apply the required permissions to the root user with an inline policy document.\", \"A, B\"],\n[\"비즈니스에서 컨테이너화된 앱을 개발 중입니다. 이 회사는 온프레미스 개발 및 운영 서비스를 AWS로 전환하기를 원합니다. 경영진에 따르면 프로덕션 시스템은 클라우드에 구애받지 않고 구성 및 관리자 도구를 공유해야 합니다. 솔루션 설계자는 오픈 소스 소프트웨어의 정렬을 보장하는 관리형 솔루션을 제공해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.EC2 인스턴스 작업자 노드가 있는 Amazon EC2에서 컨테이너를 시작합니다.\\nB. Amazon Elastic Kubernetes Service(Amazon EKS) 및 EKS 작업자 노드에서 컨테이너를 시작합니다.\\nC. AWS Fargate 인스턴스를 사용하여 Amazon Elastic Containers 서비스(Amazon ECS)에서 컨테이너를 시작합니다.\\nD. Amazon EC2 인스턴스 작업자 노드를 사용하여 Amazon Elastic Container Service(Amazon ECS)에서 컨테이너를 시작합니다.\", \"A business is developing containerized apps. The firm wishes to shift its on-premises development and operational services to AWS. According to management, production systems must be cloud agnostic and share configuration and administrator tools. A solutions architect must provide a managed solution that ensures the alignment of open-source software.\\nWhich solution satisfies these criteria?\\n\\nA.Launch the containers on Amazon EC2 with EC2 instance worker nodes.\\nB. Launch the containers on Amazon Elastic Kubernetes Service (Amazon EKS) and EKS worker nodes.\\nC. Launch the containers on Amazon Elastic Containers service (Amazon ECS) with AWS Fargate instances.\\nD. Launch the containers on Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 instance worker nodes.\", \"B\"],\n[\"자전거 공유 회사는 피크 시간 동안 자전거의 위치를 ​​모니터링하기 위해 다층 아키텍처를 구축하고 있습니다. 비즈니스는 이러한 데이터 포인트를 현재 분석 플랫폼에 통합할 계획입니다. 솔루션 설계자는 가장 적합한 다중 계층 아키텍처 지원 선택을 결정해야 합니다. REST API는 데이터 포인트에 액세스할 수 있어야 합니다.\\n위치 데이터에 대한 이러한 저장 및 검색 기준을 충족하는 작업은 무엇입니까?\\n\\nA.Amazon S3와 함께 Amazon Athena를 사용하십시오.\\nB. AWS Lambda와 함께 Amazon API Gateway를 사용합니다.\\nC. Amazon Redshift와 함께 Amazon QuickSight를 사용합니다.\\nD. Amazon Kinesis Data Analytics와 함께 Amazon API Gateway를 사용합니다.\", \"A bicycle sharing firm is building a multi-tier architecture to monitor the position of its bicycles during peak hours of operation. The business intends to incorporate these data points into its current analytics platform. A solutions architect must decide on the most suitable multi-tier architectural support choice. The REST API must be able to access the data points.\\nWhich action satisfies these storage and retrieval criteria for location data?\\n\\nA.Use Amazon Athena with Amazon S3.\\nB. Use Amazon API Gateway with AWS Lambda.\\nC. Use Amazon QuickSight with Amazon Redshift.\\nD. Use Amazon API Gateway with Amazon Kinesis Data Analytics.\", \"B\"],\n[\"솔루션 설계자는 엔지니어링 도면을 저장하고 표시하는 데 사용할 새로운 온라인 애플리케이션을 위한 스토리지 아키텍처를 개발해야 합니다. 모든 애플리케이션 구성 요소는 AWS에서 호스팅됩니다.\\n응용 프로그램의 아키텍처는 사용자가 엔지니어링 도면이 로드될 때까지 기다리는 시간을 줄이기 위해 캐싱을 사용해야 합니다. 페타바이트의 데이터를 프로그램에 저장할 수 있어야 합니다.\\n솔루션 설계자는 어떤 스토리지 및 캐싱 조합을 사용해야 합니까?\\n\\nA.Amazon CloudFront를 사용하는 Amazon S3\\nB. Amazon ElastiCache가 포함된 Amazon S3 Glacier\\nC. Amazon CloudFront를 사용한 Amazon Elastic Block Store(Amazon EBS) 볼륨\\nD. Amazon ElastiCache가 포함된 AWS Storage Gateway\", \"A solutions architect is tasked with developing the storage architecture for a new online application that will be used to store and display engineering drawings. All application components will be hosted on AWS.\\nThe application's architecture must use caching in order to decrease the time users spend waiting for engineering drawings to load. Petabytes of data must be able to be stored in the program.\\nWhich storage and caching mix should the solutions architect use?\\n\\nA.Amazon S3 with Amazon CloudFront\\nB. Amazon S3 Glacier with Amazon ElastiCache\\nC. Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront\\nD. AWS Storage Gateway with Amazon ElastiCache\", \"A\"],\n[\"미디어 비즈니스는 운영을 AWS 클라우드로 마이그레이션하는 것을 고려하고 있습니다. 조직은 비디오 처리를 위한 실현 가능한 가장 높은 I/O 성능을 갖춘 최소 10테라바이트의 저장소, 미디어 콘텐츠 저장소를 위한 300테라바이트의 매우 내구성 있는 저장소, 더 이상 사용하지 않는 자료 보관에 대한 표준을 충족하는 900테라바이트의 저장소가 필요합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 서비스를 제안해야 합니까?\\n\\nA.최대 성능을 위한 Amazon Elastic Block Store(Amazon EBS), 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier\\nB. 최대 성능을 위한 Amazon Elastic Block Store(Amazon EBS), 내구성 있는 데이터 스토리지를 위한 Amazon Elastic File System(Amazon EFS), 아카이브 스토리지를 위한 Amazon S3 Glacier\\nC. 최대 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon Elastic File System(Amazon EFS), 아카이브 스토리지를 위한 Amazon S3\\nD. 최대 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon S3, 아카이브 스토리지를 위한 Amazon S3 Glacier\", \"A media business is considering migrating its operations to the AWS Cloud. The organization requires at least ten terabytes of storage with the highest feasible I/O performance for video processing, 300 terabytes of very durable storage for media content storage, and 900 terabytes of storage to satisfy standards for archiving material that is no longer in use.\\nWhich services should a solutions architect propose in order to satisfy these requirements?\\n\\nA.Amazon Elastic Block Store (Amazon EBS) for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage\\nB. Amazon Elastic Block Store (Amazon EBS) for maximum performance, Amazon Elastic File System (Amazon EFS) for durable data storage, and Amazon S3 Glacier for archival storage\\nC. Amazon EC2 instance store for maximum performance, Amazon Elastic File System (Amazon EFS) for durable data storage, and Amazon S3 for archival storage\\nD. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage\", \"D\"],\n[\"기업은 대량의 데이터를 동시에 처리하는 애플리케이션을 구현하고 있습니다. 워크로드는 Amazon EC2 인스턴스에서 실행됩니다. 네트워크 아키텍처는 노드 그룹이 동일한 기본 하드웨어를 공유하지 않는 방식으로 구성되어야 합니다.\\n이러한 기준을 충족하는 네트워킹 솔루션은 무엇입니까?\\n\\nA.분산 배치 그룹에서 EC2 인스턴스를 실행합니다.\\nB. EC2 인스턴스를 별도의 계정으로 그룹화합니다.\\nC. 전용 테넌시로 EC2 인스턴스를 구성합니다.\\nD. 공유 테넌시로 EC2 인스턴스를 구성합니다.\", \"A business is implementing an application that handles massive amounts of data concurrently. The workload will be run on Amazon EC2 instances. The network architecture must be configured in such a way that groups of nodes do not share the same underlying hardware.\\nWhich networking solution satisfies these criteria?\\n\\nA.Run the EC2 instances in a spread placement group.\\nB. Group the EC2 instances in separate accounts.\\nC. Configure the EC2 instances with dedicated tenancy.\\nD. Configure the EC2 instances with shared tenancy.\", \"A\"],\n[\"한 트럭 회사에서 회사 차량의 모든 GPS 위치를 모니터링하는 애플리케이션을 설치하고 있습니다. 조직에는 마이크로초 범위에서 높은 읽기 처리량과 짧은 대기 시간으로 메타데이터 조회를 기반으로 실시간 통계를 생성하는 솔루션이 필요합니다. 데이터베이스는 내결함성이 있어야 하며 운영 및 개발 오버헤드가 낮아야 합니다.\\n이러한 요구 사항을 달성하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까? (2개를 선택하세요.)\\n\\nA.Amazon DynamoDB를 데이터베이스로 사용합니다.\\nB. Amazon Aurora MySQL을 데이터베이스로 사용합니다.\\nC. Amazon RDS for MySQL을 데이터베이스로 사용\\nD. Amazon ElastiCache를 캐싱 계층으로 사용합니다.\\nE. Amazon DynamoDB Accelerator(DAX)를 캐싱 계층으로 사용합니다.\", \"A trucking firm is installing an application that will monitor all of the company's vehicles' GPS positions. The organization requires a solution that generates real-time statistics based on metadata lookups with a high read throughput and low latency in the microsecond range. The database must be fault-tolerant and have a low operating and development overhead.\\nWhich actions should a solutions architect do in combination to achieve these requirements? (Select two.)\\n\\nA.Use Amazon DynamoDB as the database.\\nB. Use Amazon Aurora MySQL as the database.\\nC. Use Amazon RDS for MySQL as the database\\nD. Use Amazon ElastiCache as the caching layer.\\nE. Use Amazon DynamoDB Accelerator (DAX) as the caching layer.\", \"A, E\"],\n[\"기업은 데이터 과학 팀이 온프레미스와 Amazon Web Services(AWS) 클라우드 모두에서 데이터를 연구할 수 있는 스토리지 솔루션을 찾고 있습니다. 팀은 온프레미스 및 여러 가용 영역에 분산된 Amazon EC2 인스턴스 집합을 통해 통계 연구를 수행할 수 있어야 합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.AWS Storage Gateway 테이프 게이트웨이를 사용하여 온프레미스 파일을 Amazon S3에 복사합니다.\\nB. AWS Storage Gateway 볼륨 게이트웨이를 사용하여 온프레미스 파일을 Amazon S3에 복사합니다.\\nC. AWS Storage Gateway 파일 게이트웨이를 사용하여 온프레미스 파일을 Amazon Elastic Block Store(Amazon EBS)에 복사합니다.\\nD. Amazon Elastic File System(Amazon EFS) 파일 시스템을 온프레미스 서버에 연결합니다. 파일을 Amazon EFS에 복사합니다.\", \"A business seeks a storage solution that allows its data science team to study data both on-premises and on the Amazon Web Services (AWS) Cloud. The team must be able to conduct statistical studies on-premises and through a fleet of Amazon EC2 instances distributed across several Availability Zones.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Use an AWS Storage Gateway tape gateway to copy the on-premises files into Amazon S3.\\nB. Use an AWS Storage Gateway volume gateway to copy the on-premises files into Amazon S3.\\nC. Use an AWS Storage Gateway file gateway to copy the on-premises files to Amazon Elastic Block Store (Amazon EBS).\\nD. Attach an Amazon Elastic File System (Amazon EFS) file system to the on-premises servers. Copy the files to Amazon EFS.\", \"D\"],\n[\"비즈니스에서 MySQL 데이터베이스를 온프레미스 위치에서 AWS로 이전하려고 합니다. 조직은 최근 비즈니스 운영에 상당한 영향을 미치는 데이터베이스 중단을 겪었습니다. 이러한 일이 다시 발생하지 않도록 하려면 데이터 손실을 최소화하고 최소 2개의 노드에서 각 트랜잭션을 복제하는 확장 가능한 AWS 기반 데이터베이스 솔루션이 조직에 필요합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.3개의 가용 영역에 있는 3개의 노드에 동기식 복제를 사용하여 Amazon RDS DB 인스턴스를 생성합니다.\\nB. 데이터를 동기식으로 복제할 수 있도록 다중 AZ 기능이 활성화된 Amazon RDS MySQL DB 인스턴스를 생성합니다.\\nC. Amazon RDS MySQL DB 인스턴스를 생성한 다음 데이터를 동기식으로 복제하는 별도의 AWS 리전에 읽기 전용 복제본을 생성합니다.\\nD. AWS Lambda 함수를 트리거하여 Amazon RDS MySQL DB 인스턴스에 데이터를 동기식으로 복제하는 MySQL 엔진이 설치된 Amazon EC2 인스턴스를 생성합니다.\", \"A business wishes to transfer its MySQL database from its on-premises location to AWS. The organization recently had a database outage, which had a substantial effect on business operations. To prevent this from happening again, the organization need a scalable database solution on AWS that minimizes data loss and replicates each transaction over at least two nodes.\\nWhich solution satisfies these criteria?\\n\\nA.Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones.\\nB. Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data.\\nC. Create an Amazon RDS MySQL DB instance and then create a read replica in a separate AWS Region that synchronously replicates the data.\\nD. Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to synchronously replicate the data to an Amazon RDS MySQL DB instance.\", \"B\"],\n[\"비즈니스 애플리케이션은 단일 리전의 Amazon EC2 인스턴스에서 호스팅됩니다. 재해가 발생한 경우 솔루션 설계자는 리소스를 보조 리전에 배포할 수도 있음을 보장해야 합니다.\\n이를 달성하기 위해 솔루션 설계자는 어떤 활동을 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.EC2 인스턴스에서 볼륨을 분리하고 Amazon S3에 복사합니다.\\nB. 새 리전의 Amazon 머신 이미지(AMI)에서 새 EC2 인스턴스를 시작합니다.\\nC. 새 리전에서 새 EC2 인스턴스를 시작하고 Amazon S3에서 새 인스턴스로 볼륨을 복사합니다.\\nD. EC2 인스턴스의 Amazon 머신 이미지(AMI)를 복사하고 대상에 대해 다른 리전을 지정합니다.\\nE. Amazon S3에서 Amazon Elastic Block Store(Amazon EBS) 볼륨을 복사하고 해당 EBS 볼륨을 사용하여 대상 리전에서 EC2 인스턴스를 시작합니다.\", \"The application of a business is hosted on Amazon EC2 instances in a single Region. In the case of a catastrophe, a solutions architect must guarantee that resources are also available for deployment to a secondary Region.\\nWhich activities should the solutions architect take in conjunction to achieve this? (Select two.)\\n\\nA.Detach a volume on an EC2 instance and copy it to Amazon S3.\\nB. Launch a new EC2 instance from an Amazon Machine Image (AMI) in a new Region.\\nC. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance.\\nD. Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination.\\nE. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume.\", \"B, D\"],\n[\"비즈니스는 적절한 권한 없이는 누구도 데이터에 액세스할 수 없도록 하기 위해 AWS 클라우드 배포를 감사하고 있습니다. 솔루션 설계자는 열려 있는 모든 Amazon S3 버킷을 식별하고 설정에 대한 모든 수정 사항을 문서화할 책임이 있습니다.\\n이를 달성하기 위한 솔루션 설계자의 역할은 무엇입니까?\\n\\nA.적절한 규칙으로 AWS Config 서비스 활성화\\nB. 적절한 검사를 통해 AWS Trusted Advisor를 활성화합니다.\\nC. AWS SDK를 사용하여 버킷 보고서를 생성하는 스크립트 작성\\nD. Amazon S3 서버 액세스 로깅을 활성화하고 Amazon CloudWatch Events를 구성합니다.\", \"A business is auditing its AWS Cloud deployment to guarantee that no one may access its data without the proper authorisation. A solutions architect is responsible for identifying all open Amazon S3 buckets and documenting any modifications to their setup.\\nWhat is the solution architect's role in achieving this?\\n\\nA.Enable AWS Config service with the appropriate rules\\nB. Enable AWS Trusted Advisor with the appropriate checks.\\nC. Write a script using an AWS SDK to generate a bucket report\\nD. Enable Amazon S3 server access logging and configure Amazon CloudWatch Events.\", \"A\"],\n[\"기업은 사용자 요청을 수집하고 요청 유형에 따라 처리를 위해 적절한 마이크로 서비스로 라우팅하는 데 사용되는 비동기 API를 소유하고 있습니다. 이 회사는 Amazon API Gateway를 사용하여 API 프런트 엔드를 배포하고 있으며 Amazon DynamoDB를 호출하여 사용자 요청을 처리 마이크로서비스로 라우팅하기 전에 저장하는 AWS Lambda 함수를 배포하고 있습니다.\\n회사는 예산 제약 내에서 가능한 한 많은 DynamoDB 용량을 제공했지만 회사는 계속해서 가용성 문제를 겪고 있으며 사용자 요청을 잃고 있습니다.\\n솔루션 설계자는 현재 사용자에게 부정적인 영향을 미치지 않는 방식으로 이 문제를 처리하기 위해 무엇을 해야 합니까?\\n\\nA.서버 측 조절 제한이 있는 API Gateway에 조절을 추가합니다.\\nB. DynamoDB 가속기(DAX) 및 Lambda를 사용하여 DynamoDB에 대한 쓰기를 버퍼링합니다.\\nC. 사용자 요청이 있는 테이블에 대해 DynamoDB에 보조 인덱스를 생성합니다.\\nD. Amazon Simple Queue Service(Amazon SQS) 대기열과 Lambda를 사용하여 DynamoDB에 대한 쓰기를 버퍼링합니다.\", \"A business owns an asynchronous API that is used to ingest user requests and route them to the appropriate microservice for processing depending on the request type. The firm is deploying the API front end using Amazon API Gateway, as well as an AWS Lambda function that calls Amazon DynamoDB to store user requests before routing them to the processing microservices.\\nThe firm supplied as much DynamoDB capacity as possible within its budget constraints, yet the company continues to have availability difficulties and is losing user requests.\\nWhat should a solutions architect do to handle this problem in a way that does not negatively effect current users?\\n\\nA.Add throttling on the API Gateway with server-side throttling limits.\\nB. Use DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB.\\nC. Create a secondary index in DynamoDB for the table with the user requests.\\nD. Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB.\", \"D. write에 과부하가 걸린 상황이므로 DAX는 부적절\"],\n[\"us-east-1 리전의 한 스타트업 기업은 서로 다른 가용 영역에 걸쳐 Application Load Balancer 뒤에서 여러 Amazon EC2 인스턴스에서 작동하는 웹 애플리케이션을 보유하고 있습니다. us-west-1 리전에서 회사의 사용자 기반이 확장됨에 따라 대기 시간이 짧은 고가용성 솔루션이 필요합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.us-west-1에서 EC2 인스턴스를 프로비저닝합니다. 지역 간 로드 밸런싱을 달성하려면 Application Load Balancer를 Network Load Balancer로 전환하십시오.\\nB. us-west-1에서 EC2 인스턴스와 Application Load Balancer를 프로비저닝합니다. 로드 밸런서가 요청 위치를 기반으로 트래픽을 분산하도록 합니다.\\nC. us-west-1에서 EC2 인스턴스를 프로비저닝하고 Application Load Balancer를 구성합니다. 두 리전의 로드 밸런서 엔드포인트를 포함하는 엔드포인트 그룹을 사용하는 AWS Global Accelerator에서 액셀러레이터를 생성합니다.\\nD. EC2 인스턴스를 프로비저닝하고 us-west-1에서 Application Load Balancer를 구성합니다. 가중치 기반 라우팅 정책으로 Amazon Route 53을 구성합니다. Application Load Balancer를 가리키는 Route 53에서 별칭 레코드를 생성합니다.\", \"A start-up business in the us-east-1 Region has a web application operating on several Amazon EC2 instances behind an Application Load Balancer across different Availability Zones. As the company's user base expands in the us-west-1 Region, it requires a low-latency, high-availability solution.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Provision EC2 instances in us-west-1. Switch the Application Load Balancer to a Network Load Balancer to achieve cross-Region load balancing.\\nB. Provision EC2 instances and an Application Load Balancer in us-west-1. Make the load balancer distribute the traffic based on the location of the request.\\nC. Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions.\\nD. Provision EC2 instances and configure an Application Load Balancer in us-west-1. Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer.\", \"D\"],\n[\"한 기업에 다음 달 내에 AWS 클라우드로 마이그레이션해야 하는 150TB의 온프레미스 보관 사진 데이터가 있습니다. 회사의 현재 네트워크 연결은 이 목적을 위해 야간에만 최대 100Mbps의 업로드를 지원합니다.\\n이 데이터를 이동하고 마이그레이션 기한을 준수하는 가장 비용 효율적인 방법은 무엇입니까?\\n\\nA.AWS Snowmobile을 사용하여 데이터를 AWS로 배송합니다.\\nB. 여러 AWS Snowball 디바이스를 주문하여 데이터를 AWS로 배송합니다.\\nC. Amazon S3 Transfer Acceleration을 활성화하고 데이터를 안전하게 업로드합니다.\\nD. Amazon S3 VPC 엔드포인트를 생성하고 VPN을 설정하여 데이터를 업로드합니다.\", \"A business has 150 TB of on-premises archival picture data that must be migrated to the AWS Cloud within the next month. The company's present network connection supports uploads of up to 100 Mbps for this purpose only at night.\\nWhat is the MOST COST-EFFECTIVE method for moving this data and adhering to the migration deadline?\\n\\nA.Use AWS Snowmobile to ship the data to AWS.\\nB. Order multiple AWS Snowball devices to ship the data to AWS.\\nC. Enable Amazon S3 Transfer Acceleration and securely upload the data.\\nD. Create an Amazon S3 VPC endpoint and establish a VPN to upload the data.\", \"B\"],\n[\"솔루션 설계자는 보안 그룹이 0.0.0.0/0에서 SSH를 허용하는 규칙을 포함하지 못하도록 하는 회사의 규정 준수 정책에 대한 자동화된 솔루션을 개발해야 합니다. 정책 위반이 있는 경우 해당 업체에 알려야 합니다. 즉시 해결책이 필요합니다.\\n이러한 기준이 가능한 한 최소한의 운영 오버헤드를 충족하도록 하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.SSH가 0.0.0.0/0 주소로 열려 있는 보안 그룹을 모니터링하고 찾을 때마다 알림을 생성하는 AWS Lambda 스크립트를 작성하십시오.\\nB. 제한적 SSH AWS Config 관리형 규칙을 활성화하고 비준수 규칙이 생성될 때 Amazon Simple Notification Service(Amazon SNS) 알림을 생성합니다.\\nC. 보안 그룹 및 네트워크 ACL을 전역적으로 열 수 있는 권한이 있는 IAM 역할을 생성합니다. 사용자가 역할을 맡을 때마다 알림을 생성하도록 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다.\\nD. 관리자가 아닌 사용자가 보안 그룹을 만들거나 편집하는 것을 방지하는 SCP(서비스 제어 정책)를 구성합니다. 사용자가 관리자 권한이 필요한 규칙을 요청할 때 티켓팅 시스템에서 알림을 생성합니다.\", \"A solutions architect must develop an automated solution to a company's compliance policy that prohibits security groups from including a rule allowing SSH from 0.0.0.0/0. If there is a violation of the policy, the business must be informed. A solution is required immediately.\\nWhat actions should the solutions architect take to ensure that these criteria are met with the LEAST amount of operational overhead possible?\\n\\nA.Write an AWS Lambda script that monitors security groups for SSH being open to 0.0.0.0/0 addresses and creates a notification every time it finds one.\\nB. Enable the restricted-ssh AWS Config managed rule and generate an Amazon Simple Notification Service (Amazon SNS) notification when a noncompliant rule is created.\\nC. Create an IAM role with permissions to globally open security groups and network ACLs. Create an Amazon Simple Notification Service (Amazon SNS) topic to generate a notification every time the role is assumed by a user.\\nD. Configure a service control policy (SCP) that prevents non-administrative users from creating or editing security groups. Create a notification in the ticketing system when a user requests a rule that needs administrator permissions.\", \"B\"],\n[\"Solutions Architect는 AWS에서 호스팅되고 고객이 S3 버킷에 저장된 프리미엄 공유 콘텐츠에 대한 액세스 권한을 지불할 수 있도록 하는 웹 애플리케이션 개발을 담당합니다. 구매 후 사용자는 액세스가 금지되기 전에 14일 동안 자료를 다운로드해야 합니다.\\n다음 중 구현에 가장 적은 노력이 필요한 것은 무엇입니까?\\n\\nA.오리진 액세스 ID(OAI)가 있는 Amazon CloudFront 배포를 사용합니다. 서명된 URL을 통해 파일에 대한 액세스를 제공하도록 Amazon S3 오리진으로 배포를 구성합니다. 14일이 지난 데이터를 제거하는 Lambda 함수를 설계합니다.\\nB. S3 버킷을 사용하고 파일에 대한 직접 액세스를 제공합니다. DynamoDB 테이블에서 구매를 추적하도록 애플리케이션을 설계합니다. Amazon DynamoDB에 대한 쿼리를 기반으로 14일이 지난 데이터를 제거하도록 Lambda 함수를 구성합니다.\\nC. OAI와 함께 Amazon CloudFront 배포를 사용합니다. 서명된 URL을 통해 파일에 대한 액세스를 제공하도록 Amazon S3 오리진으로 배포를 구성합니다. URL의 만료일을 14일로 설정하도록 애플리케이션을 디자인합니다.\\nD. OAI와 함께 Amazon CloudFront 배포를 사용합니다. 서명된 URL을 통해 파일에 대한 액세스를 제공하도록 Amazon S3 오리진으로 배포를 구성합니다. URL의 만료 시간을 60분으로 설정하도록 애플리케이션을 설계하고 필요에 따라 URL을 다시 작성하십시오.\", \"A Solutions Architect is responsible for developing a web application that will be hosted on AWS and will enable customers to pay access to premium, shared content stored in an S3 bucket. After purchase, users will have 14 days to download material before being banned access.\\nWhich of the following would require the LEAST amount of effort to implement?\\n\\nA.Use an Amazon CloudFront distribution with an origin access identity (OAI). Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design a Lambda function to remove data that is older than 14 days.\\nB. Use an S3 bucket and provide direct access to the file. Design the application to track purchases in a DynamoDB table. Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB.\\nC. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 14 days for the URL.\\nD. Use an Amazon CloudFront distribution with an OAI. Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs. Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary.\", \"C. S3의 서명 URL 만료기간은 7일까지 설정 가능하지만, CF의 만료 기간은 제한이 없음.\"],\n[\"퍼블릭이 액세스할 수 있는 웹 애플리케이션은 프라이빗 서브넷의 Amazon EC2 인스턴스에 있는 데이터베이스를 쿼리합니다. 수많은 쿼리에는 수많은 데이터베이스 조인이 있으며 복잡한 쿼리의 증가로 인해 응용 프로그램의 성능이 저하되었습니다. 애플리케이션 팀은 성능을 향상시킬 것입니다.\\n솔루션 설계자는 애플리케이션 팀에 어떤 권장 사항을 제공해야 합니까? (2개를 선택하세요.)\\n\\nA.Amazon SQS의 캐시 쿼리 데이터\\nB. 쿼리 오프로드를 위한 읽기 전용 복제본 생성\\nC. 데이터베이스를 Amazon Athena로 마이그레이션\\nD. 데이터를 캐시하기 위해 Amazon DynamoDB Accelerator를 구현합니다.\\nE. 데이터베이스를 Amazon RDS로 마이그레이션\", \"A web application that is accessible to the public queries a database that is housed on an Amazon EC2 instance in a private subnet. Numerous queries have numerous database joins, and the application's performance has deteriorated as a result of the growth in complicated queries. The application team will be making performance enhancements.\\nWhat recommendations should a solutions architect provide to the application team? (Select two.)\\n\\nA.Cache query data in Amazon SQS\\nB. Create a read replica to offload queries\\nC. Migrate the database to Amazon Athena\\nD. Implement Amazon DynamoDB Accelerator to cache data.\\nE. Migrate the database to Amazon RDS\", \"B, E\"],\n[\"온프레미스에서 비즈니스는 다계층 웹 애플리케이션을 실행합니다. 웹 애플리케이션은 컨테이너화되어 있으며 사용자 기록을 저장하는 PostgreSQL 데이터베이스에 연결된 Linux 컴퓨터의 분산 네트워크에서 작동합니다. 인프라 유지 관리 및 용량 계획과 관련된 운영 비용이 회사 확장을 방해하고 있습니다. 솔루션 설계자는 애플리케이션의 인프라를 향상시키는 일을 담당합니다.\\n이를 달성하기 위해 솔루션 설계자는 어떤 활동을 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션합니다.\\nB. Amazon EC2 인스턴스에서 호스팅할 웹 애플리케이션을 마이그레이션합니다.\\nC. 웹 애플리케이션 콘텐츠에 대한 Amazon CloudFront 배포를 설정합니다.\\nD. 웹 애플리케이션과 PostgreSQL 데이터베이스 간에 Amazon ElastiCache를 설정합니다.\\nE. Amazon Elastic Container Service(Amazon ECS)를 사용하여 AWS Fargate에서 호스팅할 웹 애플리케이션을 마이그레이션합니다.\", \"On-premises, a business runs a multi-tier web application. The web application is containerized and operates on a distributed network of Linux computers that are linked to a PostgreSQL database that stores user records. The operational costs associated with infrastructure maintenance and capacity planning are impeding the company's expansion. A solutions architect is responsible for enhancing the application's infrastructure.\\nWhich activities should the solutions architect take in conjunction to achieve this? (Select two.)\\n\\nA.Migrate the PostgreSQL database to Amazon Aurora.\\nB. Migrate the web application to be hosted on Amazon EC2 instances.\\nC. Set up an Amazon CloudFront distribution for the web application content.\\nD. Set up Amazon ElastiCache between the web application and the PostgreSQL database.\\nE. Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS).\", \"A, E\"],\n[\"한 회사가 미디어 공유 서비스를 개발 중이며 Amazon S3에 저장하기로 선택했습니다. 미디어 파일이 업로드되면 회사는 썸네일 생성, 사진 내 개체 식별, 표준 형식 및 해상도로 필름 트랜스코딩, Amazon DynamoDB 데이터베이스에 정보 추출 및 저장을 포함하는 다단계 프로세스를 시작합니다. 메타데이터는 검색 및 탐색을 용이하게 하는 데 사용됩니다.\\n트래픽 양이 다릅니다. 시스템은 추가 비용 없이 트래픽 급증을 수용할 수 있도록 확장 가능해야 합니다.\\n이 워크로드를 수용하기 위해 어떤 솔루션 설계자가 권장해야 합니까?\\n\\nA.Amazon S3에 콘텐츠를 업로드하는 데 사용되는 웹 사이트 또는 모바일 앱에 처리 기능을 구축합니다. 객체가 업로드되면 필요한 데이터를 DynamoDB 테이블에 저장합니다.\\nB. 객체가 S3 버킷에 저장되면 AWS Step Functions를 트리거합니다. Step Functions에서 객체를 처리하는 데 필요한 단계를 수행한 다음 DynamoDB 테이블에 메타데이터를 쓰도록 합니다.\\nC. 객체가 S3 버킷에 저장되면 AWS Lambda 함수를 트리거합니다. Lambda 함수가 AWS Batch를 시작하여 객체를 처리하는 단계를 수행하도록 합니다. 완료되면 DynamoDB 테이블에 객체 데이터를 배치합니다.\\nD. 객체가 Amazon S3에 업로드될 때 DynamoDB 테이블에 초기 항목을 저장하도록 AWS Lambda 함수를 트리거합니다. Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행되는 프로그램을 사용하여 처리되지 않은 항목에 대한 인덱스를 폴링하고 프로그램을 사용하여 처리를 수행합니다.\", \"A firm is developing a media sharing service and has chosen to store it on Amazon S3. When a media file is uploaded, the firm initiates a multi-step process that includes creating thumbnails, identifying objects within the photos, transcoding films into standard formats and resolutions, and extracting and storing information in an Amazon DynamoDB database. Metadata is used to facilitate search and navigation.\\nThe volume of traffic varies. The system must be scalable to accommodate surges in traffic without incurring additional costs.\\nWhat solutions architect recommendations should be made to accommodate this workload?\\n\\nA.Build the processing into the website or mobile app used to upload the content to Amazon S3. Save the required data to the DynamoDB table when the objects are uploaded.\\nB. Trigger AWS Step Functions when an object is stored in the S3 bucket. Have the Step Functions perform the steps needed to process the object and then write the metadata to the DynamoDB table.\\nC. Trigger an AWS Lambda function when an object is stored in the S3 bucket. Have the Lambda function start AWS Batch to perform the steps to process the object. Place the object data in the DynamoDB table when complete.\\nD. Trigger an AWS Lambda function to store an initial entry in the DynamoDB table when an object is uploaded to Amazon S3. Use a program running on an Amazon EC2 instance in an Auto Scaling group to poll the index for unprocessed items, and use the program to perform the processing.\", \"B\"],\n[\"재무 위험 모델링을 위해 Amazon Web Services(AWS) HPC(고성능 컴퓨팅) 인프라를 사용하려는 기업이 있습니다. Linux는 회사의 HPC 워크로드를 실행하는 데 사용됩니다. 각 HPC 프로세스는 수명이 짧고 수백 개의 AmazonEC2 스팟 인스턴스에서 작동하며 수천 개의 출력 파일을 생성하여 궁극적으로 분석 및 장기적 미래 사용을 위해 영구 스토리지에 보관됩니다.\\n조직은 온프레미스 데이터를 장기 영구 스토리지로 전송하여 처리를 위해 모든 EC2 인스턴스에 액세스할 수 있도록 하는 클라우드 스토리지 솔루션을 찾고 있습니다. 또한 솔루션은 데이터세트 및 출력 파일을 읽고 쓰기 위한 영구 저장소와 결합된 빠른 파일 시스템을 제공해야 합니다.\\n이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까?\\n\\nA.Amazon S3와 통합된 Lustre용 Amazon FSx\\nB. Amazon S3와 통합된 Windows 파일 서버용 Amazon FSx\\nC. Amazon Elastic Block Store(Amazon EBS)와 통합된 Amazon S3 Glacier\\nD. Amazon Elastic Block Store(Amazon EBS) 범용 SSD(gp2) 볼륨과 통합된 VPC 엔드포인트가 있는 Amazon S3 버킷\", \"A business want to employ Amazon Web Services' (AWS) high performance computing (HPC) infrastructure for financial risk modeling. Linux is used to execute the company's HPC workloads. Each HPC process is short-lived, operates on hundreds of AmazonEC2 Spot Instances, and creates thousands of output files that are eventually kept in persistent storage for analytics and long-term future usage.\\nThe organization is looking for a cloud storage solution that enables the transfer of on-premises data to long-term persistent storage, making it accessible to all EC2 instances for processing. Additionally, the solution should provide a fast file system coupled with persistent storage for reading and writing datasets and output files.\\nWhich AWS service combination satisfies these requirements?\\n\\nA.Amazon FSx for Lustre integrated with Amazon S3\\nB. Amazon FSx for Windows File Server integrated with Amazon S3\\nC. Amazon S3 Glacier integrated with Amazon Elastic Block Store (Amazon EBS)\\nD. Amazon S3 bucket with a VPC endpoint integrated with an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) volume\", \"A\"],\n[\"솔루션 아키텍트는 AWS에 배포될 새로운 애플리케이션을 위한 클라우드 아키텍처를 구축하는 책임이 있습니다. 이 프로그램을 사용하면 사용자가 대화식으로 파일을 다운로드하고 업로드할 수 있습니다. 2년 이상 된 파일은 액세스가 제한됩니다. 솔루션 설계자는 뛰어난 가용성과 내구성을 보장하면서 애플리케이션이 원하는 수의 파일로 확장되도록 보장해야 합니다.\\n솔루션 아키텍트가 권장해야 하는 확장 가능한 솔루션은 무엇입니까? (2개를 선택하세요.)\\n\\nA.2년 이상 된 객체를 S3 Glacier로 이동하는 수명 주기 정책으로 Amazon S3에 파일을 저장합니다.\\nB. 2년 이상 된 객체를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동하는 수명 주기 정책으로 Amazon S3에 파일 저장\\nC. 2년 이상 된 객체를 EFS Infrequent Access(EFS IA)로 이동하는 수명 주기 정책을 사용하여 Amazon Elastic File System(Amazon EFS)에 파일을 저장합니다.\\nD. 파일을 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. 볼륨의 스냅샷을 예약합니다. 스냅샷을 사용하여 2년보다 오래된 데이터를 보관하십시오.\\nE. RAID 스트라이프된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일을 저장합니다. 볼륨의 스냅샷을 예약합니다. 스냅샷을 사용하여 2년보다 오래된 데이터를 보관하십시오.\", \"A solutions architect is tasked with the responsibility of building the cloud architecture for a new application that will be deployed on AWS. The program enables users to download and upload files interactively. Files older than two years will get limited access. The architect of the solution must guarantee that the application scales to any number of files while ensuring excellent availability and durability.\\nWhich scalable solutions should be recommended by the solutions architect? (Select two.)\\n\\nA.Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Glacier.\\nB. Store the files on Amazon S3 with a lifecycle policy that moves objects older than 2 years to S3 Standard-Infrequent Access (S3 Standard-IA)\\nC. Store the files on Amazon Elastic File System (Amazon EFS) with a lifecycle policy that moves objects older than 2 years to EFS Infrequent Access (EFS IA).\\nD. Store the files in Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.\\nE. Store the files in RAID-striped Amazon Elastic Block Store (Amazon EBS) volumes. Schedule snapshots of the volumes. Use the snapshots to archive data older than 2 years.\", \"A, B\"],\n[\"여러 프로덕션 앱이 비즈니스에서 호스팅됩니다. 앱 중 하나는 다양한 AWS 리전에 분산된 Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service(Amazon SNS) 및 Amazon Simple Queue Service(Amazon SQS) 리소스를 활용합니다. 모든 비즈니스 리소스는 'application'이라는 태그와 각 애플리케이션에 고유한 값으로 표시됩니다. 솔루션 설계자의 임무는 레이블이 지정된 모든 구성 요소를 인식하는 가장 간단한 방법을 제공하는 것입니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS CloudTrail을 사용하여 애플리케이션 태그가 있는 리소스 목록을 생성합니다.\\nB. AWS CLI를 사용하여 모든 리전에서 각 서비스를 쿼리하여 태그가 지정된 구성 요소를 보고합니다.\\nC. Amazon CloudWatch Logs Insights에서 쿼리를 실행하여 애플리케이션 태그가 있는 구성 요소에 대해 보고합니다.\\nD. AWS Resource Groups Tag Editor로 쿼리를 실행하여 애플리케이션 태그가 있는 리소스에 대해 전 세계적으로 보고합니다.\", \"Multiple production apps are hosted by a business. One of the apps utilizes Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service (Amazon SNS), and Amazon Simple Queue Service (Amazon SQS) resources distributed across various AWS Regions. All business resources are marked with the tag 'application' and a value unique to each application. A solutions architect's job is to offer the simplest method for recognizing all labeled components.\\nWhich solution satisfies these criteria?\\n\\nA.Use AWS CloudTrail to generate a list of resources with the application tag.\\nB. Use the AWS CLI to query each service across all Regions to report the tagged components.\\nC. Run a query in Amazon CloudWatch Logs Insights to report on the components with the application tag.\\nD. Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag.\", \"D\"],\n[\"기업은 Amazon S3를 활용하여 사용자가 업로드한 사진을 저장하려고 합니다. 저장 시 사진은 Amazon S3에 보호되어야 합니다. 기업은 키를 유지 관리하고 교체하는 데 시간을 소비하기를 원하지 않지만 누가 키에 액세스할 수 있는지 규제하기를 원합니다.\\n솔루션 설계자는 이를 위해 어떤 도구와 기술을 사용해야 합니까?\\n\\nA.S3 버킷에 저장된 키를 사용한 서버 측 암호화\\nB. 고객 제공 키를 사용한 서버 측 암호화(SSE-C)\\nC. Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3)\\nD. AWS KMS 관리형 키(SSE-KMS)를 사용한 서버 측 암호화\", \"A business intends to utilize Amazon S3 to store user-uploaded photos. At rest, the photos must be secured in Amazon S3. The business does not want to spend time maintaining and rotating the keys, but does wish to regulate who has access to them.\\nWhat tools and techniques should a solutions architect use to do this?\\n\\nA.Server-Side Encryption with keys stored in an S3 bucket\\nB. Server-Side Encryption with Customer-Provided Keys (SSE-C)\\nC. Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)\\nD. Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)\", \"D\"],\n[\"기업에서 거대한 미션 크리티컬 데이터베이스를 Amazon Web Services(AWS)로 전송하고 있습니다. 솔루션 설계자는 80,000 프로비저닝된 IOPS의 스토리지 용량을 갖춘 MySQL 다중 AZ DB 인스턴스용 Amazon RDS를 활용하기로 결정했습니다. 데이터 전송은 AWS Database Migration Service(AWS DMS)를 활용하는 솔루션 설계자가 수행합니다. 이전 절차가 예상보다 오래 걸리고 있으며 회사에서 이를 신속하게 처리하기를 원합니다. 회사의 네트워크 직원은 대역폭을 제한 조건으로 배제했습니다.\\n솔루션 설계자는 마이그레이션을 촉진하기 위해 어떻게 진행해야 합니까? (2개를 선택하세요.)\\n\\nA.대상 DB 인스턴스에서 다중 AZ를 비활성화합니다.\\nB. 인스턴스 크기가 더 큰 새 DMS 인스턴스를 만듭니다.\\nC. 초기 로드가 완료될 때까지 대상 DB 인스턴스에 대한 로깅을 끕니다.\\nD. 전송 가속이 활성화된 새 DMS 인스턴스에서 DMS 작업을 다시 시작합니다.\\nE. 대상 DB 인스턴스의 스토리지 유형을 Amazon Elastic Block Store(Amazon EBS) 범용 SSD(gp2)로 변경합니다.\", \"A business is transferring a huge, mission-critical database to Amazon Web Services (AWS). A solutions architect has chosen to utilize an Amazon RDS for MySQL Multi-AZ DB instance with storage capacity of 80,000 Provisioned IOPS. The data transfer is being carried out by the solutions architect utilizing AWS Database Migration Service (AWS DMS). The relocation process is taking longer than anticipated, and the corporation want to expedite it. The network staff at the corporation has ruled out bandwidth as a limiting constraint.\\nHow should the solutions architect proceed to expedite the migration? (Select two.)\\n\\nA.Disable Multi-AZ on the target DB instance.\\nB. Create a new DMS instance that has a larger instance size.\\nC. Turn off logging on the target DB instance until the initial load is complete.\\nD. Restart the DMS task on a new DMS instance with transfer acceleration enabled.\\nE. Change the storage type on the target DB instance to Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2).\", \"A, C\"],\n[\"솔루션 설계자는 고객을 위해 수백 개의 기계 학습 모델을 호스팅해야 하는 비즈니스를 위한 클라우드 아키텍처 개발을 담당합니다. 모델을 시작할 때 메모리에 로드하려면 Amazon S3에서 최대 10GB의 데이터가 필요하지만 디스크 액세스는 필요하지 않습니다. 대부분의 모델은 거의 사용되지 않지만 고객은 가용성이 높고 액세스 가능하며 대기 시간이 최소화되기를 원합니다.\\n사양을 충족하고 가장 비용 효율적인 옵션은 무엇입니까?\\n\\nA.각 모델에 대해 Amazon API Gateway 뒤에 AWS Lambda 함수로 모델을 배포합니다.\\nB. 각 모델의 Application Load Balancer 뒤에서 Amazon Elastic Container Service(Amazon ECS) 서비스로 모델을 배포합니다.\\nC. 하나의 경로가 각 모델에 해당하는 경로 기반 라우팅을 사용하여 단일 Amazon API Gateway 뒤에 AWS Lambda 함수로 모델을 배포합니다.\\nD. 하나의 경로가 각 모델에 해당하는 경로 기반 라우팅을 사용하여 단일 Application Load Balancer 뒤에 Amazon Elastic Container Service(Amazon ECS) 서비스로 모델을 배포합니다.\", \"A solutions architect is responsible for developing the cloud architecture for a business that requires hosting hundreds of machine learning models for its customers. The models need up to 10 GB of data from Amazon S3 to be loaded into memory on launch, but do not require disk access. Although the majority of models are used seldom, customers want them to be highly available, accessible, and with minimal latency.\\nWhich option satisfies the specifications and is the MOST cost-effective?\\n\\nA.Deploy models as AWS Lambda functions behind an Amazon API Gateway for each model.\\nB. Deploy models as Amazon Elastic Container Service (Amazon ECS) services behind an Application Load Balancer for each model.\\nC. Deploy models as AWS Lambda functions behind a single Amazon API Gateway with path-based routing where one path corresponds to each model.\\nD. Deploy models as Amazon Elastic Container Service (Amazon ECS) services behind a single Application Load Balancer with path-based routing where one path corresponds to each model.\", \"C\"],\n[\"기상 신생 기업은 날씨 데이터를 가입자에게 온라인으로 판매할 목적으로 맞춤형 웹 애플리케이션을 개발했습니다. 이 회사는 이제 데이터를 Amazon DynamoDB에 저장하고 새로운 날씨 이벤트가 기록될 때마다 4개의 내부 팀의 관리자에게 알리는 새로운 서비스를 개발하려고 합니다. 회사는 이 새로운 서비스가 기존 애플리케이션의 기능에 부정적인 영향을 미치는 것을 원하지 않습니다.\\n이러한 기준이 가능한 한 최소한의 운영 오버헤드를 충족하도록 하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.DynamoDB 트랜잭션을 사용하여 새 이벤트 데이터를 테이블에 씁니다. 내부 팀에 알리도록 트랜잭션을 구성합니다.\\nB. 현재 애플리케이션이 4개의 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시하도록 합니다. 각 팀이 하나의 주제를 구독하도록 합니다.\\nC. 테이블에서 Amazon DynamoDB 스트림을 활성화합니다. 트리거를 사용하여 팀이 구독할 수 있는 단일 Amazon Simple Notification Service(Amazon SNS) 주제에 쓰십시오.\\nD. 각 레코드에 사용자 정의 속성을 추가하여 새 항목에 플래그를 지정합니다. 1분마다 테이블에서 새로운 항목을 검색하고 팀이 구독할 수 있는 Amazon Simple Queue Service(Amazon SQS) 대기열에 알리는 cron 작업을 작성합니다.\", \"A meteorological startup business has developed a bespoke web application with the purpose of selling weather data online to its subscribers. The firm now stores its data in Amazon DynamoDB and want to develop a new service that notifies the managers of four internal teams whenever a new weather event is recorded. The firm does not want for this new service to have an adverse effect on the functioning of the existing application.\\nWhat actions should a solutions architect take to ensure that these criteria are met with the LEAST amount of operational overhead possible?\\n\\nA.Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.\\nB. Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.\\nC. Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.\\nD. Add a custom attribute to each record to flag new items. Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe.\", \"C\"],\n[\"비즈니스는 교차 통신을 용이하게 하기 위해 VPC 피어링 계획을 사용하여 동일한 지역 내의 모든 VPC를 연결합니다. 최근 계정 생성 및 VPC의 증가로 인해 VPC 피어링 전략을 유지하기가 더 어려워졌으며 비즈니스는 수백 개의 VPC에 도달할 것으로 예상합니다. 또한 일부 VPC를 사용하여 사이트 간 VPN 생성에 대한 새로운 요구가 있습니다. 솔루션 설계자는 다양한 계정, 가상 사설 클라우드 및 VPN에 대해 중앙에서 제어되는 네트워킹 인프라를 구축하는 책임을 맡았습니다.\\n이러한 기준을 충족하는 네트워킹 솔루션은 무엇입니까?\\n\\nA.공유 VPC와 VPN을 구성하고 서로 공유합니다.\\nB. 허브 및 스포크 VPC를 구성하고 VPC 피어링을 통해 모든 트래픽을 라우팅합니다.\\nC. 모든 VPC와 VPN 간에 AWS Direct Connect 연결을 구성합니다.\\nD. AWS Transit Gateway로 전송 게이트웨이를 구성하고 모든 VPC와 VPN을 연결합니다.\", \"A business uses a VPC peering plan to link all of its VPCs inside a same Region in order to facilitate cross-communication. Recent growth in account creation and VPCs has made it more difficult to sustain the VPC peering strategy, and the business anticipates reaching hundreds of VPCs. Additionally, there are fresh demands for the creation of site-to-site VPNs with some of the VPCs. A solutions architect has been charged with the responsibility of establishing a centrally controlled networking infrastructure for various accounts, virtual private clouds, and VPNs.\\nWhich networking solution satisfies these criteria?\\n\\nA.Configure shared VPCs and VPNs and share to each other.\\nB. Configure a hub-and-spoke VPC and route all traffic through VPC peering.\\nC. Configure an AWS Direct Connect connection between all VPCs and VPNs.\\nD. Configure a transit gateway with AWS Transit Gateway and connect all VPCs and VPNs.\", \"D. VPC 피어링이 복잡해지면 Transit gateway로 대체\"],\n[\"솔루션 설계자는 건물의 상업용 임차인의 시간당 에너지 사용량을 기록하는 프로그램을 개발 중입니다. 센서는 각 테넌트의 소비를 추적하는 HTTP 요청을 통해 데이터베이스에 공급합니다. 가능한 경우 솔루션 설계자는 관리형 서비스를 사용해야 합니다. 솔루션 설계자가 독립 구성 요소를 통합함에 따라 워크로드는 계속해서 기능을 얻을 것입니다.\\n다음 중 운영 오버헤드가 가장 적은 이 기준을 충족하는 방법은 무엇입니까?\\n\\nA.Amazon API Gateway를 AWS Lambda 함수와 함께 사용하여 센서에서 데이터를 수신하고, 데이터를 처리하고, Amazon DynamoDB 테이블에 데이터를 저장합니다.\\nB. Amazon EC2 인스턴스의 Auto Scaling 그룹에서 지원하는 Elastic Load Balancer를 사용하여 센서에서 데이터를 수신하고 처리합니다. Amazon S3 버킷을 사용하여 처리된 데이터를 저장합니다.\\nC. Amazon API Gateway를 AWS Lambda 함수와 함께 사용하여 센서에서 데이터를 수신하고, 데이터를 처리하고, Amazon EC2 인스턴스의 Microsoft SQL Server Express 데이터베이스에 데이터를 저장합니다.\\nD. Amazon EC2 인스턴스의 Auto Scaling 그룹에서 지원하는 Elastic Load Balancer를 사용하여 센서에서 데이터를 수신하고 처리합니다. Amazon Elastic File System(Amazon EFS) 공유 파일 시스템을 사용하여 처리된 데이터를 저장합니다.\", \"A solutions architect is developing a program that will record the hourly energy use of a building's commercial tenants. The sensors will feed a database through HTTP requests, which will keep track of each tenant's consumption. When feasible, the solutions architect should use managed services. The workload will continue to gain functionality as the solutions architect incorporates independent components.\\nWhich method satisfies these criteria with the LEAST amount of operational overhead?\\n\\nA.Use Amazon API Gateway with AWS Lambda functions to receive the data from the sensors, process the data, and store the data in an Amazon DynamoDB table.\\nB. Use an Elastic Load Balancer that is supported by an Auto Scaling group of Amazon EC2 instances to receive and process the data from the sensors. Use an Amazon S3 bucket to store the processed data.\\nC. Use Amazon API Gateway with AWS Lambda functions to receive the data from the sensors, process the data, and store the data in a Microsoft SQL Server Express database on an Amazon EC2 instance.\\nD. Use an Elastic Load Balancer that is supported by an Auto Scaling group of Amazon EC2 instances to receive and process the data from the sensors. Use an Amazon Elastic File System (Amazon EFS) shared file system to store the processed data.\", \"A\"],\n[\"솔루션 아키텍트가 작성한 두 가지 IAM 정책: Policy1 및 Policy2. 각 정책은 IAM 그룹과 연결됩니다.\\nhttps://i.imgur.com/GtVKQ1L.png\\n클라우드 엔지니어가 IAM 사용자로 IAM 그룹에 추가됩니다.\\n다음 중 클라우드 엔지니어가 수행할 수 있는 작업은 무엇입니까?\\n\\nA.IAM 사용자 삭제\\nB. 디렉토리 삭제\\nC. Amazon EC2 인스턴스 삭제\\nD. Amazon CloudWatch Logs에서 로그 삭제\", \"Two IAM policies have been written by a solutions architect: Policy1 and Policy2. Each policy is associated with an IAM group.\\nA cloud engineer is added to the IAM group as an IAM user.\\nWhich of the following actions will the cloud engineer be able to carry out?\\n\\nA.Deleting IAM users\\nB. Deleting directories\\nC. Deleting Amazon EC2 instances\\nD. Deleting logs from Amazon CloudWatch Logs\", \"C\"],\n[\"솔루션 설계자는 타사 데이터베이스 서버의 운영을 지원하는 아키텍처를 구축하는 일을 담당합니다. 데이터베이스 소프트웨어는 메모리가 많고 CPU 기반으로 라이선스가 부여되며 운영 체제의 가상 CPU 코어 수에 정비례하여 비용이 증가합니다. 솔루션 설계자는 데이터베이스 소프트웨어를 운영하기에 충분한 RAM과 많은 수의 vCPU가 있는 Amazon EC2 인스턴스를 선택해야 합니다. 솔루션 설계자는 가상 CPU가 충분히 활용되지 않고 지출을 최소화하도록 보장해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.적절한 수의 vCPU가 있는 더 작은 EC2 인스턴스를 선택하고 시작합니다.\\nB. 인스턴스 시작 중에 선택한 EC2 인스턴스에서 CPU 코어 및 스레드를 구성합니다.\\nC. 새 EC2 인스턴스를 생성하고 인스턴스 세부 정보를 구성할 때 멀티스레딩이 활성화되어 있는지 확인합니다.\\nD. 새 용량 예약을 만들고 적절한 인스턴스 유형을 선택합니다. 이 새로운 용량 예약으로 인스턴스를 시작합니다.\", \"A solutions architect is responsible for building an architecture that will support the operation of a third-party database server. The database software is memory heavy and is licensed on a CPU-based basis, with the cost increasing in direct proportion to the number of virtual CPU cores in the operating system. The solutions architect must choose an Amazon EC2 instance with adequate RAM to operate the database software, yet with a high number of vCPUs. The solutions architect must guarantee that the virtual CPUs are not underutilized and must keep expenditures to a minimum.\\nWhich solution satisfies these criteria?\\n\\nA.Select and launch a smaller EC2 instance with an appropriate number of vCPUs.\\nB. Configure the CPU cores and threads on the selected EC2 instance during instance launch.\\nC. Create a new EC2 instance and ensure multithreading is enabled when configuring the instance details.\\nD. Create a new Capacity Reservation and select the appropriate instance type. Launch the instance into this new Capacity Reservation.\", \"B\"],\n[\"워크로드가 Amazon EC2 인스턴스에서 실행 중이며 밀리초의 지연 시간이 필요합니다. 이 프로그램은 많은 작은 파일 시스템 읽기 및 쓰기를 수행하지만 파일 시스템 자체는 작습니다.\\n솔루션 설계자가 EC2 인스턴스에 연결해야 하는 Amazon Elastic Block Store(Amazon EBS)의 볼륨 유형은 무엇입니까?\\n\\nA.콜드 HDD(sc1)\\nB. 범용 SSD(gp2)\\nC. 프로비저닝된 IOPS SSD(io1)\\nD. 처리량 최적화 HDD(st1)\", \"A workload is executing on an Amazon EC2 instance and requires millisecond latency. The program does many little file system reads and writes, yet the file system itself is small.\\nWhich volume type of Amazon Elastic Block Store (Amazon EBS) should a solutions architect connect to an EC2 instance?\\n\\nA.Cold HDD (sc1)\\nB. General Purpose SSD (gp2)\\nC. Provisioned IOPS SSD (io1)\\nD. Throughput Optimized HDD (st1)\", \"C\"],\n[\"솔루션 설계자는 컴퓨팅 및 데이터베이스 리소스에 대해 고유한 프라이빗 서브넷이 있는 2계층 아키텍처를 만들고 있습니다. 컴퓨팅 서브넷에 배포된 AWS Lambda 함수는 데이터베이스 연결이 필요합니다.\\n가장 안전한 연결을 제공하는 옵션은 무엇입니까?\\n\\nA.VPC 외부에서 Amazon RDS 프록시를 사용하도록 Lambda 함수를 구성합니다.\\nB. 보안 그룹을 Lambda 함수와 연결합니다. 데이터베이스의 보안 그룹에서 이 보안 그룹에 권한을 부여하십시오.\\nC. 데이터베이스의 보안 그룹에서 컴퓨팅 서브넷의 CIDR 범위를 승인합니다.\\nD. 초기화 단계에서 데이터베이스의 보안 그룹에 있는 모든 IP 주소를 임시로 인증합니다. 초기화가 완료된 후 규칙을 제거합니다.\", \"A solutions architect is creating a two-tiered architecture with distinct private subnets for compute and database resources. AWS Lambda functions deployed in compute subnets need database connection.\\nWhich option would provide the MOST SECURE connectivity?\\n\\nA.Configure the Lambda function to use Amazon RDS Proxy outside the VPC.\\nB. Associate a security group with the Lambda function. Authorize this security group in the database's security group.\\nC. Authorize the compute subnet's CIDR ranges in the database's security group.\\nD. During the initialization phase, authorize all IP addresses in the database's security group temporarily. Remove the rule after the initialization is complete.\", \"B\"],\n[\"개발 팀은 AWS Lambda를 사용하여 이벤트 기반 애플리케이션을 구축하고 있습니다. 파일이 Amazon S3 버킷에 추가되면 이벤트가 생성됩니다. Amazon Simple Notification Service(Amazon SNS)는 현재 Amazon S3 이벤트의 이벤트 대상으로 지정되어 있습니다.\\n솔루션 설계자는 Amazon S3의 이벤트 처리를 확장하려면 어떻게 해야 합니까?\\n\\nA.이벤트가 Lambda에서 실행되기 전에 Amazon Elastic Container Service(Amazon ECS)에서 이벤트를 처리하는 SNS 구독을 생성합니다.\\nB. 이벤트가 Lambda에서 실행되기 전에 Amazon Elastic Kubernetes Service(Amazon EKS)에서 이벤트를 처리하는 SNS 구독을 생성합니다.\\nC. 이벤트를 Amazon Simple Queue Service(Amazon SQS)로 보내는 SNS 구독을 생성합니다. Lambda 함수를 트리거하도록 SQS 대기열을 구성합니다.\\nD. 이벤트를 AWS Server Migration Service(AWS SMS)로 보내는 SNS 구독을 생성합니다. SMS 이벤트에서 폴링하도록 Lambda 함수를 구성합니다.\", \"A development team is building an event-driven application using AWS Lambda. When files are added to an Amazon S3 bucket, events will be created. Amazon Simple Notification Service (Amazon SNS) is presently specified as the event target for Amazon S3 events.\\nWhat should a solutions architect do to scale the processing of events from Amazon S3?\\n\\nA.Create an SNS subscription that processes the event in Amazon Elastic Container Service (Amazon ECS) before the event runs in Lambda.\\nB. Create an SNS subscription that processes the event in Amazon Elastic Kubernetes Service (Amazon EKS) before the event runs in Lambda.\\nC. Create an SNS subscription that sends the event to Amazon Simple Queue Service (Amazon SQS). Configure the SQS queue to trigger a Lambda function.\\nD. Create an SNS subscription that sends the event to AWS Server Migration Service (AWS SMS). Configure the Lambda function to poll from the SMS event.\", \"C\"],\n[\"한 비즈니스에서 Auto Scaling 그룹의 많은 Amazon EC2 인스턴스에 다중 계층 애플리케이션을 배포했습니다. Oracle 인스턴스용 Amazon RDS는 Oracle 기본 PL/SQL 작업을 사용하여 애플리케이션의 데이터 계층 역할을 합니다. 애플리케이션의 트래픽은 지속적으로 증가하고 있습니다. 이로 인해 EC2 인스턴스에 과부하가 걸리고 RDS 인스턴스의 스토리지가 부족해집니다. Auto Scaling 그룹에는 조정 지표가 없고 대신 최소 정상 인스턴스 수를 지정합니다. 회사에 따르면 트래픽은 정체기에 도달할 때까지 일정하지만 예측할 수 없는 속도로 계속 증가할 것입니다.\\n솔루션 설계자는 트래픽 증가에 따라 시스템이 자동으로 성장할 수 있도록 보장하기 위해 무엇을 해야 합니까? (2개를 선택하세요.)\\n\\nA.RDS for Oracle 인스턴스에서 스토리지 Auto Scaling을 구성합니다.\\nB. Auto Scaling 스토리지를 사용하려면 데이터베이스를 Amazon Aurora로 마이그레이션합니다.\\nC. 사용 가능한 저장 공간 부족에 대한 Oracle 인스턴스용 RDS에 대한 경보를 구성합니다.\\nD. 평균 CPU를 스케일링 메트릭으로 사용하도록 Auto Scaling 그룹을 구성합니다.\\nE. 평균 여유 메모리를 스케일링 메트릭으로 사용하도록 Auto Scaling 그룹을 구성합니다.\", \"A business has deployed a multi-tier application on many Amazon EC2 instances in an Auto Scaling group. Amazon RDS for Oracle instances serve as the application's data layer, using Oracle-native PL/SQL operations. The application's traffic has been continuously rising. This overloads the EC2 instances and causes the RDS instance to run out of storage. The Auto Scaling group lacks scaling metrics and instead specifies the minimal healthy instance count. According to the corporation, traffic will continue to grow at a constant but unpredictable pace until it reaches a plateau.\\nWhat should a solutions architect do to guarantee that the system can grow automatically as traffic increases? (Select two.)\\n\\nA.Configure storage Auto Scaling on the RDS for Oracle instance.\\nB. Migrate the database to Amazon Aurora to use Auto Scaling storage.\\nC. Configure an alarm on the RDS for Oracle instance for low free storage space.\\nD. Configure the Auto Scaling group to use the average CPU as the scaling metric.\\nE. Configure the Auto Scaling group to use the average free memory as the scaling metric.\", \"A, D\"],\n[\"AWS Direct Connect를 사용하여 하이브리드 클라우드 액세스를 막 구축한 기업이 현재 Amazon S3로 데이터를 이동하고 있습니다. 조직은 온프레미스 스토리지 시스템과 Amazon Web Services(AWS) 스토리지 서비스 간의 데이터 복제를 자동화하고 가속화하는 완전 관리형 솔루션을 찾고 있습니다.\\n솔루션 설계자는 데이터의 기밀성을 유지하기 위해 어떤 솔루션을 제안해야 합니까?\\n\\nA.온프레미스 환경용 AWS DataSync 에이전트를 배포합니다. 데이터를 복제하고 AWS 서비스 엔드포인트와 연결하도록 동기화 작업을 구성합니다.\\nB. 온프레미스 환경용 AWS DataSync 에이전트를 배포합니다. 특정 시점 스냅샷을 AWS에 복제하도록 배치 작업을 예약합니다.\\nC. 온프레미스 환경을 위한 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다. 데이터를 로컬에 저장하도록 구성하고 특정 시점 스냅샷을 AWS에 비동기식으로 백업합니다.\\nD. 온프레미스 환경을 위한 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 데이터를 로컬에 저장하도록 구성하고 특정 시점 스냅샷을 AWS에 비동기식으로 백업합니다.\", \"A business just established hybrid cloud access with AWS Direct Connect and is now moving data to Amazon S3. The organization is seeking a fully managed solution that would automate and expedite data replication between on-premises storage systems and Amazon Web Services (AWS) storage services.\\nWhich solution should a solutions architect propose for maintaining the confidentiality of the data?\\n\\nA.Deploy an AWS DataSync agent for the on-premises environment. Configure a sync job to replicate the data and connect it with an AWS service endpoint.\\nB. Deploy an AWS DataSync agent for the on-premises environment. Schedule a batch job to replicate point-in-time snapshots to AWS.\\nC. Deploy an AWS Storage Gateway volume gateway for the on-premises environment. Configure it to store data locally, and asynchronously back up point-in- time snapshots to AWS.\\nD. Deploy an AWS Storage Gateway file gateway for the on-premises environment. Configure it to store data locally, and asynchronously back up point-in-time snapshots to AWS.\", \"A\"],\n[\"솔루션 설계자가 Amazon Web Capabilities(AWS) 서비스를 활용하여 새로운 전자 상거래 장바구니 애플리케이션을 설계하도록 개발자를 지원하고 있습니다. 개발자는 사용 중인 데이터베이스 스키마에 대해 명확하지 않으며 전자 상거래 사이트가 확장됨에 따라 변경할 것으로 예상합니다. 솔루션은 내구성이 뛰어나고 읽기 및 쓰기 용량을 자동으로 확장할 수 있어야 합니다.\\n이러한 기준을 충족하는 데이터베이스 솔루션은 무엇입니까?\\n\\nA.Amazon Aurora PostgreSQL\\nB. 온디맨드가 활성화된 Amazon DynamoDB\\nC. DynamoDB 스트림이 활성화된 Amazon DynamoDB\\nD. Amazon SQS 및 Amazon Aurora PostgreSQL\", \"A solutions architect is assisting a developer with the design of a new ecommerce shopping cart application utilizing Amazon Web Capabilities (AWS) services. The developer is unclear about the database schema in use and anticipates changing it as the ecommerce site expands. The solution must be very durable and capable of scaling read and write capacity automatically.\\nWhich database solution satisfies these criteria?\\n\\nA.Amazon Aurora PostgreSQL\\nB. Amazon DynamoDB with on-demand enabled\\nC. Amazon DynamoDB with DynamoDB Streams enabled\\nD. Amazon SQS and Amazon Aurora PostgreSQL\", \"B\"],\n[\"비즈니스에는 두 가지 별개의 단계에서 데이터를 처리하는 노후화된 애플리케이션이 있습니다. 프로세스의 두 번째 단계는 첫 번째 단계보다 더 오래 걸리기 때문에 회사는 애플리케이션을 Amazon ECS에서 실행되는 두 개의 개별 마이크로서비스로 재설계하기로 결정했습니다.\\n솔루션 설계자가 마이크로서비스를 통합하는 가장 좋은 방법은 무엇입니까?\\n\\nA.마이크로서비스 1에서 코드를 구현하여 Amazon S3 버킷으로 데이터를 보냅니다. S3 이벤트 알림을 사용하여 마이크로서비스 2를 호출합니다.\\nB. 마이크로서비스 1에서 코드를 구현하여 Amazon SNS 주제에 데이터를 게시합니다. 이 주제를 구독하려면 마이크로서비스 2에서 코드를 구현하세요.\\nC. 마이크로서비스 1에서 코드를 구현하여 Amazon Kinesis Data Firehose로 데이터를 보냅니다. Kinesis Data Firehose에서 읽을 코드를 마이크로서비스 2에 구현합니다.\\nD. 마이크로서비스 1에서 코드를 구현하여 Amazon SQS 대기열로 데이터를 보냅니다. 큐의 메시지를 처리하기 위해 마이크로서비스 2에 코드를 구현합니다.\", \"A business has an aging application that handles data in two distinct stages. Because the second stage of the process takes longer than the first, the firm opted to redesign the application as two distinct microservices running on Amazon ECS.\\nWhat is the best way for a solutions architect to incorporate microservices?\\n\\nA.Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2.\\nB. Implement code in microservice 1 to publish data to an Amazon SNS topic. Implement code in microservice 2 to subscribe to this topic.\\nC. Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose.\\nD. Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue.\", \"D\"],\n[\"비즈니스 웹 사이트는 Amazon S3에서 호스팅됩니다. 매월 웹 사이트는 회사 AWS 요금의 대부분을 차지하는 페타바이트 규모의 아웃바운드 트래픽을 제공합니다.\\n솔루션 설계자는 비용을 절감하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.기존 웹 사이트를 오리진으로 사용하여 Amazon CloudFront를 구성합니다.\\nB. 웹사이트를 Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 Amazon EC2로 이동하여 저장합니다.\\nC. AWS Global Accelerator를 사용하고 기존 웹 사이트를 엔드포인트로 지정합니다.\\nD. Amazon API Gateway와 AWS Lambda의 조합에서 실행되도록 웹 사이트를 재설계합니다.\", \"A business's website is hosted on Amazon S3. Monthly, the website provides petabytes of outbound traffic, accounting for the majority of the company's AWS charges.\\nWhat actions should a solutions architect do to save money?\\n\\nA.Configure Amazon CloudFront with the existing website as the origin.\\nB. Move the website to Amazon EC2 with Amazon Elastic Block Store (Amazon EBS) volumes for storage.\\nC. Use AWS Global Accelerator and specify the existing website as the endpoint.\\nD. Rearchitect the website to run on a combination of Amazon API Gateway and AWS Lambda.\", \"A\"],\n[\"기업은 수많은 손익 상황을 계산하기 위해 맞춤형 분산 프로그램을 사용하고자 합니다. 이를 위해 기업은 Amazon EC2 인스턴스 간에 네트워크 연결을 설정해야 합니다. 연결은 대기 시간이 짧고 처리량이 높아야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.동일한 인스턴스 유형의 EC2 전용 호스트를 사용하도록 애플리케이션을 프로비저닝합니다.\\nB. 동일한 인스턴스 유형을 가진 EC2 인스턴스에 대한 배치 그룹을 구성합니다.\\nC. 여러 AWS 탄력적 네트워크 인터페이스 및 링크 집계를 사용합니다.\\nD. EC2 인스턴스에 대해 AWS PrivateLink를 구성합니다.\", \"A business wishes to use a customized distributed program for the purpose of calculating numerous profit and loss situations. To do this, the business must establish a network connection between its Amazon EC2 instances. The connection must have a low latency and a high throughput.\\nWhich solution will satisfy these criteria?\\n\\nA.Provision the application to use EC2 Dedicated Hosts of the same instance type.\\nB. Configure a placement group for EC2 instances that have the same instance type.\\nC. Use multiple AWS elastic network interfaces and link aggregation.\\nD. Configure AWS PrivateLink for the EC2 instances.\", \"B. A도 가능하다는 의견 많음\"],\n[\"회사에서 Auto Scaling 그룹에서 UDP를 통해 클라이언트 및 서버와 통신하는 실시간 승수 게임을 구축하고 있습니다. 주간 수요 급증이 예측되고 게임 서버 플랫폼이 적절하게 대응해야 합니다. 개발자는 확장 가능한 데이터베이스 시스템에 게이머 점수 및 기타 비관계형 데이터를 저장하기를 원합니다.\\n솔루션 아키텍트가 제안해야 하는 솔루션은 무엇입니까?\\n\\nA.트래픽 분산에는 Amazon Route 53을, 데이터 저장에는 Amazon Aurora Serverless를 사용하십시오.\\nB. 트래픽 분산에는 Network Load Balancer를 사용하고 데이터 저장에는 Amazon DynamoDB 온디맨드를 사용합니다.\\nC. 트래픽 분산에는 Network Load Balancer를 사용하고 데이터 저장에는 Amazon Aurora 글로벌 데이터베이스를 사용합니다.\\nD. 트래픽 분산에는 Application Load Balancer를 사용하고 데이터 저장에는 Amazon DynamoDB 글로벌 테이블을 사용합니다.\", \"A corporation is building a real-time multiplier game that communicates with clients and servers through UDP in an Auto Scaling group. Daytime demand spikes are predicted, and the game server platform must respond appropriately. Developers wish to store gamer scores and other non-relational data in a scalable database system.\\nWhich solution, if any, should a solutions architect suggest?\\n\\nA.Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage.\\nB. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.\\nC. Use a Network Load Balancer for traffic distribution and Amazon Aurora Global Database for data storage.\\nD. Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage.\", \"B\"],\n[\"운영 팀에서 수립한 표준에 따르면 IAM 정책은 사용자에게 직접 구현되어서는 안 됩니다. 특정 새 팀원이 이 규범을 준수하지 못했습니다. 운영 관리자는 정책을 첨부한 사용자를 식별하기 위한 간단한 방법이 필요합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.AWS CloudTrail을 사용하여 모니터링합니다.\\nB. 매일 실행할 AWS Config 규칙을 생성합니다.\\nC. IAM 사용자 변경 사항을 Amazon SNS에 게시합니다.\\nD. 사용자가 수정되면 AWS Lambda를 실행합니다.\", \"A standard established by an operations team says that IAM policies should not be implemented directly to users. Certain new team members have failed to adhere to this norm. The operations manager need a simple method for identifying users who have attached policies.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Monitor using AWS CloudTrail.\\nB. Create an AWS Config rule to run daily.\\nC. Publish IAM user changes to Amazon SNS.\\nD. Run AWS Lambda when a user is modified.\", \"B\"],\n[\"Amazon EC2에서 솔루션 설계자는 고성능 컴퓨팅(HPC) 워크로드를 개발하고 있습니다. EC2 인스턴스는 정기적으로 서로 연결해야 하므로 짧은 지연 시간과 높은 처리량의 네트워크 성능이 필요합니다.\\n이 기준을 충족하는 EC2 설정은 무엇입니까?\\n\\nA.하나의 가용 영역에 있는 클러스터 배치 그룹에서 EC2 인스턴스를 시작합니다.\\nB. 하나의 가용 영역에 있는 분산 배치 그룹에서 EC2 인스턴스를 시작합니다.\\nC. 두 리전의 Auto Scaling 그룹에서 EC2 인스턴스를 시작하고 VPC를 피어링합니다.\\nD. 여러 가용 영역에 걸쳐 있는 Auto Scaling 그룹에서 EC2 인스턴스를 시작합니다.\", \"On Amazon EC2, a solutions architect is developing a high performance computing (HPC) workload. The EC2 instances must connect regularly with one another, necessitating network performance with low latency and high throughput.\\nWhich EC2 setup satisfies these criteria?\\n\\nA.Launch the EC2 instances in a cluster placement group in one Availability Zone.\\nB. Launch the EC2 instances in a spread placement group in one Availability Zone.\\nC. Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs.\\nD. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones.\", \"A\"],\n[\"비즈니스는 Amazon RDS 데이터베이스 인스턴스에서 대부분의 정보를 가져오는 모바일 게임을 소유하고 있습니다. 게임이 인기를 얻으면서 제작자는 게임의 메타데이터 로딩 시간과 관련된 성능 문제를 관찰했습니다. 성능 메트릭에 따르면 데이터베이스를 확장하는 것만으로는 도움이 되지 않습니다. 솔루션 설계자는 스냅샷 복제 및 밀리초 미만의 응답 시간을 포함하여 사용 가능한 모든 선택 사항을 고려해야 합니다.\\n솔루션 설계자는 이러한 문제를 해결하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Aurora 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션합니다.\\nB. 전역 테이블이 있는 Amazon DyramoDB로 데이터베이스를 마이그레이션합니다.\\nC. 데이터베이스 앞에 Redis용 Amazon ElastiCache 계층을 추가합니다.\\nD. 데이터베이스 앞에 Amazon ElastiCache for Memcached 계층을 추가합니다.\", \"A business owns a mobile game that derives the majority of its information from an Amazon RDS database instance. As the game gained popularity, the creators observed performance issues relating to the game's metadata loading times. According to performance metrics, merely scaling the database will not assist. A solutions architect must consider all available choices, which may include snapshot replication and sub-millisecond response times.\\nWhat recommendations should the solutions architect make to resolve these issues?\\n\\nA.Migrate the database to Amazon Aurora with Aurora Replicas.\\nB. Migrate the database to Amazon DyramoDB with global tables.\\nC. Add an Amazon ElastiCache for Redis layer in front of the database.\\nD. Add an Amazon ElastiCache for Memcached layer in front of the database.\", \"C\"],\n[\"기업이 데이터 센터를 이전하고 있으며 2주 이내에 AWS로 50TB의 안전한 데이터 전송이 필요합니다. 현재 데이터 센터는 AWS에 대한 Site-to-Site VPN 연결의 대역폭 90%를 이미 사용합니다.\\n솔루션 설계자가 이러한 요구 사항을 달성하기 위해 사용할 수 있는 Amazon Web Services 제품은 무엇입니까?\\n\\nA.VPC 엔드포인트가 있는 AWS DataSync\\nB. AWS 다이렉트 커넥트\\nC. AWS Snowball Edge 스토리지 최적화\\nD. AWS 스토리지 게이트웨이\", \"A business is transferring its data center and need a safe data transfer of 50 TB to AWS within two weeks. The present data center has a 90 percent used Site-to-Site VPN connection to AWS.\\nWhich Amazon Web Services offering could a solutions architect use to achieve these requirements?\\n\\nA.AWS DataSync with a VPC endpoint\\nB. AWS Direct Connect\\nC. AWS Snowball Edge Storage Optimized\\nD. AWS Storage Gateway\", \"C\"],\n[\"솔루션 설계자는 Amazon CloudFront 및 Amazon S3 오리진을 사용하여 정적 웹 사이트를 저장하는 솔루션을 생성해야 합니다. 회사의 보안 정책에 따라 모든 웹 사이트 트래픽은 AWS WAF에서 검토해야 합니다.\\n솔루션 설계자는 이러한 사양을 어떻게 준수해야 합니까?\\n\\nA.AWS WAF Amazon 리소스 이름(ARN)에서 오는 요청만 수락하도록 S3 버킷 정책을 구성합니다.\\nB. S3 오리진에서 콘텐츠를 요청하기 전에 수신되는 모든 요청을 AWS WAF로 전달하도록 Amazon CloudFront를 구성합니다.\\nC. Amazon CloudFront IP 주소가 Amazon S3에만 액세스하도록 허용하는 보안 그룹을 구성합니다. AWS WAF를 CloudFront에 연결합니다.\\nD. 원본 액세스 ID(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 Amazon CloudFront 및 Amazon S3를 구성합니다. 배포에서 AWS WAF를 활성화합니다.\", \"A solutions architect must create a solution that stores a static website using Amazon CloudFront and an Amazon S3 origin. According to the company's security policy, every website traffic must be reviewed by AWS WAF.\\nHow should the solutions architect adhere to these specifications?\\n\\nA.Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.\\nB. Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.\\nC. Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.\\nD. Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.\", \"D\"],\n[\"기업은 저장된 항목의 내구성과 성능을 유지하면서 프로덕션 환경에서 Amazon S3 스토리지 비용을 낮추기를 원합니다.\\n이러한 목표를 달성하기 위해 기업이 취해야 할 첫 번째 조치는 무엇입니까?\\n\\nA.비즈니스 크리티컬 S3 버킷에서 Amazon Macie를 활성화하여 객체의 민감도를 분류합니다.\\nB. S3 분석을 활성화하여 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환할 후보인 S3 버킷을 식별합니다.\\nC. 모든 비즈니스 크리티컬 S3 버킷에서 버전 관리를 활성화합니다.\\nD. 모든 S3 버킷의 객체를 S3 Intelligent-Tiering으로 마이그레이션합니다.\", \"A business wishes to lower the cost of Amazon S3 storage in its production environment while maintaining the durability and performance of the stored items.\\nWhat is the FIRST move that the business should take to accomplish these goals?\\n\\nA.Enable Amazon Macie on the business-critical S3 buckets to classify the sensitivity of the objects.\\nB. Enable S3 analytics to identify S3 buckets that are candidates for transitioning to S3 Standard-Infrequent Access (S3 Standard-IA).\\nC. Enable versioning on all business-critical S3 buckets.\\nD. Migrate the objects in all S3 buckets to S3 Intelligent-Tiering.\", \"B. D는 객체를 아카이브 및 딥 아카이브로 이동할 수 있으므로 저장된 객체의 성능에 영향을 미칠 수 있으므로 지능형 계층화가 될 수 없음\"],\n[\"비즈니스는 Amazon CloudFront가 시작되는 Amazon S3 버킷에서 정적 웹 사이트를 호스팅합니다. 이 비즈니스는 미국, 캐나다 및 유럽의 고객에게 서비스를 제공하며 비용 절감을 모색하고 있습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.CloudFront 캐싱 TTL(Time to Live)을 기본값에서 더 긴 기간으로 조정합니다.\\nB. Lambda@Edge 로 CloudFront 이벤트를 구현 하여 웹 사이트의 데이터 처리를 실행합니다.\\nC. 서비스가 제공되는 국가의 위치만 포함하도록 CloudFront 가격 등급을 수정합니다.\\nD. CloudFront SSL(Secure Sockets Layer) 인증서를 구현하여 서비스가 제공되는 국가의 위치에 더 가깝게 보안을 강화합니다.\", \"A business hosts its static website in an Amazon S3 bucket, which is where Amazon CloudFront gets its start. The business serves customers in the United States, Canada, and Europe and is looking to cut expenses.\\nWhat recommendations should a solutions architect make?\\n\\nA.Adjust the CloudFront caching time to live (TTL) from the default to a longer timeframe.\\nB. Implement CloudFront events with Lambda@Edge to run the website's data processing.\\nC. Modify the CloudFront price class to include only the locations of the countries that are served.\\nD. Implement a CloudFront Secure Sockets Layer (SSL) certificate to push security closer to the locations of the countries that are served.\", \"C\"],\n[\"솔루션 아키텍트는 웹, 애플리케이션 및 데이터베이스 계층으로 구성된 고가용성 프로그램을 설계하는 책임이 있습니다. HTTPS 콘텐츠 전송은 전송에 필요한 최소한의 시간으로 가능한 한 에지 근처에서 발생해야 합니다.\\n이러한 기준을 충족하고 가장 안전한 솔루션은 무엇입니까?\\n\\nA.퍼블릭 서브넷에 여러 개의 중복 Amazon EC2 인스턴스가 있는 퍼블릭 ALB(Application Load Balancer)를 구성합니다. 퍼블릭 ALB를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 Amazon CloudFront를 구성합니다.\\nB. 프라이빗 서브넷의 Amazon EC2 인스턴스 구성. EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 여러 중복 Amazon CloudFront가 있는 공용 Application Load Balancer를 구성합니다.\\nC. 프라이빗 서브넷에 여러 개의 중복 Amazon EC2 인스턴스가 있는 퍼블릭 ALB(Application Load Balancer)를 구성합니다. 퍼블릭 ALB를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 Amazon CloudFront를 구성합니다.\\nD. 퍼블릭 서브넷에 여러 개의 중복 Amazon EC2 인스턴스가 있는 퍼블릭 Application Load Balancer를 구성합니다. EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 Amazon CloudFront를 구성합니다.\", \"A solution architect is tasked with the responsibility of designing a highly available program that consists of web, application, and database layers. HTTPS content delivery should occur as near to the edge as practicable, with the least amount of time required for delivery.\\nWhich solution satisfies these criteria and is the MOST SECURE?\\n\\nA.Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.\\nB. Amazon EC2 instances in private subnets Configure. Configure a public Application Load Balancer with multiple redundant Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.\\nC. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.\\nD. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.\", \"C\"],\n[\"새로운 AWS 고객이 온프레미스 데이터 센터와 AWS 간에 Site-to-Site VPN을 생성합니다. 회사의 보안 정책에 따르면 온프레미스에서 발생하는 트래픽은 샘플 웹 애플리케이션이 포함된 Amazon Elastic Container Service(Amazon ECS) 클러스터와 통신하는 동안 회사의 사설 IP 공간 내에 남아 있어야 합니다.\\n이 기준을 만족하는 솔루션은 무엇입니까?\\n\\nA.Amazon ECS용 게이트웨이 엔드포인트를 구성합니다. ECS 클러스터를 가리키는 항목을 포함하도록 라우팅 테이블을 수정합니다.\\nB. ECS 클러스터를 호스팅하는 동일한 VPC에서 Amazon ECS용 Network Load Balancer 및 AWS PrivateLink 엔드포인트를 생성합니다.\\nC. 한 VPC에 Network Load Balancer를 생성하고 다른 VPC에 Amazon ECS용 AWS PrivateLink 엔드포인트를 생성합니다. VPC 피어링을 사용하여 두 VPC를 연결합니다.\\nD. Amazon ECS를 대상으로 하여 Amazon Route 53 레코드를 구성합니다. SSL 오프로딩을 위해 AWS Certificate Manager(ACM)에서 Route 53에 서버 인증서를 적용합니다.\", \"A new AWS customer creates a Site-to-Site VPN between its on-premises datacenter and AWS. According to the firm's security policy, traffic originating on-premises shall remain inside the private IP space of the company while talking with an Amazon Elastic Container Service (Amazon ECS) cluster containing a sample web application.\\nWhich solution satisfies this criterion?\\n\\nA.Configure a gateway endpoint for Amazon ECS. Modify the route table to include an entry pointing to the ECS cluster.\\nB. Create a Network Load Balancer and AWS PrivateLink endpoint for Amazon ECS in the same VPC that is hosting the ECS cluster.\\nC. Create a Network Load Balancer in one VPC and an AWS PrivateLink endpoint for Amazon ECS in another VPC. Connect the two VPCs by using VPC peering.\\nD. Configure an Amazon Route 53 record with Amazon ECS as the target. Apply a server certificate to Route 53 from AWS Certificate Manager (ACM) for SSL offloading.\", \"B\"],\n[\"Amazon Web Services(AWS)에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스, Amazon RDS 데이터베이스 인스턴스 및 Amazon Redshift 클러스터에 태그가 지정되었는지 확인해야 합니다. 조직은 이 검사를 구성하고 운영하는 데 필요한 시간과 노력을 줄이기를 원합니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.AWS Config 규칙을 사용하여 적절하게 태그가 지정되지 않은 리소스를 정의하고 감지합니다.\\nB. 비용 탐색기를 사용하여 제대로 태그가 지정되지 않은 리소스를 표시합니다. 해당 리소스에 수동으로 태그를 지정합니다.\\nC. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. EC2 인스턴스에서 주기적으로 코드를 실행합니다.\\nD. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. Amazon CloudWatch를 통해 AWS Lambda 함수를 예약하여 코드를 주기적으로 실행합니다.\", \"A firm that hosts its web application on Amazon Web Services (AWS) needs to verify that all Amazon EC2 instances, Amazon RDS database instances, and Amazon Redshift clusters are tagged. The organization wishes to reduce the time and effort required to configure and operate this check.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Use AWS Config rules to define and detect resources that are not properly tagged.\\nB. Use Cost Explorer to display resources that are not properly tagged. Tag those resources manually.\\nC. Write API calls to check all resources for proper tag allocation. Periodically run the code on an EC2 instance.\\nD. Write API calls to check all resources for proper tag allocation. Schedule an AWS Lambda function through Amazon CloudWatch to periodically run the code.\", \"A\"],\n[\"비즈니스는 일반 트래픽의 경우 최소 4개의 Amazon EC2 인스턴스와 피크 로드의 경우 최대 12개의 EC2 인스턴스가 필요한 애플리케이션에 의존합니다.\\n응용 프로그램은 회사에 중요하며 높은 수준의 가용성을 유지해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Auto Scaling 그룹에 EC2 인스턴스를 배포합니다. 가용 영역 A에 2개, 가용 영역 B에 2개로 최소값을 4로, 최대값을 12로 설정합니다.\\nB. Auto Scaling 그룹에 EC2 인스턴스를 배포합니다. 최소값을 4로, 최대값을 12로 설정하고 4개는 모두 가용 영역 A에 있습니다.\\nC. Auto Scaling 그룹에 EC2 인스턴스를 배포합니다. 가용 영역 A에 4개, 가용 영역 B에 4개로 최소값을 8로, 최대값을 12로 설정합니다.\\nD. Auto Scaling 그룹에 EC2 인스턴스를 배포합니다. 최소값은 8로, 최대값은 12로 설정하고 8개는 모두 가용 영역 A에 있습니다.\", \"A business depends on an application that requires at least four Amazon EC2 instances for normal traffic and up to twelve EC2 instances for peak loads.\\nThe application is mission-critical to the company and must maintain a high level of availability.\\nWhich solution will satisfy these criteria?\\n\\nA.Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with 2 in Availability Zone A and 2 in Availability Zone B.\\nB. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 4 and the maximum to 12, with all 4 in Availability Zone A.\\nC. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B.\\nD. Deploy the EC2 instances in an Auto Scaling group. Set the minimum to 8 and the maximum to 12, with all 8 in Availability Zone A.\", \"A\"],\n[\"기업은 확장 가능한 키 관리 인프라를 구축하여 개발자가 앱 내부의 데이터를 암호화할 수 있도록 지원하려고 합니다.\\n솔루션 설계자는 어떻게 운영 부담을 완화할 수 있습니까?\\n\\nA.MFA(다단계 인증)를 사용하여 암호화 키를 보호합니다.\\nB. AWS Key Management Service(AWS KMS)를 사용하여 암호화 키를 보호합니다.\\nC. AWS Certificate Manager(ACM)를 사용하여 암호화 키를 생성, 저장 및 할당합니다.\\nD. IAM 정책을 사용하여 암호화 키를 보호할 수 있는 액세스 권한이 있는 사용자의 범위를 제한합니다.\", \"A business seeks to construct a scalable key management infrastructure to assist developers in encrypting data inside their apps.\\nHow might a solutions architect alleviate operational burdens?\\n\\nA.Use multi-factor authentication (MFA) to protect the encryption keys.\\nB. Use AWS Key Management Service (AWS KMS) to protect the encryption keys.\\nC. Use AWS Certificate Manager (ACM) to create, store, and assign the encryption keys.\\nD. Use an IAM policy to limit the scope of users who have access permissions to protect the encryption keys.\", \"B\"],\n[\"솔루션 설계자는 온프레미스 네트워크 연결 파일 시스템에서 지사의 Amazon S3 Glacier로 750TB의 데이터를 이동하는 책임을 맡습니다.\\n마이그레이션은 온프레미스에서 1Mbps 인터넷 연결을 초과해서는 안 됩니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Amazon S3 버킷에 대한 AWS 사이트 간 VPN 터널을 생성하고 파일을 직접 전송합니다. AWS CLI를 사용하여 직접 파일을 전송합니다.\\nB. AWS Snowball Edge Storage Optimized 장치 10개를 주문하고 S3 Glacier 볼트를 대상으로 선택합니다.\\nC. 네트워크 연결 파일 시스템을 S3 버킷에 탑재하고 파일을 직접 복사합니다. S3 객체를 Amazon S3 Glacier로 전환하는 수명 주기 정책을 생성합니다.\\nD. AWS Snowball Edge Storage Optimized 디바이스 10개를 주문하고 Amazon S3 버킷을 대상으로 선택합니다. S3 객체를 Amazon S3 Glacier로 전환하는 수명 주기 정책을 생성합니다.\", \"A solutions architect is entrusted with the responsibility of moving 750 TB of data from an on-premises network-attached file system to an Amazon S3 Glacier at a branch office.\\nThe migration must not exceed the 1 Mbps internet connection on-premises.\\nWhich solution will satisfy these criteria?\\n\\nA.Create an AWS site-to-site VPN tunnel to an Amazon S3 bucket and transfer the files directly. Transfer the files directly by using the AWS CLI.\\nB. Order 10 AWS Snowball Edge Storage Optimized devices, and select an S3 Glacier vault as the destination.\\nC. Mount the network-attached file system to an S3 bucket, and copy the files directly. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.\\nD. Order 10 AWS Snowball Edge Storage Optimized devices, and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.\", \"D. Snowball을 통해 Glacier에 직접 업로드 불가능.\"],\n[\"솔루션 설계자는 야간 배치 처리 작업이 대상 Amazon EC2 용량에 도달하기 전에 추가로 1시간 동안 자동으로 확장된다는 사실을 알게 되었습니다. 매일 밤 최대 용량은 동일하고 배치 작업은 항상 오전 1시에 시작됩니다. 솔루션 설계자는 일단 배치 프로세스가 완료되면 Auto Scaling 그룹이 축소되도록 허용하면서 목표 EC2 용량을 신속하게 달성할 수 있는 비용 효율적인 접근 방식을 만들어야 합니다. 완료됩니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.Auto Scaling 그룹의 최소 용량을 늘립니다.\\nB. Auto Scaling 그룹의 최대 용량을 늘립니다.\\nC. 원하는 컴퓨팅 수준으로 확장하도록 예약된 확장을 구성합니다.\\nD. 각 조정 작업 동안 더 많은 EC2 인스턴스를 추가하도록 조정 정책을 변경합니다.\", \"A solutions architect notices that a nightly batch processing operation is automatically scaled up for an additional hour prior to reaching the targeted Amazon EC2 capacity. Every night, the peak capacity is the same, and batch operations always begin at 1 a.m. The solutions architect must create a cost-effective approach that enables rapid attainment of the targeted EC2 capacity while allowing the Auto Scaling group to scale down once the batch processes are complete.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Increase the minimum capacity for the Auto Scaling group.\\nB. Increase the maximum capacity for the Auto Scaling group.\\nC. Configure scheduled scaling to scale up to the desired compute level.\\nD. Change the scaling policy to add more EC2 instances during each scaling operation.\", \"C\"],\n[\"기업이 최근 내부 보안 정책을 수정했습니다. 이제 조직은 내부 보안 전문가가 주기적으로 생성하고 순환하는 키를 사용하여 모든 Amazon S3 버킷과 Amazon Elastic Block Store(Amazon EBS) 볼륨이 암호화되었는지 확인해야 합니다. 이를 위해 조직은 기본 소프트웨어 기반 AWS 솔루션을 찾고 있습니다.\\n솔루션 아키텍트가 추천해야 하는 솔루션은 무엇입니까?\\n\\nA.AWS Secrets Manager를 고객 마스터 키(CMK)와 함께 사용하여 마스터 키 구성 요소를 저장하고 정기적으로 새 CMK를 생성하고 AWS Secrets Manager에서 교체하는 루틴을 적용합니다.\\nB. AWS Key Management Service(AWS KMS)를 고객 마스터 키(CMK)와 함께 사용하여 마스터 키 구성 요소를 저장하고 정기적으로 새 키를 재생성하고 AWS KMS에서 교체하는 루틴을 적용합니다.\\nC. 고객 마스터 키(CMK)가 있는 AWS CloudHSM 클러스터를 사용하여 마스터 키 구성 요소를 저장하고 주기적으로 새 키를 재생성하고 CloudHSM 클러스터 노드에서 교체하는 루틴을 적용합니다.\\nD. AWS Systems Manager Parameter Store를 고객 마스터 키(CMK)와 함께 사용하여 마스터 키 구성 요소를 저장하고 정기적으로 새 키를 재생성하고 Parameter Store에서 교체하는 루틴을 적용합니다.\", \"A business recently revised its internal security policies. The organization must now verify that all Amazon S3 buckets and Amazon Elastic Block Store (Amazon EBS) volumes are encrypted using keys generated and cycled on a periodic basis by internal security professionals. To do this, the organization is searching for a native, software-based AWS solution.\\nWhat solution should a solutions architect recommend?\\n\\nA.Use AWS Secrets Manager with customer master keys (CMKs) to store master key material and apply a routine to create a new CMK periodically and replace it in AWS Secrets Manager.\\nB. Use AWS Key Management Service (AWS KMS) with customer master keys (CMKs) to store master key material and apply a routine to re-create a new key periodically and replace it in AWS KMS.\\nC. Use an AWS CloudHSM cluster with customer master keys (CMKs) to store master key material and apply a routine to re-create a new key periodically and replace it in the CloudHSM cluster nodes.\\nD. Use AWS Systems Manager Parameter Store with customer master keys (CMKs) to store master key material and apply a routine to re-create a new key periodically and replace it in the Parameter Store.\", \"B\"],\n[\"기업에는 Amazon S3에 자주 백업해야 하는 온프레미스 데이터 센터에 NFS 서버가 있습니다.\\n이 기준을 충족하고 가장 비용 효율적인 옵션은 무엇입니까?\\n\\nA.온프레미스 서버에서 Amazon S3로 데이터를 복사하도록 AWS Glue를 설정합니다.\\nB. 온프레미스 서버에 AWS DataSync 에이전트를 설정하고 데이터를 Amazon S3에 동기화합니다.\\nC. AWS Transfer for SFTP를 사용하여 SFTP 동기화를 설정하여 데이터를 온프레미스에서 Amazon S3로 동기화합니다.\\nD. 온프레미스 데이터 센터와 VPC 간에 AWS Direct Connect 연결을 설정하고 데이터를 Amazon S3에 복사합니다.\", \"A business has NFS servers in an on-premises data center that need frequent backups to Amazon S3.\\nWhich option satisfies these criteria and is the MOST cost-effective?\\n\\nA.Set up AWS Glue to copy the data from the on-premises servers to Amazon S3.\\nB. Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3.\\nC. Set up an SFTP sync using AWS Transfer for SFTP to sync data from on-premises to Amazon S3.\\nD. Set up an AWS Direct Connect connection between the on-premises data center and a VPC, and copy the data to Amazon S3.\", \"B\"],\n[\"솔루션 설계자는 공용 API 액세스를 가능하게 하는 애플리케이션에 대한 다중 지역 재해 복구 솔루션을 구축하는 책임을 집니다. 애플리케이션 코드를 로드하기 위해 애플리케이션은 사용자 데이터 스크립트 및 MySQL용 Amazon RDS 데이터베이스가 있는 Amazon EC2 인스턴스를 사용합니다. 3시간은 RTO(복구 시간 목표)이고 24시간은 RPO(복구 시점 목표)입니다.\\n이러한 요구 사항을 충족하는 데 가장 비용이 적게 드는 아키텍처는 무엇입니까?\\n\\nA.지역 장애 조치를 위해 Application Load Balancer를 사용하십시오. userdata 스크립트를 사용하여 새 EC2 인스턴스를 배포합니다. 각 리전에 별도의 RDS 인스턴스를 배포합니다.\\nB. 리전 장애 조치를 위해 Amazon Route 53을 사용합니다. userdata 스크립트를 사용하여 새 EC2 인스턴스를 배포합니다. 백업 리전에서 RDS 인스턴스의 읽기 전용 복제본을 생성합니다.\\nC. 퍼블릭 API 및 리전 장애 조치를 위해 Amazon API Gateway를 사용합니다. userdata 스크립트를 사용하여 새 EC2 인스턴스를 배포합니다. 백업 리전에서 RDS 인스턴스의 MySQL 읽기 전용 복제본을 생성합니다.\\nD. 리전 장애 조치를 위해 Amazon Route 53을 사용합니다. API용 userdata 스크립트를 사용하여 새 EC2 인스턴스를 배포하고 백업을 위해 매일 RDS 인스턴스의 스냅샷을 생성합니다. 스냅샷을 백업 리전에 복제합니다.\", \"A solutions architect is tasked with the responsibility of building a multi-region disaster recovery solution for an application that will enable public API access. To load application code, the application will use Amazon EC2 instances with a userdata script and an Amazon RDS for MySQL database. Three hours is the Recovery Time Objective (RTO), while twenty-four hours is the Recovery Point Objective (RPO).\\nWhich architecture would be the LEAST EXPENSIVE to achieve these requirements?\\n\\nA.Use an Application Load Balancer for Region failover. Deploy new EC2 instances with the userdata script. Deploy separate RDS instances in each Region.\\nB. Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the userdata script. Create a read replica of the RDS instance in a backup Region.\\nC. Use Amazon API Gateway for the public APIs and Region failover. Deploy new EC2 instances with the userdata script. Create a MySQL read replica of the RDS instance in a backup Region.\\nD. Use Amazon Route 53 for Region failover. Deploy new EC2 instances with the userdata script for APIs, and create a snapshot of the RDS instance daily for a backup. Replicate the snapshot to a backup Region.\", \"D\"],\n[\"비즈니스에서 AWS를 사용하여 새로운 웹 애플리케이션을 개발하려고 합니다. 회사는 연중 대부분의 기간 동안 트래픽이 일정할 것으로 예상하고 때때로 매우 높은 트래픽을 예상합니다. 웹 애플리케이션은 가용성이 높고 내결함성이 있어야 하며 응답 시간이 짧아야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon Route 53 라우팅 정책을 사용하여 각각 하나의 Amazon EC2 인스턴스가 있는 2개의 AWS 리전에 요청을 배포합니다.\\nB. 여러 가용 영역에서 Application Load Balancer가 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용합니다.\\nC. 여러 가용 영역에서 Application Load Balancer가 있는 클러스터 배치 그룹의 Amazon EC2 인스턴스를 사용합니다.\\nD. 클러스터 배치 그룹에서 Amazon EC2 인스턴스를 사용하고 새 Auto Scaling 그룹 내에 클러스터 배치 그룹을 포함합니다.\", \"A business intends to develop a new web application using AWS. The firm anticipates consistent traffic for the most of the year and very high traffic on occasion. The web application must be highly available, fault resistant, and have a low response time.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Use an Amazon Route 53 routing policy to distribute requests to two AWS Regions, each with one Amazon EC2 instance.\\nB. Use Amazon EC2 instances in an Auto Scaling group with an Application Load Balancer across multiple Availability Zones.\\nC. Use Amazon EC2 instances in a cluster placement group with an Application Load Balancer across multiple Availability Zones.\\nD. Use Amazon EC2 instances in a cluster placement group and include the cluster placement group within a new Auto Scaling group.\", \"B\"],\n[\"기업의 웹 애플리케이션은 많은 Linux Amazon EC2 인스턴스를 사용하며 데이터는 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장됩니다. 조직은 오류 발생 시 애플리케이션의 복원력을 높이고 원자성, 일관성, 격리 및 내구성 요구사항(ACID)을 준수하는 스토리지를 제공할 솔루션을 찾고 있습니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.각 가용 영역의 EC2 인스턴스에서 애플리케이션을 시작합니다. 각 EC2 인스턴스에 EBS 볼륨을 연결합니다.\\nB. 여러 가용 영역에 걸쳐 Auto Scaling 그룹이 있는 Application Load Balancer를 생성합니다. 각 EC2 인스턴스에 인스턴스 스토어를 탑재합니다.\\nC. 여러 가용 영역에 걸쳐 Auto Scaling 그룹이 있는 Application Load Balancer를 생성합니다. Amazon Elastic File System(Amazon EFS)에 데이터를 저장하고 각 인스턴스에 대상을 탑재합니다.\\nD. 여러 가용 영역에 걸쳐 Auto Scaling 그룹이 있는 Application Load Balancer를 생성합니다. Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)를 사용하여 데이터를 저장합니다.\", \"The web application of a business makes use of many Linux Amazon EC2 instances and data is stored on Amazon Elastic Block Store (Amazon EBS) volumes. The organization is searching for a solution that will boost the application's resilience in the event of a failure and will offer storage that adheres to the atomicity, consistency, isolation, and durability requirements (ACID).\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance.\\nB. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Mount an instance store on each EC2 instance.\\nC. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon Elastic File System (Amazon EFS) and mount a target on each instance.\\nD. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA).\", \"C\"],\n[\"비즈니스에서 데이터 처리에 하이브리드 워크로드를 사용하려고 합니다. 데이터는 NFS 프로토콜을 통해 로컬 데이터 처리를 위한 온프레미스 애플리케이션과 추가 분석 및 배치 처리를 위해 AWS 클라우드를 통해 사용할 수 있어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.AWS Storage Gateway 파일 게이트웨이를 사용하여 AWS에 파일 스토리지를 제공한 다음 AWS 클라우드에서 이 데이터에 대한 분석을 수행하십시오.\\nB. AWS Storage Gateway 테이프 게이트웨이를 사용하여 로컬 데이터의 백업을 AWS에 복사한 다음 AWS 클라우드에서 이 데이터에 대한 분석을 수행합니다.\\nC. 저장 볼륨 구성의 AWS Storage Gateway 볼륨 게이트웨이를 사용하여 정기적으로 로컬 데이터의 스냅샷을 만든 다음 데이터를 AWS에 복사합니다.\\nD. 캐시된 볼륨 구성에서 AWS Storage Gateway 볼륨 게이트웨이를 사용하여 AWS 클라우드의 모든 로컬 스토리지를 백업한 다음 클라우드에서 이 데이터에 대한 분석을 수행합니다.\", \"A business wants to use a hybrid workload for data processing. The data must be available through an NFS protocol to on-premises applications for local data processing, as well as via the AWS Cloud for further analytics and batch processing.\\nWhich solution will satisfy these criteria?\\n\\nA.Use an AWS Storage Gateway file gateway to provide file storage to AWS, then perform analytics on this data in the AWS Cloud.\\nB. Use an AWS Storage Gateway tape gateway to copy the backup of the local data to AWS, then perform analytics on this data in the AWS cloud.\\nC. Use an AWS Storage Gateway volume gateway in a stored volume configuration to regularly take snapshots of the local data, then copy the data to AWS.\\nD. Use an AWS Storage Gateway volume gateway in a cached volume configuration to back up all the local storage in the AWS cloud, then perform analytics on this data in the cloud.\", \"A\"],\n[\"한 기업이 AWS에서 2계층 전자상거래 웹사이트를 운영하고 있습니다. 기존 아키텍처는 게시 방향 Elastic Load Balancer를 사용하여 프라이빗 서브넷 내부에 있는 Amazon EC2 인스턴스로 트래픽을 라우팅합니다. 정적 자료는 Amazon Web Services 인스턴스에 보관되고 동적 콘텐츠는 MySQL 데이터베이스에서 액세스됩니다. 이 응용 프로그램은 현재 미국에서만 사용할 수 있습니다. 최근에 회사는 유럽과 호주의 소비자에게 판매를 시작했습니다. 솔루션 설계자는 국제 사용자가 향상된 브라우징 경험을 누릴 수 있는 방식으로 솔루션을 만들어야 합니다.\\n가장 저렴한 옵션은 무엇입니까?\\n\\nA.Amazon S3에서 전체 웹사이트를 호스팅합니다.\\nB. Amazon CloudFront 및 Amazon S3를 사용하여 정적 이미지를 호스팅합니다.\\nC. 퍼블릭 로드 밸런서 및 EC2 인스턴스의 수를 늘립니다.\\nD. 유럽과 호주의 AWS 리전에 2계층 웹 사이트를 배포합니다.\", \"A business is operating a two-tier ecommerce website on AWS. The existing architecture makes use of a publish-facing Elastic Load Balancer to route traffic to Amazon EC2 instances located inside a private subnet. Static material is housed on Amazon Web Services instances, while dynamic content is accessed from a MySQL database. The application is currently only available in the United States. Recently, the corporation began selling to consumers in Europe and Australia. A solutions architect must create solutions in such a way that International users benefit from an enhanced browsing experience.\\nWhich option is the MOST CHEAPEST?\\n\\nA.Host the entire website on Amazon S3.\\nB. Use Amazon CloudFront and Amazon S3 to host static images.\\nC. Increase the number of public load balancers and EC2 instances.\\nD. Deploy the two-tier website in AWS Regions in Europe and Australia.\", \"B\"],\n[\"솔루션 설계자는 Windows 인터넷 정보 서비스(IIS) 웹 애플리케이션을 Amazon Web Services(AWS)로 마이그레이션하는 업무를 담당합니다. 현재 이 프로그램은 사용자의 NAS(Network-Attached Storage)에 있는 파일 공유에 따라 다릅니다. 솔루션에서는 IIS 웹 서버를 스토리지 솔루션에 연결된 여러 가용 영역에 분산된 Amazon EC2 인스턴스로 전송하고 인스턴스에 연결된 Elastic Load Balancer를 설치할 것을 권장했습니다.\\n가장 탄력적이고 내구성이 뛰어난 온프레미스 파일 공유 대안은 무엇입니까?\\n\\nA.파일 공유를 Amazon RDS로 마이그레이션합니다.\\nB. 파일 공유를 AWS Storage Gateway로 마이그레이션\\nC. 파일 공유를 Windows 파일 서버용 Amazon FSx로 마이그레이션합니다.\\nD. 파일 공유를 Amazon Elastic File System(Amazon EFS)으로 마이그레이션\", \"A solutions architect is tasked with the responsibility of migrating a Windows internet information Services (IIS) web application to Amazon Web Services (AWS). Currently, the program depends on a file share located on the user's network-attached storage (NAS). The solutions recommended transferring the IIS web servers to Amazon EC2 instances spread across several Availability Zones linked to the storage solution, as well as installing an Elastic Load Balancer tied to the instances.\\nWhich on-premises file sharing alternative is the MOST resiliant and durable?\\n\\nA.Migrate the file Share to Amazon RDS.\\nB. Migrate the file Share to AWS Storage Gateway\\nC. Migrate the file Share to Amazon FSx for Windows File Server.\\nD. Migrate the file share to Amazon Elastic File System (Amazon EFS)\", \"C\"],\n[\"한 기업에서 솔루션 설계자는 2계층 온라인 애플리케이션을 위한 아키텍처를 개발하고 있습니다. 웹 애플리케이션은 트래픽을 Amazon EC2 Auto Scaling 인스턴스 그룹으로 라우팅하는 인터넷 연결 Application Load Balancer(ALB)로 구성됩니다. EC2 인스턴스는 Amazon RDS 데이터베이스에 연결할 수 있어야 합니다.\\n회사는 네트워크 레이아웃이 심층 방어 전략을 사용할 것을 제안했습니다. 기업은 보안 그룹이나 네트워크 액세스 제어 목록에 전적으로 의존하는 것을 원하지 않습니다.\\n필요한 최소한의 리소스만 인터넷을 통해 라우팅할 수 있어야 합니다.\\n이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 네트워크 아키텍처를 제안해야 합니까?\\n\\nA.ALB, EC2 인스턴스 및 RDS 데이터베이스를 프라이빗 서브넷에 배치합니다.\\nB. ALB를 퍼블릭 서브넷에 배치합니다. EC2 인스턴스와 RDS 데이터베이스를 프라이빗 서브넷에 배치합니다.\\nC. ALB 및 EC2 인스턴스를 퍼블릭 서브넷에 배치합니다. RDS 데이터베이스를 프라이빗 서브넷에 배치합니다.\\nD. ALB를 VPC 외부에 배치합니다. EC2 인스턴스와 RDS 데이터베이스를 프라이빗 서브넷에 배치합니다.\", \"At a corporation, a solutions architect is developing the architecture for a two-tiered online application. The web application is comprised of an internet-facing Application Load Balancer (ALB) that routes traffic to an Amazon EC2 Auto Scaling group of instances. The EC2 instances must be able to connect to an Amazon RDS database.\\nThe corporation has suggested that the network layout use a defense-in-depth strategy. The business does not want to depend entirely on security groups or network access control lists.\\nOnly the bare minimal resources required should be routeable over the internet.\\nWhich network architecture should the solutions architect suggest in order to satisfy these requirements?\\n\\nA.Place the ALB, EC2 instances, and RDS database in private subnets.\\nB. Place the ALB in public subnets. Place the EC2 instances and RDS database in private subnets.\\nC. Place the ALB and EC2 instances in public subnets. Place the RDS database in private subnets.\\nD. Place the ALB outside the VPC. Place the EC2 instances and RDS database in private subnets.\", \"B\"],\n[\"한 기업에서 AWS를 사용하여 2계층 전자상거래 웹사이트를 운영하고 있습니다. 웹 계층은 트래픽을 Amazon Elastic Compute Cloud 머신으로 라우팅하는 로드 밸런서로 구성됩니다. 데이터베이스 계층은 Amazon RDS 데이터베이스 인스턴스를 사용하여 구현됩니다. EC2 인스턴스와 RDS 데이터베이스 인스턴스는 공개적으로 액세스할 수 없도록 설정해야 합니다. EC2 인스턴스가 타사 웹 서비스를 통한 주문 결제 처리를 완료하려면 인터넷 연결이 필요합니다. 애플리케이션의 가용성이 높아야 합니다.\\n이러한 요구 사항을 충족하는 설정 대안은 무엇입니까? (2개를 선택하세요.)\\n\\nA.Auto Scaling 그룹을 사용하여 프라이빗 서브넷에서 EC2 인스턴스를 시작합니다. 프라이빗 서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다.\\nB. 2개의 가용 영역에 걸쳐 2개의 프라이빗 서브넷과 2개의 NAT 게이트웨이가 있는 VPC를 구성합니다. 프라이빗 서브넷에 Application Load Balancer를 배포합니다.\\nC. Auto Scaling 그룹을 사용하여 2개의 가용 영역에 걸쳐 퍼블릭 서브넷에서 EC2 인스턴스를 시작합니다. 프라이빗 서브넷에 RDS 다중 AZ DB 인스턴스를 배포합니다.\\nD. 2개의 가용 영역에 걸쳐 1개의 퍼블릭 서브넷, 1개의 프라이빗 서브넷 및 2개의 NAT 게이트웨이로 VPC를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer를 배포합니다.\\nE. 2개의 가용 영역에 걸쳐 2개의 퍼블릭 서브넷, 2개의 프라이빗 서브넷 및 2개의 NAT 게이트웨이로 VPC를 구성합니다. 퍼블릭 서브넷에 Application Load Balancer를 배포합니다.\", \"A corporation uses AWS to power its two-tier ecommerce website. The web tier is comprised of a load balancer that routes traffic to Amazon Elastic Compute Cloud machines. The database layer is implemented using an Amazon RDS database instance. The EC2 instances and the RDS database instance should not be made publicly accessible. Internet connectivity is required for the EC2 instances to complete payment processing of orders through a third-party web service. The application must have a high degree of availability.\\nWhich setup alternatives will satisfy these requirements? (Select two.)\\n\\nA.Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets.\\nB. Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.\\nC. Use an Auto Scaling group to launch the EC2 instances in public subnets across two Availability Zones. Deploy an RDS Multi-AZ DB instance in private subnets.\\nD. Configure a VPC with one public subnet, one private subnet, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnet.\\nE. Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets.\", \"A, E\"],\n[\"솔루션 설계자는 암호화되지 않은 EBC 스냅샷에서 복구된 모든 볼륨이 암호화되었는지 확인해야 합니다.\\n이를 달성하기 위한 솔루션 설계자의 역할은 무엇입니까?\\n\\nA.AWS 리전에 대해 기본적으로 EBS 암호화를 활성화합니다.\\nB. 특정 볼륨에 대해 기본적으로 EBS 암호화를 활성화합니다.\\nC. 새 볼륨을 생성하고 암호화에 사용할 대칭 고객 마스터 키(CMK)를 지정합니다.\\nD. 새 볼륨을 생성하고 암호화에 사용할 비대칭 고객 마스터 키(CMK)를 지정합니다.\", \"A solutions architect must verify that any volumes recovered from unencrypted EBC snapshots are encrypted.\\nWhat is the solution architect's role in achieving this?\\n\\nA.Enable EBS encryption by default for the AWS Region.\\nB. Enable EBS encryption by default for the specific volumes.\\nC. Create a new volume and specify the symmetric customer master key (CMK) to use for encryption.\\nD. Create a new volume and specify the asymmetric customer master key (CMK) to use for encryption.\", \"A\"],\n[\"비즈니스에서 Amazon S3 버킷에 파일을 쉽게 업로드할 수 있는 애플리케이션을 실행합니다. 파일이 업로드된 후 메타데이터 추출을 위해 분석되며 5초 미만이 소요됩니다. 업로드 볼륨과 빈도는 시간당 몇 개의 파일에서 수백 개의 동시 업로드까지 다양합니다. 이 조직은 이러한 요구 사항을 충족하는 비용 효율적인 아키텍처를 만들기 위해 솔루션 설계자에게 의뢰했습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.S3 API 호출을 기록하도록 AWS CloudTrail 추적을 구성합니다. AWS AppSync를 사용하여 파일을 처리합니다.\\nB. AWS Lambda 함수를 호출하여 파일을 처리하도록 S3 버킷 내에서 객체 생성 이벤트 알림을 구성합니다.\\nC. 데이터를 처리하고 Amazon S3로 보내도록 Amazon Kinesis Data Streams를 구성합니다. AWS Lambda 함수를 호출하여 파일을 처리합니다.\\nD. Amazon S3에 업로드된 파일을 처리하도록 Amazon Simple Notification Service(Amazon SNS) 주제를 구성합니다. AWS Lambda 함수를 호출하여 파일을 처리합니다.\", \"A business runs an application that facilitates the upload of files to an Amazon S3 bucket. After files are uploaded, they are analyzed for metadata extraction, which takes less than 5 seconds. The upload volume and frequency vary between a few files per hour to hundreds of concurrent uploads. The organization has commissioned a solutions architect to create a cost-effective architecture that satisfies these needs.\\nWhat recommendations should the solutions architect make?\\n\\nA.Configure AWS CloudTrail trails to log S3 API calls. Use AWS AppSync to process the files.\\nB. Configure an object-created event notification within the S3 bucket to invoke an AWS Lambda function to process the files.\\nC. Configure Amazon Kinesis Data Streams to process and send data to Amazon S3. Invoke an AWS Lambda function to process the files.\\nD. Configure an Amazon Simple Notification Service (Amazon SNS) topic to process the files uploaded to Amazon S3. Invoke an AWS Lambda function to process the files.\", \"B\"],\n[\"기업에 단일 가용 영역의 Amazon EC2 Auto Scaling 그룹에 있는 6개의 프런트 엔드 웹 서버에서 호스팅되고 ALB(Application Load Balancer)로 보호되는 다중 계층 애플리케이션이 있습니다. 애플리케이션에 영향을 주지 않으면서 솔루션 설계자는 인프라를 조정하여 액세스 가능성을 높여야 합니다.\\n솔루션 설계자는 최대 가용성을 보장하기 위해 어떤 아키텍처를 사용해야 합니까?\\n\\nA.두 리전에서 각각 3개의 인스턴스를 사용하는 Auto Scaling 그룹을 생성합니다.\\nB. 2개의 가용 영역 각각에서 3개의 인스턴스를 사용하도록 Auto Scaling 그룹을 수정합니다.\\nC. 다른 리전에서 더 많은 인스턴스를 빠르게 생성하는 데 사용할 수 있는 Auto Scaling 템플릿을 생성합니다.\\nD. 라운드 로빈 구성에서 Amazon EC2 인스턴스 앞의 ALB를 변경하여 웹 계층에 대한 트래픽 균형을 조정합니다.\", \"A business has a multi-tier application that is hosted on six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone and is protected by an Application Load Balancer (ALB). Without affecting the application, a solutions architect must adapt the infrastructure to make it highly accessible.\\nWhich architecture should the solutions architect use to ensure maximum availability?\\n\\nA.Create an Auto Scaling group that uses three instances across each of two Regions.\\nB. Modify the Auto Scaling group to use three instances across each of two Availability Zones.\\nC. Create an Auto Scaling template that can be used to quickly create more instances in another Region.\\nD. Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance traffic to the web tier.\", \"B. Auto scailing group은 여러 리전에 걸칠 수 없음.\"],\n[\"웹 애플리케이션 개발 비즈니스는 여러 지역에 수백 개의 ALB(Application Load Balancer)를 배포했습니다. 회사는 방화벽 장치에 있는 모든 로드 밸런서의 IP 주소에 대한 허용 목록을 작성하려고 합니다. 솔루션 설계자는 방화벽이 수락해야 하는 IP 수를 줄이는 데 도움이 되는 이 요구 사항에 대한 일회성 고가용성 솔루션을 찾고 있습니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.AWS Lambda 함수를 생성하여 다른 리전의 모든 ALB에 대한 IP를 추적합니다. 이 목록을 계속 새로고침하세요.\\nB. 탄력적 IP로 NLB(Network Load Balancer)를 설정합니다. 모든 ALB의 사설 IP를 이 NLB의 대상으로 등록하십시오.\\nC. AWS Global Accelerator를 시작하고 모든 리전에 대한 엔드포인트를 생성합니다. 다른 리전의 모든 ALB를 해당 엔드포인트에 등록하십시오.\\nD. Amazon EC2 인스턴스를 설정하고 이 EC2 인스턴스에 탄력적 IP를 할당하고 모든 ALB에 트래픽을 전달하는 프록시로 인스턴스를 구성합니다.\", \"A web application development business has deployed hundreds of Application Load Balancers (ALBs) across several regions. The firm want to build an allow list for all load balancers' IP addresses on its firewall device. A solutions architect is searching for a one-time, highly available solution to this requirement that will also assist lower the number of IPs that the firewall must accept.\\nWhat recommendations should the solutions architect make to satisfy these requirements?\\n\\nA.Create a AWS Lambda function to keep track of the IPs for all the ALBs in different Regions. Keep refreshing this list.\\nB. Set up a Network Load Balancer (NLB) with Elastic IPs. Register the private IPs of all the ALBs as targets to this NLB.\\nC. Launch AWS Global Accelerator and create endpoints for all the Regions. Register all the ALBs in different Regions to the corresponding endpoints.\\nD. Set up an Amazon EC2 instance, assign an Elastic IP to this EC2 instance, and configure the instance as a proxy to forward traffic to all the ALBs.\", \"C\"],\n[\"한 비즈니스에서 지역 서비스 중단 시에도 매우 안정적이어야 하는 결제 애플리케이션을 개발하고 있습니다. 솔루션 설계자는 여러 AWS 리전에 쉽게 복제 및 배포할 수 있는 데이터 스토리지 솔루션을 제공해야 합니다. 또한 애플리케이션에는 보고서 생성을 위해 즉시 액세스할 수 있어야 하는 짧은 대기 시간의 원자성, 일관성, 격리 및 내구성(ACID) 트랜잭션이 필요합니다. 또한 개발 팀은 SQL을 사용해야 합니다.\\n이 기준을 충족하는 데이터 스토리지 옵션은 무엇입니까?\\n\\nA.Amazon Aurora 글로벌 데이터베이스\\nB. Amazon DynamoDB 전역 테이블\\nC. 교차 리전 복제 및 Amazon Athena가 있는 Amazon S3\\nD. Amazon Elastic Block Store(Amazon EBS) 스냅샷 복제를 사용하는 Amazon EC2 인스턴스의 MySQL\", \"A business is developing a payment application that must be very reliable even in the event of regional service outages. A solutions architect must provide a data storage solution that is readily replicable and deployable across several AWS Regions. Additionally, the application needs low-latency atomicity, consistency, isolation, and durability (ACID) transactions that must be accessible promptly for report generation. Additionally, the development team must use SQL.\\nWhich data storage option satisfies these criteria?\\n\\nA.Amazon Aurora Global Database\\nB. Amazon DynamoDB global tables\\nC. Amazon S3 with cross-Region replication and Amazon Athena\\nD. MySQL on Amazon EC2 instances with Amazon Elastic Block Store (Amazon EBS) snapshot replication\", \"A\"],\n[\"기업은 Amazon Web Services에서 확장 가능한 웹 애플리케이션을 실행하기를 원합니다. 이 프로그램은 전 세계 사람들이 액세스할 수 있습니다.\\n애플리케이션 사용자는 기가바이트 범위의 고유한 데이터를 다운로드하고 업로드할 수 있습니다. 개발 팀은 업로드 및 다운로드 지연을 최소화하고 속도를 최적화하는 경제적인 솔루션을 찾고 있습니다.\\n솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.Transfer Acceleration이 포함된 Amazon S3를 사용하여 애플리케이션을 호스팅합니다.\\nB. CacheControl 헤더가 있는 Amazon S3를 사용하여 애플리케이션을 호스팅합니다.\\nC. Auto Scaling 및 Amazon CloudFront와 함께 Amazon EC2를 사용하여 애플리케이션을 호스팅합니다.\\nD. Auto Scaling과 함께 Amazon EC2 및 Amazon ElastiCache를 사용하여 애플리케이션을 호스팅합니다.\", \"A business want to run a scalable web application on Amazon Web Services. The program will be accessible by people from all around the globe.\\nUsers of the application will be able to download and upload unique data in the gigabyte range. The development team is looking for an economical solution that minimizes upload and download latency and optimizes speed.\\nWhat actions should a solutions architect take to achieve this?\\n\\nA.Use Amazon S3 with Transfer Acceleration to host the application.\\nB. Use Amazon S3 with CacheControl headers to host the application.\\nC. Use Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application.\\nD. Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application.\", \"A\"],\n[\"기업의 온프레미스 볼륨 백업 시스템의 수명이 다했습니다. 조직은 AWS를 새로운 백업 솔루션에 포함하고 AWS에 백업되는 동안 모든 데이터에 대한 로컬 액세스를 유지하기를 원합니다. 조직은 AWS에 백업된 데이터가 자동으로 안전하게 이동되도록 보장하기를 원합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Snowball을 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. 데이터에 대한 로컬 액세스를 제공하기 위해 Snowball S3 엔드포인트를 탑재하도록 온프레미스 시스템을 구성합니다.\\nB. AWS Snowball Edge를 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. Snowball Edge 파일 인터페이스를 사용하여 데이터에 대한 로컬 액세스 권한을 온프레미스 시스템에 제공합니다.\\nC. AWS Storage Gateway를 사용하고 캐시된 볼륨 게이트웨이를 구성합니다. 온프레미스에서 Storage Gateway 소프트웨어 어플라이언스를 실행하고 로컬에서 캐시할 데이터 비율을 구성합니다. 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 대한 로컬 액세스를 제공합니다.\\nD. AWS Storage Gateway를 사용하고 저장 볼륨 게이트웨이를 구성합니다. 온프레미스에서 Storage Gateway 소프트웨어 어플라이언스를 실행하고 게이트웨이 스토리지 볼륨을 온프레미스 스토리지에 매핑합니다. 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 대한 로컬 액세스를 제공합니다.\", \"A business's on-premises volume backup system has reached the end of its useful life. The organization wants to include AWS into a new backup solution and wishes to retain local access to all data while it is backed up on AWS. The organization want to guarantee that data backed up on AWS is moved automatically and securely.\\nWhich solution satisfies these criteria?\\n\\nA.Use AWS Snowball to migrate data out of the on-premises solution to Amazon S3. Configure on-premises systems to mount the Snowball S3 endpoint to provide local access to the data.\\nB. Use AWS Snowball Edge to migrate data out of the on-premises solution to Amazon S3. Use the Snowball Edge file interface to provide on-premises systems with local access to the data.\\nC. Use AWS Storage Gateway and configure a cached volume gateway. Run the Storage Gateway software appliance on premises and configure a percentage of data to cache locally. Mount the gateway storage volumes to provide local access to the data.\\nD. Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on-premises storage. Mount the gateway storage volumes to provide local access to the data.\", \"D\"],\n[\"기업은 온프레미스 NFS 서버에서 데이터를 수집하고 저장하는 온프레미스 애플리케이션을 유지 관리합니다. 이 회사는 방금 초당 10기가비트 AWS Direct Connect 연결을 설정했습니다. 회사의 현장 저장 용량이 빠르게 고갈되고 있습니다. 조직은 온프레미스 애플리케이션의 데이터에 대한 저지연 액세스를 유지하면서 온프레미스 환경에서 AWS 클라우드로 애플리케이션 데이터를 이동하려고 합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.애플리케이션 데이터용 AWS Storage Gateway를 배포하고 파일 게이트웨이를 사용하여 Amazon S3에 데이터를 저장합니다. NFS를 사용하여 온프레미스 애플리케이션 서버를 파일 게이트웨이에 연결합니다.\\nB. Amazon Elastic File System(Amazon EFS) 파일 시스템을 NFS 서버에 연결하고 애플리케이션 데이터를 EFS 파일 시스템에 복사합니다. 그런 다음 온프레미스 애플리케이션을 Amazon EFS에 연결합니다.\\nC. AWS Storage Gateway를 볼륨 게이트웨이로 구성합니다. NFS 서버의 온프레미스 애플리케이션과 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 통해 애플리케이션 데이터를 사용할 수 있도록 합니다.\\nD. NFS 서버를 소스 위치로 사용하고 Amazon Elastic File System(Amazon EFS) 파일 시스템을 애플리케이션 데이터 전송 대상으로 사용하여 AWS DataSync 에이전트를 생성합니다. 온-프레미스 애플리케이션을 EFS 파일 시스템에 연결합니다.\", \"A business maintains an on-premises application that gathers and saves data on an on-premises NFS server. The firm just established a ten gigabit per second AWS Direct Connect connection. The company's on-site storage capacity is rapidly depleting. The organization wants to move application data from its on-premises environment to the AWS Cloud while preserving low-latency access to the data from the on-premises application.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Deploy AWS Storage Gateway for the application data, and use the file gateway to store the data in Amazon S3. Connect the on-premises application servers to the file gateway using NFS.\\nB. Attach an Amazon Elastic File System (Amazon EFS) file system to the NFS server, and copy the application data to the EFS file system. Then connect the on-premises application to Amazon EFS.\\nC. Configure AWS Storage Gateway as a volume gateway. Make the application data available to the on-premises application from the NFS server and with Amazon Elastic Block Store (Amazon EBS) snapshots.\\nD. Create an AWS DataSync agent with the NFS server as the source location and an Amazon Elastic File System (Amazon EFS) file system as the destination for application data transfer. Connect the on-premises application to the EFS file system.\", \"D. A라는 의견도 있음\"],\n[\"다른 지역에서 기업은 환경의 격리된 백업을 구성했습니다. 애플리케이션이 웜 대기 모드에 있으며 로드 밸런서(ALB)에 의해 보호됩니다. 현재 장애 조치는 다른 리전의 보조 ALB에 연결하기 위해 DNS 별칭 레코드를 변경해야 하는 수동 작업입니다.\\n솔루션 설계자가 장애 조치 프로세스를 자동화하는 가장 좋은 방법은 무엇입니까?\\n\\nA.ALB 상태 확인 활성화\\nB. Amazon Route 53 상태 확인을 활성화합니다.\\nC. ALB 엔드포인트를 가리키는 Amazon Route 53에서 CNAME 레코드를 생성합니다.\\nD. 내부 BIND DNS 서버를 가리키는 Amazon Route 53에서 조건부 전달 규칙을 생성합니다.\", \"In another Region, a business has constructed an isolated backup of its environment. The application is in warm standby mode and is protected by a load balancer (ALB). At the moment, failover is a manual operation that needs changing a DNS alias record to link to the secondary ALB in another Region.\\nWhat is the best way for a solutions architect to automate the failover process?\\n\\nA.Enable an ALB health check\\nB. Enable an Amazon Route 53 health check.\\nC. Crate an CNAME record on Amazon Route 53 pointing to the ALB endpoint.\\nD. Create conditional forwarding rules on Amazon Route 53 pointing to an internal BIND DNS server.\", \"B\"],\n[\"기업에는 두 개의 AWS 계정이 있습니다. 하나는 프로덕션용이고 다른 하나는 개발용입니다. 개발 계정에서 프로덕션 계정으로 보낼 준비가 된 코드 수정 사항이 있습니다.\\n개발 팀의 두 명의 시니어 개발자만 알파 단계에서 프로덕션 계정에 액세스할 수 있습니다. 베타 단계 동안 더 많은 개발자가 테스트를 수행하기 위해 액세스 권한이 필요할 수 있습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.각 계정에서 AWS Management 콘솔을 사용하여 두 개의 정책 문서를 생성합니다. 액세스 권한이 필요한 개발자에게 정책을 할당합니다.\\nB. Development 계정에서 IAM 역할을 생성합니다. 하나의 IAM 역할에 프로덕션 계정에 대한 액세스 권한을 부여합니다. 개발자가 역할을 맡도록 허용합니다.\\nC. Development 계정을 지정하는 신뢰 정책을 사용하여 Production 계정에서 IAM 역할을 생성합니다. 개발자가 역할을 맡도록 허용합니다.\\nD. Production 계정에서 IAM 그룹을 생성하고 이를 Production 계정을 지정하는 신뢰 정책의 보안 주체로 추가합니다. 그룹에 개발자를 추가합니다.\", \"A business has two AWS accounts: one for production and one for development. There are code modifications ready to be sent to the Production account from the Development account.\\nOnly two senior developers on the development team need access to the Production account during the alpha phase. During the beta phase, more developers may need access to undertake testing.\\nWhat recommendations should a solutions architect make?\\n\\nA.Create two policy documents using the AWS Management Console in each account. Assign the policy to developers who need access.\\nB. Create an IAM role in the Development account. Give one IAM role access to the Production account. Allow developers to assume the role.\\nC. Create an IAM role in the Production account with the trust policy that specifies the Development account. Allow developers to assume the role.\\nD. Create an IAM group in the Production account and add it as a principal in the trust policy that specifies the Production account. Add developers to the group.\", \"C\"],\n[\"북미, 유럽 및 아시아에서 사업을 운영하는 다국적 대기업은 전 세계 공급망 및 제조 프로세스를 개선하기 위해 새로운 분산 애플리케이션을 개발하고 있습니다. 단일 대륙에서 이루어진 주문은 1초 이내에 모든 지역에서 액세스할 수 있어야 합니다. 데이터베이스는 최소한의 RTO(복구 시간 목표)로 장애 조치를 수행할 수 있어야 합니다. 애플리케이션의 가동 시간은 프로덕션에 문제가 발생하지 않도록 하는 데 매우 중요합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.Amazon DynamoDB 전역 테이블을 사용합니다.\\nB. Amazon Aurora 글로벌 데이터베이스를 사용합니다.\\nC. 리전 간 읽기 전용 복제본과 함께 MySQL용 Amazon RDS를 사용합니다.\\nD. 교차 리전 읽기 전용 복제본과 함께 PostgreSQL용 Amazon RDS를 사용합니다.\", \"A multinational conglomerate with operations in North America, Europe, and Asia is developing a new distributed application to improve its worldwide supply chain and manufacturing processes. Orders placed on a single continent should be accessible to all Regions in less than a second. The database should be capable to failover with a minimal Recovery Time Objective (RTO). The application's uptime is critical to ensuring that production does not suffer.\\nWhat recommendations should a solutions architect make?\\n\\nA.Use Amazon DynamoDB global tables.\\nB. Use Amazon Aurora Global Database.\\nC. Use Amazon RDS for MySQL with a cross-Region read replica.\\nD. Use Amazon RDS for PostgreSQL with a cross-Region read replica.\", \"B. 문제 잘못되었다는 의견 많음.\"],\n[\"비즈니스 애플리케이션은 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 호스팅됩니다. 인스턴스는 Amazon EC2 Auto Scaling 그룹을 통해 여러 가용 영역에 분산됩니다. 매월 1일 자정에 월말 재무 계산 일괄 처리가 실행됨에 따라 애플리케이션이 상당히 느려집니다. 이로 인해 EC2 인스턴스의 CPU 사용률이 즉시 100%로 급증하여 애플리케이션이 실패합니다.\\n애플리케이션이 다운타임 없이 워크로드를 처리할 수 있도록 솔루션 설계자는 무엇을 권장해야 합니까?\\n\\nA.ALB 앞에 Amazon CloudFront 배포를 구성합니다.\\nB. CPU 사용률을 기반으로 EC2 Auto Scaling 단순 조정 정책을 구성합니다.\\nC. 월별 일정을 기반으로 EC2 Auto Scaling 예정된 조정 정책을 구성합니다.\\nD. EC2 인스턴스에서 일부 워크로드를 제거하도록 Amazon ElastiCache를 구성합니다.\", \"The application of a business is hosted on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are distributed across multiple Availability Zones via an Amazon EC2 Auto Scaling group. At midnight on the first day of each month, the application becomes significantly slower as the month-end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to spike to 100% immediately, causing the application to fail.\\nWhat should a solutions architect recommend to ensure that the application can handle the workload without experiencing downtime?\\n\\nA.Configure an Amazon CloudFront distribution in front of the ALB.\\nB. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.\\nC. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.\\nD. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances.\", \"C\"],\n[\"솔루션 설계자는 Amazon Web Services(AWS)에서 고성능 컴퓨팅(HPC) 워크로드를 호스팅해야 합니다. 워크로드는 수백 개의 Amazon EC2 인스턴스에 분산되며 큰 데이터 세트의 분산 처리를 용이하게 하기 위해 공유 파일 시스템에 대한 동시 액세스가 필요합니다. 동일한 데이터 세트의 여러 인스턴스에 동시에 액세스할 수 있습니다. 워크로드는 1밀리초 미만의 액세스 대기 시간을 요구합니다. 처리 완료 후 엔지니어는 수동 후처리를 위해 데이터세트에 액세스해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족할까요?\\n\\nA.Amazon Elastic File System(Amazon EFS)을 공유 파일 시스템으로 사용하십시오. Amazon EFS에서 데이터 세트에 액세스합니다.\\nB. 공유 파일 시스템으로 사용할 Amazon S3 버킷을 탑재합니다. S3 버킷에서 직접 후처리를 수행합니다.\\nC. Lustre용 Amazon FSx를 공유 파일 시스템으로 사용합니다. 후처리를 위해 파일 시스템을 Amazon S3 버킷에 연결합니다.\\nD. 처리 및 사후 처리를 위해 모든 인스턴스에 탑재할 수 있도록 Amazon S3 버킷을 공유하도록 AWS Resource Access Manager를 구성합니다.\", \"A solutions architect must host a high-performance computing (HPC) workload on Amazon Web Services (AWS). The workload will be dispersed over hundreds of Amazon EC2 instances and will need concurrent access to a shared file system in order to facilitate distributed processing of big datasets. Multiple instances of the same dataset will be accessible concurrently. The workload demands an access latency of less than 1 millisecond. Following completion of processing, engineers will need access to the dataset for manual postprocessing.\\nWhich solution will satisfy these criteria?\\n\\nA.Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.\\nB. Mount an Amazon S3 bucket to serve as the shared file system. Perform postprocessing directly from the S3 bucket.\\nC. Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.\\nD. Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing.\", \"C. HPC나오면 Lustre를 답으로 고려해봐야 함.\"],\n[\"한 회사에서 점수 업데이트를 백엔드 프로세서로 보낸 다음 그 결과를 리더보드에 게시하는 모바일 게임을 구축하고 있습니다. 솔루션 설계자는 많은 양의 트래픽을 처리하고, 수신된 순서대로 모바일 게임 업데이트를 처리하고, 처리된 변경 사항을 액세스하기 쉬운 데이터베이스에 저장할 수 있는 솔루션을 개발해야 합니다. 또한 조직은 솔루션 유지 관리와 관련된 관리 비용을 줄이기를 원합니다.\\n솔루션 설계자는 이러한 기준을 충족하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.Amazon Kinesis Data Streams에 대한 푸시 점수 업데이트. AWS Lambda를 사용하여 Kinesis Data Streams의 업데이트를 처리합니다. 처리된 업데이트를 Amazon DynamoDB에 저장합니다.\\nB. Amazon Kinesis Data Streams에 대한 푸시 점수 업데이트. Auto Scaling용으로 설정된 Amazon EC2 인스턴스 집합으로 업데이트를 처리합니다. 처리된 업데이트를 Amazon Redshift에 저장합니다.\\nC. Amazon Simple Notification Service(Amazon SNS) 주제에 대한 푸시 점수 업데이트. AWS Lambda 함수를 SNS 주제에 구독하여 업데이트를 처리합니다. 처리된 업데이트를 Amazon EC2에서 실행되는 SQL 데이터베이스에 저장합니다.\\nD. 점수 업데이트를 Amazon Simple Queue Service(Amazon SQS) 대기열로 푸시합니다. Auto Scaling과 함께 Amazon EC2 인스턴스 집합을 사용하여 SQS 대기열의 업데이트를 처리합니다. 처리된 업데이트를 Amazon RDS 다중 AZ DB 인스턴스에 저장합니다.\", \"A firm is building a mobile game that sends score updates to a backend processor and then publishes the results on a leaderboard. A solutions architect must develop a solution capable of handling high volumes of traffic, processing mobile game updates in the order in which they are received, and storing the processed changes in a highly accessible database. Additionally, the organization wishes to reduce the management cost associated with maintaining the solution.\\nWhat actions should the solutions architect take to ensure that these criteria are met?\\n\\nA.Push score updates to Amazon Kinesis Data Streams. Process the updates in Kinesis Data Streams with AWS Lambda. Store the processed updates in Amazon DynamoDB.\\nB. Push score updates to Amazon Kinesis Data Streams. Process the updates with a fleet of Amazon EC2 instances set up for Auto Scaling. Store the processed updates in Amazon Redshift.\\nC. Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to process the updates. Store the processed updates in a SQL database running on Amazon EC2.\\nD. Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue. Use a fleet of Amazon EC2 instances with Auto Scaling to process the updates in the SQS queue. Store the processed updates in an Amazon RDS Multi-AZ DB instance.\", \"A\"],\n[\"개발 팀은 통합 제품을 생산하기 위해 다른 비즈니스와 협력하고 있습니다. 다른 회사는 개발 팀의 계정에 저장된 Amazon Simple Queue Service(Amazon SQS) 대기열에 액세스해야 합니다. 다른 회사는 자체 계정에 대한 액세스 권한을 부여하지 않고 대기열을 폴링하려고 합니다.\\n솔루션 설계자는 SQS 대기열 액세스를 어떻게 관리해야 합니까?\\n\\nA.SQS 대기열에 대한 다른 회사 액세스를 제공하는 인스턴스 프로필을 생성합니다.\\nB. 다른 회사에 SQS 대기열에 대한 액세스를 제공하는 IAM 정책을 생성합니다.\\nC. SQS 대기열에 대한 다른 회사 액세스를 제공하는 SQS 액세스 정책을 만듭니다.\\nD. SQS 대기열에 대한 다른 회사 액세스를 제공하는 Amazon Simple Notification Service(Amazon SNS) 액세스 정책을 생성합니다.\", \"A development team is working in collaboration with another business to produce an integrated product. The other firm requires access to an Amazon Simple Queue Service (Amazon SQS) queue stored in the account of the development team. The other corporation want to poll the queue without granting access to its own account.\\nHow should a solutions architect manage SQS queue access?\\n\\nA.Create an instance profile that provides the other company access to the SQS queue.\\nB. Create an IAM policy that provides the other company access to the SQS queue.\\nC. Create an SQS access policy that provides the other company access to the SQS queue.\\nD. Create an Amazon Simple Notification Service (Amazon SNS) access policy that provides the other company access to the SQS queue.\", \"C. Amazon SQS 정책 시스템을 사용하면 다른 AWS 계정에 권한을 부여할 수 있지만 IAM은 그렇지 않습니다.\"],\n[\"기업의 웹사이트는 일반 대중에게 물건을 제공하는 데 사용됩니다. 이 사이트는 Auto Scaling 그룹의 일부이고 Application Load Balancer(ALB)로 보호되는 Amazon EC2 인스턴스에서 호스팅됩니다. 또한 Amazon CloudFront 배포를 사용할 수 있으며 AWS WAF를 활용하여 SQL 주입 공격을 방어합니다. ALB는 CloudFront 배포가 시작되는 곳입니다. 최근 보안 로그 분석을 통해 웹사이트 방문을 차단해야 하는 외부 악성 IP 주소를 식별했습니다.\\n솔루션 설계자는 애플리케이션을 보호하기 위해 어떤 단계를 수행해야 합니까?\\n\\nA.CloudFront 배포에서 네트워크 ACL을 수정하여 악성 IP 주소에 대한 거부 규칙을 추가합니다.\\nB. AWS WAF의 구성을 수정하여 악성 IP 주소를 차단하는 IP 일치 조건을 추가합니다.\\nC. ALB 뒤에 있는 대상 그룹의 EC2 인스턴스에 대한 네트워크 ACL을 수정하여 악성 IP 주소를 거부합니다.\\nD. ALB 뒤에 있는 대상 그룹의 EC2 인스턴스에 대한 보안 그룹을 수정하여 악성 IP 주소를 거부합니다.\", \"The website of a business is used to offer things to the general public. The site is hosted on Amazon EC2 instances that are part of an Auto Scaling group and protected by an Application Load Balancer (ALB). Additionally, an Amazon CloudFront distribution is available, and AWS WAF is utilized to guard against SQL injection attacks. The ALB is where the CloudFront distribution originates. Recent security log analysis identified an external malicious IP address that should be prevented from visiting the website.\\nWhat steps should a solutions architect take to safeguard an application?\\n\\nA.Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address.\\nB. Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address.\\nC. Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address.\\nD. Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address.\", \"B\"],\n[\"새 VPC의 프라이빗 서브넷에 Amazon EC2 인스턴스가 생성됩니다. 이 서브넷에는 외부 인터넷 연결이 없지만 EC2 인스턴스에는 타사 공급업체로부터 월간 보안 업데이트를 받을 수 있는 기능이 필요합니다.\\n이러한 기준이 충족되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.인터넷 게이트웨이를 생성하여 VPC에 연결합니다. 인터넷 게이트웨이를 기본 경로로 사용하도록 프라이빗 서브넷 라우팅 테이블을 구성합니다.\\nB. NAT 게이트웨이를 생성하고 퍼블릭 서브넷에 배치합니다. NAT 게이트웨이를 기본 경로로 사용하도록 프라이빗 서브넷 라우팅 테이블을 구성합니다.\\nC. NAT 인스턴스를 생성하고 EC2 인스턴스가 있는 동일한 서브넷에 배치합니다. NAT 인스턴스를 기본 경로로 사용하도록 프라이빗 서브넷 라우팅 테이블을 구성합니다.\\nD. 인터넷 게이트웨이를 생성하여 VPC에 연결합니다. NAT 인스턴스를 생성하고 EC2 인스턴스가 있는 동일한 서브넷에 배치합니다. 인터넷 게이트웨이를 기본 경로로 사용하도록 프라이빗 서브넷 라우팅 테이블을 구성합니다.\", \"An Amazon EC2 instance is created in a new VPC's private subnet. Although this subnet lacks outward internet connectivity, the EC2 instance requires the ability to obtain monthly security updates from a third-party vendor.\\nWhat actions should a solutions architect take to ensure that these criteria are met?\\n\\nA.Create an internet gateway, and attach it to the VPC. Configure the private subnet route table to use the internet gateway as the default route.\\nB. Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.\\nC. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the NAT instance as the default route.\\nD. Create an internet gateway, and attach it to the VPC. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the internet gateway as the default route.\", \"B\"],\n[\"솔루션 아키텍트는 새로운 온라인 애플리케이션을 위한 아키텍처를 만드는 책임이 있습니다. 애플리케이션은 ALB(Application Load Balancer) 및 Amazon Aurora에서 호스팅되는 PostgreSQL 데이터베이스가 있는 AWS Fargate 컨테이너에서 호스팅됩니다. 웹 애플리케이션은 주로 데이터베이스에서 읽기 전용 작업을 수행합니다.\\n솔루션 설계자는 트래픽이 증가함에 따라 웹사이트의 확장성을 보장하기 위해 무엇을 해야 합니까? (2개를 선택하세요.)\\n\\nA.ALB에서 Auto Scaling을 활성화하여 로드 밸런서를 수평으로 확장합니다.\\nB. Aurora 클러스터의 Aurora 복제본 수를 동적으로 조정하도록 Aurora Auto Scaling을 구성합니다.\\nC. ALB에서 교차 영역 로드 밸런싱을 활성화하여 모든 가용 영역의 컨테이너 간에 로드를 고르게 분산합니다.\\nD. 각 가용 영역에서 Amazon Elastic Container Service(Amazon ECS) 클러스터를 구성하여 여러 가용 영역에 로드를 분산합니다.\\nE. CPU 사용률을 기반으로 하는 대상 추적 조정 정책으로 Amazon Elastic Container Service(Amazon ECS) 서비스 Auto Scaling을 구성합니다.\", \"A solutions architect is tasked with the responsibility of creating the architecture for a new online application. The application will be hosted on AWS Fargate containers with an Application Load Balancer (ALB) and a PostgreSQL database hosted on Amazon Aurora. The web application will largely do read-only operations on the database.\\nWhat should the solutions architect do to assure the website's scalability as traffic increases? (Select two.)\\n\\nA.Enable auto scaling on the ALB to scale the load balancer horizontally.\\nB. Configure Aurora Auto Scaling to adjust the number of Aurora Replicas in the Aurora cluster dynamically.\\nC. Enable cross-zone load balancing on the ALB to distribute the load evenly across containers in all Availability Zones.\\nD. Configure an Amazon Elastic Container Service (Amazon ECS) cluster in each Availability Zone to distribute the load across multiple Availability Zones.\\nE. Configure Amazon Elastic Container Service (Amazon ECS) Service Auto Scaling with a target tracking scaling policy that is based on CPU utilization.\", \"B, E\"],\n[\"기업이 여러 의심스러운 IP 주소에서 액세스 요청을 감지했습니다. 보안 팀은 동일한 CIDR 범위 내의 여러 IP 주소에서 요청이 발생하는 것을 확인했습니다.\\n솔루션 설계자는 팀에 어떤 권장 사항을 제공해야 합니까?\\n\\nA.보안의 인바운드 테이블에 규칙을 추가하여 해당 CIDR 범위의 트래픽을 거부합니다.\\nB. 보안 그룹의 아웃바운드 테이블에 규칙을 추가하여 해당 CIDR 범위의 트래픽을 거부합니다.\\nC. 네트워크 ACL의 인바운드 테이블에 다른 규칙보다 낮은 번호로 거부 규칙을 추가합니다.\\nD. 다른 규칙보다 낮은 규칙 번호로 네트워크 ACL의 아웃바운드 테이블에 거부 규칙을 추가합니다.\", \"A business has detected access requests from many dubious IP addresses. The security team determines that the requests originate from many IP addresses within the same CIDR range.\\nWhat recommendations should a solutions architect provide to the team?\\n\\nA.Add a rule in the inbound table of the security to deny the traffic from that CIDR range.\\nB. Add a rule in the outbound table of the security group to deny the traffic from that CIDR range.\\nC. Add a deny rule in the inbound table of the network ACL with a lower number than other rules.\\nD. Add a deny rule in the outbound table of the network ACL with a lower rule number than other rules.\", \"C. SG(security group)은 거부 규칙을 지원하지 않음.\"],\n[\"비즈니스에는 Auto Scaling 그룹의 일부이며 종종 수많은 Linux 인스턴스를 실행하는 빌드 서버가 있습니다. 작업 및 설정을 위해 빌드 서버에는 안정적이고 탑재 가능한 공유 NFS 스토리지가 필요합니다.\\n솔루션 설계자는 어떤 종류의 스토리지를 권장해야 합니까?\\n\\nA.아마존 S3\\nB. 아마존 FSx\\nC. Amazon Elastic Block Store(Amazon EBS)\\nD. Amazon Elastic File System(Amazon EFS)\", \"A business has a build server that is part of an Auto Scaling group and often runs numerous Linux instances. For tasks and setups, the build server needs stable and mountable shared NFS storage.\\nWhat kind of storage should a solutions architect recommend?\\n\\nA.Amazon S3\\nB. Amazon FSx\\nC. Amazon Elastic Block Store (Amazon EBS)\\nD. Amazon Elastic File System (Amazon EFS)\", \"D\"],\n[\"AWS 호스팅 애플리케이션은 데이터베이스용 Amazon Aurora 다중 AZ 배포를 활용합니다. 성능 측정을 분석할 때 솔루션 설계자는 데이터베이스 읽기가 상당한 양의 I/O를 사용하고 데이터베이스에 대한 쓰기 요청 지연을 증가시키는 것을 관찰했습니다.\\n솔루션 설계자는 읽기 요청과 쓰기 요청을 구별하기 위해 무엇을 해야 합니까?\\n\\nA.Amazon Aurora 데이터베이스에서 read-through 캐싱을 활성화합니다.\\nB. 다중 AZ 대기 인스턴스에서 읽도록 애플리케이션을 업데이트합니다.\\nC. 읽기 전용 복제본을 생성하고 적절한 엔드포인트를 사용하도록 애플리케이션을 수정합니다.\\nD. 두 번째 Amazon Aurora 데이터베이스를 생성하고 기본 데이터베이스에 읽기 전용 복제본으로 연결합니다.\", \"AWS-hosted applications make advantage of an Amazon Aurora Multi-AZ deployment for their database. When analyzing performance measurements, a solutions architect observed that database reads are using a significant amount of I/O and increasing delay to write requests to the database.\\nWhat should the solutions architect do to distinguish between read and write requests?\\n\\nA.Enable read-through caching on the Amazon Aurora database.\\nB. Update the application to read from the Multi-AZ standby instance.\\nC. Create a read replica and modify the application to use the appropriate endpoint.\\nD. Create a second Amazon Aurora database and link it to the primary database as a read replica.\", \"C\"],\n[\"한 비즈니스에서 자동차 판매 웹사이트를 운영하고 목록을 Amazon RDS 데이터베이스에 보관합니다. 자동차가 판매되면 웹 사이트에서 목록이 삭제되고 데이터가 다른 대상 시스템으로 전송됩니다.\\n솔루션 아키텍트는 어떤 디자인을 제안해야 할까요?\\n\\nA.Amazon RDS의 데이터베이스가 업데이트되어 대상이 사용할 Amazon Simple Queue Service(Amazon SQS) 대기열로 정보를 보내도록 업데이트될 때 트리거되는 AWS Lambda 함수를 생성합니다.\\nB. Amazon RDS의 데이터베이스가 대상이 사용할 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열로 정보를 보내도록 업데이트될 때 트리거되는 AWS Lambda 함수를 생성합니다.\\nC. RDS 이벤트 알림을 구독하고 여러 Amazon Simple Notification Service(Amazon SNS) 주제로 팬아웃된 Amazon Simple Queue Service(Amazon SQS) 대기열을 보냅니다. AWS Lambda 함수를 사용하여 대상을 업데이트합니다.\\nD. RDS 이벤트 알림을 구독하고 Amazon Simple Notification Service(Amazon SNS) 주제를 여러 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. AWS Lambda 함수를 사용하여 대상을 업데이트합니다.\", \"A business operates an automotive sales website and keeps its listings in an Amazon RDS database. When a car is sold, the listing is deleted from the website and the data is sent to other target systems.\\nWhat kind of design should a solutions architect suggest?\\n\\nA.Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.\\nB. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) FIFO queue for the targets to consume.\\nC. Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets.\\nD. Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets.\", \"D\"],\n[\"비즈니스에서 VPC 내부에 포함된 데이터베이스와 통신하는 웹 애플리케이션을 AWS에서 실행하려고 합니다. 애플리케이션의 가용성이 높아야 합니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.두 개의 Amazon EC2 인스턴스를 생성하여 로드 밸런서 뒤에 웹 서버를 호스팅한 다음 데이터베이스를 대규모 인스턴스에 배포합니다.\\nB. 웹 서버용 Auto Scaling 그룹을 사용하여 여러 가용 영역에 로드 밸런서를 배포한 다음, 여러 가용 영역에 Amazon RDS를 배포합니다.\\nC. 웹 서버용 Auto Scaling 그룹이 있는 퍼블릭 서브넷에 로드 밸런서를 배포한 다음 프라이빗 서브넷의 Amazon EC2 인스턴스에 데이터베이스를 배포합니다.\\nD. Auto Scaling 그룹이 있는 두 개의 웹 서버를 배포하고 두 개의 웹 서버를 가리키는 도메인을 구성한 다음 여러 가용 영역에 데이터베이스 아키텍처를 배포합니다.\", \"A business wants to run a web application on AWS that communicates with a database contained inside a VPC. The application should have a high degree of availability.\\nWhat recommendations should a solutions architect make?\\n\\nA.Create two Amazon EC2 instances to host the web servers behind a load balancer, and then deploy the database on a large instance.\\nB. Deploy a load balancer in multiple Availability Zones with an Auto Scaling group for the web servers, and then deploy Amazon RDS in multiple Availability Zones.\\nC. Deploy a load balancer in the public subnet with an Auto Scaling group for the web servers, and then deploy the database on an Amazon EC2 instance in the private subnet.\\nD. Deploy two web servers with an Auto Scaling group, configure a domain that points to the two web servers, and then deploy a database architecture in multiple Availability Zones.\", \"B\"],\n[\"소프트웨어 회사는 다수의 Amazon Web Services(AWS) 고객이 사용할 새로운 SaaS(Software-as-a-Service) 솔루션을 출시합니다. 이 서비스는 Network Load Balancer 뒤의 Virtual Private Cloud(VPC) 내부에서 호스팅됩니다. 소프트웨어 제조업체는 서비스를 공용 인터넷에 노출하지 않고 가능한 한 적은 관리 오버헤드로 사용자에게 이 서비스에 대한 액세스 권한을 제공하려고 합니다.\\n솔루션 설계자는 이 목표를 달성하기 위해 어떤 조치를 취해야 합니까?\\n\\nA.각 사용자의 VPC에서 소프트웨어 공급업체의 VPC로 피어링 VPC 연결을 생성합니다.\\nB. 소프트웨어 공급업체의 AWS 계정에 전송 VPC를 배포합니다. 각 사용자 계정으로 VPN 연결을 만듭니다.\\nC. VPC의 서비스를 AWS Private Link 엔드포인트와 연결합니다. 사용자가 엔드포인트를 구독하도록 합니다.\\nD. 소프트웨어 공급업체의 AWS 계정에 전송 VPC를 배포합니다. 각 사용자 계정으로 AWS Direct Connect 연결을 생성합니다.\", \"A software company is launching a new software-as-a-service (SaaS) solution that will be used by a large number of Amazon Web Services (AWS) customers. The service is hosted inside a Virtual Private Cloud (VPC) behind a Network Load Balancer. The software manufacturer want to give users with access to this service with as little administrative overhead as possible and without exposing the service to the public internet.\\nWhat actions should a solutions architect take to achieve this objective?\\n\\nA.Create a peering VPC connection from each user's VPC to the software vendor's VPC.\\nB. Deploy a transit VPC in the software vendor's AWS account. Create a VPN connection with each user account.\\nC. Connect the service in the VPC with an AWS Private Link endpoint. Have users subscribe to the endpoint.\\nD. Deploy a transit VPC in the software vendor's AWS account. Create an AWS Direct Connect connection with each user account.\", \"C\"],\n[\"Amazon EC2 인스턴스에서 실행되는 애플리케이션은 Amazon S3 버킷에 대한 액세스 권한이 필요합니다. 데이터의 민감성으로 인해 인터넷을 통해 전송할 수 없습니다.\\n솔루션 설계자는 액세스를 위해 어떤 구성을 해야 합니까?\\n\\nA.Amazon Route 53을 사용하여 프라이빗 호스팅 영역을 생성합니다.\\nB. VPC에서 Amazon S3용 VPC 게이트웨이 엔드포인트를 구성합니다.\\nC. EC2 인스턴스와 S3 버킷 간에 AWS PrivateLink를 구성합니다.\\nD. VPC와 S3 버킷 간에 사이트 간 VPN 연결을 설정합니다.\", \"The application running on Amazon EC2 instances requires access to an Amazon S3 bucket. Due to the sensitivity of the data, it cannot be sent via the internet.\\nWhat configuration should a solutions architect make for access?\\n\\nA.Create a private hosted zone using Amazon Route 53.\\nB. Configure a VPC gateway endpoint for Amazon S3 in the VPC.\\nC. Configure AWS PrivateLink between the EC2 instance and the S3 bucket.\\nD. Set up a site-to-site VPN connection between the VPC and the S3 bucket.\", \"B\"],\n[\"솔루션 설계자는 클라이언트용 모놀리식 온라인 애플리케이션을 다중 계층 애플리케이션으로 변환하고 있습니다. 기업은 자체 기반 시설을 통제하지 않기를 원합니다. 웹 애플리케이션의 최소 요구 사항에는 고가용성, 확장성 및 피크 시간 동안의 지역적으로 낮은 지연 시간이 포함됩니다. 또한 솔루션은 애플리케이션의 API를 통해 밀리초 지연 시간으로 데이터를 저장하고 검색할 수 있어야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.AWS Fargate를 사용하여 백엔드 Amazon RDS 다중 AZ DB 인스턴스로 웹 애플리케이션을 호스팅합니다.\\nB. 엣지 최적화 API 엔드포인트와 함께 Amazon API Gateway, 컴퓨팅용 AWS Lambda, 데이터 저장소로 Amazon DynamoDB를 사용합니다.\\nC. 정적 웹 사이트 호스팅 및 Amazon DynamoDB를 데이터 저장소로 사용하는 Amazon S3 버킷을 가리키는 지리적 위치가 있는 Amazon Route 53 라우팅 정책을 사용합니다.\\nD. Amazon RDS 다중 AZ DB 인스턴스와 함께 Amazon EC2 Auto Scaling 그룹이 있는 Elastic Load Balancer를 가리키는 Amazon CloudFront 배포를 사용합니다.\", \"A solutions architect is converting a monolithic online application for a client into a multi-tier application. The business wishes to abstain from controlling its own infrastructure. The web application's minimal requirements include high availability, scalability, and regionally low latency during peak hours. Additionally, the solution should be capable of storing and retrieving data with a millisecond latency through the application's API.\\nWhich solution satisfies these criteria?\\n\\nA.Use AWS Fargate to host the web application with backend Amazon RDS Multi-AZ DB instances.\\nB. Use Amazon API Gateway with an edge-optimized API endpoint, AWS Lambda for compute, and Amazon DynamoDB as the data store.\\nC. Use an Amazon Route 53 routing policy with geolocation that points to an Amazon S3 bucket with static website hosting and Amazon DynamoDB as the data store.\\nD. Use an Amazon CloudFront distribution that points to an Elastic Load Balancer with an Amazon EC2 Auto Scaling group, along with Amazon RDS Multi-AZ DB instances.\", \"B\"],\n[\"솔루션 설계자는 Windows 사용자의 홈 디렉토리를 위한 강력한 솔루션을 개발하는 책임이 있습니다. 솔루션에는 내결함성, 파일 수준 백업 및 복구, 액세스 제어가 있어야 하며 이 모든 것은 비즈니스의 Active Directory를 기반으로 해야 합니다.\\n이 기준을 충족하는 스토리지 옵션은 무엇입니까?\\n\\nA.사용자의 홈 디렉터리를 저장하도록 Amazon S3를 구성합니다. Amazon S3를 Active Directory에 가입합니다.\\nB. Windows 파일 서버용 Amazon FSx를 사용하여 다중 AZ 파일 시스템을 구성합니다. Amazon FSx를 Active Directory에 가입합니다.\\nC. 사용자의 홈 디렉터리에 대해 Amazon Elastic File System(Amazon EFS)을 구성합니다. Active Directory로 AWS Single Sign-On을 구성합니다.\\nD. 사용자의 홈 디렉터리를 저장하도록 Amazon Elastic Block Store(Amazon EBS)를 구성합니다. Active Directory로 AWS Single Sign-On을 구성합니다.\", \"A solutions architect is tasked with the responsibility of developing a robust solution for Windows users' home directories. The solution must have fault tolerance, file-level backup and recovery, and access control, all of which must be based on the Active Directory of the business.\\nWhich storage option satisfies these criteria?\\n\\nA.Configure Amazon S3 to store the users' home directories. Join Amazon S3 to Active Directory.\\nB. Configure a Multi-AZ file system with Amazon FSx for Windows File Server. Join Amazon FSx to Active Directory.\\nC. Configure Amazon Elastic File System (Amazon EFS) for the users' home directories. Configure AWS Single Sign-On with Active Directory.\\nD. Configure Amazon Elastic Block Store (Amazon EBS) to store the users' home directories. Configure AWS Single Sign-On with Active Directory.\", \"B\"],\n[\"비즈니스는 비즈니스의 Amazon Simple Queue Service(Amazon SQS) 대기열에 대한 쓰기 액세스 권한이 필요한 타사 공급업체와 협력하고 있습니다. 공급업체에는 자체 Amazon Web Services 계정이 있습니다.\\n최소 권한 액세스가 구현되도록 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.SQS 대기열에 대한 권한 정책을 업데이트하여 공급업체의 AWS 계정에 대한 쓰기 액세스 권한을 부여합니다.\\nB. SQS 대기열에 대한 쓰기 액세스 권한이 있는 IAM 사용자를 생성하고 IAM 사용자의 자격 증명을 공유합니다.\\nC. 공급업체의 AWS 계정에서 SQS 대기열에 대한 쓰기 액세스 권한을 제공하도록 AWS Resource Access Manager를 업데이트합니다.\\nD. 모든 SQS 대기열에 대한 액세스 권한이 있는 교차 계정 역할을 생성하고 해당 역할에 대한 신뢰 문서에서 공급업체의 AWS 계정을 사용합니다.\", \"A business is collaborating with a third-party vendor who needs write access to the business's Amazon Simple Queue Service (Amazon SQS) queue. The vendor has their own Amazon Web Services account.\\nWhat actions should a solutions architect take to ensure least privilege access is implemented?\\n\\nA.Update the permission policy on the SQS queue to give write access to the vendor's AWS account.\\nB. Create an IAM user with write access to the SQS queue and share the credentials for the IAM user.\\nC. Update AWS Resource Access Manager to provide write access to the SQS queue from the vendor's AWS account.\\nD. Create a cross-account role with access to all SQS queues and use the vendor's AWS account in the trust document for the role.\", \"A\"],\n[\"솔루션 설계자는 Amazon EC2 인스턴스 전반에 걸쳐 낮은 네트워크 지연 시간과 높은 네트워크 처리량을 요구하는 새로운 애플리케이션을 위한 아키텍처를 구축하는 업무를 담당합니다.\\n건축 설계의 어떤 구성 요소가 포함되어야 합니까?\\n\\nA.스팟 인스턴스 유형이 있는 Auto Scaling 그룹.\\nB. 클러스터 배치 전략을 사용하는 배치 그룹.\\nC. 파티션 배치 전략을 사용하는 배치 그룹.\\nD. 온디맨드 인스턴스 유형이 있는 Auto Scaling 그룹.\", \"A solutions architect is tasked with the responsibility of building an architecture for a new application that demands low network latency and high network throughput across Amazon EC2 instances.\\nWhich component of the architectural design should be included?\\n\\nA.An Auto Scaling group with Spot Instance types.\\nB. A placement group using a cluster placement strategy.\\nC. A placement group using a partition placement strategy.\\nD. An Auto Scaling group with On-Demand instance types.\", \"B\"],\n[\"비즈니스는 2개의 가용 영역에 걸쳐 있는 Amazon EC2 인스턴스에서 호스팅되는 웹 사이트를 운영합니다. 조직은 특정 휴일 전후에 트래픽이 증가할 것으로 예상하고 일관된 고객 경험을 제공하기를 원합니다.\\n솔루션 아키텍트가 이 기준을 어떻게 충족할 수 있습니까?\\n\\nA.단계적 스케일링을 사용하십시오.\\nB. 간단한 스케일링을 사용합니다.\\nC. 수명 주기 후크를 사용합니다.\\nD. 예약된 확장을 사용합니다.\", \"A business operates a website that is hosted on Amazon EC2 instances spread across two Availability Zones. The organization anticipates traffic increases around certain holidays and wants to provide a consistent customer experience.\\nHow can a solutions architect satisfy this criterion?\\n\\nA.Use step scaling.\\nB. Use simple scaling.\\nC. Use lifecycle hooks.\\nD. Use scheduled scaling.\", \"D\"],\n[\"기업은 상태 비저장 UDP 기반 워크로드의 가용성과 성능을 향상하기를 원합니다. 워크로드는 Amazon EC2 인스턴스를 사용하여 다양한 AWS 리전에 분산됩니다.\\n솔루션 설계자는 이를 달성하기 위한 수단으로 무엇을 제안해야 합니까?\\n\\nA.각 리전의 NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. AWS Global Accelerator를 사용하여 액셀러레이터를 생성합니다. NLB를 액셀러레이터의 끝점으로 사용합니다.\\nB. 각 리전의 Application Load Balancer(ALB) 뒤에 EC2 인스턴스를 배치합니다. AWS Global Accelerator를 사용하여 액셀러레이터를 생성합니다. ALB를 액셀러레이터의 끝점으로 사용합니다.\\nC. 각 리전의 NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 요청을 NLB로 라우팅하는 오리진이 있는 Amazon CloudFront 배포를 생성합니다.\\nD. 각 리전의 Application Load Balancer(ALB) 뒤에 EC2 인스턴스를 배치합니다. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 ALB로 요청을 라우팅하는 오리진이 있는 Amazon CloudFront 배포를 생성합니다.\", \"A business wants to enhance the availability and performance of its stateless UDP-based workload. The workload is spread across various AWS Regions using Amazon EC2 instances.\\nWhat should a solutions architect suggest as a means of achieving this?\\n\\nA.Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the NLBs as endpoints for the accelerator.\\nB. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an accelerator using AWS Global Accelerator. Use the ALBs as endpoints for the accelerator.\\nC. Place the EC2 instances behind Network Load Balancers (NLBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the NLBs.\\nD. Place the EC2 instances behind Application Load Balancers (ALBs) in each Region. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the ALBs.\", \"A\"],\n[\"비즈니스에는 모두 고정 IP 주소가 있는 여러 온프레미스 서버에서 호스팅되는 하이브리드 애플리케이션이 있습니다. VPC를 온프레미스 네트워크에 연결하는 VPN이 이미 있습니다. 회사는 인터넷 사용자를 위한 TCP 트래픽을 온프레미스 서버에 분산하려고 합니다.\\n접근성과 확장성이 뛰어난 솔루션을 제공하기 위해 솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.인터넷 연결 NLB(Network Load Balancer)를 시작하고 NLB에 온프레미스 IP 주소를 등록합니다.\\nB. 인터넷 연결 ALB(Application Load Balancer)를 시작하고 ALB에 온프레미스 IP 주소를 등록합니다.\\nC. Amazon EC2 인스턴스를 시작하고 탄력적 IP 주소를 연결하고 온프레미스 서버에 트래픽을 분산합니다.\\nD. Auto Scaling 그룹에서 퍼블릭 IP 주소로 Amazon EC2 인스턴스를 시작하고 온프레미스 서버로 트래픽을 분산합니다.\", \"A business has a hybrid application that is hosted on a number of on-premises servers that all have static IP addresses. There is already a VPN in place that connects the VPC to the on-premises network. The corporation want to disperse TCP traffic for internet users among its on-premises servers.\\nWhat recommendations should a solutions architect make to provide a highly accessible and scalable solution?\\n\\nA.Launch an internet-facing Network Load Balancer (NLB) and register on-premises IP addresses with the NLB.\\nB. Launch an internet-facing Application Load Balancer (ALB) and register on-premises IP addresses with the ALB.\\nC. Launch an Amazon EC2 instance, attach an Elastic IP address, and distribute traffic to the on-premises servers.\\nD. Launch an Amazon EC2 instance with public IP addresses in an Auto Scaling group and distribute traffic to the on-premises servers.\", \"A\"],\n[\"비즈니스에서는 Amazon S3 게이트웨이 엔드포인트가 신뢰할 수 있는 버킷의 트래픽만 수락해야 합니다.\\n솔루션 설계자는 이 요구 사항을 충족하기 위해 어떤 접근 방식을 사용해야 합니까?\\n\\nA.회사의 신뢰할 수 있는 VPC에서만 트래픽을 허용하는 회사의 신뢰할 수 있는 각 S3 버킷에 대한 버킷 정책을 생성합니다.\\nB. 회사의 S3 게이트웨이 엔드포인트 ID로부터의 트래픽만 허용하는 회사의 신뢰할 수 있는 각 S3 버킷에 대한 버킷 정책을 생성합니다.\\nC. 회사의 신뢰할 수 있는 VPC가 아닌 다른 VPC의 액세스를 차단하는 회사의 각 S3 게이트웨이 엔드포인트에 대한 S3 엔드포인트 정책을 생성합니다.\\nD. 신뢰할 수 있는 S3 버킷의 Amazon 리소스 이름(ARN)에 대한 액세스를 제공하는 회사의 각 S3 게이트웨이 엔드포인트에 대한 S3 엔드포인트 정책을 생성합니다.\", \"A business requires that an Amazon S3 gateway endpoint accept traffic only from trusted buckets.\\nWhich approach should a solutions architect use in order to fulfill this requirement?\\n\\nA.Create a bucket policy for each of the company's trusted S3 buckets that allows traffic only from the company's trusted VPCs.\\nB. Create a bucket policy for each of the company's trusted S3 buckets that allows traffic only from the company's S3 gateway endpoint IDs.\\nC. Create an S3 endpoint policy for each of the company's S3 gateway endpoints that blocks access from any VPC other than the company's trusted VPCs.\\nD. Create an S3 endpoint policy for each of the company's S3 gateway endpoints that provides access to the Amazon Resource Name (ARN) of the trusted S3 buckets.\", \"D. B는 엔드포인트가 아닌 S3 버킷에 대한 정책입니다. A, C는 VPC 외부로 인해 올 수 없습니다. 따라서 D\"],\n[\"비즈니스에서 Amazon Web Services(AWS)에 데이터 레이크를 배포하는 과정에 있습니다. 솔루션 설계자는 전송 및 저장 데이터에 대한 암호화 접근 방식을 설명해야 합니다. Amazon S3/ 회사의 보안 정책에 다음과 같이 명시되어 있습니다.\\n✑ 90일마다 키를 교체해야 합니다.\\n✑ 핵심 사용자와 핵심 관리자의 업무를 엄격하게 분리해야 합니다.\\n✑ 키 사용에 대한 감사가 가능해야 합니다.\\n어떤 솔루션 아키텍트가 권장해야 합니까?\\n\\nA.고객 관리형 고객 마스터 키(CMK)를 사용한 AWS KMS 관리형 키(SSE-KMS)를 사용한 서버 측 암호화\\nB. AWS 관리형 고객 마스터 키(CMK)를 사용한 AWS KMS 관리형 키(SSE-KMS)를 사용한 서버 측 암호화\\nC. 고객 관리형 고객 마스터 키(CMK)를 사용한 Amazon S3 관리형 키(SSE-S3)를 사용한 서버 측 암호화\\nD. AWS 관리형 고객 마스터 키(CMK)를 사용한 Amazon S3 관리형 키(SSE-S3)를 사용한 서버 측 암호화\", \"A business is in the process of deploying a data lake on Amazon Web Services (AWS). An architect of solutions must describe the encryption approach for data in transit and at rest. Amazon S3/ The following is stated in the company's security policy:\\n✑ Keys must be rotated every 90 days.\\n✑ Strict separation of duties between key users and key administrators must be implemented.\\n✑ Auditing key usage must be possible.\\nWhat solutions architect recommendations should be made?\\n\\nA.Server-side encryption with AWS KMS managed keys (SSE-KMS) with customer managed customer master keys (CMKs)\\nB. Server-side encryption with AWS KMS managed keys (SSE-KMS) with AWS managed customer master keys (CMKs)\\nC. Server-side encryption with Amazon S3 managed keys (SSE-S3) with customer managed customer master keys (CMKs)\\nD. Server-side encryption with Amazon S3 managed keys (SSE-S3) with AWS managed customer master keys (CMKs)\", \"A. 키 감사를 위해 SSE-KMS, 90일마다 교체 하기 위해 고객 관리형 키\"],\n[\"기업은 Amazon Elastic Container Service(Amazon ECS)를 활용하여 애플리케이션을 호스팅하고 고가용성을 보장하고자 합니다. 비즈니스는 한 가용 영역의 노드를 사용할 수 없는 경우에도 애플리케이션을 업데이트할 수 있어야 합니다.\\n애플리케이션은 초당 100개의 요청을 받을 것으로 예상되며 각 컨테이너 작업은 초당 최소 60개의 요청을 처리할 수 있습니다. 조직은 최소 정상 백분율 파라미터가 50%로 설정되고 최대 정상 백분율 파라미터가 100%로 설정된 롤링 업데이트 배포 모드를 사용하도록 Amazon ECS를 구성했습니다.\\n이러한 요구 사항을 충족하는 작업 및 가용 영역 구성은 무엇입니까?\\n\\nA.각 가용 영역에 하나의 작업을 사용하여 2개의 가용 영역에 애플리케이션을 배포합니다.\\nB. 각 가용 영역에 2개의 작업이 있는 2개의 가용 영역에 애플리케이션을 배포합니다.\\nC. 각 가용 영역에 하나의 작업으로 3개의 가용 영역에 애플리케이션을 배포합니다.\\nD. 각 가용 영역에 2개의 작업이 있는 3개의 가용 영역에 애플리케이션을 배포합니다.\", \"A business is utilizing Amazon Elastic Container Service (Amazon ECS) to host its application and want to assure high availability. The business needs to be able to update its application even if nodes in one Availability Zone are unavailable.\\nThe application is projected to get 100 requests per second, and each container job is capable of serving at least 60 requests per second. The organization configured Amazon ECS to use a rolling update deployment mode, with the minimum healthy percent parameter set to 50% and the maximum healthy percent parameter set to 100%.\\nWhich task and availability zone configurations satisfy these requirements?\\n\\nA.Deploy the application across two Availability Zones, with one task in each Availability Zone.\\nB. Deploy the application across two Availability Zones, with two tasks in each Availability Zone.\\nC. Deploy the application across three Availability Zones, with one task in each Availability Zone.\\nD. Deploy the application across three Availability Zones, with two tasks in each Availability Zone.\", \"D\"],\n[\"보안 팀은 90일마다 모든 IAM 사용자의 액세스 키를 교체해야 합니다. 액세스 키가 오래된 것으로 발견되면 비활성화해야 합니다.\\n제거되었습니다. 솔루션 설계자는 90일 이상 된 키를 감지하고 수정할 솔루션을 설계해야 합니다.\\n최소한의 운영 노력으로 이러한 기준을 충족하는 솔루션은 무엇입니까?\\n\\nA.AWS Config 규칙을 생성하여 키 수명을 확인합니다. AWS Batch 작업을 실행하여 키를 제거하도록 AWS Config 규칙을 구성합니다.\\nB. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 키 수명을 확인합니다. AWS Batch 작업을 실행하여 키를 제거하도록 규칙을 구성합니다.\\nC. 키 사용 기간을 확인하는 AWS Config 규칙을 생성합니다. 키를 제거하도록 AWS Lambda 함수를 예약하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 정의합니다.\\nD. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 키 수명을 확인합니다. AWS Batch 작업을 실행하여 키를 제거하는 EventBridge(CloudWatch 이벤트) 규칙을 정의합니다.\", \"Every 90 days, a security team must enforce the rotation of all IAM users' access keys. If an access key is discovered to be out of date, it must be rendered inactive.\\nand eliminated. A solutions architect must design a solution that will detect and remediate keys that are more than 90 days old.\\nWhich solution satisfies these criteria with the LEAST amount of operational effort?\\n\\nA.Create an AWS Config rule to check for the key age. Configure the AWS Config rule to run an AWS Batch job to remove the key.\\nB. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to check for the key age. Configure the rule to run an AWS Batch job to remove the key.\\nC. Create an AWS Config rule to check for the key age. Define an Amazon EventBridge (Amazon CloudWatch Events) rule to schedule an AWS Lambda function to remove the key.\\nD. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to check for the key age. Define an EventBridge (CloudWatch Events) rule to run an AWS Batch job to remove the key.\", \"C\"],\n[\"금융 서비스 조직은 미국과 유럽의 사용자가 액세스할 수 있는 웹 응용 프로그램을 유지 관리합니다. 프로그램은 데이터베이스 계층과 웹 서버 계층의 두 계층으로 나뉩니다. 데이터베이스 계층은 물리적으로 us-east-1에 위치한 MySQL 데이터베이스로 구성됩니다. Amazon Route 53 지리 근접 라우팅은 가장 가까운 리전의 인스턴스로 트래픽을 라우팅하는 데 사용됩니다. 시스템 성능 분석에 따르면 유럽 사용자는 미국 사용자와 동일한 수준의 쿼리 성능을 얻지 못하고 있습니다.\\n성능을 향상시키려면 데이터베이스 계층에서 어떤 개선이 이루어져야 합니까?\\n\\nA.데이터베이스를 Amazon RDS for MySQL로 마이그레이션합니다. 유럽 ​​리전 중 하나에서 다중 AZ를 구성합니다.\\nB. 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다. DynamoDB 전역 테이블을 사용하여 추가 리전에 복제할 수 있습니다.\\nC. 각 리전에 MySQL 인스턴스를 배포합니다. 기본 인스턴스의 로드를 줄이기 위해 MySQL 앞에 Application Load Balancer를 배포합니다.\\nD. 데이터베이스를 MySQL 호환 모드에서 Amazon Aurora 글로벌 데이터베이스로 마이그레이션합니다. 유럽 ​​리전 중 하나에서 읽기 전용 복제본을 구성합니다.\", \"A financial services organization maintains a web application that is accessible to users in the United States and Europe. The program is divided into two tiers: a database layer and a web server layer. The database tier is comprised of a MySQL database that is physically located in us-east-1. Amazon Route 53 geoproximity routing is used to route traffic to the nearest Region's instances. According to a performance analysis of the system, European users are not obtaining the same degree of query performance as users in the United States.\\nWhich improvements to the database layer should be made to increase performance?\\n\\nA.Migrate the database to Amazon RDS for MySQL. Configure Multi-AZ in one of the European Regions.\\nB. Migrate the database to Amazon DynamoDB. Use DynamoDB global tables to enable replication to additional Regions.\\nC. Deploy MySQL instances in each Region. Deploy an Application Load Balancer in front of MySQL to reduce the load on the primary instance.\\nD. Migrate the database to an Amazon Aurora global database in MySQL compatibility mode. Configure read replicas in one of the European Regions.\", \"D\"],\n[\"솔루션 설계자는 원래 웹 사이트에 액세스할 수 없는 경우 고객을 백업 정적 오류 페이지로 안내하는 솔루션을 개발하고 있습니다. 주요 웹사이트의 DNS 레코드는 Amazon Route 53에 보관되며 도메인은 ALB(Application Load Balancer)를 참조합니다.\\n수정 및 인프라 오버헤드를 줄이면서 비즈니스 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 구성을 사용해야 합니까?\\n\\nA.Route 53 별칭 레코드가 ALB를 오리진 중 하나로 사용하는 Amazon CloudFront 배포를 가리키도록 합니다. 그런 다음 배포에 대한 사용자 지정 오류 페이지를 만듭니다.\\nB. Route 53 활성-수동 장애 조치 구성을 설정합니다. Route 53 상태 확인에서 ALB 엔드포인트가 비정상임을 확인하면 Amazon S3 버킷 내에서 호스팅되는 정적 오류 페이지로 트래픽을 보냅니다.\\nC. 지연 기반 라우팅 정책을 사용하도록 Route 53 레코드를 업데이트합니다. 트래픽이 가장 응답성이 뛰어난 엔드포인트로 전송되도록 Amazon S3 버킷 내에서 호스팅되는 백업 정적 오류 페이지를 레코드에 추가합니다.\\nD. ALB와 정적 오류 페이지를 호스팅하는 Amazon EC2 인스턴스를 엔드포인트로 사용하여 Route 53 활성-활성 구성을 설정합니다. Route 53은 ALB에 대한 상태 확인이 실패한 경우에만 인스턴스에 요청을 보냅니다.\", \"A solutions architect is developing a solution that will lead customers to a backup static error page in the event that the original website becomes inaccessible. The DNS records for the major website are housed on Amazon Route 53, with the domain referring to an Application Load Balancer (ALB).\\nWhich configuration should the solutions architect use in order to fulfill the business's requirements while reducing modifications and infrastructure overhead?\\n\\nA.Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins. Then, create custom error pages for the distribution.\\nB. Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.\\nC. Update the Route 53 record to use a latency-based routing policy. Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints.\\nD. Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints. Route 53 will only send requests to the instance if the health checks fail for the ALB.\", \"B\"],\n[\"기업은 가장 최근 청구서에서 Amazon EC2의 비용 상승을 확인했습니다. 결제 팀은 몇 가지 EC2 인스턴스에 대한 인스턴스 유형의 수직적 확장에서 비정상을 관찰했습니다. 솔루션 설계자는 지난 2개월 동안의 EC2 요금을 비교하는 그래프를 작성하고 심층 연구를 수행하여 수직적 확장의 핵심 원인을 파악해야 합니다.\\n솔루션 설계자는 가능한 한 최소한의 운영 오버헤드로 데이터를 생성해야 합니까?\\n\\nA.AWS 예산을 사용하여 예산 보고서를 생성하고 인스턴스 유형에 따라 EC2 비용을 비교합니다.\\nB. Cost Explorer의 세분화된 필터링 기능을 사용하여 인스턴스 유형을 기반으로 EC2 비용에 대한 심층 분석을 수행합니다.\\nC. AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2개월 동안의 인스턴스 유형을 기준으로 EC2 비용을 비교합니다.\\nD. AWS 비용 및 사용 보고서를 사용하여 보고서를 생성하고 Amazon S3 버킷으로 보냅니다. Amazon S3와 함께 Amazon QuickSight를 소스로 사용하여 인스턴스 유형을 기반으로 대화형 그래프를 생성합니다.\", \"A business notices a rise in the cost of Amazon EC2 in its most recent bill. The billing team observes an anomaly in the vertical scaling of instance types for a few EC2 instances. A solutions architect should build a graph comparing the previous two months' EC2 charges and conduct an in-depth study to determine the core cause of the vertical scaling.\\nHow should the solutions architect create data with the LEAST amount of operational overhead possible?\\n\\nA.Use AWS Budgets to create a budget report and compare EC2 costs based on instance types.\\nB. Use Cost Explorer's granular filtering feature to perform an in-depth analysis of EC2 costs based on instance types.\\nC. Use graphs from the AWS Billing and Cost Management dashboard to compare EC2 costs based on instance types for the last 2 months.\\nD. Use AWS Cost and Usage Reports to create a report and send it to an Amazon S3 bucket. Use Amazon QuickSight with Amazon S3 as a source to generate an interactive graph based on instance types.\", \"B\"],\n[\"AWS에서 비즈니스는 온라인 마켓플레이스 웹 애플리케이션을 호스팅합니다. 피크 시간 동안 이 프로그램은 수십만 명의 사용자에게 서비스를 제공합니다. 비즈니스에는 다양한 내부 시스템과 수백만 건의 금융 거래에 대한 정보를 공유하기 위한 확장 가능한 거의 실시간 솔루션이 필요합니다. 또한 빠른 검색을 위해 문서 데이터베이스에 저장하기 전에 민감한 데이터를 제거하기 위해 트랜잭션을 처리해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 권장 사항을 제시해야 합니까?\\n\\nA.트랜잭션 데이터를 Amazon DynamoDB에 저장합니다. 쓰기 시 모든 트랜잭션에서 중요한 데이터를 제거하도록 DynamoDB에서 규칙을 설정합니다. DynamoDB 스트림을 사용하여 다른 애플리케이션과 트랜잭션 데이터를 공유합니다.\\nB. 트랜잭션 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB 및 Amazon S3에 데이터를 저장합니다. Kinesis Data Firehose와 AWS Lambda 통합을 사용하여 민감한 데이터를 제거하십시오. 다른 애플리케이션은 Amazon S3에 저장된 데이터를 사용할 수 있습니다.\\nC. 트랜잭션 데이터를 Amazon Kinesis Data Streams로 스트리밍합니다. AWS Lambda 통합을 사용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 AmazonDynamoDB에 트랜잭션 데이터를 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림의 트랜잭션 데이터를 사용할 수 있습니다.\\nD. 일괄 처리된 트랜잭션 데이터를 Amazon S3에 파일로 저장합니다. Amazon S3에서 파일을 업데이트하기 전에 AWS Lambda를 사용하여 모든 파일을 처리하고 민감한 데이터를 제거하십시오. 그러면 Lambda 함수가 Amazon DynamoDB에 데이터를 저장합니다. 다른 애플리케이션은 Amazon S3에 저장된 트랜잭션 파일을 사용할 수 있습니다.\", \"On AWS, a business hosts an online marketplace web application. During peak hours, the program serves hundreds of thousands of users. The business requires a scalable, near-real-time solution for sharing information about millions of financial transactions with various other internal systems. Additionally, transactions must be processed to remove sensitive data prior to being stored in a document database for fast retrieval.\\nWhat recommendations should a solutions architect make to satisfy these requirements?\\n\\nA.Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications.\\nB. Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3.\\nC. Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in AmazonDynamoDB. Other applications can consume the transactions data off the Kinesis data stream.\\nD. Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3.\", \"C\"],\n[\"한 기업이 Elastic Load Balancer의 도움으로 Amazon EC2 인스턴스에서 호스팅될 새로운 온라인 서비스를 개발 중입니다. 그러나 많은 온라인 서비스 클라이언트는 방화벽에 허용된 IP 주소와만 통신할 수 있습니다.\\n솔루션 설계자는 클라이언트의 요구 사항에 맞게 어떤 권장 사항을 제공해야 합니까?\\n\\nA.연결된 탄력적 IP 주소가 있는 Network Load Balancer.\\nB. 연결된 탄력적 IP 주소가 있는 Application Load Balancer\\nC. 탄력적 IP 주소를 가리키는 Amazon Route 53 호스팅 영역의 A 레코드\\nD. 로드 밸런서 앞에서 프록시로 실행되는 퍼블릭 IP 주소가 있는 EC2 인스턴스\", \"A business is developing a new online service that will be hosted on Amazon EC2 instances with the assistance of an Elastic Load Balancer. However, many online service clients can only communicate with IP addresses that have been whitelisted on their firewalls.\\nWhat recommendations should a solutions architect provide to suit a client's needs?\\n\\nA.A Network Load Balancer with an associated Elastic IP address.\\nB. An Application Load Balancer with an associated Elastic IP address\\nC. An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address\\nD. An EC2 instance with a public IP address running as a proxy in front of the load balancer\", \"A\"],\n[\"비즈니스에는 여러 부서에 대해 여러 AWS 계정이 있을 수 있습니다. 부서 중 하나는 Amazon S3 버킷을 나머지 조직과 공유하려고 합니다.\\n다음 솔루션 중 가장 적은 노력이 필요한 솔루션은 무엇입니까?\\n\\nA.버킷에 대해 교차 계정 S3 복제를 활성화합니다.\\nB. 버킷에 대해 미리 서명된 URL을 생성하고 다른 부서와 공유합니다.\\nC. 다른 부서에 대한 교차 계정 액세스를 허용하도록 S3 버킷 정책을 설정합니다.\\nD. 각 부서에 대한 IAM 사용자를 생성하고 읽기 전용 IAM 정책을 구성합니다.\", \"A business may have many AWS accounts for different departments. One of the departments would want to share an Amazon S3 bucket with the rest of the organization.\\nWhich of the following solutions requires the LEAST amount of effort?\\n\\nA.Enable cross-account S3 replication for the bucket.\\nB. Create a pre-signed URL for the bucket and share it with other departments.\\nC. Set the S3 bucket policy to allow cross-account access to other departments.\\nD. Create IAM users for each of the departments and configure a read-only IAM policy.\", \"C\"],\n[\"기업은 Amazon Elastic Block Store(Amazon EBS) 볼륨에 사용자 업로드 문서를 저장하는 단일 Amazon EC2 인스턴스를 사용하여 Amazon Web Services(AWS)에서 웹 애플리케이션을 호스팅합니다. 확장성과 가용성을 개선하기 위해 조직은 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 배포했습니다. 이 두 가지 모두 Application Load Balancer 뒤에 배치되었습니다. 이 업데이트가 이루어진 후 사용자는 페이지를 새로 고칠 때마다 논문의 일부를 볼 수 있지만 전체를 볼 수는 없다고 주장했습니다.\\n솔루션 설계자는 사용자가 모든 문서에 동시에 액세스할 수 있도록 보장하기 위해 무엇을 제안해야 합니까?\\n\\nA.두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다.\\nB. 문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer를 구성합니다.\\nC. 두 EBS 볼륨의 데이터를 Amazon Elastic File System(Amazon EFS)으로 복사합니다. 새 문서를 Amazon Elastic File System(Amazon EFS)에 저장하도록 애플리케이션을 수정합니다.\\nD. 두 서버 모두에 요청을 보내도록 Application Load Balancer를 구성합니다. 올바른 서버에서 각 문서를 반환하십시오.\", \"A business hosts a web application on Amazon Web Services (AWS) utilizing a single Amazon EC2 instance that saves user-uploaded documents in an Amazon Elastic Block Store (Amazon EBS) volume. To improve scalability and availability, the organization replicated the architecture and deployed a second EC2 instance and EBS volume in a different Availability Zone, both of which were placed behind an Application Load Balancer. After this update was made, users claimed that each time they refreshed the page, they could view a portion of their papers but never all of them.\\nWhat should a solutions architect suggest to guarantee that users have access to all of their documents simultaneously?\\n\\nA.Copy the data so both EBS volumes contain all the documents.\\nB. Configure the Application Load Balancer to direct a user to the server with the documents.\\nC. Copy the data from both EBS volumes to Amazon Elastic File System (Amazon EFS). Modify the application to save new documents to Amazon Elastic File System (Amazon EFS).\\nD. Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server.\", \"C\"],\n[\"솔루션 설계자는 많은 Amazon EC2 인스턴스에 분산 데이터베이스를 구현하는 과정에 있습니다. 데이터베이스는 단일 인스턴스의 손실을 견딜 수 있도록 수많은 인스턴스에 걸쳐 모든 데이터를 복제합니다. 데이터베이스는 서버당 초당 수백만 건의 트랜잭션을 수용하기 위해 대기 시간이 짧고 처리량이 높은 블록 스토리지가 필요합니다.\\n솔루션 설계자는 어떤 스토리지 옵션을 사용해야 합니까?\\n\\nA.EBS Amazon Elastic Block Store(Amazon EBS)\\nB. Amazon EC2 인스턴스 스토어\\nC. Amazon Elastic File System(Amazon EFS)\\nD. 아마존 S3\", \"A business hosts a web application on Amazon Web Services (AWS) utilizing a single Amazon EC2 instance that saves user-uploaded documents in an Amazon Elastic Block Store (Amazon EBS) volume. To improve scalability and availability, the organization replicated the architecture and deployed a second EC2 instance and EBS volume in a different Availability Zone, both of which were placed behind an Application Load Balancer. After this update was made, users claimed that each time they refreshed the page, they could view a portion of their papers but never all of them.\\nWhat should a solutions architect suggest to guarantee that users have access to all of their documents simultaneously?\\n\\nA.Copy the data so both EBS volumes contain all the documents.\\nB. Configure the Application Load Balancer to direct a user to the server with the documents.\\nC. Copy the data from both EBS volumes to Amazon Elastic File System (Amazon EFS). Modify the application to save new documents to Amazon Elastic File System (Amazon EFS).\\nD. Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server.\", \"B\"],\n[\"3계층 웹 애플리케이션은 클라이언트 주문을 처리하는 데 사용됩니다. 웹 계층은 Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스, Amazon SQS를 통해 웹 계층에서 격리된 3개의 EC2 인스턴스로 구성된 중간 계층, Amazon DynamoDB 백엔드로 구성됩니다. 성수기에는 사이트를 통해 구매하는 소비자가 처리 지연이 길어 평소보다 훨씬 더 오래 기다려야 합니다. 솔루션 설계자의 목표는 이러한 처리 시간을 최소화하는 것입니다.\\n이를 달성하는 데 가장 효과적인 조치는 무엇입니까?\\n\\nA.SQS 대기열을 Amazon Kinesis Data Firehose로 교체합니다.\\nB. DynamoDB 백엔드 계층 앞에서 ​​Redis용 Amazon ElastiCache를 사용합니다.\\nC. Amazon CloudFront 배포를 추가하여 웹 계층에 대한 응답을 캐시합니다.\\nD. Amazon EC2 Auto Scaling을 사용하여 SQS 대기열 깊이를 기반으로 중간 계층 인스턴스를 확장합니다.\", \"A three-tier web application is used to handle client orders. The web tier is made up of Amazon EC2 instances behind an Application Load Balancer, a middle tier made up of three EC2 instances that are isolated from the web layer through Amazon SQS, and an Amazon DynamoDB backend. During busy periods, consumers who place purchases through the site must wait much longer than usual for confirmations owing to prolonged processing delays. A solutions architect's objective should be to minimize these processing times.\\nWhich course of action will be the MOST EFFECTIVE in achieving this?\\n\\nA.Replace the SQS queue with Amazon Kinesis Data Firehose.\\nB. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier.\\nC. Add an Amazon CloudFront distribution to cache the responses for the web tier.\\nD. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SQS queue depth.\", \"D\"],\n[\"솔루션 설계자는 버전 관리가 활성화된 Amazon S3에서 호스팅되는 웹 사이트를 자주 수정해야 하는 솔루션을 개발하고 있습니다. 규정 준수 요구 사항으로 인해 이전 버전의 개체는 거의 액세스되지 않으며 2년 후에는 제거해야 합니다.\\n솔루션 설계자는 이러한 요구 사항을 달성하기 위한 가장 저렴한 방법으로 무엇을 제안해야 합니까?\\n\\nA.S3 일괄 작업을 사용하여 객체 태그를 교체합니다. 수정된 태그를 기반으로 개체를 만료합니다.\\nB. 이전 버전의 객체를 S3 Glacier로 전환하도록 S3 수명 주기 정책을 구성합니다. 2년 후에 객체를 만료합니다.\\nC. 추가 처리를 위해 이전 객체를 Amazon Simple Queue Service(Amazon SQS) 대기열로 보내는 버킷에서 S3 이벤트 알림을 활성화합니다.\\nD. 이전 객체 버전을 새 버킷에 복제합니다. S3 수명 주기 정책을 사용하여 2년 후에 새 버킷의 객체를 만료시킵니다.\", \"A solutions architect is developing a solution that will need frequent modifications to a website hosted on Amazon S3 with versioning enabled. Due to compliance requirements, older versions of the objects will be seldom accessed and will need to be removed after two years.\\nWhat should the solutions architect propose as the CHEAPEST way to achieve these requirements?\\n\\nA.Use S3 batch operations to replace object tags. Expire the objects based on the modified tags.\\nB. Configure an S3 Lifecycle policy to transition older versions of objects to S3 Glacier. Expire the objects after 2 years.\\nC. Enable S3 Event Notifications on the bucket that sends older objects to the Amazon Simple Queue Service (Amazon SQS) queue for further processing.\\nD. Replicate older object versions to a new bucket. Use an S3 Lifecycle policy to expire the objects in the new bucket after 2 years.\", \"B\"],\n[\"솔루션 설계자는 Amazon EC2 인스턴스에서 호스팅되고 ALB(Application Load Balancer)에서 관리할 웹 애플리케이션을 개발하고 있습니다. 조직은 적대적인 인터넷 활동 및 공격에 대한 애플리케이션의 복원력과 새로 발견된 취약점 및 노출에 대한 보호에 높은 가치를 두고 있습니다.\\n솔루션 설계자는 어떤 권장 사항을 제시해야 합니까?\\n\\nA.ALB 엔드포인트를 오리진으로 사용하여 Amazon CloudFront를 활용합니다.\\nB. AWS WAF에 대한 적절한 관리형 규칙을 배포하고 ALB와 연결합니다.\\nC. AWS Shield Advanced에 가입하고 일반적인 취약점과 노출을 차단합니다.\\nD. 포트 80 및 443만 EC2 인스턴스에 액세스할 수 있도록 네트워크 ACL 및 보안 그룹을 구성합니다.\", \"A solutions architect is developing a web application that will be hosted on Amazon EC2 instances and managed by an Application Load Balancer (ALB). The organization places a high premium on the application's resilience to hostile internet activities and assaults, as well as its protection against newly discovered vulnerabilities and exposures.\\nWhat recommendations should the solutions architect make?\\n\\nA.Leverage Amazon CloudFront with the ALB endpoint as the origin.\\nB. Deploy an appropriate managed rule for AWS WAF and associate it with the ALB.\\nC. Subscribe to AWS Shield Advanced and ensure common vulnerabilities and exposures are blocked.\\nD. Configure network ACLs and security groups to allow only ports 80 and 443 to access the EC2 instances.\", \"C. Shield Advanced에는 WAF가 포함되어 있음.\"],\n[\"비즈니스에서 온라인 애플리케이션을 Amazon Web Services(AWS)로 전환하려고 합니다. 클래식 웹 응용 프로그램은 웹 계층, 응용 프로그램 계층 및 MySQL 데이터베이스의 세 가지 계층으로 나뉩니다. 재설계된 애플리케이션은 관리 팀이 인스턴스 또는 클러스터를 관리할 필요가 없도록 하는 기술을 사용하여 구축해야 합니다.\\n솔루션 아키텍트가 전체 아키텍처에 포함해야 하는 서비스 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.Amazon Aurora 서버리스\\nB. Amazon EC2 스팟 인스턴스\\nC. Amazon Elasticsearch Service(Amazon ES)\\nD. MySQL용 Amazon RDS\\nE. AWS Fargate\", \"A business wishes to transition its online application to Amazon Web Services (AWS). The classic web application is divided into three tiers: the web layer, the application tier, and the MySQL database. The rearchitected application must be built using technologies that eliminate the need for the administration team to manage instances or clusters.\\nWhich service combination should a solution architect include into the overall architecture? (Select two.)\\n\\nA.Amazon Aurora Serverless\\nB. Amazon EC2 Spot Instances\\nC. Amazon Elasticsearch Service (Amazon ES)\\nD. Amazon RDS for MySQL\\nE. AWS Fargate\", \"A, E\"],\n[\"솔루션 설계자는 일반적인 보안 제한을 유지하면서 AWS Organizations를 통해 개별 AWS 계정을 개발자에게 제공하려는 회사를 위한 보안 솔루션을 개발하고 있습니다. 개별 개발자는 자신의 AWS 계정에 대한 루트 사용자 액세스 권한을 갖기 때문에 솔루션 설계자는 새 개발자 계정에 배포된 필수 AWS CloudTrail 구성이 업데이트되지 않았는지 확인해야 합니다.\\n이 기준을 충족하는 활동은 무엇입니까?\\n\\nA.CloudTrail에 대한 변경을 금지하는 IAM 정책을 생성하고 이를 루트 사용자에게 연결합니다.\\nB. 조직 추적 옵션이 활성화된 개발자 계정 내에서 CloudTrail에 새 추적을 생성합니다.\\nC. CloudTrail 변경을 금지하는 SCP(서비스 제어 정책)를 만들고 개발자 계정에 연결합니다.\\nD. 마스터 계정의 Amazon 리소스 이름(ARN) 변경만 허용하는 정책 조건으로 CloudTrail에 대한 서비스 연결 역할을 생성합니다.\", \"A solutions architect is developing a security solution for a firm that want to deliver individual AWS accounts to developers through AWS Organizations while retaining normal security restrictions. Due to the fact that individual developers will have root user access to their own AWS accounts, the solutions architect needs to verify that the obligatory AWS CloudTrail configuration deployed to new developer accounts is not updated.\\nWhich activity satisfies these criteria?\\n\\nA.Create an IAM policy that prohibits changes to CloudTrail, and attach it to the root user.\\nB. Create a new trail in CloudTrail from within the developer accounts with the organization trails option enabled.\\nC. Create a service control policy (SCP) the prohibits changes to CloudTrail, and attach it the developer accounts.\\nD. Create a service-linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the master account.\", \"C\"],\n[\"솔루션 설계자가 새로 전송된 워크로드의 보안을 검토하고 있습니다. 워크로드는 Auto Scaling 그룹의 일부인 Amazon EC2 인스턴스로 구성되고 Application Load Balancer를 통해 라우팅되는 웹 애플리케이션입니다. 솔루션 설계자는 보안 태세를 강화하고 DDoS 공격의 리소스 영향을 완화해야 합니다.\\n다음 중 가장 효과적인 솔루션은 무엇입니까?\\n\\nA.요금 기반 규칙을 사용하여 AWS WAF ACL을 구성합니다. Application Load Balancer를 가리키는 Amazon CloudFront 배포를 생성합니다. CloudFront 배포에서 WAF ACL을 활성화합니다.\\nB. 식별된 공격을 공통 취약성 풀에 추가하여 잠재적인 DDoS 공격을 포착하는 사용자 지정 AWS Lambda 함수를 생성합니다. 식별된 정보를 사용하여 액세스를 차단하도록 네트워크 ACL을 수정합니다.\\nC. VPC 흐름 로그를 활성화하고 Amazon S3에 저장합니다. DDoS 공격을 찾는 로그를 구문 분석하는 사용자 지정 AWS Lambda 함수를 생성합니다. 식별된 소스 IP 주소를 차단하도록 네트워크 ACL을 수정합니다.\\nD. Amazon GuardDuty를 활성화하고 Amazon CloudWatch에 기록된 결과를 구성합니다. Amazon Simple Notification Service(Amazon SNS)를 트리거하는 DDoS 알림에 대한 CloudWatch 이벤트를 사용하여 이벤트를 생성합니다. Amazon SNS가 로그를 구문 분석하는 사용자 지정 AWS Lambda 함수를 호출하여 DDoS 공격을 찾도록 합니다. 식별된 소스 IP 주소를 차단하도록 네트워크 ACL을 수정합니다.\", \"A solutions architect is reviewing the security of a newly transferred workload. The workload is a web application that is composed of Amazon EC2 instances that are part of an Auto Scaling group and are routed via an Application Load Balancer. The solutions architect must strengthen the security posture and mitigate the resource effect of a DDoS assault.\\nWhich of the following solutions is the MOST EFFECTIVE?\\n\\nA.Configure an AWS WAF ACL with rate-based rules. Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the WAF ACL on the CloudFront distribution.\\nB. Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. Use the identified information to modify a network ACL to block access.\\nC. Enable VPC Flow Logs and store then in Amazon S3. Create a custom AWS Lambda functions that parses the logs looking for a DDoS attack. Modify a network ACL to block identified source IP addresses.\\nD. Enable Amazon GuardDuty and configure findings written to Amazon CloudWatch. Create an event with CloudWatch Events for DDoS alerts that triggers Amazon Simple Notification Service (Amazon SNS). Have Amazon SNS invoke a custom AWS Lambda function that parses the logs, looking for a DDoS attack. Modify a network ACL to block identified source IP addresses.\", \"A\"],\n[\"한 비즈니스에서 로드 밸런싱된 프런트 엔드, 컨테이너 기반 응용 프로그램 및 관계형 데이터베이스가 있는 전자 상거래 솔루션을 구축하고 있습니다. 솔루션 설계자는 사람의 개입이 거의 필요하지 않은 접근성이 높은 시스템을 설계해야 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까? (2개를 선택하세요.)\\n\\nA.다중 AZ 모드에서 Amazon RDS DB 인스턴스를 생성합니다.\\nB. 다른 가용 영역에 Amazon RDS DB 인스턴스와 하나 이상의 복제본을 생성합니다.\\nC. 동적 애플리케이션 로드를 처리할 Amazon EC2 인스턴스 기반 Docker 클러스터를 생성합니다.\\nD. Fargate 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성하여 동적 애플리케이션 로드를 처리합니다.\\nE. 동적 애플리케이션 로드를 처리하기 위해 Amazon EC2 시작 유형으로 Amazon Elastic Container Service(Amazon ECS) 클러스터를 생성합니다.\", \"A business is building an ecommerce solution that will have a load-balanced front end, a container-based application, and a relational database. A solutions architect must design a highly accessible system that requires little human intervention.\\nWhich solutions satisfy these criteria? (Select two.)\\n\\nA.Create an Amazon RDS DB instance in Multi-AZ mode.\\nB. Create an Amazon RDS DB instance and one or more replicas in another Availability Zone.\\nC. Create an Amazon EC2 instance-based Docker cluster to handle the dynamic application load.\\nD. Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load.\\nE. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load.\", \"A, D. 다중 AZ는 고가용성을 위해 읽기 전용 복제본보다 사람의 개입이 덜 필요합니다.\"],\n[\"기업은 단일 가용 영역과 Amazon RDS 다중 AZ 데이터베이스 인스턴스에서 Amazon EC2를 사용하여 상태 비저장 2계층 애플리케이션을 생성했습니다. 조직의 새 관리는 응용 프로그램의 액세스 가능성을 높이려고 합니다.\\n이 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까?\\n\\nA.다중 AZ EC2 Auto Scaling을 사용하도록 애플리케이션을 구성하고 Application Load Balancer를 생성합니다.\\nB. EC2 인스턴스의 스냅샷을 생성하여 다른 AWS 리전으로 보내도록 애플리케이션을 구성합니다.\\nC. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 애플리케이션에 요청을 제공하도록 애플리케이션을 구성합니다.\\nD. 수신 요청을 처리하고 다중 AZ 애플리케이션 로드 밸런서를 생성하도록 Amazon Route 53 규칙을 구성합니다.\", \"A business created a stateless two-tier application using Amazon EC2 in a single Availability Zone and an Amazon RDS Multi-AZ database instance. The new administration of the organization wants to guarantee that the application is highly accessible.\\nWhat actions should a solutions architect do in order to satisfy this requirement?\\n\\nA.Configure the application to use Multi-AZ EC2 Auto Scaling and create an Application Load Balancer.\\nB. Configure the application to take snapshots of the EC2 instances and send them to a different AWS Region.\\nC. Configure the application to use Amazon Route 53 latency-based routing to feed requests to the application.\\nD. Configure Amazon Route 53 rules to handle incoming requests and create a Multi-AZ Application Load Balancer.\", \"A\"],\n[\"기업은 다양한 온프레미스 애플리케이션에서 활용되는 온프레미스 데이터 센터에서 데이터를 유지 관리합니다. 조직은 데이터 분석 및 향후 시각화를 위해 AWS 서비스를 사용하면서 현재 애플리케이션 환경을 유지하기를 원합니다.\\n솔루션 설계자가 고객에게 제안해야 하는 스토리지 서비스는 무엇입니까?\\n\\nA.아마존 레드시프트\\nB. 파일용 AWS Storage Gateway\\nC. Amazon Elastic Block Store(Amazon EBS)\\nD. Amazon Elastic File System(Amazon EFS)\", \"A business maintains data in an on-premises data center, which is utilized by a variety of on-premises applications. The organization wishes to preserve its current application environment while using AWS services for data analytics and future visualizations.\\nWhich storage service should a solutions architect propose to his or her clients?\\n\\nA.Amazon Redshift\\nB. AWS Storage Gateway for files\\nC. Amazon Elastic Block Store (Amazon EBS)\\nD. Amazon Elastic File System (Amazon EFS)\", \"B\"],\n[\"기업은 온프레미스 데이터 센터에서 Amazon Web Services(AWS)로 상용 기성 애플리케이션을 마이그레이션하는 것을 고려하고 있습니다. 소프트웨어는 예측 가능한 용량 및 가동 시간 요구 사항과 함께 소켓 및 코어 단위로 라이선스가 부여됩니다. 회사는 올해 초에 취득한 현재 라이선스를 계속 사용하기를 원합니다.\\n가장 비용 효율적인 Amazon EC2 가격 옵션은 무엇입니까?\\n\\nA.전용 예약 호스트\\nB. 전용 온디맨드 호스트\\nC. 전용 예약 인스턴스\\nD. 전용 온디맨드 인스턴스\", \"A business is considering migrating a commercial off-the-shelf application from its on-premises data center to Amazon Web Services (AWS). The software is licensed on a per-socket and per-core basis, with predictable capacity and uptime requirements. The corporation wants to continue using its current licenses, which were acquired earlier this year.\\nWhich price option for Amazon EC2 is the MOST cost-effective?\\n\\nA.Dedicated Reserved Hosts\\nB. Dedicated On-Demand Hosts\\nC. Dedicated Reserved Instances\\nD. Dedicated On-Demand Instances\", \"A. EC2 전용 호스트를 사용하면 Amazon EC2에서 Microsoft 및 Oracle과 같은 공급업체의 적격 소프트웨어 라이선스를 사용할 수 있음. EC2 전용 호스트는 사용자 전용의 물리적 서버이므로 기업 규정 준수 요구 사항을 충족하는 데 도움\"],\n[\"한 회사에서 Amazon S3를 사용하여 많은 수의 사진을 저장할 웹 애플리케이션을 개발 중입니다. 사용자는 다양한 시간 동안 사진에 액세스할 수 있습니다. 기업은 다음을 원합니다.\\n✑ 모든 이미지를 보관합니다.\\n✑ 검색에 비용이 들지 않습니다.\\n✑ 최소한의 관리 오버헤드가 있습니다.\\n✑ 검색 시간에 영향을 주지 않고 이미지를 사용할 수 있도록 합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.S3 Intelligent-Tiering 구현\\nB. S3 스토리지 클래스 분석 구현\\nC. 데이터를 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동하는 S3 수명 주기 정책을 구현합니다.\\nD. 데이터를 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 이동하는 S3 수명 주기 정책을 구현합니다.\", \"A firm is developing a web application that will use Amazon S3 to store a big number of photos. Users will get access to the photographs for varying durations of time. The business wishes to:\\n✑ Retain all the images\\n✑ Incur no cost for retrieval.\\n✑ Have minimal management overhead.\\n✑ Have the images available with no impact on retrieval time.\\nWhich solution satisfies these criteria?\\n\\nA.Implement S3 Intelligent-Tiering\\nB. Implement S3 storage class analysis\\nC. Implement an S3 Lifecycle policy to move data to S3 Standard-Infrequent Access (S3 Standard-IA).\\nD. Implement an S3 Lifecycle policy to move data to S3 One Zone-Infrequent Access (S3 One Zone-IA).\", \"A. Intelligent-Tiering은 검색 요금이 없음.\"],\n[\"비즈니스에서 온라인 쇼핑 애플리케이션을 제공하고 모든 주문은 PostgreSQL용 Amazon RDS 단일 AZ 데이터베이스 인스턴스에 저장됩니다. 경영진은 단일 실패 지점을 제거하기를 원하며 솔루션 설계자에게 애플리케이션 코드를 수정하지 않고 데이터베이스 다운타임을 최소화하는 방법을 제공하도록 요청했습니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.데이터베이스 인스턴스를 수정하고 다중 AZ 옵션을 지정하여 기존 데이터베이스 인스턴스를 다중 AZ 배포로 변환합니다.\\nB. 새 RDS 다중 AZ 배포를 생성합니다. 현재 RDS 인스턴스의 스냅샷을 만들고 스냅샷으로 새 다중 AZ 배포를 복원합니다.\\nC. 다른 가용 영역에 PostgreSQL 데이터베이스의 읽기 전용 복제본을 생성합니다. Amazon Route 53 가중 레코드 세트를 사용하여 데이터베이스 전체에 요청을 분산합니다.\\nD. RDS for PostgreSQL 데이터베이스를 최소 그룹 크기가 2인 Amazon EC2 Auto Scaling 그룹에 배치합니다. Amazon Route 53 가중 레코드 세트를 사용하여 인스턴스 간에 요청을 분산합니다.\", \"A business offers an online shopping application and all orders are stored in an Amazon RDS for PostgreSQL Single-AZ database instance. Management want to remove single points of failure and has requested a solutions architect to offer a method for minimizing database downtime without modifying the application code.\\nWhich solution satisfies these criteria?\\n\\nA.Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option.\\nB. Create a new RDS Multi-AZ deployment. Take a snapshot of the current RDS instance and restore the new Multi-AZ deployment with the snapshot.\\nC. Create a read-only replica of the PostgreSQL database in another Availability Zone. Use Amazon Route 53 weighted record sets to distribute requests across the databases.\\nD. Place the RDS for PostgreSQL database in an Amazon EC2 Auto Scaling group with a minimum group size of two. Use Amazon Route 53 weighted record sets to distribute requests across instances.\", \"A\"],\n[\"주요 회사의 관리자는 회사의 AWS 계정에 대한 암호화폐 관련 공격을 모니터링하고 방지하려고 합니다.\\n관리자가 사이버 공격으로부터 조직을 보호하기 위해 사용할 수 있는 AWS 서비스는 무엇입니까?\\n\\nA.Amazon Cognito\\nB. Amazon GuardDuty\\nC. Amazon Inspector\\nD. Amazon Macie\", \"A major company's administrator want to monitor for and prevent cryptocurrency-related assaults on the company's AWS accounts.\\nWhich AWS service can the administrator use to safeguard the organization from cyberattacks?\\n\\nA.Amazon Cognito\\nB. Amazon GuardDuty\\nC. Amazon Inspector\\nD. Amazon Macie\", \"B. Guard Duty: 로그 분석 - Cloudtrail, VPC 흐름, DNS 로그 분석\"],\n[\"비즈니스에서 AWS의 기본 VPC에서 새로 개발된 애플리케이션을 시작하려고 합니다. 프로그램은 웹 계층과 데이터베이스 계층의 두 계층으로 나뉩니다. 웹 서버와 MySQL 데이터베이스는 퍼블릭 서브넷에 구축된 반면 웹 서버와 MySQL 데이터베이스는 프라이빗 서브넷에 구축되었습니다. 기본 네트워크 ACL 설정은 모든 서브넷을 구축하는 데 사용되며 VPC의 기본 보안 그룹은 새 사용자 지정 보안 그룹으로 대체됩니다.\\n중요한 기준은 다음과 같습니다.\\n✑ 웹 서버는 SSL 연결을 사용하는 사용자만 액세스할 수 있어야 합니다.\\n✑ 데이터베이스는 퍼블릭 서브넷에서만 생성되는 웹 레이어에 접근할 수 있어야 합니다.\\n✑ IP 범위 182.20.0.0/16 서브넷을 오가는 모든 트래픽을 차단해야 합니다.\\n이 기준을 충족하는 작업 조합은 무엇입니까? (2개를 선택하세요.)\\n\\nA.어디서든(0 0.0.0/0) 들어오고 나가는 MySQL 포트 3306 트래픽에 대한 인바운드 및 아웃바운드 규칙을 사용하여 데이터베이스 서버 보안 그룹을 만듭니다.\\nB. MySQL 포트 3306에 대한 인바운드 규칙을 사용하여 데이터베이스 서버 보안 그룹을 생성하고 소스를 웹 서버 보안 그룹으로 지정합니다.\\nC. 모든 곳(0.0.0.0/0)의 HTTPS 포트 443 트래픽에 대한 인바운드 허용 규칙과 IP 범위 182.20.0.0/16에 대한 인바운드 거부 규칙을 사용하여 웹 서버 보안 그룹을 만듭니다.\\nD. 어디서나(0.0.0.0/0) HTTPS 포트 443 트래픽에 대한 인바운드 규칙을 사용하여 웹 서버 보안 그룹을 만듭니다. IP 범위 182.20.0.0/16에 대한 네트워크 ACL 인바운드 및 아웃바운드 거부 규칙을 만듭니다.\\nE. 모든 곳(0.0.0.0/0)에서 들어오고 나가는 HTTPS 포트 443 트래픽에 대한 인바운드 및 아웃바운드 규칙을 사용하여 웹 서버 보안 그룹을 만듭니다. IP 범위 182.20.0.0/16에 대한 네트워크 ACL 인바운드 거부 규칙을 만듭니다.\", \"A business intends to launch a freshly developed application on AWS in a default VPC. The program will be divided into two layers: a web layer and a database layer. The web server and MySQL database were constructed in public subnets, whereas the web server and MySQL database were created in private subnets. The default network ACL settings are used to build all subnets, and the default security group in the VPC is replaced with new custom security groups.\\nThe critical criteria are as follows:\\n✑ The web servers must be accessible only to users on an SSL connection.\\n✑ The database should be accessible to the web layer, which is created in a public subnet only.\\n✑ All traffic to and from the IP range 182.20.0.0/16 subnet should be blocked.\\nWhich combination of actions satisfies these criteria? (Select two.)\\n\\nA.Create a database server security group with inbound and outbound rules for MySQL port 3306 traffic to and from anywhere (0 0.0.0/0).\\nB. Create a database server security group with an inbound rule for MySQL port 3306 and specify the source as a web server security group.\\nC. Create a web server security group with an inbound allow rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0) and an inbound deny rule for IP range 182.20.0.0/16.\\nD. Create a web server security group with an inbound rule for HTTPS port 443 traffic from anywhere (0.0.0.0/0). Create network ACL inbound and outbound deny rules for IP range 182.20.0.0/16.\\nE. Create a web server security group with inbound and outbound rules for HTTPS port 443 traffic to and from anywhere (0.0.0.0/0). Create a network ACL inbound deny rule for IP range 182.20.0.0/16.\", \"B, D\"],\n[\"기업은 하이브리드 애플리케이션의 가용성과 성능을 향상하기를 원합니다. 애플리케이션은 여러 AWS 리전의 Amazon EC2 인스턴스에서 호스팅되는 상태 저장 TCP 기반 워크로드와 온프레미스에 보관되는 상태 비저장 UDP 기반 작업으로 구성됩니다.\\n솔루션 설계자는 가용성과 성능을 향상시키기 위해 어떤 활동을 함께 수행해야 합니까? (2개를 선택하세요.)\\n\\nA.AWS Global Accelerator를 사용하여 액셀러레이터를 생성합니다. 로드 밸런서를 엔드포인트로 추가합니다.\\nB. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 요청을 로드 밸런서로 라우팅하는 오리진이 있는 Amazon CloudFront 배포를 생성합니다.\\nC. 각 리전에 두 개의 Application Load Balancer를 구성합니다. 첫 번째는 EC2 엔드포인트로 라우팅되고 두 번째는 온프레미스 엔드포인트로 라우팅됩니다.\\nD. EC2 엔드포인트를 처리하도록 각 리전에서 Network Load Balancer를 구성합니다. 온프레미스 엔드포인트로 라우팅하는 각 리전에서 Network Load Balancer를 구성합니다.\\nE. EC2 엔드포인트를 처리하도록 각 리전에서 Network Load Balancer를 구성합니다. 온프레미스 엔드포인트로 라우팅하는 각 리전에서 Application Load Balancer 구성\", \"A business wishes to enhance the availability and performance of a hybrid application. The application is composed of a stateful TCP-based workload that is hosted on Amazon EC2 instances across several AWS Regions, and a stateless UOP-based task that is housed on-premises.\\nWhich activities should a solutions architect do in combination to increase availability and performance? (Select two.)\\n\\nA.Create an accelerator using AWS Global Accelerator. Add the load balancers as endpoints.\\nB. Create an Amazon CloudFront distribution with an origin that uses Amazon Route 53 latency-based routing to route requests to the load balancers.\\nC. Configure two Application Load Balancers in each Region. The first will route to the EC2 endpoints and the second will route to the on-premises endpoints.\\nD. Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure a Network Load Balancer in each Region that routes to the on- premises endpoints.\\nE. Configure a Network Load Balancer in each Region to address the EC2 endpoints. Configure an Application Load Balancer in each Region that routes to the on-premises endpoints\", \"A, D\"],\n[\"한 기업에서 CompanyConfidential Amazon S3 버킷에 대한 액세스 권한이 없어야 하는 새 클라우드 엔지니어를 모집했습니다. 클라우드 엔지니어는 AdminTools라는 S3 버킷에 대한 읽기 및 쓰기 권한이 있어야 합니다.\\n어떤 IAM 정책이 이러한 기준을 충족합니까?\\n\\nA.https://i.imgur.com/HIRGHbUl.png\\nB. https://i.imgur.com/NpJQX4bl.png\\nC. https://i.imgur.com/h3TWewFl.png\\nD. https://i.imgur.com/uqgjZTBl.png\", \"A corporation has recruited a new cloud engineer who should not have access to the CompanyConfidential Amazon S3 bucket. The cloud engineer must have read and write permissions on an S3 bucket named AdminTools.\\nWhich IAM policy will satisfy these criteria?\", \"A\"],\n[\"한 기업은 AWS Direct Connect 연결을 활용하여 코로케이션 시설에서 us-east-1 리전의 Amazon S3 버킷으로 1페타바이트의 데이터를 전송했습니다. 이제 비즈니스는 us-west-2 리전에 있는 다른 S3 버킷에 데이터를 복제하려고 합니다.\\n어떤 솔루션이 이 기준을 만족할까요?\\n\\nA.AWS Snowball Edge Storage Optimized 디바이스를 사용하여 코로케이션 시설에서 us-west-2로 데이터를 복사합니다.\\nB. S3 콘솔을 사용하여 소스 S3 버킷에서 대상 S3 버킷으로 데이터를 복사합니다.\\nC. S3 Transfer Acceleration 및 S3 copy-object 명령을 사용하여 원본 S3 버킷에서 대상 S3 버킷으로 데이터를 복사합니다.\\nD. S3 교차 리전 복제 구성을 추가하여 소스 S3 버킷에서 대상 S3 버킷으로 데이터를 복사합니다.\", \"A business utilized an AWS Direct Connect connection to transfer one petabyte of data from a colocation facility to an Amazon S3 bucket in the us-east-1 Region. The business now wishes to replicate the data in another S3 bucket located in the us-west-2 Region.\\nWhich solution will satisfy this criterion?\\n\\nA.Use an AWS Snowball Edge Storage Optimized device to copy the data from the colocation facility to us-west-2.\\nB. Use the S3 console to copy the data from the source S3 bucket to the target S3 bucket.\\nC. Use S3 Transfer Acceleration and the S3 copy-object command to copy the data from the source S3 bucket to the target S3 bucket.\\nD. Add an S3 Cross-Region Replication configuration to copy the data from the source S3 bucket to the target S3 bucket.\", \"D\"],\n[\"기업은 AWS를 사용하여 소비자 디바이스에서 센서 데이터를 수집하는 3계층 환경을 호스팅합니다. 트래픽은 NLB(Network Load Balancer)를 통해 라우팅된 다음 웹 계층의 경우 Amazon EC2 인스턴스로 라우팅된 다음 데이터베이스 호출을 수행하는 애플리케이션 계층의 경우 Amazon EC2 인스턴스로 라우팅됩니다.\\n데이터 보안을 웹 계층으로 전송할 때 솔루션 설계자는 무엇을 해야 합니까?\\n\\nA.TLS 수신기를 구성하고 NLB에 서버 인증서를 추가합니다.\\nB. AWS Shield Advanced를 구성하고 NLB에서 AWS WAF를 활성화합니다.\\nC. 로드 밸런서를 Application Load Balancer로 변경하고 여기에 AWS WAF를 연결합니다.\\nD. AWS Key Management Service(AWS KMS)를 사용하여 EC2 인스턴스에서 Amazon Elastic Block Store(Amazon EBS) 볼륨을 암호화합니다.\", \"A business uses AWS to host a three-tier environment that collects sensor data from its consumers' devices. The traffic is routed via a Network Load Balancer (NLB), then to Amazon EC2 instances for the web tier and then to Amazon EC2 instances for the application layer that conducts database calls.\\nWhat should a solutions architect do to enhance data security when it is being sent to the web tier?\\n\\nA.Configure a TLS listener and add the server certificate on the NLB.\\nB. Configure AWS Shield Advanced and enable AWS WAF on the NLB.\\nC. Change the load balancer to an Application Load Balancer and attach AWS WAF to it.\\nD. Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances using AWS Key Management Service (AWS KMS).\", \"A\"],\n[\"기업은 Windows Server 2016을 실행하는 Amazon EC2 인스턴스에서 호스팅되는 Microsoft SQL Server 데이터베이스 및 .NET 애플리케이션 서버용 공유 파일 시스템을 구현하려고 합니다. 솔루션은 기업 Active Directory 도메인과 상호 작용하고 내구성이 뛰어나고 다음에서 관리해야 합니다. AWS와 높은 수준의 처리량 및 IOPS를 제공합니다.\\n어떤 솔루션이 이러한 기준을 충족합니까?\\n\\nA.Windows 파일 서버용 Amazon FSx를 사용하십시오.\\nB. Amazon Elastic File System(Amazon EFS)을 사용합니다.\\nC. 파일 게이트웨이 모드에서 AWS Storage Gateway를 사용합니다.\\nD. 2개의 가용 영역에 걸쳐 2개의 온디맨드 인스턴스에 Windows 파일 서버를 배포합니다.\", \"A business wishes to implement a shared file system for its.NET application servers and Microsoft SQL Server databases that are hosted on Amazon EC2 instances running Windows Server 2016. The solution must interact with the corporate Active Directory domain, be very durable, be managed by AWS, and provide high levels of throughput and IOPS.\\nWhich solution satisfies these criteria?\\n\\nA.Use Amazon FSx for Windows File Server.\\nB. Use Amazon Elastic File System (Amazon EFS).\\nC. Use AWS Storage Gateway in file gateway mode.\\nD. Deploy a Windows file server on two On Demand instances across two Availability Zones.\", \"A\"]]\n","import { useQuery } from 'react-query';\nimport axios from 'axios';\nimport { data as d } from '../datas/data';\nimport { mapQueryStatusFilter } from 'react-query/types/core/utils';\n\nconst data = d;\nconst getNumbers = () => {\n    return data.map((e, i) => i+1);\n}\n\nexport const usePages = () => getNumbers();\n// const getNumbers = async () => {\n//     const { data } = await axios.get('http://jaechan.com:3000/problems');\n//     return data;\n// }\n\n// export const usePages = () => {\n//     return useQuery('page', () => getNumbers(),{enabled:true});\n// }","import axios from \"axios\"\nimport { useQuery } from \"react-query\";\n\nimport { data as d } from '../datas/data';\n\nconst data = d;\nconst getProblem = (id:number) => data[id-1];\n\nexport const useProblem = (id: number) => getProblem(id);\n\n// const getProblem = async (id: number) => {\n//     const { data } = await axios.get(`http://jaechan.com:3000/problems/${id-1}`);\n//     return data;\n// }\n\n\n// export const useProblem = (id:number) => {\n//     return useQuery(['problem', id], () => getProblem(id), {enabled:true})\n// }","import axios from 'axios';\nimport React, { useCallback, useEffect, useState } from 'react';\nimport { Link } from 'react-router-dom';\nimport { useParams } from 'react-router-dom';\nimport { usePages } from '../hooks/usePage';\nimport { useProblem } from '../hooks/useProblem';\nimport './Problem.css';\nimport { data } from '../datas/data';\nfunction Problems() {\n    const { id } = useParams();\n    const page = usePages();\n    \n    const data = useProblem(Number(id));\n    const [answer, setAnswer] = useState<boolean>();\n    const [language, setLanguage] = useState<boolean>(true);\n    console.log(page, data,)\n\n    const changeLanguage = useCallback(() => setLanguage(!language),[language]);\n    const showAnswerView = useCallback(() => setAnswer(!answer), [answer]);\n    useEffect(() => {\n        setAnswer(false);\n        setLanguage(true);\n    },[id]);\n    return (\n        <div className=\"Problem\">\n            <div className=\"Contents\">\n                <div className=\"Title\">\n                    <Link to=\"/\" style={{display:'block'}} >홈</Link>\n                    <div style={{flex:1, textAlign:'center'}}>\n                        { `문제${id}` }\n                    </div>\n                    <div onClick={() => changeLanguage()}>원문보기</div>\n\n                </div>\n                <div className='Body'>\n                    {\n                        language ? data[0].split('\\n').map((line: any) => {\n                            return (<div style={{marginBottom:'10px'}}>{line}<br/></div>)\n                        }) :  data[1].split('\\n').map( (line:any) => {\n                            return (<div style={{marginBottom:'10px'}}>{line}<br/></div>)\n                        })\n                    }\n                </div>\n                <br />\n                <br />\n                {\n                    answer && <div>{data[2]}</div>\n                }\n                \n                \n            </div>\n            <div className='Bottom' style={{ display: 'flex'}}>\n                        {\n                             ( Number(id) > 0) && <Link style={{display:'block', padding:'10px' ,flex: 1,textAlign:'center' ,background:'orange'}}to={`/problems/${Number(id) - 1}`} >prev</Link>\n                        }\n                    <div onClick={() => showAnswerView() }style={{flex:1,textAlign:'center'}}>정답보기</div>\n                        {\n                            page.length-1 !== (Number(id) ) && <Link style={{ flex: 1,textAlign:'center' ,background:'orange',display:'block', padding:'10px'}}to={`/problems/${Number(id) +1}`} >next</Link>\n                        }\n                </div>\n        </div>\n    );\n}\n\nexport default Problems;","import axios from \"axios\";\nimport { useQuery } from \"react-query\";\nimport { Link } from \"react-router-dom\";\nimport { usePages } from \"../hooks/usePage\";\nimport \"./Main.css\"\nimport { data as d } from '../datas/data';\nconst data = d;\n\nfunction MainPage() {\n    return (<div>\n        {\n            data.map((e,i) => {\n                return <Link to={`/problems/${i+1}`} className=\"Link\">{i+1}</Link>\n            })\n        }\n    </div>)\n    \n}\n\nexport default MainPage;","import React from 'react';\nimport logo from './logo.svg';\nimport './App.css';\nimport { Route, Routes } from 'react-router-dom';\nimport Problems from './pages/Problem';\nimport { QueryClient, QueryClientProvider } from 'react-query';\nimport MainPage from './pages/Main';\n\n\nfunction App() {\n  return (\n    <Routes>\n      <Route path='/' element={<MainPage />} />\n      <Route path='/problems' element={<MainPage />} />\n      <Route path='/problems/:id' element={<Problems/>} />\n    </Routes>\n  );\n}\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\nimport { BrowserRouter } from 'react-router-dom';\nimport { QueryClient, QueryClientProvider } from 'react-query';\n\nconst root = ReactDOM.createRoot(\n  document.getElementById('root') as HTMLElement\n);\n\nconst queryClient = new QueryClient();\n\nroot.render(\n  <React.StrictMode>\n    <QueryClientProvider client={queryClient}>\n      <BrowserRouter basename={process.env.PUBLIC_URL}>\n        <App />\n      </BrowserRouter>\n    </QueryClientProvider>\n  </React.StrictMode>\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"names":["aa","require","ca","p","a","b","c","arguments","length","encodeURIComponent","da","Set","ea","fa","ha","add","ia","window","document","createElement","ja","Object","prototype","hasOwnProperty","ka","la","ma","v","d","e","f","g","this","acceptsBooleans","attributeName","attributeNamespace","mustUseProperty","propertyName","type","sanitizeURL","removeEmptyString","z","split","forEach","toLowerCase","ra","sa","toUpperCase","ta","slice","pa","isNaN","qa","call","test","oa","removeAttribute","setAttribute","setAttributeNS","replace","xlinkHref","ua","__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED","va","Symbol","for","wa","ya","za","Aa","Ba","Ca","Da","Ea","Fa","Ga","Ha","Ia","Ja","iterator","Ka","La","A","assign","Ma","Error","stack","trim","match","Na","Oa","prepareStackTrace","defineProperty","set","Reflect","construct","l","h","k","displayName","includes","name","Pa","tag","render","Qa","$$typeof","_context","_payload","_init","Ra","Sa","Ta","nodeName","Va","_valueTracker","getOwnPropertyDescriptor","constructor","get","configurable","enumerable","getValue","setValue","stopTracking","Ua","Wa","checked","value","Xa","activeElement","body","Ya","defaultChecked","defaultValue","_wrapperState","initialChecked","Za","initialValue","controlled","ab","bb","cb","db","ownerDocument","eb","Array","isArray","fb","options","selected","defaultSelected","disabled","gb","dangerouslySetInnerHTML","children","hb","ib","jb","textContent","kb","lb","mb","nb","namespaceURI","innerHTML","valueOf","toString","firstChild","removeChild","appendChild","MSApp","execUnsafeLocalFunction","ob","lastChild","nodeType","nodeValue","pb","animationIterationCount","aspectRatio","borderImageOutset","borderImageSlice","borderImageWidth","boxFlex","boxFlexGroup","boxOrdinalGroup","columnCount","columns","flex","flexGrow","flexPositive","flexShrink","flexNegative","flexOrder","gridArea","gridRow","gridRowEnd","gridRowSpan","gridRowStart","gridColumn","gridColumnEnd","gridColumnSpan","gridColumnStart","fontWeight","lineClamp","lineHeight","opacity","order","orphans","tabSize","widows","zIndex","zoom","fillOpacity","floodOpacity","stopOpacity","strokeDasharray","strokeDashoffset","strokeMiterlimit","strokeOpacity","strokeWidth","qb","rb","sb","style","indexOf","setProperty","keys","charAt","substring","tb","menuitem","area","base","br","col","embed","hr","img","input","keygen","link","meta","param","source","track","wbr","ub","vb","is","wb","xb","target","srcElement","correspondingUseElement","parentNode","yb","zb","Ab","Bb","Cb","stateNode","Db","Eb","push","Fb","Gb","Hb","Ib","Jb","Kb","Lb","Mb","addEventListener","removeEventListener","Nb","apply","m","onError","Ob","Pb","Qb","Rb","Sb","Tb","Vb","alternate","return","flags","Wb","memoizedState","dehydrated","Xb","Zb","child","sibling","current","Yb","$b","ac","unstable_scheduleCallback","bc","unstable_cancelCallback","cc","unstable_shouldYield","dc","unstable_requestPaint","B","unstable_now","ec","unstable_getCurrentPriorityLevel","fc","unstable_ImmediatePriority","gc","unstable_UserBlockingPriority","hc","unstable_NormalPriority","ic","unstable_LowPriority","jc","unstable_IdlePriority","kc","lc","oc","Math","clz32","pc","qc","log","LN2","rc","sc","tc","uc","pendingLanes","suspendedLanes","pingedLanes","entangledLanes","entanglements","vc","xc","yc","zc","Ac","eventTimes","Cc","C","Dc","Ec","Fc","Gc","Hc","Ic","Jc","Kc","Lc","Mc","Nc","Oc","Map","Pc","Qc","Rc","Sc","delete","pointerId","Tc","nativeEvent","blockedOn","domEventName","eventSystemFlags","targetContainers","Vc","Wc","priority","isDehydrated","containerInfo","Xc","Yc","dispatchEvent","shift","Zc","$c","ad","bd","cd","ReactCurrentBatchConfig","dd","ed","transition","fd","gd","hd","id","Uc","stopPropagation","jd","kd","ld","md","nd","od","keyCode","charCode","pd","qd","rd","_reactName","_targetInst","currentTarget","isDefaultPrevented","defaultPrevented","returnValue","isPropagationStopped","preventDefault","cancelBubble","persist","isPersistent","wd","xd","yd","sd","eventPhase","bubbles","cancelable","timeStamp","Date","now","isTrusted","td","ud","view","detail","vd","Ad","screenX","screenY","clientX","clientY","pageX","pageY","ctrlKey","shiftKey","altKey","metaKey","getModifierState","zd","button","buttons","relatedTarget","fromElement","toElement","movementX","movementY","Bd","Dd","dataTransfer","Fd","Hd","animationName","elapsedTime","pseudoElement","Id","clipboardData","Jd","Ld","data","Md","Esc","Spacebar","Left","Up","Right","Down","Del","Win","Menu","Apps","Scroll","MozPrintableKey","Nd","Od","Alt","Control","Meta","Shift","Pd","Qd","key","String","fromCharCode","code","location","repeat","locale","which","Rd","Td","width","height","pressure","tangentialPressure","tiltX","tiltY","twist","pointerType","isPrimary","Vd","touches","targetTouches","changedTouches","Xd","Yd","deltaX","wheelDeltaX","deltaY","wheelDeltaY","wheelDelta","deltaZ","deltaMode","Zd","$d","ae","be","documentMode","ce","de","ee","fe","ge","he","ie","le","color","date","datetime","email","month","number","password","range","search","tel","text","time","url","week","me","ne","oe","event","listeners","pe","qe","re","se","te","ue","ve","we","xe","ye","ze","oninput","Ae","detachEvent","Be","Ce","attachEvent","De","Ee","Fe","He","Ie","Je","Ke","node","offset","nextSibling","Le","contains","compareDocumentPosition","Me","HTMLIFrameElement","contentWindow","href","Ne","contentEditable","Oe","focusedElem","selectionRange","documentElement","start","end","selectionStart","selectionEnd","min","defaultView","getSelection","extend","rangeCount","anchorNode","anchorOffset","focusNode","focusOffset","createRange","setStart","removeAllRanges","addRange","setEnd","element","left","scrollLeft","top","scrollTop","focus","Pe","Qe","Re","Se","Te","Ue","Ve","We","animationend","animationiteration","animationstart","transitionend","Xe","Ye","Ze","animation","$e","af","bf","cf","df","ef","ff","gf","hf","lf","mf","concat","nf","Ub","instance","listener","D","of","has","pf","qf","rf","random","sf","bind","capture","passive","n","t","J","x","u","w","F","tf","uf","parentWindow","vf","wf","na","xa","$a","ba","je","char","ke","unshift","xf","yf","zf","Af","Bf","Cf","Df","Ef","__html","Ff","setTimeout","Gf","clearTimeout","Hf","Promise","Jf","queueMicrotask","resolve","then","catch","If","Kf","Lf","Mf","previousSibling","Nf","Of","Pf","Qf","Rf","Sf","Tf","Uf","E","G","Vf","H","Wf","Xf","Yf","contextTypes","__reactInternalMemoizedUnmaskedChildContext","__reactInternalMemoizedMaskedChildContext","Zf","childContextTypes","$f","ag","bg","getChildContext","cg","__reactInternalMemoizedMergedChildContext","dg","eg","fg","gg","hg","jg","kg","lg","mg","ng","og","pg","qg","rg","sg","tg","ug","vg","wg","xg","yg","I","zg","Ag","Bg","elementType","deletions","Cg","pendingProps","overflow","treeContext","retryLane","Dg","mode","Eg","Fg","Gg","memoizedProps","Hg","Ig","Jg","Kg","Lg","defaultProps","Mg","Ng","Og","Pg","Qg","Rg","_currentValue","Sg","childLanes","Tg","dependencies","firstContext","lanes","Ug","Vg","context","memoizedValue","next","Wg","Xg","Yg","interleaved","Zg","$g","ah","updateQueue","baseState","firstBaseUpdate","lastBaseUpdate","shared","pending","effects","bh","ch","eventTime","lane","payload","callback","dh","K","eh","fh","gh","q","r","y","hh","ih","jh","Component","refs","kh","nh","isMounted","_reactInternals","enqueueSetState","L","lh","mh","enqueueReplaceState","enqueueForceUpdate","oh","shouldComponentUpdate","isPureReactComponent","ph","contextType","state","updater","qh","componentWillReceiveProps","UNSAFE_componentWillReceiveProps","rh","props","getDerivedStateFromProps","getSnapshotBeforeUpdate","UNSAFE_componentWillMount","componentWillMount","componentDidMount","sh","ref","_owner","_stringRef","th","join","uh","vh","index","wh","xh","yh","implementation","zh","Ah","done","Bh","Ch","Dh","Eh","Fh","Gh","Hh","Ih","tagName","Jh","Kh","Lh","M","Mh","revealOrder","Nh","Oh","_workInProgressVersionPrimary","Ph","ReactCurrentDispatcher","Qh","Rh","N","O","P","Sh","Th","Uh","Vh","Q","Wh","Xh","Yh","Zh","$h","ai","bi","ci","baseQueue","queue","di","ei","fi","lastRenderedReducer","action","hasEagerState","eagerState","lastRenderedState","dispatch","gi","hi","ii","ji","ki","getSnapshot","li","mi","R","ni","lastEffect","stores","oi","pi","qi","ri","create","destroy","deps","si","ti","ui","vi","wi","xi","yi","zi","Ai","Bi","Ci","Di","Ei","Fi","Gi","Hi","Ii","Ji","readContext","useCallback","useContext","useEffect","useImperativeHandle","useInsertionEffect","useLayoutEffect","useMemo","useReducer","useRef","useState","useDebugValue","useDeferredValue","useTransition","useMutableSource","useSyncExternalStore","useId","unstable_isNewReconciler","identifierPrefix","Ki","message","digest","Li","Mi","console","error","Ni","WeakMap","Oi","Pi","Qi","Ri","getDerivedStateFromError","componentDidCatch","Si","componentStack","Ti","pingCache","Ui","Vi","Wi","Xi","ReactCurrentOwner","Yi","Zi","$i","aj","bj","compare","cj","dj","ej","baseLanes","cachePool","transitions","fj","gj","hj","ij","jj","UNSAFE_componentWillUpdate","componentWillUpdate","componentDidUpdate","kj","lj","pendingContext","mj","Aj","Cj","Dj","nj","oj","pj","fallback","qj","rj","tj","dataset","dgst","uj","vj","_reactRetry","sj","subtreeFlags","wj","xj","isBackwards","rendering","renderingStartTime","last","tail","tailMode","yj","Ej","S","Fj","Gj","wasMultiple","multiple","suppressHydrationWarning","onClick","onclick","size","createElementNS","autoFocus","createTextNode","T","Hj","Ij","Jj","Kj","U","Lj","WeakSet","V","Mj","W","Nj","Oj","Qj","Rj","Sj","Tj","Uj","Vj","Wj","insertBefore","_reactRootContainer","Xj","X","Yj","Zj","ak","onCommitFiberUnmount","componentWillUnmount","bk","ck","dk","ek","fk","isHidden","gk","hk","display","ik","jk","kk","lk","__reactInternalSnapshotBeforeUpdate","src","Wk","mk","ceil","nk","ok","pk","Y","Z","qk","rk","sk","tk","uk","Infinity","vk","wk","xk","yk","zk","Ak","Bk","Ck","Dk","Ek","callbackNode","expirationTimes","expiredLanes","wc","callbackPriority","ig","Fk","Gk","Hk","Ik","Jk","Kk","Lk","Mk","Nk","Ok","Pk","finishedWork","finishedLanes","Qk","timeoutHandle","Rk","Sk","Tk","Uk","Vk","mutableReadLanes","Bc","Pj","onCommitFiberRoot","mc","onRecoverableError","Xk","onPostCommitFiberRoot","Yk","Zk","al","isReactComponent","pendingChildren","bl","mutableSourceEagerHydrationData","cl","cache","pendingSuspenseBoundaries","dl","el","fl","gl","hl","il","jl","zj","$k","ll","reportError","ml","_internalRoot","nl","ol","pl","ql","sl","rl","unmount","unstable_scheduleHydration","splice","querySelectorAll","JSON","stringify","form","tl","usingClientEntryPoint","Events","ul","findFiberByHostInstance","bundleType","version","rendererPackageName","vl","rendererConfig","overrideHookState","overrideHookStateDeletePath","overrideHookStateRenamePath","overrideProps","overridePropsDeletePath","overridePropsRenamePath","setErrorHandler","setSuspenseHandler","scheduleUpdate","currentDispatcherRef","findHostInstanceByFiber","findHostInstancesForRefresh","scheduleRefresh","scheduleRoot","setRefreshHandler","getCurrentFiber","reconcilerVersion","__REACT_DEVTOOLS_GLOBAL_HOOK__","wl","isDisabled","supportsFiber","inject","exports","createPortal","createRoot","unstable_strictMode","findDOMNode","flushSync","hydrate","hydrateRoot","hydratedSources","_getVersion","_source","unmountComponentAtNode","unstable_batchedUpdates","unstable_renderSubtreeIntoContainer","checkDCE","err","module","logger","getLogger","setLogger","newLogger","NotifyManager","transactions","notifyFn","batchNotifyFn","_proto","batch","result","flush","schedule","_this","scheduleMicrotask","batchCalls","_this2","_len","args","_key","_this3","setNotifyFunction","fn","setBatchNotifyFunction","notifyManager","_setPrototypeOf","o","setPrototypeOf","__proto__","_inheritsLoose","subClass","superClass","Subscribable","subscribe","onSubscribe","filter","onUnsubscribe","hasListeners","focusManager","_Subscribable","FocusManager","setup","onFocus","_window","isServer","cleanup","setEventListener","_this$cleanup","undefined","_this$cleanup2","focused","setFocused","isFocused","visibilityState","onlineManager","OnlineManager","onOnline","online","setOnline","isOnline","navigator","onLine","defaultRetryDelay","failureCount","pow","isCancelable","cancel","CancelledError","revert","silent","isCancelledError","Retryer","config","cancelFn","continueFn","promiseResolve","promiseReject","cancelRetry","abort","cancelOptions","continueRetry","continue","isPaused","isResolved","isTransportCancelable","promise","outerResolve","outerReject","onSuccess","reject","run","promiseOrValue","_unused","_config$retry","_config$retryDelay","retry","retryDelay","delay","shouldRetry","onFail","sleep","continueResolve","onPause","onContinue","Query","abortSignalConsumed","hadObservers","defaultOptions","setOptions","observers","queryKey","queryHash","initialState","getDefaultState","scheduleGc","_this$options$cacheTi","_extends","cacheTime","max","setDefaultOptions","clearGcTimeout","isValidTimeout","gcTimeout","optionalRemove","isFetching","remove","setData","_this$options$isDataE","_this$options","prevData","functionalUpdate","isDataEqual","structuralSharing","replaceEqualDeep","dataUpdatedAt","updatedAt","setState","setStateOptions","_this$retryer","retryer","noop","reset","isActive","some","observer","enabled","isStale","isInvalidated","getCurrentResult","isStaleByTime","staleTime","timeUntilStale","_this$retryer2","find","shouldFetchOnWindowFocus","refetch","_this$retryer3","shouldFetchOnReconnect","addObserver","notify","query","removeObserver","getObserversCount","invalidate","fetch","fetchOptions","_this$options$behavio","_context$fetchOptions","_abortController$abor","cancelRefetch","_this$retryer4","queryFn","ensureQueryKeyArray","abortController","getAbortController","queryFnContext","pageParam","signal","_this$options$behavio2","_context$fetchOptions2","fetchFn","behavior","onFetch","revertState","fetchMeta","reducer","onQueryUpdate","initialData","initialDataUpdatedAt","hasData","dataUpdateCount","errorUpdateCount","errorUpdatedAt","fetchFailureCount","status","_action$meta","_action$dataUpdatedAt","QueryCache","queries","queriesMap","build","client","_options$queryHash","hashQueryKeyByOptions","defaultQueryOptions","getQueryDefaults","queryInMap","clear","getAll","arg1","arg2","filters","parseFilterArgs","exact","matchQuery","findAll","_this4","_this5","Mutation","mutationId","mutationCache","variables","execute","restored","onMutate","executeMutation","onSettled","_this$options$retry","mutationFn","onMutationUpdate","MutationCache","mutations","mutation","defaultMutationOptions","mutationKey","getMutationDefaults","matchMutation","resumePausedMutations","pausedMutations","reduce","getNextPageParam","pages","getPreviousPageParam","QueryClient","queryCache","queryDefaults","mutationDefaults","mount","unsubscribeFocus","unsubscribeOnline","_this$unsubscribeFocu","_this$unsubscribeOnli","fetching","isMutating","getQueryData","_this$queryCache$find","getQueriesData","queryKeyOrFilters","getQueryCache","map","_ref","setQueryData","parsedOptions","parseQueryArgs","defaultedOptions","setQueriesData","_ref2","getQueryState","_this$queryCache$find2","removeQueries","resetQueries","arg3","_parseFilterArgs3","refetchFilters","active","refetchQueries","cancelQueries","_parseFilterArgs4","_parseFilterArgs4$","promises","all","invalidateQueries","_ref3","_filters$refetchActiv","_filters$refetchInact","_parseFilterArgs5","refetchActive","inactive","refetchInactive","_this6","_parseFilterArgs6","refetchPage","throwOnError","fetchQuery","prefetchQuery","fetchInfiniteQuery","_context$fetchOptions3","_context$fetchOptions4","_context$state$data","_context$state$data2","fetchMore","isFetchingNextPage","direction","isFetchingPreviousPage","oldPages","oldPageParams","pageParams","abortSignal","newPageParams","cancelled","buildNewPages","page","previous","fetchPage","manual","queryFnResult","_manual","_param","shouldFetchFirstPage","_loop","i","_param2","finalPromise","prefetchInfiniteQuery","cancelMutations","_this7","getMutationCache","getDefaultOptions","setQueryDefaults","hashQueryKey","_this$queryDefaults$f","partialMatchKey","setMutationDefaults","_this$mutationDefault","_defaulted","defaultQueryObserverOptions","isQueryKey","predicate","stale","queryStatusFilter","mapQueryStatusFilter","queryKeyHashFn","asArray","_","val","isPlainObject","sort","partialDeepEqual","array","aSize","bItems","bSize","copy","equalItems","hasObjectPrototype","ctor","prot","timeout","AbortController","ReactDOM","defaultContext","React","QueryClientSharingContext","getQueryClientContext","contextSharing","ReactQueryClientContext","QueryClientProvider","_ref$contextSharing","Context","Provider","__self","__source","jsx","jsxs","forceUpdate","escape","_status","_result","default","Children","count","toArray","only","Fragment","Profiler","PureComponent","StrictMode","Suspense","cloneElement","createContext","_currentValue2","_threadCount","Consumer","_defaultValue","_globalName","createFactory","createRef","forwardRef","isValidElement","lazy","memo","startTransition","unstable_act","pop","sortIndex","performance","setImmediate","startTime","expirationTime","priorityLevel","scheduling","isInputPending","MessageChannel","port2","port1","onmessage","postMessage","unstable_Profiling","unstable_continueExecution","unstable_forceFrameRate","floor","unstable_getFirstCallbackNode","unstable_next","unstable_pauseExecution","unstable_runWithPriority","unstable_wrapCallback","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","__webpack_modules__","getter","__esModule","definition","chunkId","miniCssF","obj","prop","inProgress","dataWebpackPrefix","script","needAttach","scripts","getElementsByTagName","s","getAttribute","charset","nc","onScriptComplete","prev","onerror","onload","doneFns","head","toStringTag","installedChunks","j","installedChunkData","errorType","realSrc","request","webpackJsonpCallback","parentChunkLoadingFunction","chunkIds","moreModules","runtime","chunkLoadingGlobal","self","_arrayLikeToArray","arr","len","arr2","_i","_s","_e","_arr","_n","_d","minLen","from","TypeError","NavigationContext","LocationContext","RouteContext","outlet","matches","invariant","cond","matchRoutes","routes","locationArg","basename","pathname","stripBasename","parsePath","branches","flattenRoutes","score","siblings","every","compareIndexes","routesMeta","childrenIndex","rankRouteBranches","matchRouteBranch","parentsMeta","parentPath","route","relativePath","path","caseSensitive","startsWith","joinPaths","computeScore","paramRe","isSplat","segments","initialScore","segment","branch","matchedParams","matchedPathname","remainingPathname","matchPath","params","pathnameBase","normalizePathname","pattern","paramNames","regexpSource","paramName","endsWith","RegExp","compilePath","matcher","captureGroups","splatValue","decodeURIComponent","safelyDecodeURIComponent","resolveTo","toArg","routePathnames","locationPathname","to","toPathname","routePathnameIndex","toSegments","fromPathname","hash","resolvePathname","normalizeSearch","normalizeHash","resolvePath","nextChar","paths","useHref","useInRouterContext","useResolvedPath","joinedPathname","getToPathname","endsWithSlash","createHref","useLocation","useNavigate","routePathnamesJson","activeRef","parse","go","_renderMatches","parentMatches","reduceRight","React.createElement","Route","_props","Router","basenameProp","locationProp","navigationType","NavigationType","static","staticProp","navigationContext","trailingPathname","Routes","_ref4","routeMatch","parentParams","parentPathnameBase","locationFromContext","parsedLocationArg","_parsedLocationArg$pa","useRoutes","createRoutesFromChildren","BrowserRouter","historyRef","createBrowserHistory","history","listen","Link","reloadDocument","rest","internalOnClick","replaceProp","navigate","isModifiedEvent","createPath","useLinkClickHandler","usePages","useProblem","getProblem","useParams","Number","answer","setAnswer","language","setLanguage","changeLanguage","showAnswerView","className","textAlign","line","marginBottom","padding","background","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","root","getElementById","queryClient","process","reportWebVitals"],"sourceRoot":""}